{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTesting things for the neuron visualization \\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing things for the neuron visualization \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directional Graphing in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-697f55cb7380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnode_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnode_colors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnode_colors_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_color_edge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "node_locations = np.array([current_locations[current_n] for current_n in current_graph.nodes])\n",
    "\n",
    "node_colors = np.array([current_color[current_n] for current_n in current_graph.nodes])\n",
    "node_colors_edge = np.array([current_color_edge[current_n] for current_n in current_graph.edges])\n",
    "\n",
    "node_edges = np.array(list(current_graph.edges))\n",
    "\n",
    "#print(\"node_locations = \" + str(node_locations))\n",
    "#print(\"current_graph.edges = \" + str(current_graph.edges))\n",
    "node_colors = np.array([current_color[current_n] for current_n in current_graph.nodes])\n",
    "node_colors_edge = np.array([current_color_edge[current_n] for current_n in current_graph.edges])\n",
    "\n",
    "#print(\"current_color_edge = \" + str(repr(current_color_edge)))\n",
    "\n",
    "node_edges = np.array(list(current_graph.edges))\n",
    "\n",
    "#getting the midpoints then the directions of arrows for the quiver\n",
    "midpoints = []\n",
    "directions = []\n",
    "for n1,n2 in current_graph.edges:\n",
    "    difference = node_locations[n1] - node_locations[n2]\n",
    "    directions.append(difference)\n",
    "    midpoints.append(node_locations[n2] + difference/2)\n",
    "directions = np.array(directions)\n",
    "midpoints = np.array(midpoints)\n",
    "    \n",
    "\n",
    "current_midpoints = midpoints[color_indices]\n",
    "current_directions = directions[color_indices]\n",
    "ipv.pylab.quiver(current_midpoints[:,0],current_midpoints[:,1],current_midpoints[:,2],\n",
    "current_directions[:,0],current_directions[:,1],current_directions[:,2],\n",
    "size=2,\n",
    "size_selected=20,\n",
    "color = n)\n",
    "\n",
    "#graphing the nodes\n",
    "nodes_mesh = ipv.pylab.scatter(node_locations[:,0], \n",
    "                                node_locations[:,1], \n",
    "                                node_locations[:,2],\n",
    "                                color=node_colors,\n",
    "                                size = 2,\n",
    "\n",
    "                                marker = \"sphere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring How to Do the Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring how to output entire skeleton of neuron (with stitching to soma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"../../meshAfterParty/meshAfterParty/\")\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_utils as pu\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Loading in the Neuron --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dc487bec494cb79dfc44904db46d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bb129ba1a5489d95e0ac71467c2198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736ab3ed2621470482d48c44079d747f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755c7ae1ad7440398a91b317871156db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7225db1607854578ad7ab56d3a9dbbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295b5c3d41564229826a1251666c5166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1397aa49f24ee4b3472e576d97d3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af302cc1eea049bd8691d7ef65f7c453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d779ee08a11d4648874c77be5a802977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca4198a3dd24288885587bee384133c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477fd7fed4fb485eb5ebb06f93f0c555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<neuron.Neuron at 0x7f146bf5a8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_neuron_path = Path(\"../test_neurons/test_objects/12345_2_soma_practice_decompress\")\n",
    "\n",
    "import neuron_utils as nru\n",
    "nru = reload(nru)\n",
    "import neuron\n",
    "neuron=reload(neuron)\n",
    "\n",
    "import system_utils as su\n",
    "\n",
    "with su.suppress_stdout_stderr():\n",
    "    recovered_neuron = nru.decompress_neuron(filepath=compressed_neuron_path,\n",
    "                      original_mesh=compressed_neuron_path)\n",
    "\n",
    "recovered_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skeleton_utils as sk\n",
    "import networkx_utils as xu\n",
    "recov_skeleton = recovered_neuron.get_skeleton()\n",
    "\n",
    "sk.graph_skeleton_and_mesh(other_meshes=[recovered_neuron.mesh],\n",
    "                          other_skeletons = [recov_skeleton])\n",
    "\n",
    "neuron = reload(neuron)\n",
    "recovered_neuron = neuron.Neuron(recovered_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the starting direction of concept networks for a limb in the neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx_utils as xu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb_obj = recovered_neuron.concept_network.nodes[\"L1\"][\"data\"]\n",
    "print(xu.get_starting_node(curr_limb_obj.concept_network_directional))\n",
    "print(curr_limb_obj.current_starting_coordinate)\n",
    "print(curr_limb_obj.current_starting_node)\n",
    "print(curr_limb_obj.current_starting_endpoints)\n",
    "print(curr_limb_obj.current_starting_soma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_visualizations as nviz\n",
    "nviz.plot_concept_network(curr_limb_obj.concept_network_directional,\n",
    "                         arrow_size=5,\n",
    "                         scatter_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = reload(neuron)\n",
    "recovered_neuron = neuron.Neuron(recovered_neuron)\n",
    "curr_limb_obj = recovered_neuron.concept_network.nodes[\"L1\"][\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb_obj.set_concept_network_directional(starting_soma=1,print_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xu.get_starting_node(curr_limb_obj.concept_network_directional))\n",
    "print(curr_limb_obj.current_starting_coordinate)\n",
    "print(curr_limb_obj.current_starting_node)\n",
    "print(curr_limb_obj.current_starting_endpoints)\n",
    "print(curr_limb_obj.current_starting_soma)\n",
    "\n",
    "import neuron_visualizations as nviz\n",
    "nviz.plot_concept_network(curr_limb_obj.concept_network_directional,\n",
    "                         arrow_size=5,\n",
    "                         scatter_size=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Visualization Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudocode for larger visualizaiton package\n",
    "\n",
    "---------------  Arguments: -------------------\n",
    "- visual_type: list containing 1 to all of the following [\"mesh\",skeleton,concept network]\n",
    "    describes what category of visual to make\n",
    "\n",
    "- For each visual_type:\n",
    "\n",
    "\n",
    "General: That will be applied to all the visual types selected (unless overrided) \n",
    "0: configuration_dict: dictionary with all of these values (so could copy this to all fields)\n",
    "1  Limb_branch_dict #like the kind returned from a query \n",
    "    - Dictionary mapping limb to a list of the branches that want to be visualized (if \"all\" in list then will do all of the branches)\n",
    "    - this could also e specified by hand and not the result of a query\n",
    "a. resolution: \"limb\" or \"branch\" (the level to show), \n",
    "    if a limb with only one branch in limb_branch_dict then will still show the whole branch\n",
    "b. color_grouping: \"limb\" or \"branch\": \n",
    "    whether you want colors differing for different branches (more specific) or just\n",
    "    want different colors for branches\n",
    "c. color: \"random\", list of colors (either rgb or strings), dictionary mapping limb,branch to color (either rgb or string)\n",
    "    tells the plotting how to color the visual\n",
    "    ** if it is limb reolution then if passed dictionary should be a limb to color dictionary\n",
    "d. color_alpha: float,\n",
    "    the level of transparency for the colors\n",
    "    if the item does not have a transparency level yet then assign it this value to end of color\n",
    "e. soma=True or False\n",
    "    whether you want the soma included\n",
    "f. soma_color = string or rgba\n",
    "    what color for soma visualization\n",
    "g. whole_neuron = True/False:\n",
    "    whether you want the entire visual type of the neuron in the visualization as well\n",
    "h. whole_neuron_color: string or rgb/a value for what to color this\n",
    "i: whole_neuron_alpha: float\n",
    "    if the item does not have a transparency level yet then assign it this value to end of color\n",
    "    \n",
    "\n",
    "Each category will have it's own of the above\n",
    "- specific_limb_branch_dict    \n",
    "\n",
    "Specifics for concept_network\n",
    "j: directional: True or False\n",
    "    whether you want the directional or undirection form\n",
    "k: starting_soma: limb --> soma_idx dictionary:\n",
    "    maps the limb to which starting soma to use for directional if directional selected\n",
    "    if not selected then just uses the current one\n",
    "\n",
    "k: starting_node: True/False : whether to graph it\n",
    "l: starting_node_color: str/ rga/a\n",
    "m: starting_node_alpha: float\n",
    "n: starting_node_size: float\n",
    "\n",
    "l: arrow_color: str/ rga/a\n",
    "m: arrow_alpha: float\n",
    "n: arrow_size: float\n",
    "\n",
    "\n",
    "n: node_size: float\n",
    "\n",
    "\n",
    "- finishing arguments: \n",
    "whether to append\n",
    "whether to show figure at end\n",
    "\n",
    "\n",
    "\n",
    "---------------  Process: -------------------\n",
    "For each category chosen: \n",
    "1) Get the resolution: \n",
    "2) Get the list of items specified by the limb_branch_dict (general or specific):\n",
    "------\n",
    "for mesh/skeleton: iterate through and get the branches/limb mesh/skeleton\n",
    "for concept_network: get the network, get the subgraph specified by the branches (if limb resolution then just keep whole network)\n",
    "-----\n",
    "3) if dictionary for colors not pased:\n",
    "- build it using all of the color specifications in arguments\n",
    "----\n",
    "for concept_network: color only applies to node\n",
    "----\n",
    "4) If soma is requested then get the soma item, add it to the list to graph\n",
    "---\n",
    "concept network this will be a little more involved where will have to convert it to fully connected graph\n",
    "---\n",
    "5) Graph the specific thing using the items in list and the colors\n",
    "-----\n",
    "concept network will involve graphing the arrows and starting node\n",
    "----\n",
    "6) Graph the whole_neuron if requested\n",
    "\n",
    "- chain together the graphs if still aren't on the last context\n",
    "\n",
    "Go to the next category\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_resolution = branch\n",
      "mesh_color = red\n",
      "\n",
      " Working on visualization type: mesh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7def9fc1fd4c433e9178d7125f17afe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import neuron_visualizations as nviz\n",
    "\n",
    "limb_branch_dict = {\"L0\":[1,3,4,6],\n",
    "                   \"L1\":[0,1,3,4,6]}\n",
    "\n",
    "color_dict_skeleton = dict()\n",
    "color_dict_skeleton[\"L0\"] = {1:\"red\",2:\"pink\"}\n",
    "color_dict_skeleton[\"L1\"] = {37:\"red\",12:\"pink\"}\n",
    "color_dict_skeleton[\"L2\"] = {5:\"red\"}\n",
    "\n",
    "color_dict = dict()\n",
    "color_dict[\"L0\"] = \"pink\"\n",
    "color_dict[\"L1\"] = \"red\"\n",
    "color_dict[\"L2\"] = \"green\"\n",
    "\n",
    "nviz = reload(nviz)\n",
    "plot_items_returned = nviz.visualize_neuron(recovered_neuron,\n",
    "                                            limb_branch_dict=limb_branch_dict,\n",
    "                                            visualize_type=[\"mesh\"],\n",
    "                                            mesh_resolution=\"branch\",\n",
    "                                            #mesh_color=[\"green\",[1,0,0,0.4],[0,0.9,0,0.6],\"yellow\"],\n",
    "                                            #mesh_color = color_dict,\n",
    "                                            mesh_color=\"red\",\n",
    "                                            mesh_color_alpha = 0.8,\n",
    "                                            mesh_soma=False,\n",
    "                                            #mesh_whole_neuron=True,\n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "\n",
    "\n",
    "#                                             skeleton_resolution=\"branch\",\n",
    "#                                             #skeleton_color = color_dict_skeleton,\n",
    "#                                             skeleton_color=\"yellow\",\n",
    "#                                             skeleton_fill_color=\"black\",\n",
    "#                                             skeleton_soma=True,\n",
    "#                                             skeleton_whole_neuron=True,\n",
    "\n",
    "                                            #colors_to_omit=[\"yellow\",\"green\"],\n",
    "                                            print_flag = False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn a concept network into a larger one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To combine all of the concept maps into one \n",
    "(will involve a renaming process for the branches)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recieved another instance of Neuron class in init -- so just copying data\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudocode on how to do the plotting for concept network\n",
    "\n",
    "what we have: \n",
    "plot_items: the mesh centers\n",
    "plot_items_order: the list of nodes we are keeping to plot\n",
    "color_list_correct_size: the color lists that corresponds to the items we are plotting\n",
    "\n",
    "All the arguments:\n",
    "- plotting soma\n",
    "- plotting whole thing\n",
    "- colors and sizes of all nodes or arrows\n",
    "\n",
    "What we want: plot the subgraph but be able to specify all of the \n",
    "colors of the scatter plots and arrows\n",
    "\n",
    "Pseudocode of old code: \n",
    "1) Gets all of the node locations (as a dictionary)\n",
    "2) Gets all of the edges (which only index into the node dictionary)\n",
    "3) If directional:\n",
    "Iterates through all the edges\n",
    "- gets the directions (where to put the arrows) by using node[e2] - node[e1]\n",
    "- gets the midpoints\n",
    "- plots the arrows using midpoints and directions\n",
    "\n",
    "4) turns the node_locations dictionary into array of scatter points\n",
    "5) if asked to highlight the starting point then gets those coordinates and \n",
    "plots them with size/color in graph_skeleton_and_mesh\n",
    "\n",
    "6) Converts the concept network to a skeleton (so can plot the skeleton to plot the edges)\n",
    "\n",
    "7) plots the nodes,skeleton using the sk graphing function\n",
    "\n",
    "Differences between new code and old: \n",
    "- just graph all of the scatter points in other_scatter as a list of just one scatter point\n",
    " (the scatter color is already in the color_list_correct_size)\n",
    " \n",
    "- want to specify some arrows as different colors (can just change up the section that iterates \n",
    "through all of the edges)\n",
    "\n",
    "Idea for new function that can plot concept network\n",
    "\n",
    "Accpets: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0. , 0. , 0.2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_color = \"red\"\n",
    "curr_alpha = 0.2\n",
    "\n",
    "\n",
    "import matplotlib_utils as mu\n",
    "mu = reload(mu)\n",
    "curr_rgb = mu.color_to_rgb(curr_color)\n",
    "\n",
    "mu.apply_alpha_to_color_list(curr_rgb,alpha=curr_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Arguments:\n",
    "\n",
    "node_color: list/dictionary or just one color\n",
    "edge_color\n",
    "\n",
    "starting_node=True,\n",
    "starting_node_size=0.3,\n",
    "starting_node_color= \"pink\",\n",
    "starting_node_alpha=0.5,\n",
    "\n",
    "arrow_color = \"maroon\",\n",
    "arrow_alpha = 0.5,\n",
    "arrow_size = 0.5,\n",
    "\n",
    "#make these all\n",
    "arrow_color_reciprocal = \"maroon\",\n",
    "arrow_alpha_reciprocal = 0.5,\n",
    "arrow_size_reciprocal = 0.5,\n",
    "\n",
    "show_at_end=True,\n",
    "append_figure=False,\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz = reload(nviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6387168964e94aaf870aa72848df4475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xu = reload(xu)\n",
    "nviz = reload(nviz)\n",
    "import skeleton_utils as sk\n",
    "sk = reload(sk)\n",
    "nviz.visualize_concept_map(returned_network,\n",
    "                          #starting_node_size = 10,\n",
    "                          arrow_color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recieved another instance of Neuron class in init -- so just copying data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8a4baff84845858442f49e9b8ab2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neuron = reload(neuron)\n",
    "recovered_neuron = neuron.Neuron(recovered_neuron)\n",
    "nru = reload(nru)\n",
    "nviz = reload(nviz)\n",
    "returned_network = nru.whole_neuron_branch_concept_network(recovered_neuron,\n",
    "                                  directional=True,\n",
    "                                 limb_soma_touch_dictionary = \"all\",\n",
    "                                 print_flag = False)\n",
    "\n",
    "nviz.plot_concept_network(returned_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aee6bd78ee342dd913cf35cf1484b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curr_subgraph = nx.subgraph(returned_network,found_reciprocal.ravel())\n",
    "nviz.plot_concept_network(curr_subgraph,\n",
    "                          arrow_size=1,\n",
    "                          scatter_size = 5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Plotting the Concept Networks\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f9aa750e3a4a2488b3c8c14a9a764b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyvolume as ipv\n",
    "ipv.pylab.clear()\n",
    "nviz.plot_ipv_skeleton(recovered_neuron.concept_network.nodes[\"L1\"][\"data\"].skeleton,color=[0,0.,1,1])\n",
    "nviz.plot_ipv_skeleton(recovered_neuron.concept_network.nodes[\"L2\"][\"data\"].skeleton,color=[0,0.,1,0.2])\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Working on visualization type: network\n",
      "edge_color = black IN SKELETON\n",
      "Color in skeleton ipv plot local = black\n",
      "whole_neuron_network_edge_color = [0.  0.  0.  0.2]\n",
      "edge_color = [0.  0.  0.  0.2] IN SKELETON\n",
      "Color in skeleton ipv plot local = [0.  0.  0.  0.2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31fd9446c0e456cb54d32d847a9d893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz = reload(nviz)\n",
    "nru = reload(nru)\n",
    "mu = reload(mu)\n",
    "sk = reload(sk)\n",
    "\n",
    "limb_branch_dict = {\"L0\":[0,1,2,3,4,5,6],\n",
    "                   \"L1\":[0,1,2,3,4,5,6]}\n",
    "\n",
    "color_dict_skeleton = dict()\n",
    "color_dict_skeleton[\"L0\"] = {1:\"red\",2:\"pink\"}\n",
    "color_dict_skeleton[\"L1\"] = {37:\"red\",12:\"pink\"}\n",
    "color_dict_skeleton[\"L2\"] = {5:\"red\"}\n",
    "\n",
    "color_dict = dict()\n",
    "color_dict[\"L0\"] = \"pink\"\n",
    "color_dict[\"L1\"] = \"red\"\n",
    "color_dict[\"L2\"] = \"green\"\n",
    "\n",
    "nviz.visualize_neuron(recovered_neuron,\n",
    "                      limb_branch_dict = limb_branch_dict,\n",
    "                     visualize_type=[\"network\"],\n",
    "                      #for concept_network \n",
    "                    network_configuration_dict=dict(),\n",
    "                    network_limb_branch_dict=None,\n",
    "                    network_resolution=\"branch\",\n",
    "                    network_color_grouping=\"branch\",\n",
    "                    network_color=\"random\",\n",
    "                    network_color_alpha=0.5,\n",
    "                    network_soma=True,\n",
    "                    network_fill_color = \"brown\",\n",
    "                    network_soma_color=\"red\",\n",
    "                    network_soma_alpha=0.5,\n",
    "                      \n",
    "                    network_whole_neuron=True,\n",
    "                    network_whole_neuron_color=\"black\",\n",
    "                    network_whole_neuron_alpha=0.2,\n",
    "\n",
    "                    # ------ specific arguments for the concept_network -----\n",
    "                    network_directional=True,\n",
    "                    limb_to_starting_soma=\"all\",\n",
    "\n",
    "                    edge_color = \"black\",\n",
    "                    node_size = 0.3,\n",
    "\n",
    "                    starting_node=True,\n",
    "                    starting_node_size=0.3,\n",
    "                    starting_node_color= \"pink\",\n",
    "                    starting_node_alpha=0.8,\n",
    "\n",
    "                    arrow_color = \"brown\",\n",
    "                    arrow_alpha = 0.8,\n",
    "                    arrow_size = 0.3,\n",
    "\n",
    "                    arrow_color_reciprocal = \"brown\",\n",
    "                    arrow_alpha_reciprocal = 0.8,\n",
    "                    arrow_size_reciprocal = 0.3,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_array = [['L1_11', 'L1_15'], ['L1_15', 'L1_30']]\n",
    "nu.matching_rows(ex_array,['L2_11', 'L1_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx_utils as xu\n",
    "xu = reload(xu)\n",
    "found_reciprocal = xu.find_reciprocal_connections(returned_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['L1_11'],\n",
       "       ['L1_15'],\n",
       "       ['L1_15'],\n",
       "       ['L1_30'],\n",
       "       ['L1_30'],\n",
       "       ['L1_52'],\n",
       "       ['L1_52'],\n",
       "       ['L1_32'],\n",
       "       ['L1_32'],\n",
       "       ['L1_37'],\n",
       "       ['L1_37'],\n",
       "       ['L1_38'],\n",
       "       ['L1_38'],\n",
       "       ['L1_40']], dtype='<U5')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_reciprocal.reshape(-1,1).astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
