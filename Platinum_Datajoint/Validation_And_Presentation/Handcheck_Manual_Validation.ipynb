{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To visualize how the proofreading performs on the manually proofread cells\n",
    "\n",
    "Pseucode: \n",
    "For the example neuron id\n",
    "1) get the neuron decomposition\n",
    "2) Run the error detection to get the errored faces\n",
    "3) Get the errored synapses\n",
    "4) Plot them mesh and errored synapses\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-30 17:59:57,904 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2020-11-30 17:59:57,905 - settings - Setting database.user to celiib\n",
      "INFO - 2020-11-30 17:59:57,906 - settings - Setting database.password to newceliipass\n",
      "INFO - 2020-11-30 17:59:57,911 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2020-11-30 17:59:57,912 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2020-11-30 17:59:57,925 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-30 17:59:58,127 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "\n",
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import neuron_visualizations as nviz\n",
    "\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-30 17:59:58,148 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2020-11-30 17:59:58,355 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datajoint_utils as du\n",
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np\n",
    "\n",
    "from datajoint_utils import *\n",
    "\n",
    "import error_detection as ed\n",
    "\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        \n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_version</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_ratio</p>\n",
       "                                <span class=\"djtooltiptext\">ratio of remaining mesh vertices/faces (which ones depends on what metric the decimation technique uses)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">nucleus_id</p>\n",
       "                                <span class=\"djtooltiptext\">id of segmented nucleus</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">nucleus_version</p>\n",
       "                                <span class=\"djtooltiptext\">segmentation version</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">centroid_x</p>\n",
       "                                <span class=\"djtooltiptext\">(EM voxels)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">centroid_y</p>\n",
       "                                <span class=\"djtooltiptext\">(EM voxels)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">centroid_z</p>\n",
       "                                <span class=\"djtooltiptext\">(EM voxels)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">size</p>\n",
       "                                <span class=\"djtooltiptext\">(EM voxels) scaled by (4x4x40)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">svid</p>\n",
       "                                <span class=\"djtooltiptext\">supervoxel_id of centroid</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>864691135564655959</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>225498</td>\n",
       "<td>1</td>\n",
       "<td>149712</td>\n",
       "<td>151648</td>\n",
       "<td>17549</td>\n",
       "<td>1315328</td>\n",
       "<td>85369450370640387</td></tr><tr><td>864691135748568361</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>230236</td>\n",
       "<td>1</td>\n",
       "<td>162848</td>\n",
       "<td>184560</td>\n",
       "<td>19809</td>\n",
       "<td>1385955</td>\n",
       "<td>87203504753932217</td></tr><tr><td>864691136194042326</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>258307</td>\n",
       "<td>1</td>\n",
       "<td>174944</td>\n",
       "<td>137648</td>\n",
       "<td>21113</td>\n",
       "<td>1587826</td>\n",
       "<td>88815663879212610</td></tr><tr><td>864691135233108569</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>262773</td>\n",
       "<td>1</td>\n",
       "<td>168096</td>\n",
       "<td>161952</td>\n",
       "<td>21503</td>\n",
       "<td>1314296</td>\n",
       "<td>87904100020764569</td></tr><tr><td>864691135740225387</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>264870</td>\n",
       "<td>1</td>\n",
       "<td>164832</td>\n",
       "<td>177856</td>\n",
       "<td>21208</td>\n",
       "<td>1831649</td>\n",
       "<td>87413717834430502</td></tr><tr><td>864691136105498585</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>269247</td>\n",
       "<td>1</td>\n",
       "<td>177536</td>\n",
       "<td>213824</td>\n",
       "<td>19894</td>\n",
       "<td>1571057</td>\n",
       "<td>89177746601154881</td></tr><tr><td>864691134988386682</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>269380</td>\n",
       "<td>1</td>\n",
       "<td>168016</td>\n",
       "<td>216288</td>\n",
       "<td>21534</td>\n",
       "<td>1688056</td>\n",
       "<td>87911453071322695</td></tr><tr><td>864691136333776819</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>271518</td>\n",
       "<td>1</td>\n",
       "<td>168464</td>\n",
       "<td>226192</td>\n",
       "<td>21121</td>\n",
       "<td>1666190</td>\n",
       "<td>87912758674384086</td></tr><tr><td>864691135771629819</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>294545</td>\n",
       "<td>1</td>\n",
       "<td>182976</td>\n",
       "<td>135728</td>\n",
       "<td>21116</td>\n",
       "<td>1462702</td>\n",
       "<td>89941288908168255</td></tr><tr><td>864691135748575017</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>296726</td>\n",
       "<td>1</td>\n",
       "<td>180976</td>\n",
       "<td>143888</td>\n",
       "<td>22162</td>\n",
       "<td>1827886</td>\n",
       "<td>89660913577301286</td></tr><tr><td>864691136105484249</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>300763</td>\n",
       "<td>1</td>\n",
       "<td>182048</td>\n",
       "<td>178240</td>\n",
       "<td>20186</td>\n",
       "<td>1456434</td>\n",
       "<td>89806255002282134</td></tr><tr><td>864691135212632448</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>301095</td>\n",
       "<td>1</td>\n",
       "<td>185152</td>\n",
       "<td>185344</td>\n",
       "<td>21255</td>\n",
       "<td>2228706</td>\n",
       "<td>90229429674273152</td> </tr> </tbody>\n",
       "            </table>\n",
       "            <p>...</p>\n",
       "            <p>Total: 63</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segment_id    *decimation_ve *decimation_ra *nucleus_id    *nucleus_versi centroid_x     centroid_y     centroid_z     size        svid          \n",
       "+------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +------------+ +---------+ +------------+\n",
       "86469113556465 0              0.25           225498         1              149712         151648         17549          1315328     85369450370640\n",
       "86469113574856 0              0.25           230236         1              162848         184560         19809          1385955     87203504753932\n",
       "86469113619404 0              0.25           258307         1              174944         137648         21113          1587826     88815663879212\n",
       "86469113523310 0              0.25           262773         1              168096         161952         21503          1314296     87904100020764\n",
       "86469113574022 0              0.25           264870         1              164832         177856         21208          1831649     87413717834430\n",
       "86469113610549 0              0.25           269247         1              177536         213824         19894          1571057     89177746601154\n",
       "86469113498838 0              0.25           269380         1              168016         216288         21534          1688056     87911453071322\n",
       "86469113633377 0              0.25           271518         1              168464         226192         21121          1666190     87912758674384\n",
       "86469113577162 0              0.25           294545         1              182976         135728         21116          1462702     89941288908168\n",
       "86469113574857 0              0.25           296726         1              180976         143888         22162          1827886     89660913577301\n",
       "86469113610548 0              0.25           300763         1              182048         178240         20186          1456434     89806255002282\n",
       "86469113521263 0              0.25           301095         1              185152         185344         21255          2228706     90229429674273\n",
       "   ...\n",
       " (Total: 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m65 = minnie\n",
    "decimation_version = 0\n",
    "decimation_ratio = 0.25\n",
    "key_source = (m65.Decimation().proj(decimation_version='version')  &\n",
    "              dict(decimation_version=decimation_version,decimation_ratio=decimation_ratio)\n",
    "              & m65.ManualProofreadIDs() & (m65.BaylorSegmentCentroid() & \"multiplicity=1\").proj())\n",
    "nucleus_table =(m65.NucleusID & 'nucleus_version=1')  # Aug 1 timestamp\n",
    "proofread_nucs = nucleus_table & m65.ManualProofreadIDs()\n",
    "single_soma_nucs = nucleus_table & (dj.U('segment_id').aggr(proofread_nucs, n_nucs='count(nucleus_id)') & 'n_nucs=1').proj()\n",
    "final_nucs = key_source* single_soma_nucs\n",
    "final_nucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_table = minnie.Decomposition & final_nucs.proj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([864691135564655959, 864691135748568361, 864691136194042326,\n",
       "       864691135233108569, 864691135740225387, 864691136105498585,\n",
       "       864691134988386682, 864691136333776819, 864691135771629819,\n",
       "       864691136105484249, 864691135212632448, 864691136296650011,\n",
       "       864691136311740477, 864691135491233631, 864691135945413668,\n",
       "       864691135393964789, 864691135113167769, 864691136105493209,\n",
       "       864691135272164113, 864691136618403213, 864691135974454639,\n",
       "       864691136003930314, 864691135510455760, 864691136537220258,\n",
       "       864691135785277636, 864691136333787571, 864691136105491417,\n",
       "       864691135645592260, 864691136056391384, 864691136099807093,\n",
       "       864691135348272855, 864691135737374100, 864691135212690816,\n",
       "       864691136550489250, 864691136194103510, 864691135589907979,\n",
       "       864691135407289801, 864691136545546146, 864691135382947307,\n",
       "       864691136008425132, 864691135925564174, 864691136333790899,\n",
       "       864691135974454895, 864691136008573614, 864691136134446219,\n",
       "       864691135736387732, 864691135501578306, 864691136537477538,\n",
       "       864691135865518469, 864691136201041854, 864691136311791677,\n",
       "       864691135735426708, 864691136618412685, 864691136370815112,\n",
       "       864691135699269154, 864691135589906955, 864691136056340440])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ids_to_test = eligible_table.fetch(\"segment_id\")\n",
    "seg_ids_to_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the Actual Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segment_id': 864691135740225387}\n"
     ]
    }
   ],
   "source": [
    "segment_id = seg_ids_to_test[4]\n",
    "key = dict(segment_id=segment_id)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Working on 864691135740225387-------\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "functions_list = [<function width at 0x7ff1519b27b8>, <function median_mesh_center at 0x7ff1519b2a60>, <function n_spines at 0x7ff1519b28c8>, <function n_faces_branch at 0x7ff153b1a488>, <function skeleton_distance_branch at 0x7ff1519b2840>, <function spines_per_skeletal_length at 0x7ff1519b2d08>, <function no_spine_median_mesh_center at 0x7ff1519b2b70>]\n",
      "functions_list = [<function axon_segment at 0x7ff1519b3400>]\n",
      "Axons not keeping because of soma: {'L1': array([ 6,  7,  8,  9, 12, 13])}\n",
      "\n",
      "----- Working on L0 ------\n",
      "-- Axon Group 0 of size 29--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 1 of size 1--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 2 of size 1--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 3 of size 5--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 4 of size 9--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 5 of size 9--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 6 of size 5--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 7 of size 3--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 8 of size 43--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 9 of size 3--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "-- Axon Group 10 of size 3--\n",
      "   Working on soma 0, starting_node 4\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 8.215939908057189\n",
      "\n",
      "\n",
      "For limb 0 the valid axon branches are [  0   1   2   3  35  36  37  38  39  40  41  42  43  45  54  55  56  80\n",
      "  92  95  99 104 105 106 107 114 115 124 126  44  88 130  74  75  76  79\n",
      " 128 121  71  72  73 119 120  89 122  66  67   5   6  90  91 127  62  63\n",
      "  32  33  34  97  98  57  58  77 131  12  13  14  15  16  17  18  19  20\n",
      "  21  26  27  28  29  30  31  49  51  52  53  59  60  61  64  65  70  78\n",
      "  86  87  93  94  96 100 101 102 103 111 112 116 117 118 125 113 109 110\n",
      "  81  82 123]\n",
      "The following are not valid: []\n",
      "\n",
      "----- Working on L2 ------\n",
      "-- Axon Group 0 of size 15--\n",
      "   Working on soma 0, starting_node 0\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 108.23025260640867\n",
      "*****Path to axon group not valid******\n",
      "\n",
      "\n",
      "For limb 2 the valid axon branches are []\n",
      "The following are not valid: [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 20, 21]\n",
      "\n",
      "----- Working on L3 ------\n",
      "-- Axon Group 0 of size 7--\n",
      "   Working on soma 0, starting_node 3\n",
      "Not using AIS angle threshold\n",
      "sk_angle= 96.58083861926315\n",
      "*****Path to axon group not valid******\n",
      "\n",
      "\n",
      "For limb 3 the valid axon branches are []\n",
      "The following are not valid: [7, 8, 10, 11, 12, 13, 14]\n",
      "\n",
      "----- Working on L4 ------\n",
      "\n",
      "\n",
      "For limb 4 the valid axon branches are []\n",
      "The following are not valid: []\n",
      "\n",
      "----- Working on L5 ------\n",
      "\n",
      "\n",
      "For limb 5 the valid axon branches are []\n",
      "The following are not valid: []\n",
      "\n",
      "----- Working on L7 ------\n",
      "\n",
      "\n",
      "For limb 7 the valid axon branches are []\n",
      "The following are not valid: []\n",
      "\n",
      "----- Working on L9 ------\n",
      "\n",
      "\n",
      "For limb 9 the valid axon branches are []\n",
      "The following are not valid: []\n",
      "final_error_axons = {'L1': array([ 6,  7,  8,  9, 12, 13]), 'L0': [], 'L2': [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 20, 21], 'L3': [7, 8, 10, 11, 12, 13, 14], 'L4': [], 'L5': [], 'L7': [], 'L9': []}\n",
      "\n",
      "\n",
      " -------- Total number of error faces = 49496 --------------\n",
      "\n",
      "\n",
      " ------ Total time for 864691135740225387 = 64.92174553871155 ------\n"
     ]
    }
   ],
   "source": [
    "segment_id = key[\"segment_id\"]\n",
    "global_start = time.time()\n",
    "\n",
    "verbose = True\n",
    "\n",
    "print(f\"\\n\\n----- Working on {segment_id}-------\")\n",
    "whole_pass_time = time.time()\n",
    "\n",
    "neuron_obj = (minnie.Decomposition() & key).fetch1(\"decomposition\")\n",
    "errored_faces = ed.error_faces_by_axons(neuron_obj,verbose=True,visualize_errors_at_end=False)\n",
    "\n",
    "print(f\"\\n\\n ------ Total time for {segment_id} = {time.time() - global_start} ------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Actual Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691135740225387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d342ad6297df45cda787018385149f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(neuron_obj.segment_id)\n",
    "nviz.plot_objects(main_mesh=neuron_obj.mesh,\n",
    "             mesh_alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"n_errored_faces = {len(errored_faces)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = reload(ed)\n",
    "\n",
    "\n",
    "if neuron_obj is None:\n",
    "    neuron_obj = (minnie.Decomposition() & dict(segment_id=segment_id)).fetch1(\"decomposition\")\n",
    "\n",
    "current_mesh = neuron_obj.mesh\n",
    "\n",
    "error_submesh = current_mesh.submesh([errored_faces],append=True)\n",
    "valid_mesh = tu.subtract_mesh(current_mesh,error_submesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(main_mesh=valid_mesh,\n",
    "             meshes=error_submesh,\n",
    "              meshes_colors=\"red\",\n",
    "             mesh_alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get the percentage of synapses removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudocode: \n",
    "1) Get the synapse file that corresponds to it\n",
    "2) Get the matching v7 id\n",
    "3) Get the v7 synapses (pre and post) that are still there\n",
    "4) Get the pre and post that are stil their after autoproofreading\n",
    "5) Things to find:\n",
    "- Eliminated and should have been (true positives)\n",
    "- Eliminated but SHOULDN'T (false positives) \n",
    "- Not Eliminated and should have been not (true negative)\n",
    "- Not Eliminated but should have been eliminated (false negatie) \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get the synapse file that corresponds to it\n",
    "data_path = Path(\"./manual_proofread_data/\")\n",
    "current_file = data_path / Path(f\"{segment_id}.pkl\")\n",
    "current_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su\n",
    "curr_synapse_table = su.load_object(current_file)\n",
    "#eliminating the self connections\n",
    "df = curr_synapse_table[curr_synapse_table[\"pre_pt_root_id_Aug\"] != curr_synapse_table[\"post_pt_root_id_Aug\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b) Get the synapse data for the august neuron \n",
    "ctr_pt_position = df[\"ctr_pt_position\"].to_numpy()\n",
    "synapse_ids = df[\"id\"].to_numpy()\n",
    "synapse_centers = np.vstack(ctr_pt_position)\n",
    "synapse_ids.shape,synapse_centers.shape\n",
    "timestamps = np.zeros(len(synapse_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Get the matching v7 id\n",
    "import pandas as pd\n",
    "aug_to_v7_table = pd.read_csv(\"./proofread_cells_seg_correspondence_Aug1-v7.csv\")\n",
    "v7_id = aug_to_v7_table[aug_to_v7_table[\"old_seg_id\"]==segment_id][\"new_seg_id\"].tolist()[0]\n",
    "v7_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the new v7 segment id is in the synapse table\n",
    "\n",
    "def get_pd_id_data(col_name,return_unique=False):\n",
    "    ret_data = df [col_name].to_numpy()\n",
    "    if return_unique:\n",
    "        return np.unique(ret_data)\n",
    "    else:\n",
    "        return ret_data\n",
    "    \n",
    "pre_pt_root_id = get_pd_id_data(\"pre_pt_root_id\")\n",
    "pre_pt_root_id.shape,v7_id in pre_pt_root_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pt_root_id = get_pd_id_data(\"post_pt_root_id\")\n",
    "post_pt_root_id.shape,v7_id in post_pt_root_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_presyn = df[(df[\"pre_pt_root_id_Aug\"] == segment_id)][\"id\"].to_numpy()\n",
    "original_postsyn = df[(df[\"post_pt_root_id_Aug\"] == segment_id)][\"id\"].to_numpy()\n",
    "\n",
    "original_presyn.shape,original_postsyn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Get the v7 synapses (pre and post) that are still there\n",
    "manual_remaining_presyn = df[(df[\"pre_pt_root_id\"] == v7_id)][\"id\"].to_numpy()\n",
    "manual_remaining_postsyn = df[(df[\"post_pt_root_id\"] == v7_id)][\"id\"].to_numpy()\n",
    "manual_remaining_presyn.shape,manual_remaining_postsyn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the non-remaining presyns and postsyns\n",
    "manual_error_presyn = np.setdiff1d(original_presyn,manual_remaining_presyn)\n",
    "manual_error_postsyn = np.setdiff1d(original_postsyn,manual_remaining_postsyn)\n",
    "\n",
    "manual_error_presyn.shape,manual_error_postsyn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manual_remaining_presyn) + len(manual_error_presyn), len(manual_remaining_postsyn) + len(manual_error_postsyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Get the pre and post that are stil their after autoproofreading\n",
    "ed = reload(ed)\n",
    "err_synapse_ids,non_err_synapse_ids = ed.get_error_synapse_inserts(current_mesh,segment_id,\n",
    "                                                     errored_faces,return_synapse_ids=True,\n",
    "                                                                   synapse_centers=synapse_centers,\n",
    "                                                                   synapse_ids=synapse_ids\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divided the valid synapses into presyn and postsyn\n",
    "auto_remaining_presyn = np.intersect1d(original_presyn,non_err_synapse_ids)\n",
    "auto_remaining_postsyn = np.intersect1d(original_postsyn,non_err_synapse_ids)\n",
    "\n",
    "#dividing the error synapses into presyn and postsyn\n",
    "auto_error_presyn = np.intersect1d(original_presyn,err_synapse_ids)\n",
    "auto_error_postsyn = np.intersect1d(original_postsyn,err_synapse_ids)\n",
    "\n",
    "len(auto_remaining_presyn), len(auto_error_presyn), len(auto_remaining_postsyn), len(auto_error_postsyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the final scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the presyn analysis\n",
    "true_positive_presyn = np.intersect1d(manual_error_presyn,auto_error_presyn) #deemed an error and was an error\n",
    "false_positive_presyn = np.intersect1d(manual_remaining_presyn,auto_error_presyn)#deemed an error but not an error\n",
    "\n",
    "true_negative_presyn = np.intersect1d(manual_remaining_presyn,auto_remaining_presyn) #not deemed an error and should not be an error\n",
    "false_negative_presyn = np.intersect1d(manual_error_presyn,auto_remaining_presyn) #not deemed and error but should be an error\n",
    "\n",
    "len(true_positive_presyn),len(false_positive_presyn),len(true_negative_presyn),len(false_negative_presyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([len(true_positive_presyn),len(false_positive_presyn),len(true_negative_presyn),len(false_negative_presyn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the postsyn analysis\n",
    "true_positive_postsyn = np.intersect1d(manual_error_postsyn,auto_error_postsyn) #deemed an error and was an error\n",
    "false_positive_postsyn = np.intersect1d(manual_remaining_postsyn,auto_error_postsyn)#deemed an error but not an error\n",
    "\n",
    "true_negative_postsyn = np.intersect1d(manual_remaining_postsyn,auto_remaining_postsyn) #not deemed an error and should not be an error\n",
    "false_negative_postsyn= np.intersect1d(manual_error_postsyn,auto_remaining_postsyn) #not deemed and error but should be an error\n",
    "\n",
    "len(true_positive_postsyn),len(false_positive_postsyn),len(true_negative_postsyn),len(false_negative_postsyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([len(true_positive_postsyn),len(false_positive_postsyn),len(true_negative_postsyn),len(false_negative_postsyn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "true_positive_total = list(true_positive_presyn) + list(true_positive_postsyn) \n",
    "false_positive_total = list(false_positive_presyn) + list(false_positive_postsyn)\n",
    "\n",
    "true_negative_total = list(true_negative_presyn) + list(true_negative_postsyn)\n",
    "false_negative_total = list(false_negative_presyn) + list(false_negative_postsyn)\n",
    "\n",
    "len(true_positive_total),len(false_positive_total),len(true_negative_total),len(false_negative_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([len(true_positive_total),len(false_positive_total),len(true_negative_total),len(false_negative_total)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(TP,FP):\n",
    "    if (TP + FP) > 0:\n",
    "        return TP/(TP + FP)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def recall(TP,FN):\n",
    "    if (TP + FN) > 0:\n",
    "        return TP/(TP + FN)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def f1(TP,FP,FN):\n",
    "    curr_prec = precision(TP,FP)\n",
    "    curr_recall = recall(TP,FN)\n",
    "    \n",
    "    if curr_prec + curr_recall > 0:\n",
    "        return 2*(curr_prec*curr_recall)/(curr_prec + curr_recall)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def calculate_scores(TP,FP,FN):\n",
    "    return dict(precision=precision(TP,FP),\n",
    "               recall=recall(TP,FN),\n",
    "               f1=f1(TP,FP,FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the accuracy, precision and f1\n",
    "\n",
    "#precision = (true positives)/(true positives + false positives)\n",
    "presyn_scores =  calculate_scores(len(true_positive_presyn),len(false_positive_presyn),len(false_negative_presyn))\n",
    "presyn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsyn_scores =  calculate_scores(len(true_positive_postsyn),len(false_positive_postsyn),len(false_negative_postsyn))\n",
    "postsyn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores =  calculate_scores(len(true_positive_total),len(false_positive_total),len(false_negative_total))\n",
    "total_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If no automatic proofreading was done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "err_synapses,non_err_synapses = ed.get_error_synapse_inserts(current_mesh,segment_id,\n",
    "                                                     errored_faces,return_synapse_centroids=True,\n",
    "                                                                   synapse_centers=synapse_centers,\n",
    "                                                                   synapse_ids=synapse_ids\n",
    "                                                                  )\n",
    "\n",
    "print(f\"Segment ID = {segment_id}\")\n",
    "print(f\"n_synapses = {len(err_synapses) + len(non_err_synapses)}, n_errored_synapse = {len(err_synapses)}\")\n",
    "\n",
    "\n",
    "valid_synapse_color = \"yellow\"\n",
    "error_color = \"red\"\n",
    "scatters_list = []\n",
    "scatters_colors = []\n",
    "\n",
    "if len(err_synapses) > 0:\n",
    "    scatters_list.append(err_synapses)\n",
    "    scatters_colors.append(error_color)\n",
    "if len(non_err_synapses) > 0:\n",
    "    scatters_list.append(non_err_synapses)\n",
    "    scatters_colors.append(valid_synapse_color)\n",
    "    \n",
    "if len(scatters_list) > 0:\n",
    "    nviz.plot_objects(main_mesh=valid_mesh,\n",
    "              meshes=[error_submesh],\n",
    "                      mesh_alpha=1,\n",
    "              meshes_colors=[error_color],\n",
    "            scatters=[err_synapses,non_err_synapses],\n",
    "             scatters_colors=[error_color,valid_synapse_color],\n",
    "                     scatter_size=0.2)\n",
    "\n",
    "else:\n",
    "    nviz.plot_objects(main_mesh=valid_mesh,\n",
    "             meshes=error_submesh,\n",
    "              meshes_colors=error_color,\n",
    "             mesh_alpha=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the Results to a Datajoint Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class ValidationStats(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.ManualProofreadIDs\n",
    "    ---\n",
    "    new_segment_id: bigint unsigned\n",
    "    \n",
    "    true_positive_presyn: int\n",
    "    false_positive_presyn: int\n",
    "    true_negative_presyn: int\n",
    "    false_negative_presyn: int\n",
    "\n",
    "    precision_presyn=NULL: double\n",
    "    recall_presyn=NULL: double\n",
    "    f1_presyn=NULL: double\n",
    "\n",
    "    true_positive_postsyn: int\n",
    "    false_positive_postsyn: int\n",
    "    true_negative_postsyn: int\n",
    "    false_negative_postsyn: int\n",
    "\n",
    "    precision_postsyn=NULL: double\n",
    "    recall_postsyn=NULL: double\n",
    "    f1_postsyn=NULL: double\n",
    "\n",
    "    true_positive_total : int\n",
    "    false_positive_total : int\n",
    "    true_negative_total : int\n",
    "    false_negative_total : int\n",
    "\n",
    "    precision_total=NULL: double\n",
    "    recall_total=NULL: double\n",
    "    f1_total=NULL: double\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_key = dict(segment_id=segment_id,\n",
    "               new_segment_id=v7_id,\n",
    "               \n",
    "                true_positive_presyn = len(true_positive_presyn),\n",
    "                false_positive_presyn = len(false_positive_presyn),\n",
    "                true_negative_presyn= len(true_negative_presyn),\n",
    "                false_negative_presyn = len(false_negative_presyn),\n",
    "\n",
    "                precision_presyn = presyn_scores[\"precision\"],\n",
    "                recall_presyn = presyn_scores[\"recall\"],\n",
    "                f1_presyn = presyn_scores[\"f1\"],\n",
    "\n",
    "                true_positive_postsyn = len(true_positive_postsyn),\n",
    "                false_positive_postsyn = len(false_positive_postsyn),\n",
    "                true_negative_postsyn = len(true_negative_postsyn),\n",
    "                false_negative_postsyn = len(false_negative_postsyn),\n",
    "\n",
    "                precision_postsyn = postsyn_scores[\"precision\"],\n",
    "                recall_postsyn = postsyn_scores[\"recall\"],\n",
    "                f1_postsyn = postsyn_scores[\"f1\"],\n",
    "\n",
    "                true_positive_total= len(true_positive_total),\n",
    "                false_positive_total = len(false_positive_total),\n",
    "                true_negative_total = len(true_negative_total),\n",
    "                false_negative_total = len(false_negative_total),\n",
    "\n",
    "                precision_total = total_scores[\"precision\"],\n",
    "                recall_total=total_scores[\"recall\"],\n",
    "                f1_total = total_scores[\"f1\"],\n",
    "                \n",
    "                \n",
    "               )\n",
    "\n",
    "ValidationStats.insert1(info_key,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP,FP,FN = ValidationStats.fetch(\"true_positive_total\",\"false_positive_total\",\"false_negative_total\")\n",
    "total_dict = dict(type=\"presyn and postsyn\")\n",
    "total_stats = calculate_scores(TP = np.sum(TP),FP = np.sum(FP),FN = np.sum(FN))\n",
    "total_dict.update(total_stats)\n",
    "total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_pre,FP_pre,FN_pre = ValidationStats.fetch(\"true_positive_presyn\",\"false_positive_presyn\",\"false_negative_presyn\")\n",
    "presyn_dict = dict(type=\"presyn\")\n",
    "presyn_stats = calculate_scores(TP = np.sum(TP_pre),FP = np.sum(FP_pre),FN = np.sum(FN_pre))\n",
    "presyn_dict.update(presyn_stats)\n",
    "presyn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_post,FP_post,FN_post = ValidationStats.fetch(\"true_positive_postsyn\",\"false_positive_postsyn\",\"false_negative_postsyn\")\n",
    "postsyn_dict = dict(type=\"postsyn\")\n",
    "postsyn_stats = calculate_scores(TP = np.sum(TP_post),FP = np.sum(FP_post),FN = np.sum(FN_post))\n",
    "postsyn_dict.update(postsyn_stats)\n",
    "postsyn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Figure for the Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
