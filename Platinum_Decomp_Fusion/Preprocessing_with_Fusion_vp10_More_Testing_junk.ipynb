{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo make sure the fusion decomposition works\\nup to the part where we would stitch the sublimbs together into one limb\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To make sure the fusion decomposition works\n",
    "up to the part where we would stitch the sublimbs together into one limb\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Need to pip install annotationframeworkclient to repair mesh with pychunkedgraph\n",
      "WARNING:root:Need to pip install annotationframeworkclient to use dataset_name parameters\n"
     ]
    }
   ],
   "source": [
    "import skeleton_utils as sk\n",
    "import soma_extraction_utils as sm\n",
    "import trimesh_utils as tu\n",
    "import trimesh\n",
    "import numpy_utils as nu\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import networkx as nx\n",
    "import time\n",
    "import compartment_utils as cu\n",
    "import networkx_utils as xu\n",
    "import matplotlib_utils as mu\n",
    "import neuron_utils as nru\n",
    "\n",
    "#importing at the bottom so don't get any conflicts\n",
    "import itertools\n",
    "from tqdm_utils import tqdm\n",
    "\n",
    "#for meshparty preprocessing\n",
    "import meshparty_skeletonize as m_sk\n",
    "import general_utils as gu\n",
    "import compartment_utils as cu\n",
    "from meshparty import trimesh_io\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from neuron_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "curent_neuron = tu.load_mesh_no_processing(\"/notebooks/test_neurons/Segmentation_2/864691135969633280_junk.off\")\n",
    "segment_id = 864691135969633280\n",
    "description = \"junk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a04257897240aea2316f6d83420c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import neuron_visualizations as nviz\n",
    "nviz.plot_objects(main_mesh=curent_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Arguments that would be present inside a preprocessing function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predefined arguments for the Neuron constructor\n",
    "\n",
    "decomposition_type=\"meshafterparty\"\n",
    "mesh_correspondence=\"meshparty\" #meshafterparty_adaptive\n",
    "distance_by_mesh_center=True #how the distance is calculated for mesh correspondence\n",
    "meshparty_segment_size = 100\n",
    "meshparty_n_surface_downsampling = 2\n",
    "meshparty_adaptive_correspondence_after_creation=False\n",
    "suppress_preprocessing_print=True\n",
    "computed_attribute_dict=None\n",
    "somas = None\n",
    "branch_skeleton_data=None\n",
    "combine_close_skeleton_nodes = True\n",
    "combine_close_skeleton_nodes_threshold=700\n",
    "ignore_warnings=True\n",
    "suppress_output=False\n",
    "calculate_spines=True\n",
    "widths_to_calculate=[\"no_spine_median_mesh_center\",\n",
    "                \"no_spine_mean_mesh_center\"]\n",
    "fill_hole_size=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments for the preprocess neuron\n",
    "mesh = curent_neuron\n",
    "segment_id=segment_id\n",
    "description=description\n",
    "\n",
    "sig_th_initial_split=15 #for significant splitting meshes in the intial mesh split\n",
    "limb_threshold = 2000 #the mesh faces threshold for a mesh to be qualified as a limb (otherwise too small)\n",
    "filter_end_node_length=4001 #used in cleaning the skeleton during skeletonizations\n",
    "return_no_somas = False\n",
    "\n",
    "decomposition_type=decomposition_type\n",
    "mesh_correspondence=mesh_correspondence\n",
    "distance_by_mesh_center=distance_by_mesh_center\n",
    "meshparty_segment_size =meshparty_segment_size\n",
    "meshparty_n_surface_downsampling = meshparty_n_surface_downsampling\n",
    "somas=somas\n",
    "branch_skeleton_data=branch_skeleton_data\n",
    "combine_close_skeleton_nodes = combine_close_skeleton_nodes\n",
    "combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_processing_tiempo = time.time()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: To process the mesh into a format that can be loaded into the neuron class\n",
    "and used for higher order processing (how to visualize is included)\n",
    "\n",
    "\"\"\"\n",
    "if description is None:\n",
    "    description = \"no_description\"\n",
    "if segment_id is None:\n",
    "    #pick a random segment id\n",
    "    segment_id = np.random.randint(100000000)\n",
    "    print(f\"picking a random 7 digit segment id: {segment_id}\")\n",
    "    description += \"_random_id\"\n",
    "\n",
    "\n",
    "if mesh is None:\n",
    "    if current_mesh_file is None:\n",
    "        raise Exception(\"No mesh or mesh_file file were given\")\n",
    "    else:\n",
    "        current_neuron = trimesh.load_mesh(current_mesh_file)\n",
    "else:\n",
    "    current_neuron = mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ************************ Phase A: Soma and Limb Identification ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 937.5 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 2330 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25552520.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(188198, 3), faces.shape=(400887, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(188198, 3), faces.shape=(400887, 3))>\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece.off\n",
      "xvfb-run -n 8989 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/poisson_633192.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trimesh:face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(247017, 3), faces.shape=(495094, 3))>, <trimesh.Trimesh(vertices.shape=(17738, 3), faces.shape=(35576, 3))>, <trimesh.Trimesh(vertices.shape=(9825, 3), faces.shape=(19694, 3))>, <trimesh.Trimesh(vertices.shape=(8598, 3), faces.shape=(17216, 3))>, <trimesh.Trimesh(vertices.shape=(7369, 3), faces.shape=(14798, 3))>, <trimesh.Trimesh(vertices.shape=(5241, 3), faces.shape=(10522, 3))>, <trimesh.Trimesh(vertices.shape=(5257, 3), faces.shape=(10514, 3))>, <trimesh.Trimesh(vertices.shape=(5143, 3), faces.shape=(10282, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(247017, 3), faces.shape=(495094, 3))>\n",
      "xvfb-run -n 832 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25738801.mls\n",
      "done exporting decimated mesh: neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005047321319580078\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113596963328000_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 30.121978521347046\n",
      "2) Finished: Generating CGAL segmentation for neuron: 32.191709995269775\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 7\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.04583430290222168\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.67572021484375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.12238168716430664\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.795921802520752\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.579901\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 7, 31, 60, 32, 46, 64,  5, 17,  1, 13, 71, 14, 29, 62, 25, 45, 30,\n",
      "       48, 15, 44, 53,  4, 28, 65, 43,  8, 49, 38, 50, 37, 26, 27, 47, 61,\n",
      "       59, 22, 72, 12, 40, 39, 16, 68,  6, 58,  3, 54, 42, 34,  0,  2, 51,\n",
      "       36, 52, 67, 66, 21, 19,  9, 35, 69, 18, 56, 24, 70, 55, 11, 63, 10,\n",
      "       23, 57, 20, 33, 41]), array([0.579901  , 0.335238  , 0.170487  , 0.166577  , 0.156625  ,\n",
      "       0.15256   , 0.15134   , 0.149641  , 0.147473  , 0.146547  ,\n",
      "       0.144557  , 0.142879  , 0.135467  , 0.132712  , 0.129258  ,\n",
      "       0.12903   , 0.126086  , 0.115271  , 0.1115815 , 0.11093   ,\n",
      "       0.110043  , 0.1083295 , 0.107001  , 0.105407  , 0.105382  ,\n",
      "       0.1044845 , 0.1012765 , 0.100433  , 0.0993151 , 0.0961611 ,\n",
      "       0.0950679 , 0.0940922 , 0.09405785, 0.09352525, 0.0927764 ,\n",
      "       0.0919008 , 0.0918646 , 0.09184725, 0.09101805, 0.090419  ,\n",
      "       0.08901065, 0.08874945, 0.0871627 , 0.0862705 , 0.0861988 ,\n",
      "       0.0860742 , 0.0860634 , 0.08196235, 0.0816432 , 0.08158405,\n",
      "       0.0798637 , 0.0793762 , 0.0786742 , 0.0769017 , 0.076535  ,\n",
      "       0.0750867 , 0.0745999 , 0.07031665, 0.0682948 , 0.0682381 ,\n",
      "       0.0632483 , 0.0611939 , 0.0592071 , 0.05774625, 0.0554858 ,\n",
      "       0.055079  , 0.0549049 , 0.046088  , 0.043157  , 0.0413262 ,\n",
      "       0.0408792 , 0.0372433 , 0.0178739 ]))\n",
      "Sizes = [6185, 455, 513, 235, 411, 841, 1456, 1451, 22445, 14457, 599, 1523, 1527, 2025, 626, 937, 111, 515, 3542, 705, 1835, 18462, 453, 533, 2999, 8766, 432, 285, 2877, 1833, 322, 4563, 450, 2526, 4517, 911, 93, 254, 1678, 314, 26, 972, 1081, 63, 2364, 125, 325, 122, 962, 458, 222, 161, 79, 55, 114, 452, 51, 196, 53, 90, 115, 43, 102, 2, 148, 201, 21, 119, 129, 37, 15, 53, 38]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [7]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5987 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_387158.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_387158_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_430941.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_387158.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_387158_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_430941.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.281672788273283\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(17738, 3), faces.shape=(35576, 3))>\n",
      "xvfb-run -n 1258 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25738801.mls\n",
      "done exporting decimated mesh: neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00025081634521484375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113596963328001_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.9635207653045654\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.1018054485321045\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.003613710403442383\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001995563507080078\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007351875305175781\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.04405474662780762\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.4769285\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([15,  1,  0,  2, 12,  5, 14,  6,  9,  4, 17, 11,  3,  8, 18, 16, 19,\n",
      "       10,  7, 13, 20]), array([0.781675  , 0.6908535 , 0.4769285 , 0.463367  , 0.430367  ,\n",
      "       0.425109  , 0.340165  , 0.3031875 , 0.268631  , 0.2652625 ,\n",
      "       0.2322295 , 0.198965  , 0.193465  , 0.157569  , 0.129993  ,\n",
      "       0.127463  , 0.108037  , 0.0981381 , 0.09484735, 0.0608846 ,\n",
      "       0.0605965 ]))\n",
      "Sizes = [307, 112, 5060, 1075, 192, 379, 239, 466, 89, 536, 48, 42, 23, 75, 41, 29, 19, 46, 70, 23, 15]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9852 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_121810.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_121810_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_715367.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_121810.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_121810_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_715367.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 150.1195602118855\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(2513, 3), faces.shape=(5060, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_475998.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 31.58530546816153\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(533, 3), faces.shape=(1075, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(9825, 3), faces.shape=(19694, 3))>\n",
      "xvfb-run -n 9230 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25738801.mls\n",
      "done exporting decimated mesh: neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002582073211669922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113596963328002_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.5908286571502686\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6726374626159668\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002046823501586914\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.0067901611328125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005009651184082031\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.027194976806640625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 2,  4,  0,  5,  9, 12,  7,  8,  3,  1, 11,  6, 10]), array([0.683293  , 0.433097  , 0.387966  , 0.3821515 , 0.267016  ,\n",
      "       0.266519  , 0.2252345 , 0.198815  , 0.1766155 , 0.1391055 ,\n",
      "       0.0718586 , 0.06462535, 0.0452786 ]))\n",
      "Sizes = [500, 522, 1730, 1374, 233, 82, 72, 55, 170, 76, 13, 70, 21]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 5]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 163 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_479293.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_479293_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_588210.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_479293.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_479293_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_588210.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 79.05901102979458\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(870, 3), faces.shape=(1730, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6429 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_500508.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_500508_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_572966.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_500508.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_500508_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_572966.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 37.201724534864006\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(694, 3), faces.shape=(1374, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(8598, 3), faces.shape=(17216, 3))>\n",
      "xvfb-run -n 647 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25738801.mls\n",
      "done exporting decimated mesh: neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00034809112548828125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113596963328003_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.34727978706359863\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.42450857162475586\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0018584728240966797\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.888938903808594e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0043904781341552734\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.023097991943359375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1,  4,  2,  8,  5,  0, 10, 11,  3,  7,  6,  9]), array([0.5098945, 0.455318 , 0.454329 , 0.299416 , 0.239089 , 0.230782 ,\n",
      "       0.219673 , 0.158731 , 0.157616 , 0.1509835, 0.150634 , 0.0645171]))\n",
      "Sizes = [2116, 645, 971, 172, 79, 140, 37, 25, 23, 40, 21, 31]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5303 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_119063.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_119063_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_721676.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_119063.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_119063_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_721676.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 475.20122275637436\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1060, 3), faces.shape=(2116, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_812756.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 459.21682639774923\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(488, 3), faces.shape=(971, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(7369, 3), faces.shape=(14798, 3))>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 6035 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25738801.mls\n",
      "done exporting decimated mesh: neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00026917457580566406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113596963328004_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.38791894912719727\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.45893406867980957\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.001535654067993164\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.863739013671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.003818511962890625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.020246267318725586\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 4, 3, 0, 5, 6, 7, 2, 8]), array([0.7331635, 0.486644 , 0.367135 , 0.347602 , 0.212661 , 0.136781 ,\n",
      "       0.127801 , 0.0668254, 0.0209331]))\n",
      "Sizes = [228, 712, 375, 2257, 39, 15, 23, 32, 13]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9997 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_839869.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_839869_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_947395.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_839869.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_839869_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_947395.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 11.644524174972954\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1110, 3), faces.shape=(2257, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(5241, 3), faces.shape=(10522, 3))>\n",
      "xvfb-run -n 3119 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25738801.mls\n",
      "done exporting decimated mesh: neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00026297569274902344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113596963328005_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.2190546989440918\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.26567625999450684\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0012087821960449219\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.364418029785156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0030481815338134766\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.013650178909301758\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 3,  2,  1,  0,  5,  6,  7,  4,  8,  9, 10]), array([0.620463 , 0.5983475, 0.468727 , 0.461187 , 0.261715 , 0.256757 ,\n",
      "       0.234866 , 0.200842 , 0.1628   , 0.136539 , 0.       ]))\n",
      "Sizes = [225, 730, 829, 523, 43, 105, 82, 43, 11, 33, 2]\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(5257, 3), faces.shape=(10514, 3))>\n",
      "xvfb-run -n 1886 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135969633280/neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135969633280/decimation_meshlab_25738801.mls\n",
      "done exporting decimated mesh: neuron_864691135969633280_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002658367156982422\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113596963328006_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.25753211975097656\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.30070972442626953\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0015053749084472656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.793571472167969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0031571388244628906\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.013563871383666992\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([11,  5,  1,  2,  0, 12, 10,  3,  9,  8,  4,  6,  7]), array([0.7284685, 0.643057 , 0.4877675, 0.439472 , 0.38724  , 0.342216 ,\n",
      "       0.283416 , 0.277213 , 0.231236 , 0.214054 , 0.0705079, 0.0696017,\n",
      "       0.0664199]))\n",
      "Sizes = [194, 844, 226, 433, 381, 165, 87, 81, 124, 37, 7, 20, 23]\n",
      "valid_soma_segments_width\n",
      "breaking inner loop because 2 soma fails in a row\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 202.72265243530273\n",
      "Before Filtering the number of somas found = 1\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 22\n",
      "viable_meshes = [0]\n",
      "There were 21 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(3185, 3), faces.shape=(6185, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(188198, 3), faces.shape=(400103, 3))>\n",
      "\n",
      "inside Soma subtraction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(139723, 3), faces.shape=(297223, 3))>, <trimesh.Trimesh(vertices.shape=(44666, 3), faces.shape=(94317, 3))>]\n",
      "There were 2 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(139723, 3), faces.shape=(297223, 3))>, <trimesh.Trimesh(vertices.shape=(44666, 3), faces.shape=(94317, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.767\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(139723, 3), faces.shape=(297223, 3))>, <trimesh.Trimesh(vertices.shape=(44666, 3), faces.shape=(94317, 3))>]\n",
      "Total time for Subtract Soam = 0.7679281234741211\n",
      "mesh_pieces_without_soma_stacked = <trimesh.Trimesh(vertices.shape=(184389, 3), faces.shape=(391540, 3))>\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.29358792304992676\n",
      "soma_faces = [  9527   9528   9529 ... 338364 338398 338399]\n",
      "soma_meshes = <trimesh.Trimesh(vertices.shape=(4193, 3), faces.shape=(8563, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9981 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_937772.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_937772_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_791919.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_937772.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_937772_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_791919.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.617488642931529\n",
      "Soma List = [<trimesh.Trimesh(vertices.shape=(4163, 3), faces.shape=(8525, 3))>]\n",
      "soma_mesh_list_centers = [array([1441221.36151814, 1049386.68676435,  668536.78025462])]\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Doing the soma detection\n",
    "if somas is None:\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                             current_neuron.vertices,\n",
    "                                             current_neuron.faces)\n",
    "else:\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = somas\n",
    "\n",
    "# geting the soma centers\n",
    "if len(soma_mesh_list) <= 0:\n",
    "    print(f\"**** No Somas Found for Mesh {segment_id} so just one mesh\")\n",
    "    soma_mesh_list_centers = []\n",
    "    if return_no_somas:\n",
    "        return_value= soma_mesh_list_centers\n",
    "    raise Exception(\"Processing of No Somas is not yet implemented yet\")\n",
    "else:\n",
    "    #compute the soma centers\n",
    "    print(f\"Soma List = {soma_mesh_list}\")\n",
    "\n",
    "    soma_mesh_list_centers = sm.find_soma_centroids(soma_mesh_list)\n",
    "    print(f\"soma_mesh_list_centers = {soma_mesh_list_centers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 35\n",
      "There were 34 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n"
     ]
    }
   ],
   "source": [
    "#--- 2) getting the soma submeshes that are connected to each soma and identifiying those that aren't (and eliminating any mesh pieces inside the soma)\n",
    "\n",
    "main_mesh_total = current_neuron\n",
    "\n",
    "\n",
    "#finding the mesh pieces that contain the soma\n",
    "#splitting the current neuron into distinct pieces\n",
    "split_meshes = tu.split_significant_pieces(\n",
    "                            main_mesh_total,\n",
    "                            significance_threshold=sig_th_initial_split,\n",
    "                            print_flag=False)\n",
    "\n",
    "print(f\"# total split meshes = {len(split_meshes)}\")\n",
    "\n",
    "\n",
    "#returns the index of the split_meshes index that contains each soma    \n",
    "containing_mesh_indices = sm.find_soma_centroid_containing_meshes(soma_mesh_list,\n",
    "                                        split_meshes)\n",
    "\n",
    "# filtering away any of the inside floating pieces: \n",
    "non_soma_touching_meshes = [m for i,m in enumerate(split_meshes)\n",
    "                 if i not in list(containing_mesh_indices.values())]\n",
    "\n",
    "\n",
    "#Adding the step that will filter away any pieces that are inside the soma\n",
    "if len(non_soma_touching_meshes) > 0 and len(soma_mesh_list) > 0:\n",
    "    \"\"\"\n",
    "    *** want to save these pieces that are inside of the soma***\n",
    "    \"\"\"\n",
    "\n",
    "    non_soma_touching_meshes,inside_pieces = sm.filter_away_inside_soma_pieces(soma_mesh_list,non_soma_touching_meshes,\n",
    "                                    significance_threshold=sig_th_initial_split,\n",
    "                                    return_inside_pieces = True)                                                      \n",
    "\n",
    "\n",
    "split_meshes # the meshes of the original mesh\n",
    "containing_mesh_indices #the mapping of each soma centroid to the correct split mesh\n",
    "soma_containing_meshes = sm.grouping_containing_mesh_indices(containing_mesh_indices)\n",
    "\n",
    "soma_touching_meshes = [split_meshes[k] for k in soma_containing_meshes.keys()]\n",
    "\n",
    "\n",
    "#     print(f\"# of non soma touching seperate meshes = {len(non_soma_touching_meshes)}\")\n",
    "#     print(f\"# of inside pieces = {len(inside_pieces)}\")\n",
    "print(f\"# of soma containing seperate meshes = {len(soma_touching_meshes)}\")\n",
    "print(f\"meshes with somas = {soma_containing_meshes}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(580791, 3), faces.shape=(1178636, 3))>, <trimesh.Trimesh(vertices.shape=(186522, 3), faces.shape=(377875, 3))>, <trimesh.Trimesh(vertices.shape=(4392, 3), faces.shape=(8867, 3))>, <trimesh.Trimesh(vertices.shape=(928, 3), faces.shape=(1794, 3))>, <trimesh.Trimesh(vertices.shape=(180, 3), faces.shape=(340, 3))>]\n",
      "There were 5 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(580791, 3), faces.shape=(1178636, 3))>, <trimesh.Trimesh(vertices.shape=(186522, 3), faces.shape=(377875, 3))>, <trimesh.Trimesh(vertices.shape=(4392, 3), faces.shape=(8867, 3))>, <trimesh.Trimesh(vertices.shape=(928, 3), faces.shape=(1794, 3))>, <trimesh.Trimesh(vertices.shape=(180, 3), faces.shape=(340, 3))>]\n",
      "Total Time for soma mesh cancellation = 3.072\n",
      "Total time for Subtract Soam = 3.072704553604126\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 1.1262123584747314\n",
      "Total time for Original_mesh_faces_map for somas= 0.9405703544616699\n",
      "Total time for sig_non_soma_pieces= 1.8494961261749268\n",
      "Total time for split= 0.04053330421447754\n",
      "Total time for mesh_pieces_connectivity= 16.630496740341187\n",
      "# of insignificant_limbs = 2 with trimesh : [<trimesh.Trimesh(vertices.shape=(928, 3), faces.shape=(1794, 3))>, <trimesh.Trimesh(vertices.shape=(180, 3), faces.shape=(340, 3))>]\n"
     ]
    }
   ],
   "source": [
    "tu = reload(tu)\n",
    "#--- 3)  Soma Extraction was great (but it wasn't the original soma faces), so now need to get the original soma faces and the original non-soma faces of original pieces\n",
    "\n",
    "#     sk.graph_skeleton_and_mesh(other_meshes=[soma_meshes])\n",
    "\n",
    "\"\"\"\n",
    "for each soma touching mesh get the following:\n",
    "1) original soma meshes\n",
    "2) significant mesh pieces touching these somas\n",
    "3) The soma connectivity to each of the significant mesh pieces\n",
    "-- later will just translate the \n",
    "\n",
    "\n",
    "Process: \n",
    "\n",
    "1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "2) Subtact all soma faces from original mesh\n",
    "3) Find all significant mesh pieces\n",
    "4) Backtrack significant mesh pieces to orignal mesh and find connectivity of each to all\n",
    "   the available somas\n",
    "Conclusion: Will have connectivity map\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "soma_touching_mesh_data = dict()\n",
    "\n",
    "for z,(mesh_idx, soma_idxes) in enumerate(soma_containing_meshes.items()):\n",
    "    soma_touching_mesh_data[z] = dict()\n",
    "    print(f\"\\n\\n----Working on soma-containing mesh piece {z}----\")\n",
    "\n",
    "    #1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "    current_mesh = split_meshes[mesh_idx]\n",
    "\n",
    "    current_soma_mesh_list = [soma_mesh_list[k] for k in soma_idxes]\n",
    "\n",
    "    current_time = time.time()\n",
    "    mesh_pieces_without_soma = sm.subtract_soma(current_soma_mesh_list,current_mesh,\n",
    "                                                significance_threshold=250)\n",
    "    print(f\"Total time for Subtract Soam = {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    mesh_pieces_without_soma_stacked = tu.combine_meshes(mesh_pieces_without_soma)\n",
    "\n",
    "    # find the original soma faces of mesh\n",
    "    soma_faces = tu.original_mesh_faces_map(current_mesh,mesh_pieces_without_soma_stacked,matching=False)\n",
    "    print(f\"Total time for Original_mesh_faces_map for mesh_pieces without soma= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "    soma_meshes = current_mesh.submesh([soma_faces],append=True,repair=False)\n",
    "\n",
    "    # finding the non-soma original faces\n",
    "    non_soma_faces = tu.original_mesh_faces_map(current_mesh,soma_meshes,matching=False)\n",
    "    non_soma_stacked_mesh = current_mesh.submesh([non_soma_faces],append=True,repair=False)\n",
    "\n",
    "    print(f\"Total time for Original_mesh_faces_map for somas= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    # 3) Find all significant mesh pieces\n",
    "    sig_non_soma_pieces,insignificant_limbs = tu.split_significant_pieces(non_soma_stacked_mesh,significance_threshold=limb_threshold,\n",
    "                                                     return_insignificant_pieces=True)\n",
    "\n",
    "    print(f\"Total time for sig_non_soma_pieces= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    soma_touching_mesh_data[z][\"branch_meshes\"] = sig_non_soma_pieces\n",
    "\n",
    "    #4) Backtrack significant mesh pieces to orignal mesh and find connectivity of each to all the available somas\n",
    "    # get all the seperate mesh faces\n",
    "\n",
    "    #How to seperate the mesh faces\n",
    "    seperate_soma_meshes,soma_face_components = tu.split(soma_meshes,only_watertight=False)\n",
    "    #take the top largest ones depending how many were originally in the soma list\n",
    "    seperate_soma_meshes = seperate_soma_meshes[:len(soma_mesh_list)]\n",
    "    soma_face_components = soma_face_components[:len(soma_mesh_list)]\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_meshes\"] = seperate_soma_meshes\n",
    "\n",
    "    print(f\"Total time for split= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    soma_to_piece_connectivity = dict()\n",
    "    soma_to_piece_touching_vertices = dict()\n",
    "    soma_to_piece_touching_vertices_idx = dict()\n",
    "    limb_root_nodes = dict()\n",
    "    \n",
    "    m_vert_graph = tu.mesh_vertex_graph(current_mesh)\n",
    "    \n",
    "    for i,curr_soma in enumerate(seperate_soma_meshes):\n",
    "        (connected_mesh_pieces,\n",
    "         connected_mesh_pieces_vertices,\n",
    "         connected_mesh_pieces_vertices_idx) = tu.mesh_pieces_connectivity(\n",
    "                        main_mesh=current_mesh,\n",
    "                        central_piece=curr_soma,\n",
    "                        periphery_pieces = sig_non_soma_pieces,\n",
    "                        return_vertices = True,\n",
    "                        return_vertices_idx=True)\n",
    "        #print(f\"soma {i}: connected_mesh_pieces = {connected_mesh_pieces}\")\n",
    "        soma_to_piece_connectivity[i] = connected_mesh_pieces\n",
    "\n",
    "        soma_to_piece_touching_vertices[i] = dict()\n",
    "        for piece_index,piece_idx in enumerate(connected_mesh_pieces):\n",
    "            limb_root_nodes[piece_idx] = connected_mesh_pieces_vertices[piece_index][0]\n",
    "            \n",
    "            \"\"\" Old way of finding vertex connected components on a mesh without trimesh function\n",
    "            #find the number of touching groups and save those \n",
    "            soma_touching_graph = m_vert_graph.subgraph(connected_mesh_pieces_vertices_idx[piece_index])\n",
    "            soma_con_comp = [current_mesh.vertices[np.array(list(k)).astype(\"int\")] for k in list(nx.connected_components(soma_touching_graph))]\n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = soma_con_comp\n",
    "            \"\"\"\n",
    "            \n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = tu.split_vertex_list_into_connected_components(\n",
    "                                                vertex_indices_list=connected_mesh_pieces_vertices_idx[piece_index],\n",
    "                                                mesh=current_mesh, \n",
    "                                                vertex_graph=m_vert_graph, \n",
    "                                                return_coordinates=True\n",
    "                                               )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#         border_debug = False\n",
    "#         if border_debug:\n",
    "#             print(f\"soma_to_piece_connectivity = {soma_to_piece_connectivity}\")\n",
    "#             print(f\"soma_to_piece_touching_vertices = {soma_to_piece_touching_vertices}\")\n",
    "\n",
    "\n",
    "    print(f\"Total time for mesh_pieces_connectivity= {time.time() - current_time}\")\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_to_piece_connectivity\"] = soma_to_piece_connectivity\n",
    "\n",
    "print(f\"# of insignificant_limbs = {len(insignificant_limbs)} with trimesh : {insignificant_limbs}\")\n",
    "\n",
    "\n",
    "\n",
    "# Lets have an alert if there was more than one soma disconnected meshes\n",
    "if len(soma_touching_mesh_data.keys()) > 1:\n",
    "    raise Exception(\"More than 1 disconnected meshes that contain somas\")\n",
    "\n",
    "current_mesh_data = soma_touching_mesh_data\n",
    "soma_containing_idx = 0\n",
    "\n",
    "#doing inversion of the connectivity and touching vertices\n",
    "piece_to_soma_touching_vertices = gu.flip_key_orders_for_dict(soma_to_piece_touching_vertices)\n",
    "\n",
    "\n",
    "# ****Soma Touching mesh Data has the branches and the connectivity (So this is where you end up skipping if you don't have somas)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e3f27e95d546909db14918a6ddcd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=soma_mesh_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process that will start for each limb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Working on Proper Limb # 0 ---------\n",
      "Time for preparing soma vertices and root: 1.0251998901367188e-05\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d1144fcd3341c7bcd94fdf483961e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=580790.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:41<00:00, 161.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 167.2790961265564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:888: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:921: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branches_touching_root = [694]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:949: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 56685\n",
      "Working on path [3722. 3747. 3772. 3796. 3819. 3842. 3860.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [4427. 4444. 4460. 4476. 4498. 4523. 4531.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [4495. 4511. 4527. 4542. 4553. 4566.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [5491. 5501. 5512. 5526. 5533.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [5632. 5655. 5682. 5704. 5725. 5731.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [6464. 6465. 6467.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [9080. 9089. 9104. 9118. 9132. 9151.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [10798. 10827. 10847. 10872. 10896. 10913.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [11166. 11191. 11215. 11241. 11266. 11293. 11322. 11347.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [15159. 15185. 15196.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [16086. 16090. 16097. 16104. 16109. 16115. 16117. 16118.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [16644. 16669. 16695. 16711.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [16670. 16704. 16744. 16779. 16820. 16862. 16896. 16916.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [56696. 16712. 16714. 16716. 16718.]\n",
      "path_degrees = [4, 2, 2, 2, 3]\n",
      "Working on path [18313. 18362. 18409. 18459. 18507. 18558. 18607. 18620.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [56699. 18644. 18679. 18708. 18733. 18764.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 3]\n",
      "Working on path [18737. 18752. 56700.]\n",
      "path_degrees = [3, 2, 5]\n",
      "Working on path [18807. 18813. 18824. 18828. 18829.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [22019. 22020. 22017. 22018. 22022. 22026. 22028.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [26630. 26721. 26796. 26871. 26955. 27032. 27037.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [26652. 26697. 26743. 26781. 26787.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [56704. 27107. 27168. 27183.]\n",
      "path_degrees = [4, 2, 2, 3]\n",
      "Working on path [29081. 29148. 29217. 29293. 29355.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [56707. 29433. 29506. 29580. 29646. 29728. 29801. 29847.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [31550. 31588. 31634. 31695. 31700.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [31723. 31758. 31802. 31841. 31888. 31944. 31978.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [32637. 32680. 32718. 32755. 32781. 32818. 32845. 32875.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [35967. 36043. 36117. 36183. 36257. 36327. 36392. 36417.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [37034. 37106. 37182. 37257. 37334. 37363.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [37216. 37254. 37286. 37328. 37353.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [37260. 37347. 37423. 37503. 37581. 37659. 37697.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [37280. 37305. 37339. 56714.]\n",
      "path_degrees = [3, 2, 2, 4]\n",
      "Working on path [37675. 37751. 37831. 37951. 38035. 38141. 38228. 38273.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [37974. 38033. 38092. 38144. 38180. 38181.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [56718. 38252. 38328. 38373. 38415. 38419.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 3]\n",
      "Working on path [38406. 38479. 38559. 38631. 38708. 38789. 38865. 38871.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [42509. 42579. 42651. 42721. 42803. 42880. 42958. 43017.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [56721. 43052. 43105. 43148. 43190. 43231. 43274. 43289.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [44443. 44514. 44579. 44645. 44710. 44779. 44850. 44874.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [44729. 44752. 44777. 44803. 44832. 44869. 44871.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [56723. 44926. 44980. 45029. 45082. 45089.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 3]\n",
      "Working on path [44929. 44975. 45022. 45061. 45103. 45123.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [45571. 45567. 45561. 45564. 45569. 45577. 45588.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [46546. 46567. 46572.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [47188. 47197. 47200. 47208. 47214.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [48348. 48401. 48461. 48474.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [49158. 49186. 49220. 49238.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [50325. 50363. 50395. 50427. 50432.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [51230. 51282. 51332. 51377. 51424. 51471. 51514. 51542.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [51263. 51298. 51334. 51371. 51410. 51416.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [52534. 52571. 52609. 52644. 52679. 52695.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 4]\n",
      "Working on path [53151. 53188. 53222. 53259. 53290. 53323. 53356. 53383.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:974: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 694, len(kept_branches_idx) = 643\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.04128746366798494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a73019826a4a8c81766d186a1aa906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=501.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2065b4729b14988b19db0cc05d37768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=643.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:972: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposing first pass: 181.53709650039673\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [327, 504, 42, 32, 1458, 698, 1188, 3059, 311, 1089, 512, 5410, 2401, 1473, 130, 179, 858, 3255, 135, 121, 1058, 6540, 219, 1068, 1589, 121, 573, 1325, 1507, 1437, 759, 203, 1408, 621, 927, 1631, 3477, 49, 2407, 204, 197, 2226, 918, 2740, 548, 171, 1453, 1657, 662, 744, 1042, 1097, 5157, 6545, 2688, 4073]\n",
      "mesh_large_connectivity: 3.57283878326416\n",
      "Finding MAP candidates connected components: 0.0009295940399169922\n",
      "len(filtered_pieces) = 15\n",
      "skeleton_connectivity_MP : 4.59103536605835\n",
      "Grouping MP Sublimbs by Graph: 1.8732874393463135\n",
      "Divinding into MP and MAP pieces: 1.9073486328125e-06\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.04695010185241699\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 5238 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_257692.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 520 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_47450.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_47450_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_853227.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_47450.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_47450_fill_holes.off\n",
      "-----Time for Screened Poisson= 10.993775844573975\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c749f0625f5c4a5c93a75f3fa32eebce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9d0c6e36e14144a0bbdc7e332c7df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.02514052391052246\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 11.408618688583374\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.0013701915740966797\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n",
      "no small end nodes to get rid of so returning whole skeleton\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (18, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 11.428004741668701\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9826ffe10f45dc86a9fb7096329349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.2666585445404053\n",
      "mesh_correspondence_first_pass: 0.26669955253601074\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (18, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (18, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.0791044776119403\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd760f8ce7541b7b1b130477bfce874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7605f5efb8594f1198ac1933197418b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 11.83207893371582\n",
      "correspondence_1_to_1: 0.09035587310791016\n",
      "--- Working on MAP piece 1---\n",
      "MAP Filtering Soma Pieces: 0.0401606559753418\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8106 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_381912.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8776 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_157.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_157_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_455511.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_157.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_157_fill_holes.off\n",
      "-----Time for Screened Poisson= 11.701351881027222\n",
      "     Starting Calcification\n",
      "node_degrees = [3 3 4]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d6c7dea12f41a583d9d525c3bf09ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8763e56e8942ac893ba92c9dfd7c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.07058429718017578\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "node_degrees = [3 3 4]\n",
      "    Total time for skeletonizing branch: 13.67656135559082\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.0037860870361328125\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505b10c758084993b1458a50c3977347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (20, 2, 3)\n",
      "type(branch_subgraph) = <class 'networkx_utils.GraphOrderedEdges'>\n",
      "in remove edge\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 13.815099716186523\n",
      "Working on limb correspondence for #1 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd418a32cdfd41beae264eccdea488c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 1.1745452880859375\n",
      "mesh_correspondence_first_pass: 1.1745924949645996\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (19, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (19, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.32547321142123836\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899c599df86d40de9c47601dbdc8e001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cec56278d742b692dcdd923208b288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #1 mesh processing = 15.551871061325073\n",
      "correspondence_1_to_1: 0.5217452049255371\n",
      "--- Working on MAP piece 2---\n",
      "MAP Filtering Soma Pieces: 0.27567315101623535\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 4252 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_141264.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8337 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_36351.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_36351_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_203035.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_36351.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_36351_fill_holes.off\n",
      "-----Time for Screened Poisson= 11.806235551834106\n",
      "     Starting Calcification\n",
      "node_degrees = [2 2 4]\n",
      "node_degrees = [3 3 2 2 3 2 2]\n",
      "node_degrees = [3 2 3]\n",
      "node_degrees = [3 2 3]\n",
      "node_degrees = [3 2 2 2 3 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ff824f8d3148b98aa1feb64f224196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff19b995dac47c6bffa134d57cd5921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.03162813186645508\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "node_degrees = [3 3 2 2 3 2 2]\n",
      "    Total time for skeletonizing branch: 13.38739538192749\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.23123788833618164\n",
      "sbv[0].reshape(-1,3) = [[1448748. 1048383.  667464.]]\n",
      "closest_sk_pt_coord BEFORE = [1450210. 1048010.  667344.]\n",
      "current_skeleton.shape = (93, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1450210. 1048010.  667344.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1450210., 1048010.,  667344.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.33387231826782227\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[1450210. 1048010.  667344.]]\n",
      "Number of end_nodes BEFORE filtering = 14\n",
      "all_single_nodes_to_eliminate = [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088a3109c64b42de859c17fcf71bbda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (70, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 1 valid paths to replace\n",
      "valid_paths = [array([39., 41.])]\n",
      "valid_path_lengths = [589.6744864753773]\n",
      "length of Graph = 70\n",
      "Working on path [39. 41.]\n",
      "path_degrees = [3, 3]\n",
      "skeletonize_and_clean_connected_branch_CGAL: 13.823211908340454\n",
      "Working on limb correspondence for #2 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c6704d211a407ba924d2846255e381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 2.634873628616333\n",
      "mesh_correspondence_first_pass: 2.6349358558654785\n",
      "Limb decomposed into 7 branches\n",
      "divided_skeleton_graph_recovered = (69, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (69, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "**** Warning: There were redundant edges in the skeleton*****\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (6, 7)\n",
      "empty_indices % = 0.15593285249250016\n",
      " conflict_indices % = 0.10435948171315504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae7e7f1102f4acfb832f51dac35f9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0b50f62fea41e1ab297c4c48e3d612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #2 mesh processing = 18.51858162879944\n",
      "correspondence_1_to_1: 1.7849400043487549\n",
      "--- Working on MAP piece 3---\n",
      "MAP Filtering Soma Pieces: 0.04069232940673828\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 1192 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_269607.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 5301 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_19560.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_19560_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_326513.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_19560.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_19560_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.4944539070129395\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99829a6e53fa411eb4c480141f19bfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03aa91f6ac2243e999702f79635dadda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.021303892135620117\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 6.820257186889648\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.03496408462524414\n",
      "sbv[0].reshape(-1,3) = [[1442952. 1046420.  667023.]]\n",
      "closest_sk_pt_coord BEFORE = [1444690. 1045770.  666644.]\n",
      "current_skeleton.shape = (16, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1444690. 1045770.  666644.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "sbv[0].reshape(-1,3) = [[1443884.  1046466.   667978.1]]\n",
      "closest_sk_pt_coord BEFORE = [1444690. 1045770.  666644.]\n",
      "current_skeleton.shape = (16, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1444690. 1045770.  666644.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "sbv[0].reshape(-1,3) = [[1443405.  1046716.   667119.2]]\n",
      "closest_sk_pt_coord BEFORE = [1444690. 1045770.  666644.]\n",
      "current_skeleton.shape = (16, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1444690. 1045770.  666644.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1444690., 1045770.,  666644.],\n",
      "       [1444690., 1045770.,  666644.],\n",
      "       [1444690., 1045770.,  666644.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.15823841094970703\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[1444690. 1045770.  666644.]\n",
      " [1444690. 1045770.  666644.]\n",
      " [1444690. 1045770.  666644.]]\n",
      "Number of end_nodes BEFORE filtering = 4\n",
      "all_single_nodes_to_eliminate = [0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86f5df56b8f4a1ba756d4c0a50d6206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (13, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.024103164672852\n",
      "Working on limb correspondence for #3 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f3cb77055f4f7fa610758aaf866569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.21252703666687012\n",
      "mesh_correspondence_first_pass: 0.21258068084716797\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (13, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (13, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.2535793827553293\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc05c1157f564b48a1e37d3789c07329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "Took 0 iterations to expand the label back\n",
      "Took 0 iterations to expand the label back\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc26371e84c495daabe1c55a839a185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #3 mesh processing = 7.445226192474365\n",
      "correspondence_1_to_1: 0.16771340370178223\n",
      "--- Working on MAP piece 4---\n",
      "MAP Filtering Soma Pieces: 0.04199624061584473\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 4565 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_686430.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 7742 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_94044.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_94044_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_959867.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_94044.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_94044_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.648805618286133\n",
      "     Starting Calcification\n",
      "file /notebooks/Platinum_Decomp_Fusion/temp/None_0_skeleton.cgal not found so skipping\n",
      "No skeletons to stack so returning empty list\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a667d0198d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                    \u001b[0mwidth_threshold_MAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                    \u001b[0msize_threshold_MAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                    \u001b[0msurface_reconstruction_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                    )\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#Storing all of the data to be sent to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/preprocessing_vp2.py\u001b[0m in \u001b[0;36mpreprocess_limb\u001b[0;34m(mesh, soma_touching_vertices_dict, distance_by_mesh_center, meshparty_segment_size, meshparty_n_surface_downsampling, combine_close_skeleton_nodes, combine_close_skeleton_nodes_threshold, filter_end_node_length, use_meshafterparty, perform_cleaning_checks, width_threshold_MAP, size_threshold_MAP, use_surface_after_CGAL, surface_reconstruction_size, move_MAP_stitch_to_end_or_branch, distance_to_move_point_threshold, run_concept_network_checks, return_concept_network, return_concept_network_starting_info, verbose, print_fusion_steps)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mcombine_close_skeleton_nodes_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombine_close_skeleton_nodes_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0muse_surface_after_CGAL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_surface_after_CGAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         surface_reconstruction_size=surface_reconstruction_size)\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurr_limb_endpoints_must_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mskeletonize_and_clean_connected_branch_CGAL\u001b[0;34m(mesh, curr_soma_to_piece_touching_vertices, total_border_vertices, filter_end_node_length, perform_cleaning_checks, combine_close_skeleton_nodes, combine_close_skeleton_nodes_threshold, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   4285\u001b[0m     \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4286\u001b[0m     \u001b[0mclean_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4287\u001b[0;31m     \u001b[0mcurrent_skeleton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskeletonize_connected_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4289\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Checking connected components after skeletonize_connected_branch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mskeletonize_connected_branch\u001b[0;34m(current_mesh, output_folder, delete_temp_files, name, surface_reconstruction_size, surface_reconstruction_width, n_surface_downsampling, n_surface_samples, skeleton_print, mesh_subtraction_distance_threshold, mesh_subtraction_buffer, max_stitch_distance, current_min_edge, close_holes, limb_name, use_surface_after_CGAL, remove_cycles)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremove_cycles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m                 \u001b[0msignificant_poisson_skeleton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_cycles_from_skeleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignificant_poisson_skeleton\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignificant_poisson_skeleton\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mremove_cycles_from_skeleton\u001b[0;34m(skeleton, max_cycle_distance, verbose, check_cycles_at_end)\u001b[0m\n\u001b[1;32m   4456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4457\u001b[0m     \u001b[0;31m#A) Convert the skeleton into a graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4458\u001b[0;31m     \u001b[0mskeleton_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_skeleton_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskeleton\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4459\u001b[0m     \u001b[0;31m#B) Find all cycles in the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4460\u001b[0m     \u001b[0mcycles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all_cycles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskeleton_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mconvert_skeleton_to_graph\u001b[0;34m(staring_edges, stitch_print, combine_node_dist, node_matching_size_threshold)\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0mstitch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m     \u001b[0mall_skeleton_vertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaring_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m     \u001b[0munique_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_skeleton_vertices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[0;31m#need to merge unique indices so if within a certain range of each other then merge them together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "sk = reload(sk)\n",
    "tu = reload(tu)\n",
    "cu = reload(cu)\n",
    "m_sk = reload(m_sk)\n",
    "pre = reload(pre)\n",
    "xu = reload(xu)\n",
    "nu = reload(nu)\n",
    "gu = reload(gu)\n",
    "\n",
    "\n",
    "proper_time = time.time()\n",
    "\n",
    "#The containers that will hold the final data for the preprocessed neuron\n",
    "limb_correspondence=dict()\n",
    "limb_network_stating_info = dict()\n",
    "\n",
    "# ---------- Part A: skeletonization and mesh decomposition --------- #\n",
    "skeleton_time = time.time()\n",
    "\n",
    "for curr_limb_idx,limb_mesh_mparty in enumerate(current_mesh_data[0][\"branch_meshes\"]):\n",
    "    \n",
    "    #Arguments to pass to the specific function (when working with a limb)\n",
    "    soma_touching_vertices_dict = piece_to_soma_touching_vertices[curr_limb_idx]\n",
    "    \n",
    "#     if curr_limb_idx != 10:\n",
    "#         continue\n",
    "    \n",
    "    curr_limb_time = time.time()\n",
    "    print(f\"\\n\\n----- Working on Proper Limb # {curr_limb_idx} ---------\")\n",
    "    \n",
    "\n",
    "    limb_correspondence_individual,network_starting_info = pre.preprocess_limb(mesh=limb_mesh_mparty,\n",
    "                   soma_touching_vertices_dict = soma_touching_vertices_dict,\n",
    "                   return_concept_network = False, \n",
    "                   return_concept_network_starting_info=True,\n",
    "                   width_threshold_MAP=500,\n",
    "                   size_threshold_MAP=2000,\n",
    "                   surface_reconstruction_size=1000,                                                            \n",
    "                   )\n",
    "    #Storing all of the data to be sent to \n",
    "    \n",
    "    limb_correspondence[curr_limb_idx] = limb_correspondence_individual\n",
    "    limb_network_stating_info[curr_limb_idx] = network_starting_info\n",
    "    \n",
    "#     raise Exception(\"Done with #10\")\n",
    "    \n",
    "    \n",
    "print(f\"Total time for Skeletonization and Mesh Correspondence = {time.time() - skeleton_time}\")\n",
    "\n",
    "pre=reload(pre)\n",
    "neuron=reload(neuron)\n",
    "nru = reload(nru)\n",
    "# ---------- Part B: Stitching on floating pieces --------- #\n",
    "floating_stitching_time = time.time()\n",
    "\n",
    "limb_correspondence_with_floating_pieces = pre.attach_floating_pieces_to_limb_correspondence(\n",
    "        limb_correspondence,\n",
    "        floating_meshes=non_soma_touching_meshes,\n",
    "        floating_piece_face_threshold = 600,\n",
    "        max_stitch_distance=8000,\n",
    "        distance_to_move_point_threshold = 4000,\n",
    "        verbose = False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total time for stitching floating pieces = {time.time() - floating_stitching_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Part C: Computing Concept Networks --------- #\n",
    "concept_network_time = time.time()\n",
    "\n",
    "limb_concept_networks=dict()\n",
    "limb_labels=dict()\n",
    "\n",
    "for curr_limb_idx,limb_mesh_mparty in enumerate(current_mesh_data[0][\"branch_meshes\"]):\n",
    "    limb_to_soma_concept_networks = pre.calculate_limb_concept_networks(limb_correspondence_with_floating_pieces[curr_limb_idx],\n",
    "                                                                        run_concept_network_checks=True,\n",
    "                                                                       **limb_network_stating_info[curr_limb_idx])   \n",
    "\n",
    "\n",
    "\n",
    "    limb_concept_networks[curr_limb_idx] = limb_to_soma_concept_networks\n",
    "    limb_labels[curr_limb_idx]= \"Unlabeled\"\n",
    "    \n",
    "print(f\"Total time for Concept Networks = {time.time() - concept_network_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preprocessed_data= dict(\n",
    "    soma_meshes = current_mesh_data[0][\"soma_meshes\"],\n",
    "    soma_to_piece_connectivity = current_mesh_data[0][\"soma_to_piece_connectivity\"],\n",
    "    soma_sdfs = total_soma_list_sdf,\n",
    "    insignificant_limbs=insignificant_limbs,\n",
    "    non_soma_touching_meshes=non_soma_touching_meshes,\n",
    "    inside_pieces=inside_pieces,\n",
    "    limb_correspondence=limb_correspondence_with_floating_pieces,\n",
    "    limb_concept_networks=limb_concept_networks,\n",
    "    limb_network_stating_info=limb_network_stating_info,\n",
    "    limb_labels=limb_labels,\n",
    "    limb_meshes=current_mesh_data[0][\"branch_meshes\"],\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "print(f\"Total time for all limb decomps = {time.time() - proper_time}\")\n",
    "\n",
    "#864049.29563888 1004924.982468    884750.28428994\n",
    "\n",
    "neuron_obj = neuron.Neuron(\n",
    "                mesh=curent_neuron,\n",
    "                 segment_id=segment_id,\n",
    "                 description=description,\n",
    "                 preprocessed_data=preprocessed_data,\n",
    "#                  decomposition_type=\"meshafterparty\",\n",
    "#                  mesh_correspondence=\"meshparty\", #meshafterparty_adaptive\n",
    "#                  distance_by_mesh_center=True, #how the distance is calculated for mesh correspondence\n",
    "#                  meshparty_segment_size = 0,\n",
    "#                  meshparty_n_surface_downsampling = 0,\n",
    "#                  meshparty_adaptive_correspondence_after_creation=False,\n",
    "#                 suppress_preprocessing_print=True,\n",
    "#                  computed_attribute_dict=None,\n",
    "#                  somas = None,\n",
    "#                  branch_skeleton_data=None,\n",
    "#                  combine_close_skeleton_nodes = True,\n",
    "#                 combine_close_skeleton_nodes_threshold=700,\n",
    "    \n",
    "    \n",
    "                ignore_warnings=True,\n",
    "                suppress_output=False,\n",
    "                calculate_spines=True,\n",
    "                widths_to_calculate=[\"no_spine_median_mesh_center\"]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_spines(neuron_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_soma_limb_concept_network(neuron_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.visualize_neuron(neuron_obj,\n",
    "                      visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending the data to the Neuron Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nru = reload(nru)\n",
    "save_time = time.time()\n",
    "neuron_obj.save_compressed_neuron(output_folder=\"/notebooks/test_neurons/Fusion_decomp/\",\n",
    "                                 export_mesh=True,\n",
    "                                 suppress_output=True)\n",
    "print(f\"Save time = {time.time() - save_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nru = reload(nru)\n",
    "reload_time = time.time()\n",
    "recovered_neuron = nru.decompress_neuron(filepath=\"./12345_double_soma\",\n",
    "                     original_mesh=\"./12345_double_soma\")\n",
    "print(f\"Save time = {time.time() - reload_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_visualizations as nviz\n",
    "returned_colors = nviz.visualize_neuron(recovered_neuron,\n",
    "                     visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=dict(L6=\"all\"),\n",
    "                                       return_color_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
