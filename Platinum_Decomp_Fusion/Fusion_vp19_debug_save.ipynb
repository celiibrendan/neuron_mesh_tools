{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2020-11-18 01:45:02,955 - trimesh_repair - Need to pip install annotationframeworkclient to repair mesh with pychunkedgraph\n",
      "WARNING - 2020-11-18 01:45:02,957 - trimesh_io - Need to pip install annotationframeworkclient to use dataset_name parameters\n",
      "INFO - 2020-11-18 01:45:02,964 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2020-11-18 01:45:02,965 - settings - Setting database.user to celiib\n",
      "INFO - 2020-11-18 01:45:02,965 - settings - Setting database.password to newceliipass\n"
     ]
    }
   ],
   "source": [
    "import skeleton_utils as sk\n",
    "import soma_extraction_utils as sm\n",
    "import trimesh_utils as tu\n",
    "import trimesh\n",
    "import numpy_utils as nu\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import networkx as nx\n",
    "import time\n",
    "import compartment_utils as cu\n",
    "import networkx_utils as xu\n",
    "import matplotlib_utils as mu\n",
    "import neuron_utils as nru\n",
    "\n",
    "#importing at the bottom so don't get any conflicts\n",
    "import itertools\n",
    "from tqdm_utils import tqdm\n",
    "\n",
    "#for meshparty preprocessing\n",
    "import meshparty_skeletonize as m_sk\n",
    "import general_utils as gu\n",
    "import compartment_utils as cu\n",
    "from meshparty import trimesh_io\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from neuron_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-18 01:46:34,343 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2020-11-18 01:46:34,344 - settings - Setting database.user to celiib\n",
      "INFO - 2020-11-18 01:46:34,346 - settings - Setting database.password to newceliipass\n"
     ]
    }
   ],
   "source": [
    "import datajoint_utils as du\n",
    "import neuron_visualizations as nviz\n",
    "du = reload(du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-18 01:46:36,061 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2020-11-18 01:46:36,062 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2020-11-18 01:46:36,078 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_segment_id = 864691135612275396\n",
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-18 01:46:36,259 - settings - Setting enable_python_native_blobs to True\n",
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8970e182171f4985b51045955bd813b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segment_id = 864691135612275396\n",
    "\n",
    "print(f\"curr_segment_id = {segment_id}\")\n",
    "current_neuron = du.fetch_segment_id_mesh(segment_id)\n",
    "nviz.plot_objects(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "description=\"double_soma_with_large_apical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predefined arguments for the Neuron constructor\n",
    "\n",
    "decomposition_type=\"meshafterparty\"\n",
    "mesh_correspondence=\"meshparty\" #meshafterparty_adaptive\n",
    "distance_by_mesh_center=True #how the distance is calculated for mesh correspondence\n",
    "meshparty_segment_size = 100\n",
    "meshparty_n_surface_downsampling = 2\n",
    "meshparty_adaptive_correspondence_after_creation=False\n",
    "suppress_preprocessing_print=True\n",
    "computed_attribute_dict=None\n",
    "#somas = None\n",
    "branch_skeleton_data=None\n",
    "combine_close_skeleton_nodes = True\n",
    "combine_close_skeleton_nodes_threshold=700\n",
    "ignore_warnings=True\n",
    "suppress_output=False\n",
    "calculate_spines=True\n",
    "widths_to_calculate=[\"no_spine_median_mesh_center\"]\n",
    "fill_hole_size=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments for the preprocess neuron\n",
    "mesh = current_neuron\n",
    "segment_id=segment_id\n",
    "description=description\n",
    "\n",
    "sig_th_initial_split=15 #for significant splitting meshes in the intial mesh split\n",
    "limb_threshold = 2000 #the mesh faces threshold for a mesh to be qualified as a limb (otherwise too small)\n",
    "filter_end_node_length=4001 #used in cleaning the skeleton during skeletonizations\n",
    "return_no_somas = False\n",
    "\n",
    "decomposition_type=decomposition_type\n",
    "mesh_correspondence=mesh_correspondence\n",
    "distance_by_mesh_center=distance_by_mesh_center\n",
    "meshparty_segment_size =meshparty_segment_size\n",
    "meshparty_n_surface_downsampling = meshparty_n_surface_downsampling\n",
    "somas=None\n",
    "branch_skeleton_data=branch_skeleton_data\n",
    "combine_close_skeleton_nodes = combine_close_skeleton_nodes\n",
    "combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold\n",
    "\n",
    "if \"meshafterparty\" in decomposition_type.lower():\n",
    "    use_meshafterparty = True\n",
    "else:\n",
    "    use_meshafterparty = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random port chosen was = 8210\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab = reload(meshlab)\n",
    "import numpy as np\n",
    "random_port = np.random.randint(100,10000)\n",
    "meshlab.set_meshlab_port(random_port)\n",
    "print(f\"The random port chosen was = {meshlab.Meshlab.unique_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh was not none\n"
     ]
    }
   ],
   "source": [
    "whole_processing_tiempo = time.time()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: To process the mesh into a format that can be loaded into the neuron class\n",
    "and used for higher order processing (how to visualize is included)\n",
    "\n",
    "\"\"\"\n",
    "if description is None:\n",
    "    description = \"no_description\"\n",
    "if segment_id is None:\n",
    "    #pick a random segment id\n",
    "    segment_id = np.random.randint(100000000)\n",
    "    print(f\"picking a random 7 digit segment id: {segment_id}\")\n",
    "    description += \"_random_id\"\n",
    "\n",
    "\n",
    "if mesh is None:\n",
    "    if current_mesh_file is None:\n",
    "        raise Exception(\"No mesh or mesh_file file were given\")\n",
    "    else:\n",
    "        current_neuron = trimesh.load_mesh(current_mesh_file)\n",
    "else:\n",
    "    print(\"Mesh was not none\")\n",
    "    current_neuron = mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 937.5 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396.off -o /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135612275396/decimation_meshlab_25432968.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(135549, 3), faces.shape=(268703, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(135549, 3), faces.shape=(268703, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_48525.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_48525_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_690447.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Platinum_Decomp_Fusion/temp/neuron_48525.off loaded has 135549 vn 268703 fn\n",
      "output mesh  /notebooks/Platinum_Decomp_Fusion/temp/neuron_48525_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Platinum_Decomp_Fusion/temp/fill_holes_690447.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 6477612\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 6477612\n",
      "LOG: 2 Successfully removed 4 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 4 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 6477564\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/fill_holes_690447.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_89971.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_89971_remove_interior.off -s /notebooks/Platinum_Decomp_Fusion/temp/remove_interior_733351.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_89971.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_89971_remove_interior.off\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/remove_interior_733351.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present, largest is 78\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated_largest_piece.off\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated_largest_piece.off -o /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Decomp_Fusion/864691135612275396/poisson_946135.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(20084, 3), faces.shape=(40172, 3))>, <trimesh.Trimesh(vertices.shape=(11477, 3), faces.shape=(22950, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(20084, 3), faces.shape=(40172, 3))>\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135612275396/decimation_meshlab_25738603.mls\n",
      "done exporting decimated mesh: neuron_864691135612275396_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002982616424560547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113561227539600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.7618191242218018\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.9101014137268066\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.003573894500732422\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.553794860839844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0077669620513916016\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.047028541564941406\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.055256\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 2,  9,  1,  3,  7,  5,  6,  0,  4, 10,  8]), array([0.7313135, 0.397386 , 0.204407 , 0.0804403, 0.0758204, 0.0593571,\n",
      "       0.0556487, 0.055256 , 0.0448431, 0.0391457, 0.0284641]))\n",
      "Sizes = [1750, 762, 263, 135, 135, 27, 939, 4650, 1122, 145, 112]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_329997.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_329997_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_517100.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_329997.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_329997_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_517100.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.0433432695851663\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(11477, 3), faces.shape=(22950, 3))>\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Decomp_Fusion/864691135612275396/neuron_864691135612275396_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Decomp_Fusion/864691135612275396/decimation_meshlab_25738603.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done exporting decimated mesh: neuron_864691135612275396_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002899169921875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Decomp_Fusion/temp/86469113561227539601_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.5373692512512207\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6244008541107178\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0021331310272216797\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.029273986816406e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004998922348022461\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02633070945739746\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1, 4, 3, 5, 6]), array([0.854554  , 0.517373  , 0.0864122 , 0.0745012 , 0.06232715,\n",
      "       0.057912  , 0.0387436 ]))\n",
      "Sizes = [2273, 557, 1368, 342, 262, 265, 669]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_613912.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_613912_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_131345.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_613912.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_613912_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_131345.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.699922845343273\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 94.17641568183899\n",
      "Before Filtering the number of somas found = 2\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 18\n",
      "viable_meshes = [0 1]\n",
      "min_distances_to_soma = [125247.11479588432, 1042327.386431715]\n",
      "dist_min_to_soma = [8.877499647995393, 249.8532569328753]\n",
      "There were 17 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(906, 3), faces.shape=(1750, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(135549, 3), faces.shape=(268390, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(68529, 3), faces.shape=(135733, 3))>, <trimesh.Trimesh(vertices.shape=(38190, 3), faces.shape=(75693, 3))>, <trimesh.Trimesh(vertices.shape=(13717, 3), faces.shape=(26966, 3))>, <trimesh.Trimesh(vertices.shape=(9444, 3), faces.shape=(18577, 3))>, <trimesh.Trimesh(vertices.shape=(2688, 3), faces.shape=(5331, 3))>]\n",
      "There were 5 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(68529, 3), faces.shape=(135733, 3))>, <trimesh.Trimesh(vertices.shape=(38190, 3), faces.shape=(75693, 3))>, <trimesh.Trimesh(vertices.shape=(13717, 3), faces.shape=(26966, 3))>, <trimesh.Trimesh(vertices.shape=(9444, 3), faces.shape=(18577, 3))>, <trimesh.Trimesh(vertices.shape=(2688, 3), faces.shape=(5331, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.465\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(68529, 3), faces.shape=(135733, 3))>, <trimesh.Trimesh(vertices.shape=(38190, 3), faces.shape=(75693, 3))>, <trimesh.Trimesh(vertices.shape=(13717, 3), faces.shape=(26966, 3))>, <trimesh.Trimesh(vertices.shape=(9444, 3), faces.shape=(18577, 3))>, <trimesh.Trimesh(vertices.shape=(2688, 3), faces.shape=(5331, 3))>]\n",
      "Total time for Subtract Soam = 0.4661071300506592\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.21514606475830078\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_474744.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_474744_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_118350.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_474744.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_474744_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_118350.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.6352932094910124\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 18\n",
      "viable_meshes = [0]\n",
      "There were 17 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1164, 3), faces.shape=(2273, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(135549, 3), faces.shape=(268390, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(84488, 3), faces.shape=(167263, 3))>, <trimesh.Trimesh(vertices.shape=(23782, 3), faces.shape=(47093, 3))>, <trimesh.Trimesh(vertices.shape=(14811, 3), faces.shape=(29201, 3))>, <trimesh.Trimesh(vertices.shape=(5513, 3), faces.shape=(10900, 3))>, <trimesh.Trimesh(vertices.shape=(2728, 3), faces.shape=(5402, 3))>, <trimesh.Trimesh(vertices.shape=(222, 3), faces.shape=(434, 3))>]\n",
      "There were 6 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(84488, 3), faces.shape=(167263, 3))>, <trimesh.Trimesh(vertices.shape=(23782, 3), faces.shape=(47093, 3))>, <trimesh.Trimesh(vertices.shape=(14811, 3), faces.shape=(29201, 3))>, <trimesh.Trimesh(vertices.shape=(5513, 3), faces.shape=(10900, 3))>, <trimesh.Trimesh(vertices.shape=(2728, 3), faces.shape=(5402, 3))>, <trimesh.Trimesh(vertices.shape=(222, 3), faces.shape=(434, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.456\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(84488, 3), faces.shape=(167263, 3))>, <trimesh.Trimesh(vertices.shape=(23782, 3), faces.shape=(47093, 3))>, <trimesh.Trimesh(vertices.shape=(14811, 3), faces.shape=(29201, 3))>, <trimesh.Trimesh(vertices.shape=(5513, 3), faces.shape=(10900, 3))>, <trimesh.Trimesh(vertices.shape=(2728, 3), faces.shape=(5402, 3))>, <trimesh.Trimesh(vertices.shape=(222, 3), faces.shape=(434, 3))>]\n",
      "Total time for Subtract Soam = 0.4569697380065918\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.22909045219421387\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_76529.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_76529_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_359733.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_76529.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_76529_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_359733.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.2010490975077404\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_90070.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_90070_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_470503.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_90070.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_90070_fill_holes.off\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/fill_holes_470503.mls is being deleted....\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_73177.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_73177_remove_interior.off -s /notebooks/Platinum_Decomp_Fusion/temp/remove_interior_598270.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_73177.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_73177_remove_interior.off\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/remove_interior_598270.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present, largest is 58\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c579437cfa7d4edc8fac6d6c872a6514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(3073, 3), faces.shape=(5949, 3))>, <trimesh.Trimesh(vertices.shape=(83, 3), faces.shape=(140, 3))>]\n",
      "meshes_split_sdf = [0.678388  0.0573567]\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_93937.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_93937_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_775990.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Platinum_Decomp_Fusion/temp/neuron_93937.off loaded has 4151 vn 8096 fn\n",
      "output mesh  /notebooks/Platinum_Decomp_Fusion/temp/neuron_93937_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Platinum_Decomp_Fusion/temp/fill_holes_775990.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 196776\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 196776\n",
      "LOG: 2 Successfully removed 0 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 0 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 196776\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/fill_holes_775990.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_42703.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_42703_remove_interior.off -s /notebooks/Platinum_Decomp_Fusion/temp/remove_interior_968902.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_42703.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_42703_remove_interior.off\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/remove_interior_968902.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present, largest is 10\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2548039251e442d8b8675d82f0324f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(3887, 3), faces.shape=(7549, 3))>, <trimesh.Trimesh(vertices.shape=(244, 3), faces.shape=(430, 3))>, <trimesh.Trimesh(vertices.shape=(48, 3), faces.shape=(88, 3))>, <trimesh.Trimesh(vertices.shape=(16, 3), faces.shape=(26, 3))>, <trimesh.Trimesh(vertices.shape=(5, 3), faces.shape=(3, 3))>]\n",
      "meshes_split_sdf = [0.849137   0.393761   0.00865181 0.00373345 0.130333  ]\n",
      "Soma List = [<trimesh.Trimesh(vertices.shape=(3073, 3), faces.shape=(5949, 3))>, <trimesh.Trimesh(vertices.shape=(3887, 3), faces.shape=(7549, 3))>]\n",
      "soma_mesh_list_centers = [array([917309.54835666, 996751.17295802, 918815.01324439]), array([988192.73228711, 991952.13771546, 911378.92876254])]\n"
     ]
    }
   ],
   "source": [
    "tu = reload(tu)\n",
    "\n",
    "# -------- Phase 1: Doing Soma Detection (if Not already done) ---------- #\n",
    "if somas is None:\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                             current_neuron.vertices,\n",
    "                                             current_neuron.faces)\n",
    "else:\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = somas\n",
    "    print(f\"Using pre-computed somas: soma_mesh_list = {soma_mesh_list}\")\n",
    "\n",
    "# geting the soma centers\n",
    "if len(soma_mesh_list) <= 0:\n",
    "    print(f\"**** No Somas Found for Mesh {segment_id} so just one mesh\")\n",
    "    soma_mesh_list_centers = []\n",
    "    if return_no_somas:\n",
    "        return_value= soma_mesh_list_centers\n",
    "    raise Exception(\"Processing of No Somas is not yet implemented yet\")\n",
    "else:\n",
    "    #compute the soma centers\n",
    "    print(f\"Soma List = {soma_mesh_list}\")\n",
    "\n",
    "    soma_mesh_list_centers = sm.find_soma_centroids(soma_mesh_list)\n",
    "    print(f\"soma_mesh_list_centers = {soma_mesh_list_centers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_61307.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_61307_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_210685.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Platinum_Decomp_Fusion/temp/neuron_61307.off loaded has 556040 vn 1107938 fn\n",
      "output mesh  /notebooks/Platinum_Decomp_Fusion/temp/neuron_61307_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Platinum_Decomp_Fusion/temp/fill_holes_210685.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 26640216\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 26640216\n",
      "LOG: 2 Successfully removed 38 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 38 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 26639760\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/fill_holes_210685.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_32836.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_32836_remove_interior.off -s /notebooks/Platinum_Decomp_Fusion/temp/remove_interior_342899.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_32836.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_32836_remove_interior.off\n",
      "/notebooks/Platinum_Decomp_Fusion/temp/remove_interior_342899.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(8477, 3), faces.shape=(16901, 3))>]\n",
      "# total split meshes = 82\n",
      "There were 80 pieces found after size threshold\n",
      "\n",
      "-----Before filtering away multiple disconneted soma pieces-----\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "#--- Phase 2: getting the soma submeshes that are connected to each soma and identifiying those that aren't \n",
    "# ------------------ (and eliminating any mesh pieces inside the soma) ------------------------\n",
    "\n",
    "# -------- 11/13 Addition: Will remove the inside nucleus --------- #\n",
    "main_mesh_total,inside_nucleus_pieces = tu.remove_mesh_interior(current_neuron,return_removed_pieces=True)\n",
    "\n",
    "\n",
    "#finding the mesh pieces that contain the soma\n",
    "#splitting the current neuron into distinct pieces\n",
    "split_meshes = tu.split_significant_pieces(\n",
    "                            main_mesh_total,\n",
    "                            significance_threshold=sig_th_initial_split,\n",
    "                            print_flag=False)\n",
    "\n",
    "print(f\"# total split meshes = {len(split_meshes)}\")\n",
    "\n",
    "\n",
    "#returns the index of the split_meshes index that contains each soma    \n",
    "containing_mesh_indices = sm.find_soma_centroid_containing_meshes(soma_mesh_list,\n",
    "                                        split_meshes)\n",
    "\n",
    "# filtering away any of the inside floating pieces: \n",
    "non_soma_touching_meshes = [m for i,m in enumerate(split_meshes)\n",
    "                 if i not in list(containing_mesh_indices.values())]\n",
    "\n",
    "\n",
    "#Adding the step that will filter away any pieces that are inside the soma\n",
    "if len(non_soma_touching_meshes) > 0 and len(soma_mesh_list) > 0:\n",
    "    \"\"\"\n",
    "    *** want to save these pieces that are inside of the soma***\n",
    "    \"\"\"\n",
    "\n",
    "    non_soma_touching_meshes,inside_pieces = sm.filter_away_inside_soma_pieces(soma_mesh_list,non_soma_touching_meshes,\n",
    "                                    significance_threshold=sig_th_initial_split,\n",
    "                                    return_inside_pieces = True)\n",
    "\n",
    "else:\n",
    "    non_soma_touching_meshes = []\n",
    "    inside_pieces=[]\n",
    "\n",
    "#adding in the nuclei center to the inside pieces\n",
    "inside_pieces += inside_nucleus_pieces\n",
    "\n",
    "\n",
    "split_meshes # the meshes of the original mesh\n",
    "containing_mesh_indices #the mapping of each soma centroid to the correct split mesh\n",
    "soma_containing_meshes = sm.grouping_containing_mesh_indices(containing_mesh_indices)\n",
    "\n",
    "soma_touching_meshes = [split_meshes[k] for k in soma_containing_meshes.keys()]\n",
    "\n",
    "\n",
    "#     print(f\"# of non soma touching seperate meshes = {len(non_soma_touching_meshes)}\")\n",
    "#     print(f\"# of inside pieces = {len(inside_pieces)}\")\n",
    "print(f\"\\n-----Before filtering away multiple disconneted soma pieces-----\")\n",
    "print(f\"# of soma containing seperate meshes = {len(soma_touching_meshes)}\")\n",
    "print(f\"meshes with somas = {soma_containing_meshes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Part that will only keep the largest piece that has a soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of not_processed_soma_containing_meshes = 0\n",
      "\n",
      "-----After filtering away multiple disconneted soma pieces-----\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "# ------ 11/15 Addition: Part 2.b \n",
    "\n",
    "\"\"\"\n",
    "Pseudocode: \n",
    "1) Get the largest of the meshes with a soma (largest in soma_touching_meshes)\n",
    "2) Save all other meshes not the largest in \n",
    "3) Overwrite the following variables:\n",
    "    soma_mesh_list\n",
    "    soma_containing_meshes\n",
    "    soma_touching_meshes\n",
    "    total_soma_list_sdf\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "#1) Get the largest of the meshes with a soma (largest in soma_touching_meshes)\n",
    "soma_containing_meshes_keys = np.array(list(soma_containing_meshes.keys()))\n",
    "soma_touching_meshes = np.array([split_meshes[k] for k in soma_containing_meshes_keys])\n",
    "largest_soma_touching_mesh_idx = soma_containing_meshes_keys[np.argmax([len(kk.faces) for kk in soma_touching_meshes])]\n",
    "\n",
    "#2) Save all other meshes not the largest in \n",
    "not_processed_soma_containing_meshes_idx = np.setdiff1d(soma_containing_meshes_keys,[largest_soma_touching_mesh_idx])\n",
    "not_processed_soma_containing_meshes = [split_meshes[k] for k in not_processed_soma_containing_meshes_idx]\n",
    "print(f\"Number of not_processed_soma_containing_meshes = {len(not_processed_soma_containing_meshes)}\")\n",
    "\n",
    "\"\"\"\n",
    "3) Overwrite the following variables:\n",
    "    soma_mesh_list\n",
    "    soma_containing_meshes\n",
    "    soma_touching_meshes\n",
    "    total_soma_list_sdf\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "somas_idx_to_process = soma_containing_meshes[largest_soma_touching_mesh_idx]\n",
    "soma_mesh_list = [soma_mesh_list[k] for k in somas_idx_to_process]\n",
    "\n",
    "soma_containing_meshes = {largest_soma_touching_mesh_idx:list(np.arange(0,len(soma_mesh_list)))}\n",
    "\n",
    "soma_touching_meshes = [split_meshes[largest_soma_touching_mesh_idx]]\n",
    "\n",
    "total_soma_list_sdf = total_soma_list_sdf[somas_idx_to_process]\n",
    "\n",
    "print(f\"\\n-----After filtering away multiple disconneted soma pieces-----\")\n",
    "print(f\"# of soma containing seperate meshes = {len(soma_touching_meshes)}\")\n",
    "print(f\"meshes with somas = {soma_containing_meshes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(155254, 3), faces.shape=(309814, 3))>, <trimesh.Trimesh(vertices.shape=(95592, 3), faces.shape=(190661, 3))>, <trimesh.Trimesh(vertices.shape=(68038, 3), faces.shape=(135727, 3))>, <trimesh.Trimesh(vertices.shape=(56116, 3), faces.shape=(111760, 3))>, <trimesh.Trimesh(vertices.shape=(54962, 3), faces.shape=(109325, 3))>, <trimesh.Trimesh(vertices.shape=(36685, 3), faces.shape=(73050, 3))>, <trimesh.Trimesh(vertices.shape=(22728, 3), faces.shape=(45319, 3))>, <trimesh.Trimesh(vertices.shape=(11100, 3), faces.shape=(22153, 3))>, <trimesh.Trimesh(vertices.shape=(10667, 3), faces.shape=(21276, 3))>, <trimesh.Trimesh(vertices.shape=(136, 3), faces.shape=(264, 3))>]\n",
      "There were 10 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(155254, 3), faces.shape=(309814, 3))>, <trimesh.Trimesh(vertices.shape=(95592, 3), faces.shape=(190661, 3))>, <trimesh.Trimesh(vertices.shape=(68038, 3), faces.shape=(135727, 3))>, <trimesh.Trimesh(vertices.shape=(56116, 3), faces.shape=(111760, 3))>, <trimesh.Trimesh(vertices.shape=(54962, 3), faces.shape=(109325, 3))>, <trimesh.Trimesh(vertices.shape=(36685, 3), faces.shape=(73050, 3))>, <trimesh.Trimesh(vertices.shape=(22728, 3), faces.shape=(45319, 3))>, <trimesh.Trimesh(vertices.shape=(11100, 3), faces.shape=(22153, 3))>, <trimesh.Trimesh(vertices.shape=(10667, 3), faces.shape=(21276, 3))>, <trimesh.Trimesh(vertices.shape=(136, 3), faces.shape=(264, 3))>]\n",
      "Total Time for soma mesh cancellation = 2.13\n",
      "Total time for Subtract Soam = 2.130707263946533\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.7842800617218018\n",
      "Total time for Original_mesh_faces_map for somas= 0.6764450073242188\n",
      "Total time for sig_non_soma_pieces= 0.9025564193725586\n",
      "Total time for split= 0.04241204261779785\n",
      "Total time for mesh_pieces_connectivity= 15.729101419448853\n",
      "# of insignificant_limbs = 1 with trimesh : [<trimesh.Trimesh(vertices.shape=(136, 3), faces.shape=(264, 3))>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--- Phase 3:  Soma Extraction was great (but it wasn't the original soma faces), so now need to get the original soma faces and the original non-soma faces of original pieces\n",
    "\n",
    "\"\"\"\n",
    "for each soma touching mesh get the following:\n",
    "1) original soma meshes\n",
    "2) significant mesh pieces touching these somas\n",
    "3) The soma connectivity to each of the significant mesh pieces\n",
    "-- later will just translate the \n",
    "\n",
    "\n",
    "Process: \n",
    "\n",
    "1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "2) Subtact all soma faces from original mesh\n",
    "3) Find all significant mesh pieces\n",
    "4) Backtrack significant mesh pieces to orignal mesh and find connectivity of each to all\n",
    "   the available somas\n",
    "Conclusion: Will have connectivity map\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "soma_touching_mesh_data = dict()\n",
    "\n",
    "for z,(mesh_idx, soma_idxes) in enumerate(soma_containing_meshes.items()):\n",
    "    soma_touching_mesh_data[z] = dict()\n",
    "    print(f\"\\n\\n----Working on soma-containing mesh piece {z}----\")\n",
    "\n",
    "    #1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "    current_mesh = split_meshes[mesh_idx]\n",
    "\n",
    "    current_soma_mesh_list = [soma_mesh_list[k] for k in soma_idxes]\n",
    "\n",
    "    current_time = time.time()\n",
    "    mesh_pieces_without_soma = sm.subtract_soma(current_soma_mesh_list,current_mesh,\n",
    "                                                significance_threshold=250)\n",
    "    print(f\"Total time for Subtract Soam = {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    mesh_pieces_without_soma_stacked = tu.combine_meshes(mesh_pieces_without_soma)\n",
    "\n",
    "    # find the original soma faces of mesh\n",
    "    soma_faces = tu.original_mesh_faces_map(current_mesh,mesh_pieces_without_soma_stacked,matching=False)\n",
    "    print(f\"Total time for Original_mesh_faces_map for mesh_pieces without soma= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "    soma_meshes = current_mesh.submesh([soma_faces],append=True,repair=False)\n",
    "\n",
    "    # finding the non-soma original faces\n",
    "    non_soma_faces = tu.original_mesh_faces_map(current_mesh,soma_meshes,matching=False)\n",
    "    non_soma_stacked_mesh = current_mesh.submesh([non_soma_faces],append=True,repair=False)\n",
    "\n",
    "    print(f\"Total time for Original_mesh_faces_map for somas= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    # 3) Find all significant mesh pieces\n",
    "    sig_non_soma_pieces,insignificant_limbs = tu.split_significant_pieces(non_soma_stacked_mesh,significance_threshold=limb_threshold,\n",
    "                                                     return_insignificant_pieces=True)\n",
    "\n",
    "    print(f\"Total time for sig_non_soma_pieces= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    soma_touching_mesh_data[z][\"branch_meshes\"] = sig_non_soma_pieces\n",
    "\n",
    "    #4) Backtrack significant mesh pieces to orignal mesh and find connectivity of each to all the available somas\n",
    "    # get all the seperate mesh faces\n",
    "\n",
    "    #How to seperate the mesh faces\n",
    "    seperate_soma_meshes,soma_face_components = tu.split(soma_meshes,only_watertight=False)\n",
    "    #take the top largest ones depending how many were originally in the soma list\n",
    "    seperate_soma_meshes = seperate_soma_meshes[:len(soma_mesh_list)]\n",
    "    soma_face_components = soma_face_components[:len(soma_mesh_list)]\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_meshes\"] = seperate_soma_meshes\n",
    "\n",
    "    print(f\"Total time for split= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    soma_to_piece_connectivity = dict()\n",
    "    soma_to_piece_touching_vertices = dict()\n",
    "    soma_to_piece_touching_vertices_idx = dict()\n",
    "    limb_root_nodes = dict()\n",
    "\n",
    "    m_vert_graph = tu.mesh_vertex_graph(current_mesh)\n",
    "\n",
    "    for i,curr_soma in enumerate(seperate_soma_meshes):\n",
    "        (connected_mesh_pieces,\n",
    "         connected_mesh_pieces_vertices,\n",
    "         connected_mesh_pieces_vertices_idx) = tu.mesh_pieces_connectivity(\n",
    "                        main_mesh=current_mesh,\n",
    "                        central_piece=curr_soma,\n",
    "                        periphery_pieces = sig_non_soma_pieces,\n",
    "                        return_vertices = True,\n",
    "                        return_vertices_idx=True)\n",
    "        #print(f\"soma {i}: connected_mesh_pieces = {connected_mesh_pieces}\")\n",
    "        soma_to_piece_connectivity[i] = connected_mesh_pieces\n",
    "\n",
    "        soma_to_piece_touching_vertices[i] = dict()\n",
    "        for piece_index,piece_idx in enumerate(connected_mesh_pieces):\n",
    "            limb_root_nodes[piece_idx] = connected_mesh_pieces_vertices[piece_index][0]\n",
    "\n",
    "            \"\"\" Old way of finding vertex connected components on a mesh without trimesh function\n",
    "            #find the number of touching groups and save those \n",
    "            soma_touching_graph = m_vert_graph.subgraph(connected_mesh_pieces_vertices_idx[piece_index])\n",
    "            soma_con_comp = [current_mesh.vertices[np.array(list(k)).astype(\"int\")] for k in list(nx.connected_components(soma_touching_graph))]\n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = soma_con_comp\n",
    "            \"\"\"\n",
    "\n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = tu.split_vertex_list_into_connected_components(\n",
    "                                                vertex_indices_list=connected_mesh_pieces_vertices_idx[piece_index],\n",
    "                                                mesh=current_mesh, \n",
    "                                                vertex_graph=m_vert_graph, \n",
    "                                                return_coordinates=True\n",
    "                                               )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         border_debug = False\n",
    "#         if border_debug:\n",
    "#             print(f\"soma_to_piece_connectivity = {soma_to_piece_connectivity}\")\n",
    "#             print(f\"soma_to_piece_touching_vertices = {soma_to_piece_touching_vertices}\")\n",
    "\n",
    "\n",
    "    print(f\"Total time for mesh_pieces_connectivity= {time.time() - current_time}\")\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_to_piece_connectivity\"] = soma_to_piece_connectivity\n",
    "\n",
    "print(f\"# of insignificant_limbs = {len(insignificant_limbs)} with trimesh : {insignificant_limbs}\")\n",
    "\n",
    "\n",
    "\n",
    "# Lets have an alert if there was more than one soma disconnected meshes\n",
    "if len(soma_touching_mesh_data.keys()) > 1:\n",
    "    raise Exception(\"More than 1 disconnected meshes that contain somas\")\n",
    "\n",
    "current_mesh_data = soma_touching_mesh_data\n",
    "soma_containing_idx = 0\n",
    "\n",
    "#doing inversion of the connectivity and touching vertices\n",
    "piece_to_soma_touching_vertices = gu.flip_key_orders_for_dict(soma_to_piece_touching_vertices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac0d11c102c409eb06696df2b7a1fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=seperate_soma_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the Limb Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import meshlab\n",
    "# meshlab = reload(meshlab)\n",
    "# import numpy as np\n",
    "# random_port = np.random.randint(100,10000)\n",
    "# meshlab.set_meshlab_port(random_port)\n",
    "# print(f\"The random port chosen was = {meshlab.Meshlab.unique_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Working on Proper Limb # 0 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 1.2636184692382812e-05\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8291a3aa3f341a68d996fe91e73213e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=155253.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 3.309154510498047\n",
      "connecting at the root\n",
      "branches_touching_root = [28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:933: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 15981\n",
      "Working on path [931. 935. 939. 942. 946. 950. 953.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [12274. 12280. 12282. 12286.]\n",
      "path_degrees = [3, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 28, len(kept_branches_idx) = 27\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.004238040366285469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22325b27bdd4e58b8951d48ffea543a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948a9a5f762948618566b0c72ce0e1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 10.476264238357544\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [79515, 58086, 11874, 8200, 5448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_large_connectivity: 0.2638814449310303\n",
      "Finding MAP candidates connected components: 0.0001308917999267578\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.44032931327819824\n",
      "Grouping MP Sublimbs by Graph: 0.07255744934082031\n",
      "Divinding into MP and MAP pieces: 9.5367431640625e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.00965261459350586\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_588788.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_63307.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_63307_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_5410.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_63307.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_63307_fill_holes.off\n",
      "-----Time for Screened Poisson= 13.562836170196533\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357fc580b39f40b69e36aac027e2690a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6958bc28bc9c4953926c81446de549b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** The distance exceeded max stitch distance of 18000 and still had 5 left\n",
      "   Actual distance was 33721.85429361796 \n",
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.09287142753601074\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 16.612866640090942\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.9679889678955078\n",
      "sbv[0].reshape(-1,3) = [[917314.8 991489.1 919697.2]]\n",
      "closest_sk_pt_coord BEFORE = [919594. 990720. 919833.]\n",
      "current_skeleton.shape = (1822, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [919594. 990720. 919833.]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[919594., 990720., 919833.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 1.5774657726287842\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[919594. 990720. 919833.]]\n",
      "Number of end_nodes BEFORE filtering = 13\n",
      "all_single_nodes_to_eliminate = [11]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35641ab5b56540afb69d1eea05eb2f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (1808, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 20.22088384628296\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d036e03ab8a046569a5ab0d839b5bf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 28.009053945541382\n",
      "mesh_correspondence_first_pass: 28.00908923149109\n",
      "Limb decomposed into 3 branches\n",
      "divided_skeleton_graph_recovered = (1808, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (1808, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.12508965627164778\n",
      " conflict_indices % = 0.0005762522758899726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f2bf848bd548e290e682ffe316fa4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424bab133c104c3489cde4edd2ceacb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee02d22d83bf4452a8f55e85d55277f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 56.82619547843933\n",
      "correspondence_1_to_1: 8.586686849594116\n",
      "Total time for MAP sublimb processing 56.82646727561951\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0030350685119628906\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0015430450439453125\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.002482175827026367\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "---- Working on MP Decomposition #3 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0010764598846435547\n",
      "Fixing Possible Soma Extension Branch for Sublimb 3\n",
      "Total time for mesh KDTree = 0.008385181427001953\n",
      "sbv[0].reshape(-1,3) = [[918033.  991896.4 919838.2]]\n",
      "closest_sk_pt_coord BEFORE = [921700.49216226 989322.86537675 921457.23636597]\n",
      "current_skeleton.shape = (50, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 99.99999999999325\n",
      "Changing the stitch point becasue the distance to end or branch node was 99.99999999999325\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [921680.81898131 989240.18359026 921404.54207658]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[921680.81898131, 989240.18359026, 921404.54207658]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "No soma extending branch was added for this sublimb even though it had a soma border (means they already existed)\n",
      "MP (because soma touching verts) soma extension add: 0.028592586517333984\n",
      "---- Working on MP Decomposition #4 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0028569698333740234\n",
      "Do Not Need to Fix MP Decomposition 4 so just continuing\n",
      "---- Working on MP Decomposition #5 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0015289783477783203\n",
      "Do Not Need to Fix MP Decomposition 5 so just continuing\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 15995.591012896131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_conn = [1, 3]\n",
      "conn = [1, 3]\n",
      "winning_vertex = [923908.13955673 978548.02050543 912013.85177892]\n",
      "MP_branches_with_stitch_point = [1, 3]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1214.2141706324674) \n",
      "Found winning edge: [644, 645.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1113.7531206087428) \n",
      "Found winning edge: [928, 929.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc76370d95d45279a21e2338ed7f8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.07219631110797715\n",
      " conflict_indices % = 0.0002719827542786917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99de235d3d3a40f98ebff6bed19de606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3db6d4e31a24171b90cc05d6f5b889b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d6f5a0870c4f058b0c1fbea993e011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.07965142452890861\n",
      " conflict_indices % = 0.010820631551868288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7d476a267b4904986679dfc843f01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b357f9e8c11744469f0cecbaf3ed3aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1, 3]\n",
      "MP_branches_for_correspondence = [1 3]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [878936.27333791 438308.72638442 805039.49121152]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (965.76095251474) \n",
      "Found winning edge: [84, 85.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1004.9734704183675) \n",
      "Found winning edge: [549, 550.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b409b930161443fa863210012c493da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n",
      "WARNING - 2020-11-18 01:54:36,028 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2020-11-18 01:54:36,566 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.19187753663852167\n",
      " conflict_indices % = 0.0033539091964973184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2304eaa34c574da4a0202f74bd4dc360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ee10f6aa53433db5d9ed39711f1d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 20912.801315612658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_conn = [1]\n",
      "conn = [1]\n",
      "winning_vertex = [929547.98629035 960985.71659998 903738.74781564]\n",
      "MP_branches_with_stitch_point = [1]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (510.6248741006441) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac2be2d20a64d868c2131c6802bf0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.07942015411469198\n",
      " conflict_indices % = 0.0007769594278172762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18b4a2db910402ca2d2f1ada97c0805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8910f594efe4571a90a04e92db353af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c29d95fc244b16bc00dd3f13396606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2020-11-18 01:55:02,206 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2020-11-18 01:55:03,294 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.07801022942134934\n",
      " conflict_indices % = 0.009706622983958803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50df32b67eca4f10a5b411b3ae317ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c400b1da29474e97ec9a2ed6af0ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1]\n",
      "MP_branches_for_correspondence = [1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (3, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 420.66376121553424\n",
      "Changing the stitch point becasue the distance to end or branch node was 420.66376121553424\n",
      "New stitch point has degree 1\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winning_vertex = [921680.81898131 989240.18359026 921404.54207658]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [3]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3004.5695461515884) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3004.61328790091) \n",
      "Found winning edge: [1040, 1041.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49fa485f14d4647af5a466315e67544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.23797592461463044\n",
      " conflict_indices % = 0.00010893839533743668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0d1da328364c2e8f019ecac84669c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d48cb82250d4e2faed351e2075e7057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (3, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 53902.43954005796\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [909202.21677249 776823.66707196 846895.17000003]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (642.1304932260083) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c95b5efa03479a9f2ad964af9f45f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.07175137961080454\n",
      " conflict_indices % = 0.0002904443799012489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162edad8bfc146fbb5406f4a72f2dd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f5045b1442466191670eb5537bc1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c09da4b7ebd4a7f90c74af783157205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.06997867610362506\n",
      " conflict_indices % = 0.0045460732271675516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9abfb6236748b4b4a66cc3f709b0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543ae96a1f40416d921805871e61f9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (5, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 32653.777905091425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [925225.03045591 933618.85835818 895309.35917944]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [5]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (423.3299407230513) \n",
      "Found winning edge: [1008, 1010.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77e57b5492f4183b06306d105cdc193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.07404469875081438\n",
      " conflict_indices % = 0.00018412032971702123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb0a81c08b04079a83bbef03b6cffda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12675177ccd6414fa5aab14d840cd9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d444af50ef34316b13a5681a035a30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.14722365480488225\n",
      " conflict_indices % = 0.00025213454816342903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c47858efb54a26899507d9a5302783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbee757725344d98b5fcf3de76effd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (5, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 213.39954471588135\n",
      "Number of matching vertices = 23\n",
      "Number of matching vertices = 15\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 1 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 8.58306884765625e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b287b27558431ab178f5f1f0b8d9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=95591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 2.057297945022583\n",
      "connecting at the root\n",
      "branches_touching_root = [28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:933: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 11938\n",
      "Working on path [3888. 3889. 3892. 3894. 3896. 3897. 3901. 3903.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 28, len(kept_branches_idx) = 28\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.005272877994522503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa0639a14f24028833ccc50cbbcfd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bedfd1bd4844eca97de866a202a23a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 6.046761751174927\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [19324, 4177, 3427, 1984, 5371, 3935, 19389, 1353, 8281, 8199, 18706, 11403]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_large_connectivity: 0.2816658020019531\n",
      "Finding MAP candidates connected components: 0.00016736984252929688\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.2843606472015381\n",
      "Grouping MP Sublimbs by Graph: 0.04728102684020996\n",
      "Divinding into MP and MAP pieces: 1.1920928955078125e-06\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.006613969802856445\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_108357.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_51964.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_51964_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_719484.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_51964.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_51964_fill_holes.off\n",
      "-----Time for Screened Poisson= 26.421821355819702\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ac8ef6f32a4698bb51dc97c2c6c474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770f05a4d61b4b2894af49af416b6cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.07415938377380371\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 34.655030488967896\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.055875539779663086\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b764bff01945fc96879942c371b803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (1223, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 35.63737344741821\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fff85e51ca40e589cb0b392dddb1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 13.667153358459473\n",
      "mesh_correspondence_first_pass: 13.667202472686768\n",
      "Limb decomposed into 3 branches\n",
      "divided_skeleton_graph_recovered = (1223, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (1223, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.029559730551686893\n",
      " conflict_indices % = 0.00298439587300685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dfa7c7ac6d4267a3e02653e3cd0e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09217524002a42b9b9b07c254a634e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 52.024933099746704\n",
      "correspondence_1_to_1: 2.713884115219116\n",
      "Total time for MAP sublimb processing 52.025192737579346\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001893758773803711\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0005779266357421875\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0004336833953857422\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "---- Working on MP Decomposition #3 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0010771751403808594\n",
      "Do Not Need to Fix MP Decomposition 3 so just continuing\n",
      "---- Working on MP Decomposition #4 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0003743171691894531\n",
      "Do Not Need to Fix MP Decomposition 4 so just continuing\n",
      "---- Working on MP Decomposition #5 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0010256767272949219\n",
      "Do Not Need to Fix MP Decomposition 5 so just continuing\n",
      "---- Working on MP Decomposition #6 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0013737678527832031\n",
      "Do Not Need to Fix MP Decomposition 6 so just continuing\n",
      "---- Working on MP Decomposition #7 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.004027605056762695\n",
      "Do Not Need to Fix MP Decomposition 7 so just continuing\n",
      "---- Working on MP Decomposition #8 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0004105567932128906\n",
      "Do Not Need to Fix MP Decomposition 8 so just continuing\n",
      "---- Working on MP Decomposition #9 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0009374618530273438\n",
      "Do Not Need to Fix MP Decomposition 9 so just continuing\n",
      "---- Working on MP Decomposition #10 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0004992485046386719\n",
      "Fixing Possible Soma Extension Branch for Sublimb 10\n",
      "Total time for mesh KDTree = 0.05730867385864258\n",
      "sbv[0].reshape(-1,3) = [[986575.1 991553.6 917753.1]]\n",
      "closest_sk_pt_coord BEFORE = [983558.59487623 991536.79838002 918027.29499536]\n",
      "current_skeleton.shape = (257, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 7217.977765426994\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [983558.59487623 991536.79838002 918027.29499536]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [984577.77222222 991779.71805556 917127.71527778]\n",
      "endpoints_must_keep = {0: array([[984577.77222222, 991779.71805556, 917127.71527778]])}\n",
      "orig_vertex = [983558.59487623 991536.79838002 918027.29499536]\n",
      "match_sk_branches = [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f3e1f19559408592ad6d0476b172e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.18721755971594578\n",
      " conflict_indices % = 0.10049494297396169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2a1bf031cc47e0ba6bbba996fa549c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90c8b417ec5485a9060acae0772aaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dda0580a94437b9ccf594693a12155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curr_width_median = 313.2093081473418\n",
      "curr_width_median = 1644.3100948306194\n",
      "curr_width_median = 1074.7183754526334\n",
      "checked segment branches after soma add on\n",
      "MP (because soma touching verts) soma extension add: 1.2937092781066895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1313: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([k for i,k in enumerate(segment_branches) if i not in match_sk_branches] + new_skeletal_branches)\n",
      "/meshAfterParty/preprocessing_vp2.py:1322: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  divided_submeshes_idx = np.array([k for i,k in enumerate(divided_submeshes_idx) if i not in match_sk_branches] + new_submeshes_idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 64982.86117464737\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [ 905777.02934514 1022582.25971473  988611.22707734]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Found winning edge: [4, 5.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872ed561eb554b059dddc4e5a768ccc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.030312287847929397\n",
      " conflict_indices % = 6.788866259334691e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dc62282a3a4e37a810be4b6e3fc4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dae0e80a9684e2c9bedeb8731322cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93bac3c635342ff93d77777e82cdfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.02981138374228009\n",
      " conflict_indices % = 0.0023368385912201635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d203e6ab2a48b5a1c7541253acd08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66ebaccb0e342de9b4e60912a450392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 15925.326773950099\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [988983.728824   993067.19222526 936019.66280842]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (790.4886676642255) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [330, 332.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f1d2810d714fec838a90d7173b925c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.032166195259923924\n",
      " conflict_indices % = 0.001775090217497318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06aafa215f5a4add8f5088a1e7e8a20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e8ca44667448a89d4fa37c132557f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d503ff048e5845d29d6cb7f0e27861a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.03544068034860838\n",
      " conflict_indices % = 0.009857323587292662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e63b262b114941bf9b89697d67effb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c07eb55462943bc9b7137236a582c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 13385.18008876251\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [ 893727.42446986 1025740.72452638  989465.49953154]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1018.8409742688676) \n",
      "Found winning edge: [54, 55.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1108.1274852107701) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7586d42ab785435fa8340f7ab2821520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.04211035818005808\n",
      " conflict_indices % = 0.004453049370764763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893935b067944c71b61e584859765d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f879e1514c5b494bb98208579e4d8b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a592da133b04d3f97643b6b7d771fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.039926571821936666\n",
      " conflict_indices % = 0.004681046351537403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cf401aae4b4d1da68606725810c7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc53f7e6aff473c8bdfc8998d5a99f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [1], MP_leftover_idx = [1]\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (3, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 35233.64906284169\n",
      "sk_conn = [1]\n",
      "conn = [1]\n",
      "winning_vertex = [ 964503.99055039 1002793.28356568  930531.64196468]\n",
      "MP_branches_with_stitch_point = [1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max stitch distance (300) for smoothing because stitch_distance greater (514.3879356213504) \n",
      "Found winning edge: [662, 663.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4605a961c248b2973d0e1de69477c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.03355832102931871\n",
      " conflict_indices % = 0.0018561484918793504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753bd3ab789d462585fce67b3aacd0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b76454720e432d970271a779a0f37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155210275d6344b684bb3612bb5880d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.027922567963635726\n",
      " conflict_indices % = 0.007564190315730357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbf0dc67ea94dcd81a5fc306bd526e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766d005619c74fd09a0f01e4952aa845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1]\n",
      "MP_branches_for_correspondence = [1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (3, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [1016643.65370889 1012632.19003595 1080664.68954586]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Found winning edge: [56, 57.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [47, 48.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e7c78fecd34a3c90f72ba8f075de01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.035830121723203726\n",
      " conflict_indices % = 0.0006868393940550235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24039fe3bf845b8ad8bcd48f9c9b6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd83b39e3574dd4adc50811ef452c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (5, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 22919.12756784664\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [1015777.2238413  1008090.71902822 1060075.66259735]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max stitch distance (300) for smoothing because stitch_distance greater (908.1819783908642) \n",
      "Found winning edge: [604, 605.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29df997cd0f4b7d9d105a4da1ea9c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.027504121597169168\n",
      " conflict_indices % = 0.0005227391531625719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ce3168b278430c8ce197cc9e259bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b67ae7b1b140dbb7ddd3531ef1e439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a18eea8e644446c9fbbd6ad0c9c8fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.02036774269835639\n",
      " conflict_indices % = 0.004966300106420717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2841b056345f472aa1829fa679242d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5215dad4b129482a9dfbf3096001c8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (5, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (6, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 64000.814053179594\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [ 849287.75518149 1049106.70501281  977110.40006482]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Found winning edge: [6, 7.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fccb285dfb04c0482bd30f538238b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.035617720465890186\n",
      " conflict_indices % = 0.00023398502495840267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbf16d00cbd435a8a3007c76011cde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ac1c6a838f4524bd70c64540d2944e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b9909be9054585b168a73537d01df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.036506065330646084\n",
      " conflict_indices % = 0.007605430277217933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6615938b1584dd3bbb2baa8eee343e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac066165e6864206b17bb49998df8ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (6, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (7, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [ 794602.90305413 1048157.71801962  974092.08835234]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1522.7681693206514) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [9, 15.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1599.4767472696262) \n",
      "Found winning edge: [1308, 1309.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af97ab1e9a64670bcbabd2b86b344f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.06085363289580392\n",
      " conflict_indices % = 0.0017421079506202506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a8cb9164634cfca8d497f449561b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21437bd64c094178b547af0c0c945a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (7, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (8, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 50620.156017364934\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [ 889586.45078321 1029419.05587952  966945.02322074]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [8]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (709.5503768411047) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [223, 224.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda7e42a81264e959626177223930cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.018567737172388334\n",
      " conflict_indices % = 0.002916205241786637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb45513e45241eba89557c36a3c5026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb07d74967ee4684b0b8ebe12f7df512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d4e5066a4142afb12b00d2155efc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.01915194102855568\n",
      " conflict_indices % = 0.005063552753952671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d099d763bb40f79b725dfef890fcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab49559eac9e4b6f81a88d48d7eb9380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (8, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (9, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 9026.630171089231\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [997353.64789288 997329.42906893 957870.53905192]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (387.12602652725803) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0185af134b4b1dbb6debab19f41f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.037899761336515514\n",
      " conflict_indices % = 0.0005727923627684964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ba2a5d867348c8ac42cf634f2f6495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad346d22ba549dda2fde809279c7af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4296a3da4241db82f7306c2161c6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.05923819320485281\n",
      " conflict_indices % = 0.005234018092155024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64f90d5c460409eb75d622db3fed53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3e88bbb7f54a219cd3243a8c50b4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (9, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (10, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 12547.481689635591\n",
      "sk_conn = [1]\n",
      "conn = [1]\n",
      "winning_vertex = [983795.41163267 993610.27562932 924758.78241519]\n",
      "MP_branches_with_stitch_point = [1]\n",
      "MAP_branches_with_stitch_point = [6]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (582.6451079962328) \n",
      "Found winning edge: [8, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b3fe52a7504e159785adbc79fb743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.06337798105194381\n",
      " conflict_indices % = 0.002069040618534248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fa731e71f8485ebd84dfe4f026d7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3b8b6de441409f969565936dfaa924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af03273ea5d4b7289cafffd363e0701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.12511461198632992\n",
      " conflict_indices % = 0.04351087771942986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef74b5c4b0b4e8d8160a6c386c3acbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e536164f4042cbbea221a7ff20877f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1]\n",
      "MP_branches_for_correspondence = [1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (10, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 156.93367671966553\n",
      "Number of matching vertices = 72\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 2 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 5.4836273193359375e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2c5f62dba64720ace4bd3f42dade6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=68037.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 1.9558227062225342\n",
      "branches_touching_root = [10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 12613\n",
      "Working on path [558. 562. 563.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [6620. 6631. 6645. 6658. 6661.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [6963. 6980. 6994. 7006. 7021. 7034.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 50, len(kept_branches_idx) = 48\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.008306798749926294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204af940d99b4e06b41fd6edb9cf6a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9727bb9793340e79743c16d519959a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 6.244120121002197\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [5826, 17664, 9629, 3946, 1326]\n",
      "mesh_large_connectivity: 0.08279585838317871\n",
      "Finding MAP candidates connected components: 0.00013017654418945312\n",
      "len(filtered_pieces) = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeleton_connectivity_MP : 0.45960497856140137\n",
      "Grouping MP Sublimbs by Graph: 0.06349563598632812\n",
      "Divinding into MP and MAP pieces: 9.5367431640625e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.01008749008178711\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_512142.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_80907.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_80907_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_779970.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_80907.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_80907_fill_holes.off\n",
      "-----Time for Screened Poisson= 14.703882455825806\n",
      "     Starting Calcification\n",
      "node_degrees = [3 2 3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d9b442575f44b0b0fb5e03fe4c7f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b48dae41c7e4e09af2d40c68ac5987d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.04171419143676758\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 17.864885568618774\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.7978806495666504\n",
      "sbv[0].reshape(-1,3) = [[980826. 992061. 914025.]]\n",
      "closest_sk_pt_coord BEFORE = [980157. 991894. 914384.]\n",
      "current_skeleton.shape = (395, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [980157. 991894. 914384.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "sbv[0].reshape(-1,3) = [[924211.4 999131.7 917929. ]]\n",
      "closest_sk_pt_coord BEFORE = [923969. 998675. 918335.]\n",
      "current_skeleton.shape = (395, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [923969. 998675. 918335.]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[980157., 991894., 914384.]]), 1: array([[923969., 998675., 918335.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.9796469211578369\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[980157. 991894. 914384.]\n",
      " [923969. 998675. 918335.]]\n",
      "Number of end_nodes BEFORE filtering = 15\n",
      "all_single_nodes_to_eliminate = [8, 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c1653d90144ddfb221ed1d794490e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (384, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 19.130828380584717\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e70876861c04a359c7fa46840e47ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 4.483160495758057\n",
      "mesh_correspondence_first_pass: 4.483199596405029\n",
      "Limb decomposed into 8 branches\n",
      "divided_skeleton_graph_recovered = (384, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (384, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (7, 8)\n",
      "empty_indices % = 0.07918522570394103\n",
      " conflict_indices % = 0.015837045140788205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96a9ae8e2a74222b2ab0d8ddd0ecdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4a4221df2d482e8099dc72f82afdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ceb585cd3044fca2cb05e2ece51f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d125e3fba2549aca96177d109ec29dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 26.258495330810547\n",
      "correspondence_1_to_1: 2.6345102787017822\n",
      "Total time for MAP sublimb processing 26.258753538131714\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.006350517272949219\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0034935474395751953\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0004143714904785156\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [5, 15]\n",
      "conn = [5, 15]\n",
      "winning_vertex = [1012890.88928568  993692.84835554  891681.90431767]\n",
      "MP_branches_with_stitch_point = [5, 15]\n",
      "MAP_branches_with_stitch_point = [7]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1184.5915748471207) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1088.063424332613) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acb3f57bbdf4597b6b2805655c3d366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.11903460837887067\n",
      " conflict_indices % = 0.0034608378870673953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9514c1803d3d4cd8a7a530a581c4351e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebae742d21b482dbcde40a0f3a1e90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [5, 15]\n",
      "MP_branches_for_correspondence = [ 5 15]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 2]\n",
      "conn = [0, 2]\n",
      "winning_vertex = [ 933025.05835153 1007928.77016529  920863.86711443]\n",
      "MP_branches_with_stitch_point = [0, 2]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1548.1249960245113) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [576, 578.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1618.2593060616425) \n",
      "Found winning edge: [154, 156.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa715b2c0f2f4e65b143a994b3025421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n",
      "WARNING - 2020-11-18 01:59:23,779 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.07328430075665379\n",
      " conflict_indices % = 0.050584687020477276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0605748642e4452a0705d0c5801688d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c6dfdf64be4f2784195747786b5cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 2]\n",
      "MP_branches_for_correspondence = [0 2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 6717.796951363818\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [989952.92983292 993033.04126696 893761.29101944]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [5]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (401.8523297834327) \n",
      "Found winning edge: [60, 61.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba77c9cd1c2f4790bbdd4caf2773b6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.08996336996336997\n",
      " conflict_indices % = 0.0016117216117216117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d245ec927bef4994b9f8f21cb4b98e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f981c922fa724de19fb8dcac69907c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343db6b2f40a4af2b8d506ec893db9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.08965960179833012\n",
      " conflict_indices % = 0.011175337186897881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2298eafc044742269b60a7a2226acda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9683ad0eae894a8d88488c5b0f52ab05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 43.81963562965393\n",
      "Number of matching vertices = 14\n",
      "Number of matching vertices = 29\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 3 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 5.245208740234375e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59703b67f9fa466c8fdc334ecd8ac021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=56115.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 1.6422033309936523\n",
      "branches_touching_root = [7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 10218\n",
      "Working on path [1394. 1399. 1404. 1408. 1410.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [3597. 3600. 3605. 3609. 3612. 3616.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [4545. 4555. 4563.]\n",
      "path_degrees = [3, 2, 4]\n",
      "Working on path [7522. 7546. 7570. 7587.]\n",
      "path_degrees = [3, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 53, len(kept_branches_idx) = 50\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.017243384965056865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651e4d07f09a4aa9a8cee712b928699f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d93ccf2e564f78ac30b9f21a93c704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 6.007824420928955\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [1647, 4722, 5246, 2095, 1098, 1273, 347, 8126, 12638]\n",
      "mesh_large_connectivity: 0.09703254699707031\n",
      "Finding MAP candidates connected components: 0.000164031982421875\n",
      "len(filtered_pieces) = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeleton_connectivity_MP : 0.32752156257629395\n",
      "Grouping MP Sublimbs by Graph: 0.05272388458251953\n",
      "Divinding into MP and MAP pieces: 7.152557373046875e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.003728628158569336\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_798674.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_98073.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_98073_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_312617.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_98073.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_98073_fill_holes.off\n",
      "-----Time for Screened Poisson= 15.204207420349121\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0f1f93839843ffbe98a0c85c7b95cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1948053d17e5437299bbe6da7d920460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.04591870307922363\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 19.23522639274597\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.23554277420043945\n",
      "sbv[0].reshape(-1,3) = [[986028.2 990610.1 903746. ]]\n",
      "closest_sk_pt_coord BEFORE = [987781. 988761. 902291.]\n",
      "current_skeleton.shape = (462, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 29178.63151270509\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [987781. 988761. 902291.]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [986386.95957447 988521.05957447 905097.41702128]\n",
      "endpoints_must_keep = {0: array([[986386.95957447, 988521.05957447, 905097.41702128]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.3914668560028076\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[986386.95957447 988521.05957447 905097.41702128]]\n",
      "Number of end_nodes BEFORE filtering = 8\n",
      "all_single_nodes_to_eliminate = [3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c440a0c5b7c41cc990e32e15d57798f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (459, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 19.939661741256714\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747f1b8da0834cdd95c8d47d5599aa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 4.540588617324829\n",
      "mesh_correspondence_first_pass: 4.54062294960022\n",
      "Limb decomposed into 6 branches\n",
      "divided_skeleton_graph_recovered = (459, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (459, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (5, 6)\n",
      "empty_indices % = 0.06202946870294687\n",
      " conflict_indices % = 0.011427188642718864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dd319ca0dd41dbae0da527770fe45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189b14fdec7d4d6ea68cf20bf85b9026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab95cccb12b404f9dd9093daa291308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 26.47602128982544\n",
      "correspondence_1_to_1: 1.9919486045837402\n",
      "Total time for MAP sublimb processing 26.4761164188385\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0014998912811279297\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0005974769592285156\n",
      "Fixing Possible Soma Extension Branch for Sublimb 1\n",
      "Total time for mesh KDTree = 0.035366058349609375\n",
      "sbv[0].reshape(-1,3) = [[992270.1 989095.2 906230.1]]\n",
      "closest_sk_pt_coord BEFORE = [991894.42190245 990483.4991747  905797.9899198 ]\n",
      "current_skeleton.shape = (73, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [991894.42190245 990483.4991747  905797.9899198 ]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[991894.42190245, 990483.4991747 , 905797.9899198 ]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "No soma extending branch was added for this sublimb even though it had a soma border (means they already existed)\n",
      "MP (because soma touching verts) soma extension add: 0.0861504077911377\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.002207040786743164\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "---- Working on MP Decomposition #3 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.003439664840698242\n",
      "Do Not Need to Fix MP Decomposition 3 so just continuing\n",
      "---- Working on MP Decomposition #4 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0008046627044677734\n",
      "Do Not Need to Fix MP Decomposition 4 so just continuing\n",
      "---- Working on MP Decomposition #5 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0006177425384521484\n",
      "Do Not Need to Fix MP Decomposition 5 so just continuing\n",
      "---- Working on MP Decomposition #6 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0004076957702636719\n",
      "Do Not Need to Fix MP Decomposition 6 so just continuing\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [2, 11]\n",
      "conn = [2, 11]\n",
      "winning_vertex = [995064.64289639 972447.99597209 879514.26450227]\n",
      "MP_branches_with_stitch_point = [2, 11]\n",
      "MAP_branches_with_stitch_point = [4]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (758.3718647021772) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (692.3411158252966) \n",
      "Found winning edge: [33, 35.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4730738ea83543aeb19b062ec80e8db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.12659084754941782\n",
      " conflict_indices % = 0.0025724343352288115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225e729a5fe341ad8e2f7852ff9cb62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c6b60324cc482dac280194c9a5cd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [2, 11]\n",
      "MP_branches_for_correspondence = [ 2 11]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1423.3456489649038\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [988018.5150823  989422.45226546 901709.91572237]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [3]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1820.199056666848) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac298c20e1141d5b8c23fdcca4742bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.13646633529145955\n",
      " conflict_indices % = 0.02349751468594668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f56b88681d4e7c9c71546ba9f6b0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5089373046064473aeac25e650fe760a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415ff648eab9460589270ba33b7135ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.21438082556591212\n",
      " conflict_indices % = 0.07086847166740642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343d581a26b6474c8c34696c7b60ca1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc52f370461e4a92b9fd85ebbc980bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 6723.379289004949\n",
      "sk_conn = [2]\n",
      "conn = [2]\n",
      "winning_vertex = [982865.64228102 985471.40176113 898600.76823966]\n",
      "MP_branches_with_stitch_point = [2]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1206.3082233996583) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [529, 530.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404d3543da3348a7850bd2a1ab1c3cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.06964306475991164\n",
      " conflict_indices % = 0.0055807464248343215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c03378c72a242ff8c8af2e5f6ab19db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7965809aa9474b934e689ae5c68bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cbd7e2b7e74f64bb5448d5e1e5de75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.028579513299377475\n",
      " conflict_indices % = 0.012280701754385965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96d767dc6b94e2c887204643dbaabda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60ecb2b8ccd4ecb9f7d364900a8f8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [2]\n",
      "MP_branches_for_correspondence = [2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (3, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [4, 14]\n",
      "conn = [4, 14]\n",
      "winning_vertex = [1000308.58853892 1016832.27205512  870826.2037682 ]\n",
      "MP_branches_with_stitch_point = [4, 14]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1588.67086355305) \n",
      "Found winning edge: [117, 118.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1566.0096406710854) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca77a3ed48f4a9988156e453992e902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.09509146893678681\n",
      " conflict_indices % = 0.00045281651874660387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516ae7309df24c66897b6238c40c84c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a2cfdebab943bf8fad4f519770a12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [4, 14]\n",
      "MP_branches_for_correspondence = [ 4 14]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (3, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [1000485.88465416 1015766.86012488  871666.22090763]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (439.6870729155871) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527b77d924e5481ebd8544b85246937d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.06622516556291391\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5d4ce40caa458fb33dc2f024aae1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6fa91c77eb452698312210234bafb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (5, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2188.708707303542\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [985961.81864011 987342.59015886 901120.21748151]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [7]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (473.7062926053393) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [447, 449.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeec723c48a4aaca6ca1bed0d862079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty mesh_correspondence_indices_2 returned so returning original mesh correspondence\n",
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.08289768483943241\n",
      " conflict_indices % = 0.008961911874533234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d934c27508c8412daf05696654dd0aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66b25dc39394ed1a267247438d4ae8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779c433352de4f00a7d7ef6a48451f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty mesh_correspondence_indices_2 returned so returning original mesh correspondence\n",
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.06968585552543453\n",
      " conflict_indices % = 0.03013873385424972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fab3a86899746388b30310b0893dbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb28f60861054c81bd4b87f92e34ecbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (5, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (6, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 13771.438805674408\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [983959.74182789 980860.34413226 885941.50746628]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (431.72632524372943) \n",
      "Found winning edge: [210, 212.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb62c89fef343af90aaba4e041a6460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.07807766455521895\n",
      " conflict_indices % = 0.006196640044064996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392e44a906ae4b75a1ee47dab0a91d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a49bc5e43ed47a3bef3c71d7dbd510b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fd69add0c6477d8613691238370c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.06427343078245916\n",
      " conflict_indices % = 0.0088134135855546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b2061731b0432880d29311064e1ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cf4907660d4bf6b7a6a7ffe6896fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (6, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 49.47438144683838\n",
      "Number of matching vertices = 47\n",
      "Number of matching vertices = 93\n",
      "MORE THAN one endpoint after filtering away the endpoints that are not on the skeleton: 2\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 4 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 6.4373016357421875e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8617941967814cfda88ccbf072f9fc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54961.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 0.9166934490203857\n",
      "connecting at the root\n",
      "branches_touching_root = [18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:933: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 4605\n",
      "Working on path [2072. 2074. 2077. 2080. 2082.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [4262. 4264. 4268. 4271. 4275. 4277.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 18, len(kept_branches_idx) = 17\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.00906919493735758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d7b8f26416473bad2b0794ecfd9053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ecb8d053c946bea2656de25eb1fe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 3.627619981765747\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [18508, 5768, 1492, 12808, 7515]\n",
      "mesh_large_connectivity: 0.07585835456848145\n",
      "Finding MAP candidates connected components: 0.00013947486877441406\n",
      "len(filtered_pieces) = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeleton_connectivity_MP : 0.14017677307128906\n",
      "Grouping MP Sublimbs by Graph: 0.032660484313964844\n",
      "Divinding into MP and MAP pieces: 7.152557373046875e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.0012850761413574219\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_709475.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_58046.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_58046_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_302615.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_58046.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_58046_fill_holes.off\n",
      "-----Time for Screened Poisson= 11.199821949005127\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdfe0eb71df4477ac51d5223470b694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486702e71c18472d8775b19c28655a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.055603742599487305\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 12.753494262695312\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.006426811218261719\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7e19c16289484987fc5a975886a320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (131, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 12.897640705108643\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35860a979c3e40538e49addf97772c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 1.5919215679168701\n",
      "mesh_correspondence_first_pass: 1.5919554233551025\n",
      "Limb decomposed into 7 branches\n",
      "divided_skeleton_graph_recovered = (131, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (131, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (6, 7)\n",
      "empty_indices % = 0.1402096390749946\n",
      " conflict_indices % = 0.03247244434838988\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9086b156544b5ea9377db66ed72459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8730bccca4c64e4e88933a6972a0eb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 14.868046522140503\n",
      "correspondence_1_to_1: 0.37714242935180664\n",
      "--- Working on MAP piece 1---\n",
      "MAP Filtering Soma Pieces: 0.006559133529663086\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_781896.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_23492.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_23492_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_20275.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_23492.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_23492_fill_holes.off\n",
      "-----Time for Screened Poisson= 13.992798089981079\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450850b5d59f487cbe531fdf5b8fe63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bd234d940a4f189d638147dc4d0ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.04395556449890137\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 17.408875942230225\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.17954707145690918\n",
      "sbv[0].reshape(-1,3) = [[911505. 996135. 914928.]]\n",
      "closest_sk_pt_coord BEFORE = [914645. 995496. 913932.]\n",
      "current_skeleton.shape = (189, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1015.7105887013288\n",
      "Changing the stitch point becasue the distance to end or branch node was 1015.7105887013288\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [913775. 995268. 913460.]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[913775., 995268., 913460.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.2773144245147705\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[913775. 995268. 913460.]]\n",
      "Number of end_nodes BEFORE filtering = 9\n",
      "all_single_nodes_to_eliminate = [5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3589ba13a740d69cd1f59a8f6c1e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (182, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 17.827429056167603\n",
      "Working on limb correspondence for #1 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a125af2b12994882a66b87e6be1f108b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty mesh_correspondence_indices_2 returned so returning original mesh correspondence\n",
      "\n",
      "Total time for decomposition = 2.1447975635528564\n",
      "mesh_correspondence_first_pass: 2.1448569297790527\n",
      "Limb decomposed into 5 branches\n",
      "divided_skeleton_graph_recovered = (182, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (182, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (4, 5)\n",
      "empty_indices % = 0.20164594134068087\n",
      " conflict_indices % = 0.024834136968422578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c0eeee38f140c7bd8004a3fd4fa1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5a377b0ff64d7b82044225d109d5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae38d8a972a64644b3a5a712563d7219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #1 mesh processing = 22.079909086227417\n",
      "correspondence_1_to_1: 2.1010167598724365\n",
      "Total time for MAP sublimb processing 36.948129415512085\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0059261322021484375\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0023360252380371094\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0007550716400146484\n",
      "Fixing Possible Soma Extension Branch for Sublimb 2\n",
      "Total time for mesh KDTree = 0.044957637786865234\n",
      "sbv[0].reshape(-1,3) = [[921396. 996450. 913122.]]\n",
      "closest_sk_pt_coord BEFORE = [921302.18010157 996647.16306386 912394.01048514]\n",
      "current_skeleton.shape = (172, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 4242.734972124059\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [921302.18010157 996647.16306386 912394.01048514]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [920095.79583333 995845.74305556 912971.06666667]\n",
      "endpoints_must_keep = {1: array([[920095.79583333, 995845.74305556, 912971.06666667]])}\n",
      "orig_vertex = [921302.18010157 996647.16306386 912394.01048514]\n",
      "match_sk_branches = [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0313ceab63468c84f0e8337bd73b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.3367252543940796\n",
      " conflict_indices % = 0.18100524205982116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b3e4cef37d4b3298904f09e516d2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce857e7acbd439fa512600b82368120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfee4a7efac349c19055a5952c3194bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curr_width_median = 2908.1490625090973\n",
      "curr_width_median = 398.0555856372773\n",
      "curr_width_median = 2941.464122350755\n",
      "checked segment branches after soma add on\n",
      "Total time for mesh KDTree = 0.00359344482421875\n",
      "sbv[0].reshape(-1,3) = [[922336.6 998283.1 915472.3]]\n",
      "closest_sk_pt_coord BEFORE = [922598.46490747 998394.83798807 915318.38758301]\n",
      "current_skeleton.shape = (43, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 443.87092848615237\n",
      "Changing the stitch point becasue the distance to end or branch node was 443.87092848615237\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [922824.19943108 998769.44943818 915383.37577568]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[922824.19943108, 998769.44943818, 915383.37577568]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "MP (because soma touching verts) soma extension add: 0.9647769927978516\n",
      "---- Working on MP Decomposition #3 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0010526180267333984\n",
      "Do Not Need to Fix MP Decomposition 3 so just continuing\n",
      "---- Working on MP Decomposition #4 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001188516616821289\n",
      "Do Not Need to Fix MP Decomposition 4 so just continuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1313: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([k for i,k in enumerate(segment_branches) if i not in match_sk_branches] + new_skeletal_branches)\n",
      "/meshAfterParty/preprocessing_vp2.py:1322: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  divided_submeshes_idx = np.array([k for i,k in enumerate(divided_submeshes_idx) if i not in match_sk_branches] + new_submeshes_idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [1, 2]\n",
      "conn = [1, 2]\n",
      "winning_vertex = [834085.85469375 987991.46183449 878846.13274976]\n",
      "MP_branches_with_stitch_point = [1, 2]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (586.6316069280932) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [831, 832.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (535.0731536699088) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a290b4684574dafa4b18e9be42e27ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.0665767533104463\n",
      " conflict_indices % = 0.0006130456105934281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44d2018406a459c8f7432bd35d723d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451b3c544333482da0dccb14f7006611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [1, 2]\n",
      "MP_branches_for_correspondence = [1 2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [883067.56900183 992269.10331008 901224.95897411]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [6]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Found winning edge: [8, 9.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (660.5659457864634) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [137, 138.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b848ba645e443b1a256b80e8623bea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.0479026411185914\n",
      " conflict_indices % = 0.030554117037804248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0953f6ee0274480b914bfedc6fc7a20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e136d10b7d4b474d9aa17ad9df880875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (0, 1) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 6950.75931641148\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [901364.3954276  996165.98403962 909077.9175479 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (908.7600735132338) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b326467f9d44d49a511310b6f6a8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.006174845628859279\n",
      " conflict_indices % = 0.031524211894702635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9e644b0b7b49c78273b967779aa682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcc0bafc09842c287a6f71a88dae252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a455cf945b424d99cc5e7b2ef72ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.07238993232453805\n",
      " conflict_indices % = 0.027564443768534713\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6dde674126416b93f5375c499288cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05fdc26eea04ff589d312dd73240215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 1) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 6073.315482694189\n",
      "sk_conn = [0, 1, 3]\n",
      "conn = [0, 1, 3]\n",
      "winning_vertex = [921097.42676701 994356.50618052 910439.852539  ]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [4]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2328.096600698952) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2270.45764035925) \n",
      "Found winning edge: [22, 24.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f4b004eb674440a17283d5b654d0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.1546124726041044\n",
      " conflict_indices % = 0.002656571694228598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7701973f6c643029524d672fca89b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee913fcebc141ba87d0737359263e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495867582e44404c8d51659d365d3000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.17653995170980966\n",
      " conflict_indices % = 0.04520186422595317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe2aa948b234e5dbfd79aca34f20239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e843066fc3484d5cb4eb2cc5b7c3e6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (3, 1) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [ 933577.17078525 1007202.93694291  879309.77365913]\n",
      "MP_branches_with_stitch_point = [0, 1, 2]\n",
      "MAP_branches_with_stitch_point = [6]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1004.8725721609339) \n",
      "Found winning edge: [44, 46.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (650.1138704827603) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1007.8902744415248) \n",
      "Found winning edge: [22, 26.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79063f84c9f14bd2ae6d52d8cc04b7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.1640109001893677\n",
      " conflict_indices % = 0.0005080596739180639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39fa4eaf6f540699c989073833ca8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646a8133b3094b53a2ac5721c3b3d80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1, 2]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [2], MP_leftover_idx = [2]\n",
      " Finished with (3, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 1) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [882923. 991885. 900913.]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Not adjusting MP skeletons because keep_MP_stitch_static = True\n",
      "Not adjusting MP skeletons because keep_MP_stitch_static = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2296.2547768050476) \n",
      "Found winning edge: [1, 2.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a69f4639c5d4d93a55f20c6467dc650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.09290637564618036\n",
      " conflict_indices % = 0.025990809879379666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9bc563d588443d9e246611eb719beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4b0e1cedae40d39acd5dcd47840c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 1) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 59.590373039245605\n",
      "Number of matching vertices = 116\n",
      "Number of matching vertices = 0\n",
      "Number of matching vertices = 72\n",
      "Number of matching vertices = 0\n",
      "Number of matching vertices = 0\n",
      "Number of matching vertices = 38\n",
      "MORE THAN one endpoint after filtering away the endpoints that are not on the skeleton: 2\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 5 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 5.7220458984375e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6717c18ceea144bd9c70957365d30c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36684.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for 1st pass MP skeletonization: 0.5340480804443359\n",
      "connecting at the root\n",
      "branches_touching_root = [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:933: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 2, len(kept_branches_idx) = 3\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.001437371663244353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a0be7e31c54f2f92b374c2436a0a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80869fcab87643a7a092c60cb59a8e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 1.7481358051300049\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [30238, 37419, 5393]\n",
      "mesh_large_connectivity: 0.05420708656311035\n",
      "Finding MAP candidates connected components: 0.00011610984802246094\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.015697717666625977\n",
      "Grouping MP Sublimbs by Graph: 3.3855438232421875e-05\n",
      "Divinding into MP and MAP pieces: 7.152557373046875e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.004893779754638672\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_382291.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_82245.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_82245_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_6721.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_82245.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_82245_fill_holes.off\n",
      "-----Time for Screened Poisson= 22.52457332611084\n",
      "     Starting Calcification\n",
      "**** Warning: There were redundant edges in the skeleton*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c037a4d79474ae98d4bc93815c0023d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7e02e4384340deb98c162d16f2a800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.0589604377746582\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 27.57209300994873\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.43314242362976074\n",
      "sbv[0].reshape(-1,3) = [[915558. 999159. 925050.]]\n",
      "closest_sk_pt_coord BEFORE = [916136. 999747. 926903.]\n",
      "current_skeleton.shape = (679, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [916136. 999747. 926903.]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[916136., 999747., 926903.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.6369237899780273\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[916136. 999747. 926903.]]\n",
      "Number of end_nodes BEFORE filtering = 38\n",
      "all_single_nodes_to_eliminate = [27]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd9cd43ee274f388e139b7274ce86de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (618, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 29.363459587097168\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c2bf7faa3347b2a50e151945c57557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n",
      "WARNING - 2020-11-18 02:01:52,582 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2020-11-18 02:01:52,807 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 8.671956300735474\n",
      "mesh_correspondence_first_pass: 8.67200493812561\n",
      "Limb decomposed into 13 branches\n",
      "divided_skeleton_graph_recovered = (618, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (618, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (12, 13)\n",
      "empty_indices % = 0.14420260095824777\n",
      " conflict_indices % = 0.021423682409308694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ca250894524eebac1ca64da67d57e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949271d2065647ee9510ef57ebd902a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb1f72318ad4968b34917dd51bb3ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 41.903533697128296\n",
      "correspondence_1_to_1: 3.8631298542022705\n",
      "Total time for MAP sublimb processing 41.90364480018616\n",
      "There were not both MAP and MP pieces so skipping the stitch resolving phase\n",
      "Time for decomp of Limb = 44.256279706954956\n",
      "Number of matching vertices = 20\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 6 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 6.67572021484375e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cb08a7ed744ddcbc886ea09379c45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22727.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 0.36665964126586914\n",
      "branches_touching_root = [3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 1825\n",
      "max(kept_branches_idx) = 6, len(kept_branches_idx) = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n",
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.010039939098391404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ffc24952024132b4f7a0a1bd417862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4045bdbc5d4d079bfae53841b0b031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 1.0674526691436768\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [2042, 753, 1732]\n",
      "mesh_large_connectivity: 0.028896093368530273\n",
      "Finding MAP candidates connected components: 0.00011110305786132812\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.09277892112731934\n",
      "Grouping MP Sublimbs by Graph: 0.01925063133239746\n",
      "Divinding into MP and MAP pieces: 9.5367431640625e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.001026153564453125\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_107211.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_94580.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_94580_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_307609.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_94580.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_94580_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.905598402023315\n",
      "     Starting Calcification\n",
      "**** Warning: There were redundant edges in the skeleton*****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a53d74c9d914364aaf26a0f46f8b022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caa9cb2e4524cc3b7d9f9f81ca7669b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.02600550651550293\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 7.58383321762085\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.04962968826293945\n",
      "sbv[0].reshape(-1,3) = [[994164.1 992856.5 916759.2]]\n",
      "closest_sk_pt_coord BEFORE = [996026. 992588. 917711.]\n",
      "current_skeleton.shape = (18, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [996026. 992588. 917711.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[996026., 992588., 917711.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.0977625846862793\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[996026. 992588. 917711.]]\n",
      "Number of end_nodes BEFORE filtering = 3\n",
      "all_single_nodes_to_eliminate = [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eae90ef510b4b6ba285739e639dfe4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (17, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.719755172729492\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138fecaac3df4b17a8e115d494e1c17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.2048189640045166\n",
      "mesh_correspondence_first_pass: 0.20487380027770996\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (17, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (17, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.6231499889551579\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7974186348c54f57b242a33b3ed74895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492c941a0e0f42c0981e2d03fe140cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a19817135534d9589e511458da8e1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 8.17653512954712\n",
      "correspondence_1_to_1: 0.2504260540008545\n",
      "Total time for MAP sublimb processing 8.176620483398438\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.003913164138793945\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0027806758880615234\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0031380653381347656\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [999011.12608704 995184.84514516 922738.95778911]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1610.1617264010272) \n",
      "Found winning edge: [981, 984.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1622.2656322409782) \n",
      "Found winning edge: [415, 416.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b22c7840e56487e8821e5894497fe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.12818540244254256\n",
      " conflict_indices % = 0.021228002692566594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad41bf31826b4564be3fb6aba27b1f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bcd65cc07140abb5468e7a52d6b6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3174.39995483091\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [998523.89424233 993711.59620524 920169.85044907]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (611.0283277851032) \n",
      "Found winning edge: [74, 75.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15674d6b71b4b5bb32487bf3b3b1c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.6532140628250468\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c195b4aa4de49e1b2ff7d984114de45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac576e45480436abb457be225c0538e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e23a87571e4a0381c2c502e6335ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.5903893951946976\n",
      " conflict_indices % = 0.014913007456503728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60035ab124c047c5b9cc96332d721b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231cd788a173420e9af7272c388971c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 800.2439269103452\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [1000347.30989615  993487.5336817   920165.93172175]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (997.5450437796597) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6673badbb8d94e358a066dfaabcc0422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty mesh_correspondence_indices_2 returned so returning original mesh correspondence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.8691471571906354\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e8299019e74d698587c57d763860e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f76467ea53d436e96250d56bbb862da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f1b620f7ac4629b6ac9e302bf3c16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2020-11-18 02:02:18,768 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.2969101698383466\n",
      " conflict_indices % = 0.031512175158584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaa887e7e90489fa592d7b208fb7432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e47c5ad33e44554b54e917f9eb66ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 19.529751777648926\n",
      "Number of matching vertices = 24\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 7 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 7.3909759521484375e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cef3a588e348e09b49e5fecf2fa555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 0.24697518348693848\n",
      "branches_touching_root = [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 1684\n",
      "max(kept_branches_idx) = 2, len(kept_branches_idx) = 3\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0015799214553333634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3725c96961e44433a27a3b845d6e0266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a64ff4898840fe8fdaf53d7590b9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 0.7336885929107666\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Divinding into MP and MAP pieces: 7.200241088867188e-05\n",
      "Total time for MAP sublimb processing 2.6226043701171875e-06\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Using Quicker soma_to_piece_touching_vertices because no MAP and only one sublimb_mesh piece \n",
      "MP filtering soma verts: 5.936622619628906e-05\n",
      "Fixing Possible Soma Extension Branch for Sublimb 0\n",
      "Total time for mesh KDTree = 0.12956905364990234\n",
      "sbv[0].reshape(-1,3) = [[ 922236. 1001553.  922614.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest_sk_pt_coord BEFORE = [ 922580.84961416 1001711.60316471  922926.58497181]\n",
      "current_skeleton.shape = (1509, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [ 922580.84961416 1001711.60316471  922926.58497181]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[ 922580.84961416, 1001711.60316471,  922926.58497181]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "No soma extending branch was added for this sublimb even though it had a soma border (means they already existed)\n",
      "MP (because soma touching verts) soma extension add: 0.3468050956726074\n",
      "There were not both MAP and MP pieces so skipping the stitch resolving phase\n",
      "Time for decomp of Limb = 1.3278326988220215\n",
      "Number of matching vertices = 19\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 8 ---------\n",
      "meshparty_segment_size = 100\n",
      "Time for preparing soma vertices and root: 5.0067901611328125e-06\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d303e34e969a4e9e864e3840dbcdbfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10666.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for 1st pass MP skeletonization: 0.24053692817687988\n",
      "connecting at the root\n",
      "branches_touching_root = [6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:933: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 1303\n",
      "max(kept_branches_idx) = 6, len(kept_branches_idx) = 7\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.010058281631885694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac98fd6163142aebceb90a4735e782f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f072b056e8343dbb7e7786358197fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 0.6688716411590576\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [9042, 5220, 2116]\n",
      "mesh_large_connectivity: 0.014181137084960938\n",
      "Finding MAP candidates connected components: 0.00010061264038085938\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.022005319595336914\n",
      "Grouping MP Sublimbs by Graph: 0.004548549652099609\n",
      "Divinding into MP and MAP pieces: 9.5367431640625e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.003203153610229492\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_199908.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_91772.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_91772_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_193021.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_91772.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_91772_fill_holes.off\n",
      "-----Time for Screened Poisson= 10.085968017578125\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a768695980f4ce2ac65bbe9ee74dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390837c0dd8540dc816fcd9dbfa575b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.03896141052246094\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 11.935248136520386\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.12830638885498047\n",
      "sbv[0].reshape(-1,3) = [[988533.4 998595.3 908796.7]]\n",
      "closest_sk_pt_coord BEFORE = [988580. 998707. 909323.]\n",
      "current_skeleton.shape = (208, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [988580. 998707. 909323.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[988580., 998707., 909323.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.1936354637145996\n",
      "filter_end_node_length = 1500\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[988580. 998707. 909323.]]\n",
      "Number of end_nodes BEFORE filtering = 6\n",
      "all_single_nodes_to_eliminate = [3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e23f68d7254be2988e2487649ae5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (199, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 12.2862708568573\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ef592a92aa44098b67368a373df04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 1.380946159362793\n",
      "mesh_correspondence_first_pass: 1.3809795379638672\n",
      "Limb decomposed into 3 branches\n",
      "divided_skeleton_graph_recovered = (199, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (199, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.06991085602637685\n",
      " conflict_indices % = 0.007632189522530223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fbe07e9b4344a6a3ac826e96cddf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed3ced11d934641a13787d0b61cd6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca28ac8cf724a219e313be656cfd641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 14.864243745803833\n",
      "correspondence_1_to_1: 1.1937406063079834\n",
      "Total time for MAP sublimb processing 14.864327907562256\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.003353118896484375\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "\n",
      "---- Working on (0, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1590: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [1, 2]\n",
      "conn = [1, 2]\n",
      "winning_vertex = [ 970012.1106727  1022380.48511881  894765.51735411]\n",
      "MP_branches_with_stitch_point = [1, 2]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1672.6846978685605) \n",
      "Found winning edge: [164, 165.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1662.5096876695043) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bf07be451e49619e0dcaa426a998a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:331: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.04969091773656681\n",
      " conflict_indices % = 0.01925820256776034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84811aeef340398df1dd6a3afe82a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495d3e8f78aa4e8d847512c2efb41624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [1, 2]\n",
      "MP_branches_for_correspondence = [1 2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 17.105413913726807\n",
      "Number of matching vertices = 24\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Total time for Skeletonization and Mesh Correspondence = 605.4724779129028\n",
      "\n",
      "\n",
      " ----- Working on Stitching ----------\n",
      "The closest float distance was 29954.958981225634 which was greater than the maximum stitch distance 8000\n",
      " --> so ending the floating mesh stitch processs\n",
      "Total time for stitching floating pieces = 0.7777481079101562\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [919594. 990720. 919833.]---------\n",
      "Starting_edge inside branches_to_conept = [[919594. 990720. 919833.]\n",
      " [924946. 978849. 912296.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [19]\n",
      "printing out current edge:\n",
      "[[919594. 990720. 919833.]\n",
      " [924946. 978849. 912296.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 29 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 3\n",
      "Total time for branches to concept conversion = 0.935497522354126\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [3]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [984577.77222222 991779.71805556 917127.71527778]---------\n",
      "Starting_edge inside branches_to_conept = [[983558.59487623 991536.79838002 918027.29499536]\n",
      " [984577.77222222 991779.71805556 917127.71527778]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [21]\n",
      "printing out current edge:\n",
      "[[984577.77222222 991779.71805556 917127.71527778]\n",
      " [983558.59487623 991536.79838002 918027.29499536]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 30 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 29\n",
      "Total time for branches to concept conversion = 0.611177921295166\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [29]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [980157. 991894. 914384.]---------\n",
      "Starting_edge inside branches_to_conept = [[928904. 999210. 920332.]\n",
      " [980157. 991894. 914384.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [11]\n",
      "printing out current edge:\n",
      "[[980157. 991894. 914384.]\n",
      " [928904. 999210. 920332.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 52 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 3\n",
      "Total time for branches to concept conversion = 0.882070779800415\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [3]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [923969. 998675. 918335.]---------\n",
      "Starting_edge inside branches_to_conept = [[923969. 998675. 918335.]\n",
      " [928904. 999210. 920332.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [1]\n",
      "printing out current edge:\n",
      "[[923969. 998675. 918335.]\n",
      " [928904. 999210. 920332.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 52 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 0\n",
      "Total time for branches to concept conversion = 0.89451003074646\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [0]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [986386.95957447 988521.05957447 905097.41702128]---------\n",
      "Starting_edge inside branches_to_conept = [[986386.95957447 988521.05957447 905097.41702128]\n",
      " [987781.         988761.         902291.        ]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [17]\n",
      "printing out current edge:\n",
      "[[986386.95957447 988521.05957447 905097.41702128]\n",
      " [987781.         988761.         902291.        ]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 51 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 2\n",
      "Total time for branches to concept conversion = 0.6614501476287842\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [2]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [913775. 995268. 913460.]---------\n",
      "Starting_edge inside branches_to_conept = [[913775. 995268. 913460.]\n",
      " [914645. 995496. 913932.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [18]\n",
      "printing out current edge:\n",
      "[[913775. 995268. 913460.]\n",
      " [914645. 995496. 913932.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 28 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 10\n",
      "Total time for branches to concept conversion = 0.3009147644042969\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [10]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 1, endpt = [922824.19943108 998769.44943818 915383.37577568]---------\n",
      "Starting_edge inside branches_to_conept = [[921302.18010157 996647.16306386 912394.01048514]\n",
      " [922824.19943108 998769.44943818 915383.37577568]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [23]\n",
      "printing out current edge:\n",
      "[[922824.19943108 998769.44943818 915383.37577568]\n",
      " [921302.18010157 996647.16306386 912394.01048514]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 28 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 21\n",
      "Total time for branches to concept conversion = 0.299724817276001\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [21]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [916136. 999747. 926903.]---------\n",
      "Starting_edge inside branches_to_conept = [[ 910524. 1000400.  938219.]\n",
      " [ 916136.  999747.  926903.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [8]\n",
      "printing out current edge:\n",
      "[[ 916136.  999747.  926903.]\n",
      " [ 910524. 1000400.  938219.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 13 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 7\n",
      "Total time for branches to concept conversion = 0.058509111404418945\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [7]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [996026. 992588. 917711.]---------\n",
      "Starting_edge inside branches_to_conept = [[996026. 992588. 917711.]\n",
      " [998847. 993547. 919723.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [3]\n",
      "printing out current edge:\n",
      "[[996026. 992588. 917711.]\n",
      " [998847. 993547. 919723.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 7 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 0\n",
      "Total time for branches to concept conversion = 0.14398813247680664\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [0]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [ 922580.84961416 1001711.60316471  922926.58497181]---------\n",
      "Starting_edge inside branches_to_conept = [[ 922580.84961416 1001711.60316471  922926.58497181]\n",
      " [ 939991.02732718 1066100.41823929  968195.35725274]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [0]\n",
      "printing out current edge:\n",
      "[[ 922580.84961416 1001711.60316471  922926.58497181]\n",
      " [ 939991.02732718 1066100.41823929  968195.35725274]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 3 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 1\n",
      "Total time for branches to concept conversion = 0.15546917915344238\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [1]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [988580. 998707. 909323.]---------\n",
      "Starting_edge inside branches_to_conept = [[ 988580.  998707.  909323.]\n",
      " [ 989936. 1007680.  904049.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [5]\n",
      "printing out current edge:\n",
      "[[ 988580.  998707.  909323.]\n",
      " [ 989936. 1007680.  904049.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 7 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 2\n",
      "Total time for branches to concept conversion = 0.049323081970214844\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "recovered_touching_piece = [2]\n",
      "Total time for Concept Networks = 7.6502461433410645\n"
     ]
    }
   ],
   "source": [
    "sk = reload(sk)\n",
    "tu = reload(tu)\n",
    "cu = reload(cu)\n",
    "m_sk = reload(m_sk)\n",
    "pre = reload(pre)\n",
    "xu = reload(xu)\n",
    "nu = reload(nu)\n",
    "gu = reload(gu)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Phase 4: Skeletonization, Mesh Correspondence,  \n",
    "\n",
    "proper_time = time.time()\n",
    "\n",
    "#The containers that will hold the final data for the preprocessed neuron\n",
    "limb_correspondence=dict()\n",
    "limb_network_stating_info = dict()\n",
    "\n",
    "# ---------- Part A: skeletonization and mesh decomposition --------- #\n",
    "skeleton_time = time.time()\n",
    "\n",
    "for curr_limb_idx,limb_mesh_mparty in enumerate(current_mesh_data[0][\"branch_meshes\"]):\n",
    "\n",
    "    #Arguments to pass to the specific function (when working with a limb)\n",
    "    soma_touching_vertices_dict = piece_to_soma_touching_vertices[curr_limb_idx]\n",
    "\n",
    "#     if curr_limb_idx != 10:\n",
    "#         continue\n",
    "\n",
    "    curr_limb_time = time.time()\n",
    "    print(f\"\\n\\n----- Working on Proper Limb # {curr_limb_idx} ---------\")\n",
    "\n",
    "    print(f\"meshparty_segment_size = {meshparty_segment_size}\")\n",
    "    limb_correspondence_individual,network_starting_info = pre.preprocess_limb(mesh=limb_mesh_mparty,\n",
    "                   soma_touching_vertices_dict = soma_touching_vertices_dict,\n",
    "                   return_concept_network = False, \n",
    "                   return_concept_network_starting_info=True,\n",
    "                   width_threshold_MAP=500,\n",
    "                   size_threshold_MAP=2000,\n",
    "                   surface_reconstruction_size=1000,  \n",
    "\n",
    "                   #arguments added from the big preprocessing step                                                            \n",
    "                   distance_by_mesh_center=distance_by_mesh_center,\n",
    "                   meshparty_segment_size=meshparty_segment_size,\n",
    "                   meshparty_n_surface_downsampling = meshparty_n_surface_downsampling,\n",
    "\n",
    "                    use_meshafterparty=use_meshafterparty,\n",
    "\n",
    "                   )\n",
    "    #Storing all of the data to be sent to \n",
    "\n",
    "    limb_correspondence[curr_limb_idx] = limb_correspondence_individual\n",
    "    limb_network_stating_info[curr_limb_idx] = network_starting_info\n",
    "\n",
    "print(f\"Total time for Skeletonization and Mesh Correspondence = {time.time() - skeleton_time}\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Part B: Stitching on floating pieces --------- #\n",
    "print(\"\\n\\n ----- Working on Stitching ----------\")\n",
    "\n",
    "floating_stitching_time = time.time()\n",
    "\n",
    "limb_correspondence_with_floating_pieces = pre.attach_floating_pieces_to_limb_correspondence(\n",
    "        limb_correspondence,\n",
    "        floating_meshes=non_soma_touching_meshes,\n",
    "        floating_piece_face_threshold = 600,\n",
    "        max_stitch_distance=8000,\n",
    "        distance_to_move_point_threshold = 4000,\n",
    "        verbose = False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total time for stitching floating pieces = {time.time() - floating_stitching_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Part C: Computing Concept Networks --------- #\n",
    "concept_network_time = time.time()\n",
    "\n",
    "limb_concept_networks=dict()\n",
    "limb_labels=dict()\n",
    "\n",
    "for curr_limb_idx,limb_mesh_mparty in enumerate(current_mesh_data[0][\"branch_meshes\"]):\n",
    "    limb_to_soma_concept_networks = pre.calculate_limb_concept_networks(limb_correspondence_with_floating_pieces[curr_limb_idx],\n",
    "                                                                    limb_network_stating_info[curr_limb_idx],\n",
    "                                                                    run_concept_network_checks=True,\n",
    "                                                                       )   \n",
    "\n",
    "\n",
    "\n",
    "    limb_concept_networks[curr_limb_idx] = limb_to_soma_concept_networks\n",
    "    limb_labels[curr_limb_idx]= \"Unlabeled\"\n",
    "\n",
    "print(f\"Total time for Concept Networks = {time.time() - concept_network_time}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have preprocessed data\n",
      "No soma volume ratios so computing them now\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_248840.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_248840_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_907001.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_248840.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_248840_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_907001.mls is being deleted....\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_344836.off -o /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_344836_poisson.off -s /notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_565416.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_344836.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/Poisson_temp/neuron_344836_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Decomp_Fusion/Poisson_temp/poisson_565416.mls is being deleted....\n",
      "--- 1) Finished unpacking preprocessed materials: 22.484812259674072\n",
      "total_edges = [['S0', 'L1'], ['S0', 'L2'], ['S0', 'L3'], ['S0', 'L6'], ['S0', 'L8'], ['S1', 'L0'], ['S1', 'L2'], ['S1', 'L4'], ['S1', 'L5'], ['S1', 'L7']]\n",
      "--- 2) Finished creating neuron connectivity graph: 0.00016808509826660156\n",
      "Having to generate soma_meshes_face_idx because none in preprocessed data\n",
      "--- 3a) Finshed generating soma_meshes_face_idx: 1.006317377090454\n",
      "Using precomputed volume ratio\n",
      "Using precomputed volume ratio\n",
      "--- 3) Finshed generating soma objects and adding them to concept graph: 0.270047664642334\n",
      "--- 4a) Finshed generating curr_limb_meshes_face_idx: 3.2354321479797363\n",
      "curr_limb_concept_networks= {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7321f3d048>]}\n",
      "concept_network_dict = {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7321f3d048>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31240>]}\n",
      "concept_network_dict = {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31240>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31160>], 1: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e310b8>]}\n",
      "concept_network_dict = {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31160>], 1: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e310b8>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31320>]}\n",
      "concept_network_dict = {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31320>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31ac8>, <networkx_utils.GraphOrderedEdges object at 0x7f7319e31a58>]}\n",
      "concept_network_dict = {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31ac8>, <networkx_utils.GraphOrderedEdges object at 0x7f7319e31a58>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31438>]}\n",
      "concept_network_dict = {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7319e31438>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7440439d30>]}\n",
      "concept_network_dict = {0: [<networkx_utils.GraphOrderedEdges object at 0x7f7440439d30>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7317a6ea58>]}\n",
      "concept_network_dict = {1: [<networkx_utils.GraphOrderedEdges object at 0x7f7317a6ea58>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f73bcd2b978>]}\n",
      "concept_network_dict = {0: [<networkx_utils.GraphOrderedEdges object at 0x7f73bcd2b978>]}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "--- 4) Finshed generating Limb objects and adding them to concept graph: 1.9361894130706787\n",
      "--- 5) SKIPPING Doing the adaptive mesh correspondence on the meshparty preprocessing ---\n",
      "--- 6) SKIPPING Using the computed_attribute_dict to populate neuron attributes ---\n",
      "7) Calculating the spines for the neuorn if do not already exist\n",
      "7a) calculating spines because didn't exist\n",
      "query = median_mesh_center > 200 and n_faces_branch>100\n",
      "smoothness_threshold = 0.08\n",
      "The median_mesh_center was requested but has not already been calculated so calculating now.... \n",
      "Working on limb L1 branch 29\n",
      "Working on limb L1 branch 27\n",
      "Working on limb L1 branch 28\n",
      "Working on limb L1 branch 6\n",
      "Working on limb L1 branch 11\n",
      "Working on limb L1 branch 9\n",
      "Working on limb L1 branch 17\n",
      "Working on limb L1 branch 4\n",
      "Working on limb L1 branch 13\n",
      "Working on limb L1 branch 8\n",
      "Working on limb L1 branch 25\n",
      "Working on limb L1 branch 16\n",
      "Working on limb L1 branch 18\n",
      "Working on limb L1 branch 2\n",
      "Working on limb L1 branch 3\n",
      "Working on limb L1 branch 0\n",
      "Working on limb L1 branch 22\n",
      "Working on limb L1 branch 10\n",
      "Working on limb L1 branch 26\n",
      "Working on limb L1 branch 5\n",
      "Working on limb L1 branch 12\n",
      "Working on limb L1 branch 23\n",
      "Working on limb L1 branch 24\n",
      "Working on limb L1 branch 7\n",
      "Working on limb L1 branch 21\n",
      "Working on limb L1 branch 1\n",
      "Working on limb L1 branch 14\n",
      "Working on limb L1 branch 15\n",
      "Working on limb L1 branch 19\n",
      "Working on limb L1 branch 20\n",
      "Working on limb L2 branch 3\n",
      "Working on limb L2 branch 0\n",
      "Working on limb L2 branch 1\n",
      "Working on limb L2 branch 2\n",
      "Working on limb L2 branch 45\n",
      "Working on limb L2 branch 47\n",
      "Working on limb L2 branch 4\n",
      "Working on limb L2 branch 5\n",
      "Working on limb L2 branch 46\n",
      "Working on limb L2 branch 49\n",
      "Working on limb L2 branch 8\n",
      "Working on limb L2 branch 51\n",
      "Working on limb L2 branch 48\n",
      "Working on limb L2 branch 50\n",
      "Working on limb L2 branch 6\n",
      "Working on limb L2 branch 7\n",
      "Working on limb L2 branch 14\n",
      "Working on limb L2 branch 24\n",
      "Working on limb L2 branch 13\n",
      "Working on limb L2 branch 42\n",
      "Working on limb L2 branch 12\n",
      "Working on limb L2 branch 16\n",
      "Working on limb L2 branch 11\n",
      "Working on limb L2 branch 29\n",
      "Working on limb L2 branch 30\n",
      "Working on limb L2 branch 15\n",
      "Working on limb L2 branch 20\n",
      "Working on limb L2 branch 10\n",
      "Working on limb L2 branch 36\n",
      "Working on limb L2 branch 28\n",
      "Working on limb L2 branch 33\n",
      "Working on limb L2 branch 19\n",
      "Working on limb L2 branch 32\n",
      "Working on limb L2 branch 9\n",
      "Working on limb L2 branch 44\n",
      "Working on limb L2 branch 35\n",
      "Working on limb L2 branch 40\n",
      "Working on limb L2 branch 27\n",
      "Working on limb L2 branch 38\n",
      "Working on limb L2 branch 18\n",
      "Working on limb L2 branch 21\n",
      "Working on limb L2 branch 23\n",
      "Working on limb L2 branch 31\n",
      "Working on limb L2 branch 41\n",
      "Working on limb L2 branch 34\n",
      "Working on limb L2 branch 43\n",
      "Working on limb L2 branch 17\n",
      "Working on limb L2 branch 26\n",
      "Working on limb L2 branch 22\n",
      "Working on limb L2 branch 39\n",
      "Working on limb L2 branch 25\n",
      "Working on limb L2 branch 37\n",
      "Working on limb L3 branch 2\n",
      "Working on limb L3 branch 1\n",
      "Working on limb L3 branch 3\n",
      "Working on limb L3 branch 8\n",
      "Assigning the old width calculation because no valid new widths\n",
      "Working on limb L3 branch 30\n",
      "Working on limb L3 branch 40\n",
      "Working on limb L3 branch 48\n",
      "Working on limb L3 branch 6\n",
      "Working on limb L3 branch 22\n",
      "Working on limb L3 branch 7\n",
      "Working on limb L3 branch 49\n",
      "Working on limb L3 branch 29\n",
      "Working on limb L3 branch 33\n",
      "Working on limb L3 branch 4\n",
      "Working on limb L3 branch 5\n",
      "Working on limb L3 branch 9\n",
      "Working on limb L3 branch 25\n",
      "Working on limb L3 branch 28\n",
      "Working on limb L3 branch 39\n",
      "Working on limb L3 branch 32\n",
      "Working on limb L3 branch 38\n",
      "Working on limb L3 branch 12\n",
      "Working on limb L3 branch 21\n",
      "Working on limb L3 branch 0\n",
      "Working on limb L3 branch 50\n",
      "Working on limb L3 branch 23\n",
      "Working on limb L3 branch 24\n",
      "Working on limb L3 branch 27\n",
      "Working on limb L3 branch 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on limb L3 branch 31\n",
      "Working on limb L3 branch 41\n",
      "Working on limb L3 branch 42\n",
      "Working on limb L3 branch 46\n",
      "Working on limb L3 branch 37\n",
      "Working on limb L3 branch 47\n",
      "Working on limb L3 branch 11\n",
      "Working on limb L3 branch 15\n",
      "Working on limb L3 branch 18\n",
      "Working on limb L3 branch 26\n",
      "Working on limb L3 branch 43\n",
      "Working on limb L3 branch 35\n",
      "Working on limb L3 branch 44\n",
      "Working on limb L3 branch 10\n",
      "Working on limb L3 branch 14\n",
      "Working on limb L3 branch 16\n",
      "Working on limb L3 branch 17\n",
      "Assigning the old width calculation because no valid new widths\n",
      "Working on limb L3 branch 20\n",
      "Working on limb L3 branch 34\n",
      "Working on limb L3 branch 45\n",
      "Working on limb L3 branch 13\n",
      "Working on limb L3 branch 19\n",
      "Working on limb L6 branch 0\n",
      "Working on limb L6 branch 1\n",
      "Assigning the old width calculation because no valid new widths\n",
      "Working on limb L6 branch 5\n",
      "Working on limb L6 branch 2\n",
      "Working on limb L6 branch 6\n",
      "Working on limb L6 branch 3\n",
      "Working on limb L6 branch 4\n",
      "Working on limb L8 branch 2\n",
      "Working on limb L8 branch 0\n",
      "Working on limb L8 branch 1\n",
      "Working on limb L8 branch 4\n",
      "Working on limb L8 branch 5\n",
      "Working on limb L8 branch 3\n",
      "Working on limb L8 branch 6\n",
      "Working on limb L0 branch 25\n",
      "Working on limb L0 branch 3\n",
      "Working on limb L0 branch 26\n",
      "Working on limb L0 branch 4\n",
      "Working on limb L0 branch 8\n",
      "Working on limb L0 branch 10\n",
      "Working on limb L0 branch 6\n",
      "Working on limb L0 branch 21\n",
      "Working on limb L0 branch 7\n",
      "Working on limb L0 branch 14\n",
      "Working on limb L0 branch 9\n",
      "Working on limb L0 branch 13\n",
      "Working on limb L0 branch 16\n",
      "Working on limb L0 branch 5\n",
      "Working on limb L0 branch 28\n",
      "Working on limb L0 branch 20\n",
      "Working on limb L0 branch 23\n",
      "Working on limb L0 branch 12\n",
      "Working on limb L0 branch 17\n",
      "Working on limb L0 branch 1\n",
      "Working on limb L0 branch 27\n",
      "Working on limb L0 branch 22\n",
      "Working on limb L0 branch 24\n",
      "Working on limb L0 branch 11\n",
      "Working on limb L0 branch 15\n",
      "Working on limb L0 branch 0\n",
      "Working on limb L0 branch 2\n",
      "Working on limb L0 branch 18\n",
      "Working on limb L0 branch 19\n",
      "Working on limb L4 branch 10\n",
      "Working on limb L4 branch 11\n",
      "Working on limb L4 branch 12\n",
      "Working on limb L4 branch 13\n",
      "Working on limb L4 branch 19\n",
      "Working on limb L4 branch 20\n",
      "Working on limb L4 branch 8\n",
      "Working on limb L4 branch 14\n",
      "Working on limb L4 branch 23\n",
      "Working on limb L4 branch 24\n",
      "Working on limb L4 branch 25\n",
      "Working on limb L4 branch 21\n",
      "Working on limb L4 branch 22\n",
      "Working on limb L4 branch 7\n",
      "Working on limb L4 branch 9\n",
      "Working on limb L4 branch 6\n",
      "Working on limb L4 branch 26\n",
      "Working on limb L4 branch 27\n",
      "Working on limb L4 branch 4\n",
      "Working on limb L4 branch 5\n",
      "Working on limb L4 branch 2\n",
      "Working on limb L4 branch 3\n",
      "Working on limb L4 branch 0\n",
      "Working on limb L4 branch 1\n",
      "Working on limb L4 branch 16\n",
      "Working on limb L4 branch 17\n",
      "Working on limb L4 branch 15\n",
      "Working on limb L4 branch 18\n",
      "Working on limb L5 branch 7\n",
      "Working on limb L5 branch 5\n",
      "Working on limb L5 branch 8\n",
      "Working on limb L5 branch 4\n",
      "Working on limb L5 branch 6\n",
      "Working on limb L5 branch 9\n",
      "Working on limb L5 branch 10\n",
      "Working on limb L5 branch 1\n",
      "Working on limb L5 branch 3\n",
      "Working on limb L5 branch 11\n",
      "Working on limb L5 branch 12\n",
      "Working on limb L5 branch 0\n",
      "Working on limb L5 branch 2\n",
      "Working on limb L7 branch 1\n",
      "Working on limb L7 branch 0\n",
      "Working on limb L7 branch 2\n",
      "functions_list = [<function median_mesh_center at 0x7f73bce08158>, <function n_faces_branch at 0x7f73bce07c80>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aeba441664b475aaf6a24c196b2cdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb879b5add8411d8026e0d4ef6f3d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e814bdcf13c342f497f9837f83810706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07f55e8f61d47d59d6da7684a38c606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab7cc31fe75438b83d99704f41ce82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=256.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55eabdd05aea47b68d77eed45f3864d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b13dfc0dd354fffb87437b86d4e26c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1367d25142438f807bdea2101a656c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f59e473481f47c29bbeb0a06c28a42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=93.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a253672daee44a4a607e5c8b69d4cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676146c750cd4a9e8069ef5b1b0499b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9024c5bfab740378b7f3d4ee38e35d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=33.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12eb4eff4d844b58b568efbc444804d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f0cc9ff096427fb6cebc259eae98f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a5a641a78f42dc9d3c86c5978d4163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074fd78e4b494674bacdc0f9934ec4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4db0ca5fe934dada94ac320f7f984c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd19a78ebb00404590d26b383c76dbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6cafac66b64370bac851871c430fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274c7f6a37b3486a98de4840845cdf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8a556f28ca4ca2ab1cda66e924c705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a198c93d82d34f97ac681f8d5b1a1f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5e89c02a98428c9996dc92bdabb8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565b8b6e0d8f4d47a740de1365e7aadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fce879dcbcc4890b86ae4182be80ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6a05eec5994f1bb1d11c8b1bf025c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67022acc61c44b058f2f39741776003f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c210a6c216c9443a91a72d73498a32c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd86bc9c77b34a4a80c8609d0df4fa8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1756e99b68d2445ea3dbdaa3b0bf96d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7795002088ec424fb558af7e625c047b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea525bc4d3724856ba4bbb905d63daee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a75cf1489fd4e2f8488d04754eafb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46eb5857f344850978cb962dc9af333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2c1a43bcdd46d19821b4730b93bb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cb391e281e4c7f92e35e8e98db0649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5474bbb845e4bd39020d1f37f55b7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6545470efa7e4898adae6b99f5172c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0e22decfe1407b876ed6ed4a820a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729a3981982644c5a971f65b9cb253a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb394fd66ebe4b23b054065fc1a7c380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4350212b9f224a3998aed8f2eb8cad1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a31a8bca3bb470682b9286b35ef117c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58afe7820574c688fc4a3853e069354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd26b18b483e449eaf6e137181ac7fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0f03725a3d4f3388c8cdb258f37558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165a939a783b427e9a2b188ed4cd82e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f0d15ce9d24a51802a20011649d2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a5f4199f874b9aa9fb8cdcb448ee38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b80f72661a40f9bbd6926dfe08a22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d93abce606546d7b98330a7a65a4873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd846b94c48410d9d4c9735082fe4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2c4186dd1d41d59305ba6b2be91c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168ebf4544e64f8faa72e446b427b0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d8e2cf849434cb3a38f5150425d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7ab24466664b5bab80ebc1f4acdb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30db0053202a499c9a33f38b65b74a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587dccf0f59241cebfdde98be45fe8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a284f5ff9c4a9597b15a9f60ca2b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67636e7a7d0e48d4919272ed79be8bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9237d4691b3b4209ba65b0cfe8b4de32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a005f2da3d2467b9a32ebe088467f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d55f21f8194620907f638752018a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214ba73fd57a4fcb98876afb600e0a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e49ce1a521a460e8619d2bffad886c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e1ab926ae54ed4ad6f70fe735bf5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6a9f49d496419cae904ca582a3b77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There was only one mesh found from the spine process and mesh split, returning empty array\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2466736110a4abdbbfec591e35bf38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e2c5fc8a62495a94a9f8c335ef1199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fdcb0d18d54489823117803464013e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=47.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e26fe63530a44d9bd15c9238fe8818f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfcd4ec599941c78c078f7cf2f656f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cbfdafb49a490b968350a6e589ad43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72603fd97ecd455790f32513f5779e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab8a3c7de9049ff8d75b6d1eb0efe34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6210e07b5932481c929dc8f28d5774c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=47.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ddf3b35b574819956d141346633bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64843228743f4e098d13e217d991adca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b61386217946de9b7590d04292d1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There was only one mesh found from the spine process and mesh split, returning empty array\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8746f4855a3f4409be242193fea4c242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069dbfaac5b945b18dd6147755ca0c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0038cefb8b9d4786b24b599e6d36edbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e941d58c8a54810b7979fabe69e37ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060c9f1cb213403190f7f43c4b9d5b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8335cb42a48048c1a5daf9676e4d1ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042cabc61517400e95b80d245c5c2130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51d8c3b9dcb41089a50a5f2fd27daa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on limb L1 branch 29\n",
      "Working on limb L1 branch 27\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 28\n",
      "Working on limb L1 branch 6\n",
      "Working on limb L1 branch 11\n",
      "Working on limb L1 branch 9\n",
      "Working on limb L1 branch 17\n",
      "Working on limb L1 branch 4\n",
      "Working on limb L1 branch 13\n",
      "Working on limb L1 branch 8\n",
      "Working on limb L1 branch 25\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 16\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 18\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 2\n",
      "Working on limb L1 branch 3\n",
      "Working on limb L1 branch 0\n",
      "Working on limb L1 branch 22\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 10\n",
      "Working on limb L1 branch 26\n",
      "Working on limb L1 branch 5\n",
      "Working on limb L1 branch 12\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 23\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 24\n",
      "Working on limb L1 branch 7\n",
      "Working on limb L1 branch 21\n",
      "Working on limb L1 branch 1\n",
      "Working on limb L1 branch 14\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 15\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 19\n",
      "No spines and using precomputed width\n",
      "Working on limb L1 branch 20\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 3\n",
      "Working on limb L2 branch 0\n",
      "Working on limb L2 branch 1\n",
      "Working on limb L2 branch 2\n",
      "Working on limb L2 branch 45\n",
      "Working on limb L2 branch 47\n",
      "Working on limb L2 branch 4\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 5\n",
      "Working on limb L2 branch 46\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 49\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 8\n",
      "Working on limb L2 branch 51\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 48\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 50\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 6\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 7\n",
      "Working on limb L2 branch 14\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 24\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 13\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 42\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 12\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 16\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 11\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 29\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 30\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 15\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 20\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 10\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 36\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 28\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 33\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 19\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 32\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 9\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 44\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 35\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 40\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 27\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 38\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 18\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 21\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 23\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 31\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 41\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 34\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 43\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 17\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 26\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 22\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 39\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 25\n",
      "No spines and using precomputed width\n",
      "Working on limb L2 branch 37\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 2\n",
      "Working on limb L3 branch 1\n",
      "Working on limb L3 branch 3\n",
      "Working on limb L3 branch 8\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 30\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 40\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 48\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 6\n",
      "Working on limb L3 branch 22\n",
      "Working on limb L3 branch 7\n",
      "Working on limb L3 branch 49\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 29\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 33\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 4\n",
      "Working on limb L3 branch 5\n",
      "Working on limb L3 branch 9\n",
      "Working on limb L3 branch 25\n",
      "Working on limb L3 branch 28\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 39\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 32\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 38\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 12\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 21\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 0\n",
      "Working on limb L3 branch 50\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 23\n",
      "Working on limb L3 branch 24\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 27\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 36\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 31\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 41\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 42\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 46\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 37\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 47\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 11\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 15\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 18\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 26\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 43\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 35\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 44\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 10\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 14\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 16\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 17\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 20\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 34\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 45\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 13\n",
      "No spines and using precomputed width\n",
      "Working on limb L3 branch 19\n",
      "No spines and using precomputed width\n",
      "Working on limb L6 branch 0\n",
      "No spines and using precomputed width\n",
      "Working on limb L6 branch 1\n",
      "No spines and using precomputed width\n",
      "Working on limb L6 branch 5\n",
      "No spines and using precomputed width\n",
      "Working on limb L6 branch 2\n",
      "Working on limb L6 branch 6\n",
      "No spines and using precomputed width\n",
      "Working on limb L6 branch 3\n",
      "Working on limb L6 branch 4\n",
      "Working on limb L8 branch 2\n",
      "No spines and using precomputed width\n",
      "Working on limb L8 branch 0\n",
      "Working on limb L8 branch 1\n",
      "Working on limb L8 branch 4\n",
      "Working on limb L8 branch 5\n",
      "No spines and using precomputed width\n",
      "Working on limb L8 branch 3\n",
      "No spines and using precomputed width\n",
      "Working on limb L8 branch 6\n",
      "Working on limb L0 branch 25\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 3\n",
      "Working on limb L0 branch 26\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on limb L0 branch 8\n",
      "Working on limb L0 branch 10\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 6\n",
      "Working on limb L0 branch 21\n",
      "Working on limb L0 branch 7\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 14\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 9\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 13\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 16\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 5\n",
      "Working on limb L0 branch 28\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 20\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 23\n",
      "Working on limb L0 branch 12\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 17\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 1\n",
      "Working on limb L0 branch 27\n",
      "Working on limb L0 branch 22\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 24\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 11\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 15\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 0\n",
      "Working on limb L0 branch 2\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 18\n",
      "No spines and using precomputed width\n",
      "Working on limb L0 branch 19\n",
      "Working on limb L4 branch 10\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 11\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 12\n",
      "Working on limb L4 branch 13\n",
      "Working on limb L4 branch 19\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 20\n",
      "Working on limb L4 branch 8\n",
      "Working on limb L4 branch 14\n",
      "Working on limb L4 branch 23\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 24\n",
      "Working on limb L4 branch 25\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 21\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 22\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 7\n",
      "Working on limb L4 branch 9\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 6\n",
      "Working on limb L4 branch 26\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 27\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 4\n",
      "Working on limb L4 branch 5\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 2\n",
      "Working on limb L4 branch 3\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 0\n",
      "Working on limb L4 branch 1\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 16\n",
      "Working on limb L4 branch 17\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 15\n",
      "No spines and using precomputed width\n",
      "Working on limb L4 branch 18\n",
      "No spines and using precomputed width\n",
      "Working on limb L5 branch 7\n",
      "Working on limb L5 branch 5\n",
      "No spines and using precomputed width\n",
      "Working on limb L5 branch 8\n",
      "Working on limb L5 branch 4\n",
      "Working on limb L5 branch 6\n",
      "No spines and using precomputed width\n",
      "Working on limb L5 branch 9\n",
      "No spines and using precomputed width\n",
      "Working on limb L5 branch 10\n",
      "Working on limb L5 branch 1\n",
      "Working on limb L5 branch 3\n",
      "No spines and using precomputed width\n",
      "Working on limb L5 branch 11\n",
      "Working on limb L5 branch 12\n",
      "No spines and using precomputed width\n",
      "Working on limb L5 branch 0\n",
      "Working on limb L5 branch 2\n",
      "No spines and using precomputed width\n",
      "Working on limb L7 branch 1\n",
      "No spines and using precomputed width\n",
      "Working on limb L7 branch 0\n",
      "No spines and using precomputed width\n",
      "Working on limb L7 branch 2\n",
      "No spines and using precomputed width\n",
      "Total time for neuron instance creation = 295.78477787971497\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data= dict(\n",
    "    soma_meshes = current_mesh_data[0][\"soma_meshes\"],\n",
    "    soma_to_piece_connectivity = current_mesh_data[0][\"soma_to_piece_connectivity\"],\n",
    "    soma_sdfs = total_soma_list_sdf,\n",
    "    insignificant_limbs=insignificant_limbs,\n",
    "    not_processed_soma_containing_meshes=not_processed_soma_containing_meshes,\n",
    "    non_soma_touching_meshes=non_soma_touching_meshes,\n",
    "    inside_pieces=inside_pieces,\n",
    "    limb_correspondence=limb_correspondence_with_floating_pieces,\n",
    "    limb_concept_networks=limb_concept_networks,\n",
    "    limb_network_stating_info=limb_network_stating_info,\n",
    "    limb_labels=limb_labels,\n",
    "    limb_meshes=current_mesh_data[0][\"branch_meshes\"],\n",
    "    )\n",
    "neuron_obj = neuron.Neuron(\n",
    "                mesh=current_neuron,\n",
    "                 segment_id=segment_id,\n",
    "                 description=description,\n",
    "                 preprocessed_data=preprocessed_data,\n",
    "#                  decomposition_type=\"meshafterparty\",\n",
    "#                  mesh_correspondence=\"meshparty\", #meshafterparty_adaptive\n",
    "#                  distance_by_mesh_center=True, #how the distance is calculated for mesh correspondence\n",
    "#                  meshparty_segment_size = 0,\n",
    "#                  meshparty_n_surface_downsampling = 0,\n",
    "#                  meshparty_adaptive_correspondence_after_creation=False,\n",
    "#                 suppress_preprocessing_print=True,\n",
    "#                  computed_attribute_dict=None,\n",
    "#                  somas = None,\n",
    "#                  branch_skeleton_data=None,\n",
    "#                  combine_close_skeleton_nodes = True,\n",
    "#                 combine_close_skeleton_nodes_threshold=700,\n",
    "\n",
    "\n",
    "                ignore_warnings=True,\n",
    "                suppress_output=False,\n",
    "                calculate_spines=True,\n",
    "                widths_to_calculate=[\"no_spine_median_mesh_center\"]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Working on visualization type: mesh\n",
      "\n",
      " Working on visualization type: skeleton\n",
      "working on soma border vertices\n",
      "Working on  new stand alone scatter points\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e142477fb74697b57937442a4bae90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.visualize_neuron(neuron_obj,visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=\"all\"#dict(L2=\"all\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5FUlEQVR4nO3deZyO9f7H8dc9Y/YZhghlTbINU5aIEi2HFJ02FSctqlOkpP1IOToVhxSpcyotCu3haCGUREZa0KD6pWxhrGPMMPv9++PrtszcM2bmvu77uu/7ej8fj/txzMx1f+fjOGfe891dbrfbjYiIiENE2F2AiIhIICn4RETEURR8IiLiKAo+ERFxFAWfiIg4ioJPREQcRcEnIiKOUs3uAkREnCIPmAcsBZYB+zC9j2ZAD+AioJ1dxTmISxvYRUT8Kwf4F/Ai4D78cXGJZ2KASEwIPg1cGsgCHUbBJyLiR18D/YH9wKEKvice6A1MBWr6qS4nU/CJiPjJe8BNVDzwjhUNnAosB+paWJMo+ERE/OIL4DKqFnoe1YCmwBog1oqiBNCqThERy+0HrsW30AMoBLYCj/hckRxLwSciYrF/ANkWtXUIeAlYa1F7ouATEbFUNvAGkFvyC02awMKFpd+waBG0bAnx8dCzJ2zaVOqRAuAZqwt1MAWfiIiFPqASP1h374Yrr4QnnoC9e6FjR7j22lKPFQJvA/nWleloCj4REQt9QSWGOT/6CNq0gWuugdhYGD0aVq+Gn38u9WgUkG5dmY6m4BMRsVBaZR5euxZSU49+nJAAzZqZz5dQBPzga3ECKPhERCyVWZmHs7OhRo3jP1ejBhw4UOrRPGC3D3XJUQo+ERELuSrzcGIiZGUd/7msLEhK8tqufmBbQ/89iohYqH5lHm7TxszpeeTkwIYN5vMlxAINfC1OAAWfiIilzi3viwUFkJt79HXFFZCeDh9+aD4eMwbatTPbG7zo4JeKnUfBJyJioV5A6YHKw/r0gbi4o69Jk0zojRwJNWvCihXwzjte3xoFNPdTzU6jszpFRCxUCNQD9ljYZgzwIDDGwjadTD0+ERELVcOcrZlgcZtDLGzP6RR8IiIWG465VcGKH7AJwERML1KsoaFOERE/+A3oiLmpoarigL8As6jkNgkpl3p8IiJ+cDrm9vWamIUplZUAXIi5zFahZy0Fn4iIn7QF1gE9qPicXxQQDzwFzMHcxC7W0lCniIifuYHPgKeB7zBhllVUBJGRgNmcHg0UAzcD9wGNbanUGRR8IiIBtB1YCdz71lu06t6d0xo3pjlmc3p7TAiKfyn4RERscOaZZ/Laa6/Rvn17u0txHM3xiYjYYOfOndStW9fuMhxJPT4RkQArLi4mJiaGnJwcoqO1fCXQ1OMTEQmwffv2kZSUpNCziYJPRCTAMjIyOPnkk+0uw7EUfCIiAab5PXsp+EREAkw9Pnsp+EREAkw9PntVs7uAULcf+AHYgLmHqzqQCrQEIm2sS0SCl3p89lLwVUEe8D4wDvgFc65eAeZYomqH/7MQuBYYAbSzp0wRCVI7d+6kQ4cOdpfhWBrqrKTlmFPX7wTSMYG3HzgIHAIOANlALjAd6II5e++AHcWKSFBSj89eCr5KmIC5JmQrJtxOpAgThu8ALTDDoSIimuOzl4KvgiYAj2OCrLJygQygM7DJyqJEJCSpx2cvHVlWAWnABVQt9I4ViZnv+w79xiHiZImJiWzfvp2kpCS7S3Ek/fw9gXygP76HHpihz1+B5yxoS0RCU05ODkVFRSQmJtpdimMp+E7gQ2BfyU82aQILF5Z++L33oFUrSEqC1q1h9uxSj+QAT2AWxYiI83jm91wul92lOJaC7wTGUbGFLPz5J/ztbzBxImRlwfjxMGAA7NxZ6tEiYI7FdYpIaND8nv0UfOU4AKyr6MNbt0JyMlxyCbhccOmlkJAAG0qv5TwAzLKuTBEJIVrRaT8FXzlWAXEVfbhjRzPM+b//QVGRGeaMiYF23revp1lTooiEGPX47KeTW8rxO2ZYskIiI2HQIDO8mZsL0dHw/vum1+fFNquKFJGQoh6f/dTjK0dhZR5euBAefBAWL4b8fPjqK7j1Vli1yuvjFQ5UEQkr6vHZT8FXjhpU4qDpVauge3cz5BkRAZ06QefO3ld/Ys73FBHnUY/Pfgq+cqRSTs+soMAMaXpenTrB118f7eH9+KP5uIw5vjZ+qFdEgp96fPbTHF85mpX3xT59jv945EgYPRquvhoyMqBOHfjHP+Avfyn11ijMSTAi4jzq8dlPR5adwB3Aq1Ryvu8EYoE1QHML2xSR0FC7dm3Wr19PnTp17C7FsRR8J/Az0B5rjiwDM7Z8DrDUovZEJHQUFhYSFxdHbm4ukZG6qtoumuM7gZaY+/QqvJ/vBGKAqRa1JSKhZdeuXZx00kkKPZsp+CpgPHAylVjhWYZ44J+YMBUR59HCluCg4KuAeGAJUJuqh18CcBNwv0U1iUjo0cKW4KDgq6BGwA9AJ0yIVVQEZph0NDAF0HnsIs6lHl9wUPBVwinAN5jb2GsD5V0hGYVZvXke8COmp6fQE3E29fggD9iOObYx16YaFHyV5MJscdgBzABuwczZJWCCrkZhIfErVzISWAssBlrYU6qIBBmn9vjWAXcCp2M6DM2O+XNTYDDmUoBA0Qb2KooE+h5+HSuvqIjk7t15aN8+YmNjbahMRILVzp07adWqld1lBMxGYBDwHebybc9+6IISz0wD3gFaA9Pxf2dBPT6LxcTE0Lx5c9auXWt3KSISZJzU43sTczTjN5h90OUdAlIEHMSsozgLsx7CnxR8ftCuXTvWrFljdxkiEmScMsc3BTO0eZDK3URTjAnJh4An/FCXh4LPD1JTU1m9erXdZYhIkHFCj+8LTHAd9KGNg8BYYJYlFZWm4PMD9fhEpCS3283OnTvDOvgOANfjW+h5HMScmrXbgrZKUvD5gafHp2NQRcQjMzOTuLi4sF70NgkTfsdp0qT0vaQzZkBi4tFXfDy4XPD998c9dgj4lx/qVPD5Qd26dYmMjGTbtm12lyIiQSLc5/eKMMFXoQP9Bw6E7OyjrxdfhNNOg/btj3ssH3M7jlWXBHgo+PzA5XJpnk9EjhPu83tpmM3pVTJtGgwaZHp9JURg5g2tpODzE83zicixwr3H59mrV2mbNsGSJSb4vMgBvvWhLm8UfH6iHp+IHCvce3wrqeIRZG++CeedB02bev1yEQq+kJGamqoen4gcEe49vlKLWirqzTfhxhv903YZFHx+0rJlS37//Xdyc+06hlVEgkm49/iqdFn3smWwbRtcfXW5j1m9DlbB5yeeo8vWrVtndykiEgTCvcd3FhBd1hcLCiA39+ir8PABZtOmwVVXQVLZd91EAO3L/GrVKPj8qF27dprnExEg/Ht8nSinZ9anD8TFHX2NHm0C8L33TjjMmQh0trZU3c7gT1rgIiIe4d7j6wZ4PbJj48ay35SZecJ284GLqlRR2dTj8yNtaRARj3Dv8cUAt1HOcGcVRALXAjUsbBPA5da5Wn6zY8cO2rRpw+7du3F52ZgpIs5w6NAhkpOTyc3NDeufBTuB5kCWRe0lAOlAE4va81CPz490dJmIAEcOpw7n0AM4GRi9fTuug74fU50A/BvrQw8UfH6lo8tEBMJ/fs9j8eLFjD3zTC747TfifWgnHrgKc6efPyj4/EzzfCIS7vN7AK+++ir9+/dnxowZLGjXjhFUbW9fPHAL8Drgr/6xVnX6WWpqKp999pndZYiIjcK5x1dUVMTDDz/M7Nmz+frrr2nRogVgblC/FLM4ZR8nPn0lCTO8ORPo6cd6QT0+v1OPT0TCtceXnZ3NlVdeyXfffUdaWtqR0PPoAvwOvIMJs/jDrxqHXwmYvX/dgGnAFvwfeqAen9+1atXqyNFl4XwBpYiUbefOnTRs2NDuMiy1efNm+vXrR8eOHXn//feJjva+kSES6HP45Qb+AHYAxUBdoBmB74Gpx+dnMTExnH766Tq6TMTBwq3Ht2LFCs455xxuuOEGXnnllTJDryQXcBrQFTgXs/XBjhBS8AWAVnaKOFs4zfG9++67XHbZZfznP//hvvvuC8ktGhrqDADN84k4W0ZGRsgHn9vt5oknnuDVV19l4cKFpKam2l1SlSn4AiA1NZV58+bZXYaI2MSzgT1U5ebmcsstt7BhwwZWrFhBvXr17C7JJxrqDABPj0+nw4k4T1FREXv37qV27dp2l1IlGRkZ9OzZk6KiIhYvXhzyoQcKvoCoV68eEREROrpMxIF2795NcnIy1aqF3gDbTz/9ROfOnenVqxfvvPMOcXFVum426Cj4AsBzdJnm+UScJ1QXtnz88cdceOGFPP3004wePTokF7GURcEXILqUVsSZQm0rg9vtZuLEidx+++3873//4/rrr7e7JMuFXt87RGmBi4gzhVKPr6CggKFDh5KWlsby5ctp3Lix3SX5hXp8AaIen4gzhUqPb+/evfTu3Ztt27axbNmysA09UPAFzLFHl4mIc4RCj+/XX3+lS5cunHnmmcyZM4ekpCS7S/IrBV+A6OgyEWcK9h7fl19+yXnnnccDDzzAM888Q2RkpN0l+Z2CL4B0dJmI8wRzj++VV17huuuu4+233+a2226zu5yA0eKWANLRZSLOE4w9vqKiIh588EHmzp3L119/zRlnnGF3SQGl4AsgrewUcZ5g6/EdOHCAAQMGkJOTQ1paGrVq1bK7pIDTUGcA6egyEWdxu91B1ePbtGkT3bp1o379+syfP9+RoQcKvoDS0WUiznLgwAGioqKIj4+3uxTS0tI455xzuPnmm3nppZeIioqyuyTbKPgCyOVyaZ5PxEGCpbf3zjvv0LdvX1566SXuvffesDp+rCoUfAGmlZ0izmH3/J7b7Wb06NE8/PDDLFq0iL59+9pWSzDR4pYAa9euHfPnz7e7DBEJADt7fIcOHeLmm29m06ZNrFixIqgW2NgtID2+HGAbsAMoDMQ3DGLq8Yk4h109vh07dtCjRw8iIiL48ssvFXol+CX43MBXQH/gVCAZOB04DUgAWgMPAZv88c2DnI4uE3EOO3p8q1evpnPnzlx66aXMmDGD2NjYgH7/UGB58KUBzYFLgQ8wPb1C4NDhVz6wHngOaAlcCey2uoggpqPLRJwj0D2+uXPnctFFF/Hvf/+bxx57zPGLWMpiWfAVAw8AFwAbMMOb5e1WywdygU8wvcEFVhUSArSyU8QZAtXjc7vdPPPMM9xxxx18/PHHXHvttX7/nqHMksUtbuBmTA/vUCXfm3/4dTnwHnCZFQUFOc3ziThDIHp8+fn5DBkyhJUrV7J8+XIaNWrk1+8XDizp8Y3HhN5BH9o4BFwL/GJFQUEuNTVVPT4RB/B3j2/v3r306tWLnTt3snTpUoVeBfkcfL8Ao/Et9DxygWuAIgvaCmaeS2l1dJlIePNnj++XX36hc+fOdOzYkVmzZoX9HXpW8jn47gHySn6ySRNYuPD4z61bBx07Qs2a5nXRReZzxygGfgfe97WoIOc5umz79u12lyIifpKXl0dOTg7JycmWt71o0SK6d+/Oww8/zPjx4x1xh56VfAq+PzHbFoor8vApp8AHH8DevbB7N/TrB9ddV+qxHODfvhQVAjxHl2meTyR87dq1izp16hARYe3i+ZdeeokBAwbw7rvvMnjwYEvbdgqf/kU+qszDycmmJ+hygdsNkZHw229eH10HhHtfSAtcRMKb1fN7RUVF3HvvvUycOJGlS5fSo0cPy9p2Gp9WdX6FmZerlORkyM6G4mIYM8brIzHA94T3Ck8dXSYS3qyc38vKymLAgAEcOnSItLQ0atasaUm7TuVTj69K/ZXMTNi/H6ZMgbPO8vrIQSDdh7pCgXp8IuHNqh7fxo0b6datG6eeeirz5s1T6FnAp+Cr8krOhAS44w4YNAh27iz15ULMXF8409FlIuHNih7f8uXL6dq1K4MHD+a///2vo+/Qs5JPwRfjy5uLi+HgQfjzz1JfigDC/XQ5HV0mEt587fHNmDGDyy+/nKlTpzJ8+HAdP2Yhn4KvVXlfLCiA3NyjrwUL4McfoagIsrJgxAizraFV6VYSMed4hjsdXSYSvqra4ysuLuaxxx7j0UcfZdGiRfTp08cP1TmbT4tbegALMUeOlVLyH6t1axN6W7dCXBycfTbMmwdeTg4vADr4UliI0DyfSPiqSo/v4MGD3HTTTWzdupUVK1YExe3t4cin4LsceNzbFzZu9KVZ6gONfWohNGhlp0iYKS6GLVvgwAFit2yhXiUWomzfvp3LL7+c5s2b88UXX+g6IT/yaajzDCDVokI8YgoLedDtxgmj2Z4en44uEwlhOTkwdao5mSohwYxude3KzF9+IfXcc6F5c3j0Ua/rGTxWrVpF586d6devH9OnT1fo+ZnPRwo8B8T5XscRRbt3886ll7J27VoLWw1O9erVw+Vy6egykVDkdsOLL0LdunDvvfD992Y9w8GDcOAAiW43rsJCc1DHhAlw+ukweLDZx3yMOXPmcPHFFzNhwgQeffRRLWIJAJ+DrzNwG9aEXxzwRe3aXNG7Nz169ODee+8lMzPTgpaDk8vl0jyfSCjKzIRzz4UHHzQ9vhJhVkpengnFmTNNAK5ahdvtZvz48QwdOpRPPvmE/v37B6R0sfBaorPxLfziD7dzXrVq3H333axdu5bs7GxatWrFa6+9RnFxhU4EDTla2SkSYjIzoXNn+O47E3qVkZsLGRm4zzuPf15+OTNnzmT58uWcffbZfilVvHO5LZpgygP6A4uo3ObzCMx+wMnArV6+vnLlSoYNG4bb7eb5558Pu/+BTJs2jfnz5zNz5ky7SxGRE3G74S9/gSVLIN/revYKOxAVhWvDBhIbNrSoOKkoy44NjwFmA68C1TF78crjAhKAFOAHvIceQKdOnfjmm28YMmQIf/3rXxk8eDAZGRkWVW0/9fhEQsj06bB8uc+hB5AYEUHiffdZUJRUlqX3Zbgwt6jvAJ7HrPiMwoRgjcOvWCAJ6At8BqzixJvVIyIiuPHGG1m/fj01a9YkJSWF5557joKCAivLt0Xr1q3ZsGGDji4TCXaFhWYRS4nhzaVAV8zPt1pAN2Al5oaZfsApmJ+NG0s058rLg48/hvRwP5k4+Fh7UdRhccBNmFA7CKQBc4FPgV+B/cAc4Dyo1LaFGjVqMGHCBJYsWcKnn37KmWeeyaJFi6wsPeA8R5etX7/e7lJEpDwff1yqp5eFuUVmGLAXc0fp45gRsAigN/BheW3m58Ozz/qjWimHZXN8geZ2u5kzZw733nsvHTp04JlnnqFx49Dc9j5w4EAuvvhibrrpJrtLEZGyXHklzJp13Ke+Ay4CMst5WyFm5OsPoIm3B5KSzI012sYQMH7p8QWCy+Xir3/9K+vWraNdu3a0b9+eMWPGcOjQIbtLq7TU1FTN84kEu2+/LfWpM4BI4EbM1M2+qrRbUFDu5naxXsgGn0dcXByPPfYYP/zwA2vWrKF169bMmjUrpE5DadeunfbyiQSzoiLwctBEdcwcnwuzn7kOZl6vUsvvYmJAt7QEVMgHn0fjxo354IMPmDp1Ko8++ii9evUKmXkzHV0mEuTy8iDC+4/LVsAbwFbMBdrbgOGVadvthhAcqQplYRN8HhdeeCGrVq2iT58+dO/enfvuu4+srCy7yyqXji4TCT5ZWVmsXr2a2bNn89yLL1JcWHjC97TELOyr1DpNl8vrLTXiPz7dzhCsoqKiGD58OAMGDOCRRx6hZcuWPPXUUwwaNIiIMn5rs9OxR5edcsopdpcj4gi5ubls2rSJP/74w+srNzeXJk2a0LRpU5o2bUpOjRok7d9/XBs/A59gtnE1ALYAbwNdPN8DKDr857zDH5eKuPx8c7C1BEzIruqsjG+//ZZhw4YRERHB888/T8eOHe0uqZQRI0ZQt25dHnroIbtLEQkLRUVFbN26tcxg2717Nw0aNDgSbCVfJ5988vEHRl9xBcyefdz3+BO4F1iGWdmZjNneMB4z/+dtnWapH7ha1RlwYdnjK+nss89m+fLlTJs2jb59+3LZZZfx1FNPUadOHbtLOyI1NVV384W5XcAs4CvMaUXZmGXuLYHzMYc66Pf+inO73ezcubPMYNu6dSu1a9c+LswuuOCCI39u0KABkZGRFf+GgwbBokVw4MCRT50KvFdejSdqMzISrr5aoRdgjujxHWv//v2MHj2a6dOnM2rUKIYMGUK1avbn/48//sgNN9xAuk5xCDubgPswQ2IRmEMdSorGLItvDUwAegSquCC3f//+MoNt48aNxMbGltlja9y4sbX32hUWmiuI9u61rMni2FgiVq6ElBTL2pQTc1zweaxbt467776bjIwMJk+eTM+ePW2tJy8vj+TkZPbt26dLKMPIy8AIzPzOiZdGGHHAAMyxf1bedRmMcnNz2bhxY5nhlpeXV2awNW3alOrVqwe24GnTYOjQyt/K4EVhtWp8EhFB2ogRPProoyQkJFhQoFSEY4MPzFDJRx99xH333cfZZ5/NhAkTaNSokW31pKSk8NZbb3HWWWfZVoNYww08APwH7z28E4kF2mCGRUP5x2FhYWG582x79uyhYcOGZQZbnTp1gutiVrcbLroIli71/aDqWrXY/vXX3P/kkyxdupRnn32WK664Irj+vmHK0cHncfDgQf79738zZcoUhg8fzv33329Lr0tHl4WPCZgzG6sSeh4xmNWBX1K5M20Dye12k5GRUWaw/fnnn9SpU6fMYDv11FMrN88WDDIz4eyzYdOmqodfYiIsXgwdOgCwePFihg4dSsOGDXn++edp3ry5ZeVKaQq+Y2zcuJH77ruPVatWMXHiRPr16xfQ377GjRtHRkYGEydODNj3FOutAzoCVmxJTsCsELzTgraqKjMzs9x5tvj4+HLn2WJiYmys3k/27YNLL4U1ayo37BkbC9Wrw7x5UGJkp6CggEmTJjF27FjuvPNOHnnkEeLj4y0uXEDB59WCBQu45557aNSoEZMmTaJFixYB+b7z5s1j/PjxIX/jhNOdjTm82Kr/YyVg9ofVtKi9kg4dOlTuPFthYeFxYXbs3ramTZuSlJTkp8qCXHEx/Pe/8OCD5uPyAjAmxqzcvP56mDTJbGEow9atW7nvvvv49ttvmTRpEv369bO4cFHwlaGgoIApU6bw1FNPcdNNNzFq1Ci/T6Rv27aNdu3asWvXLo3zh6ifgM546e01aQJTp5r5IY+0NBg1Cr7/3ixr79EDJk+G+vWPe2s8MAazMrQqCgsL2bJlS5nBtm/fPho1alRmr+2kk07S/x7Lk5MDM2aYEFy/3hxtVq0a7uJiCrOziWjShMjrrjOLYho0qHCzCxYs4K677uKMM85g0qRJnHbaaX78SziLgu8EduzYwSOPPMLnn3/O2LFjGThwoN9Of3G73Zx88sk6wSWEDcMsaCkq+QVvwffZZ5CdDb16QbVqcNddsG2bGQYroTGlLzL1cLvd7Nixo8xg27ZtG3Xr1i0z2E455ZSgPNEoJBUXm7m/7GyIiqLnzTfz+NNP06NHjyo1l5eXx8SJE5kwYQL33HMPDz74oFZ9W0DBV0FpaWkMGzaMqKgopkyZQvv27f3yfS688EIeeOABevfu7Zf2xb/aYOb4SvEWfCX98AOcf/5xG6Q9qrndfLF6NTs3bCgVbJs2bSIxMbHMYGvUqBHR0dEW/Q2lMu644w7atGnDsGHDfGpn8+bNDB8+nDVr1vD8889zySWXWFShM9m/cztEdOnShRUrVvD666/Tp08fLr/8cp588klq165t6ffxnNmp4As9xcD/+dLAkiXQpo3XLxVmZXHzc8+RkplJ06ZNadGiBb179z4y55aYmOjLdxY/adu2rSVXjjVq1IiPPvqIzz77jGHDhtG2bVuee+65kL18224a36iEiIgIBg8ezM8//0xsbCytW7fmhRdeoLACp7ZXlC6lDV15mPCrkjVrYMwYGD/e65erV6/OxDfeYPbs2Tz77LPcfffd9O3bl5SUFIVeEGvbti0//fSTZe1dcsklpKen0759e9q3b89TTz1FXl6eZe07hYKvCpKTk5k0aRJffPEFH374IR06dOCrr76ypG1dSht68vPz+eOPP/jm668prsrMwW+/wSWXmNV+553n/RmXS/9nDUFt27Zl7dq1FBdX+VeiUmJjYxk1ahQrV64kLS2Ndu3asWDBAsvadwLN8fnI7XbzwQcfcP/999O1a1fGjx9Pg0qs3CrJc3RZZmZmeO5/CjFut5u9e/eyefPmMl+7du2ifv36NGzUiBWff05hnJeDxsqa49u0yczrPfww3HFHmXUkYW76bmflX04CokGDBnz99dc0bdrUL+3PnTuXe+65h44dOzJx4kSffv44heb4fORyubjmmmu49NJLGTt2LGeeeSYjRoxgxIgRlV99lZVFzOzZTI+NpbhNGygoMMvcTzvN/HDs0+fISQ9ijdzcXLZu3VpusMXGxtKoUaMjr4YNG9K+ffsjH9evX//IQefdgG/K+mYFBZCbe/TjjAy44AKzmrOc0ANzj5tubghNnuFOfwVf3759ueiii3j66adJTU3loYceYvjw4VrQVA71+Cz2+++/M2LECNLT03nuuee47LLLTvym3bvNb/wzZ5qgy84u/Uy1ahAdDY0bw7hx0Lev9cWHmeLiYnbt2uU1zLZs2cLmzZvZt28fDRo0OBJoxwac53OV2aA9HnNUmdd9fJs2eX9TycOJvfz7d8Xc+Sah58EHH6RGjRqMHDnS79/rt99+Y9iwYWzatIkXXnjB9sP3g5WCz0/mz5/PPffcQ7NmzXj22Wc544wzvD84Zw7ceCMcOlTxc//i4+Evf4HXX4fkZMtqDjU5OTlHAqxkoHn+nJSUVCrMjn3VrVvX0j1sezB3tFm53CAJeAu43MI2JXDeeustPvnkE955552AfD+3283s2bMZPnw43bp1Y8KECdoXXIKCz4/y8/OZPHkyY8eO5dZbb2XkyJHH9x4mT4ZHHoGDVTjKODranAKRlgZBdKGuVYqKitixY4fXQPO8cnJyvPbSPK8GDRrYctbhbcB0zPCkFRoBG9C8RKhatWoVAwcOZO3atQH9vjk5OTz55JO8/PLLjBw5krvuuouoqKiA1hCsFHwBsH37dh5++GEWLVrEuHHjGDBgAK733oNbbqla6HlERcHpp8OqVSYIQ0hWVlaZgbZ582a2bdtGrVq1ygy1hg0bBt+VNYcdAE4HdlrQVhywGHP+p4Qmuxes/fLLL9x1113s2LGDF154ge7duwe8hmCj4Augb775hmHDhtEgMpKP1q4l0pfQ84iPh7vvhqef9r0tixQWFrJt27ZyF4wUFhaWG2oNGjQI6VWty4GL8O1aonhgFPCwJRWJnVq3bs3bb79NamqqLd/fs/p8xIgR9OzZk/Hjx1O3bl1bagkGCr4AKyoqYtPZZ9Pghx+wrI8WF2c2QJ9+ulUtlsntdpOZmVluqGVkZFC3bt1SYXbsxzVr1gzK3pqVFgN9MQtdSp3deQLxmMAbZXFNYo9rr72Wfv36MXDgQFvryM7OZsyYMbz++us89thj3HnnnUdWJDuJgi/QMjLMyswSpy0sBR4E1gKRQCvgOaATMBN4BNgNXAy8BtQ69s1RUWY5/OTJPpeXn59f5vJ+z7BkZGRkmYHWqFEjTjnlFM0lHPY7cB2wHvCyVreUeMw1RDMxPUYJD//617/Izs5m7NixdpcCwNq1a7nrrrvIzMzkhRdeoGvXrnaXFFAKvkCbOBFGjjxuP1cWZgHDf4D+QD7wNVAPE4JdgE+A9sDtmGOxSq0PS0iArCxzJUoZ3G43u3fvLjPQNm/ezJ49ezjllFPKXDTSsGFDatSoYdl/HU5QDMwGxgGrMTerHwQ8B90lHX4mGXgAuOXw5yR8zJkzh5dffplPPvnE7lKOcLvdvP322zzwwAP06tWLcePGUScMF8p5o+ALtEsuKXXtzHeY3+4zvTz+D8x1NDMPf7wB0xvcQ4kfjgkJ5C5bxua4uDJXQm7ZsoW4uLhyl/fXq1ePyMhIa//OckQG8D2wBvMLTwzQAuiAWRAT3oO/zvX777/To0cPNm/ebHcppWRlZTF69GimT5/OP//5T26//faw/xmg4Au0+vVhx47jPpUFNAUuwwyLdeHobduXYzYvP3TM84nAV5gflh4HgCHVqrG8ceNyF40klNwsLSJ+V1xcTI0aNdiyZQvJQbr3ds2aNQwdOpTc3FxefPFFOnXqZHdJfuO8WU27ZWWV+lR1zBzfOMwesB1AH+AVzLxQyYHFGpigO1ZCbCzTJkwgYuhQqysWER9FRETQpk0b0tPTOffcc+0ux6t27dqxZMkS3nrrLfr160e/fv146qmnOOmkk+wuzXI68D3QypiDawW8AWwF0oFtwHBM765kVGZReg4owuUiwoGrs0RChdVXFPmDy+Vi0KBBrF+/nujoaFq3bs3UqVMtvV0iGCj4Aq0Ce2daAjdhArANZkGEx++Y47BKHYAWHQ0NG1pSoohYLyUlJeiDzyM5OZnnn3+eefPm8eqrr9K1a1d++OEHu8uyjIIv0Lp0KfWpn4FnML09gC3A25i5voHAXMwqzxzgMeBKvKz6y83VzQ0iQSwUenwlnXXWWSxbtozbb7+dPn36MHToUPbt22d3WT5T8AXaZZdBiRuzk4AVQGfMHq4uQAomDNsA/8UE4MmYub0XvbVbt26FepMiYg9P8IXaesKIiAhuueUW1q1bR3FxMa1ateKNN94I6eFPreoMtLw8c6j0gZLLU3wQHw9jx8KwYda1KSKWq1evHitXrqRhCE9LrFy5kiFDhhATE8MLL7xg2zFsvlCPL9BiYuCBB0xYWSU62lxtJCJBLRSHO0vq1KkTaWlp3HDDDVx88cUMHz6c/fv3V7qdLOBdzCK+bkAqZrTrDuBNYJd1JZei4LPDww9TfOqpWDJQEB8P06ZB9epWtCYifhQOwQcQGRnJ3//+d9atW0d2djatWrVixowZFRrG3YY5nageZvvWZOAbzKEOK4CXgKGY06yuAn7xQ/0KPhvs3LePAfHx5EZF4dM4c3w83HAD9OtnVWki4kfhEnwetWvXZurUqXz00Uc888wz9OjRg/T09DKffxNzUtFbmMPbD4DXn4HZmPssZ2OOahwH1nQUDlPwBdgvv/zCOeecQ/O+fYlbsQJXzZrmkOnKSkiAAQPgRa9LXUQkCIVb8Hl06dKFlStX0r9/f3r27Mn999/PgWPWMbgxh/DfiQm1wjLaKakYc67tGOBaKn/LSVkUfAG0ZMkSunfvzsiRI3niiSdwnXUWrF8PF1xggqwiYmPNsOZrr8Err5R7KLWIBJfWrVvz66+/UlBQYHcplouMjGTo0KGkp6eze/duWrVqxbvvvovb7WYc8AJVv5/yIPAp8HeLatWqzgCZMWMG9957LzNnzuSii0pcOON2w4IFMG4cLFsGMTEUHjhANc8/jWf7Q0yMuXR2yBCoXTuwfwERscQZZ5zBrFmzaNOmjd2l+NXSpUsZOnQosWefzeqXXiLPgl/S44EPgd4+tqPg8zO3282TTz7J1KlT+fjjj0lJSSn/DXv2wPff89rdd3NeSgrNW7eGZs3M5vRWrSDMT00XCXdXXXUV11xzDdddd53dpfhdQWEhjTMz2V6rlmWjU7WBP8Gni7w1TuZHBQUFDB48mFmzZrF8+fIThx7ASSfBX/7Cf6tXZ8/998OYMWarQkqKQk8kDITrPJ83P1arRlbt2qVDr0kTWLjw+M9t3Agulxnh8ryeeKJUm55FL77QqcZ+sn//fq6++mpiY2P56quvSCxxWsuJ7N692zGXQoo4Sdu2bZk2bZrdZQTE85jVm5WSmQnlHLifDUzEXNpdVerx+cGmTZvo1q0bLVu2ZPbs2ZUOPYBdu3Yp+ETCkJN6fF9h7TYEj1U+tqvgs9j3339P165dufXWW5k8eXKVbjLOzc0lPz+fpKRSR1GLSIhr1qwZO3fuPG65fzg6CGyvyhsbN4YGDeDmm2H3bq+PVAP+z4faFHwWmjt3Lr1792bKlCkMHz4cl8tVpXZ27dpF7dq1q/x+EQlekZGRtGrVirVr19pdil/to5ILUGrXhpUrYdMm+P57c57xwIFeH60GeI/EilHwWWTKlCn8/e9/55NPPuGKK67wqS3N74mENycMd7rwfipLmRIToWNHM79Xty5MmQKff17mgf6+dAu0uMVHRUVF3H///cybN49ly5bRtGlTn9vU/J5IeHNC8NWm4ie0eOUZ8fJy/VE+cIoPTSv4fHDw4EEGDhxIZmYm33zzDTVr1rSkXQWfSHhr27Ytc+fOtbsMv4oGGgO/lfVAQYG5QNtj9WpITobmzWHfPnNYR48eUKNGqbdGHG67qjTUWUUZGRn07NmTpKQk5s+fb1nowdE5PhEJT6F6KW1l9QbKPIm4Tx+Iizv6GjAAeveGpCSzbzkmBt5+2+tbu6GhzoBbv349l156KYMGDeLxxx+3fBGKenwi4a1u3bq4XC527NhB/fr17S7Hb+4CpgKlTibduLHKbSYC91f53YZ6fJX05Zdf0qNHDx5//HFGjx7tl5WXWtwiEt5cLhcpKSlhP8/XAtM7s7KHVQ+40Mc2FHyV8NZbb3Hdddfx9ttvc6MfbzxXj08k/DlhgQvAG0CMRW3FYW5t9zW4NNRZAW63myeeeILXX3+dL7/8ktatW/v1+2mOTyT8tW3blmXLltldht81AF4DbqIKx5cdIx4YhbmY1lfq8Z1Afn4+N998M3PnzmX58uV+Dz1Qj0/ECZzS4wNzruaLmPCqinjgAeBhi+pRj68cmZmZXHnllVSvXp3FixeTUNHLYn2kOT6R8NemTRvWr19PUVFRlY42DDU3AS2Ba4C9VOxS2lhM6L0JXGphLerxlWHjxo107dqVdu3a8eGHHwYs9IqKiti/fz+1atUKyPcTEXskJSVRr149fvutzJ1uYacL8CvwFGYINOHw61hxQBJwEvAIsAFrQw/U4/Nq5cqV/PWvf+Whhx7i7rvvDuj33rNnD8nJyY74DVDE6TzDnS1atLC7lICJA+4B7gbWAN8DPwAHDn8tFeiAmcvzV0Ap+EqYM2cOt912G1OnTqVfv34B//5a2CLiHJ7gu/rqq+0uJeBcmJBLBW4J8PfWUOcxJk2axJAhQ/j0009tCT3QwhYRJ3HSApdgouDDzKvdc889vPzyyyxbtoyOHTvaVosWtog4h4LPHo4f6szJyWHAgAFkZ2ezbNkykpOTba1HPT4R52jevDl//vknOTk5AVtAJw7v8e3YsYPzzz+fWrVq8dlnn9keeqA5PhEniYqK4owzzmDdunV2l+Iojg2+tWvX0qVLFy6//HJee+01oqMrdVew36jHJ+IsGu4MPEcG3xdffEHPnj3517/+xahRo/xy0HRVaY5PxFnatm1Lenq63WU4iuOCb9q0aVx//fW89957/O1vf7O7nFLU4xNxFvX4As8xi1vcbjePP/4406dPZ/HixbRq1crukrxS8Ik4i4Iv8BwRfHl5edx66638+uuvpKWlcfLJJ9tdUpm0uEXEWU499VTy8vL0S28Ahf1Q5759++jVqxc5OTl8+eWXQR16brdbc3wiDuNyudTrC7CwDr7ff/+dc845hw4dOvD+++8TH1/VSzECIysri9jYWGJirLq2UURCgYIvsMI2+FasWMG5557LsGHDeOaZZ0Li0GcNdYg4k4IvsMIy+D766CMuu+wyXn75ZYYOHWp3ORWm+T0RZ0pJSVHwBVBYLW5xu908++yzTJw4kfnz59O+vRWX1AeOenwizpSSksLatWspLi4mIiIs+yNBJWyCr7CwkOHDh/PVV1/xzTff0KhRI7tLqjQtbBFxpuTkZGrVqsUff/xBs2bN7C4n7IVF8GVnZ3P99deTm5vL0qVLqVGjht0lVYl6fCLO5ZnnU/D5X8j3qbdt20b37t05+eST+fTTT0M29EDBJ+JkWuASOCEdfD/99BPnnHMOV111FVOnTiUqKsruknyixS0izqXgC5yQDb4FCxZw4YUXMnbsWEaOHBlUB01XlXp8Is6l4AuckAy+1157jb/97W98+OGHXH/99XaXYxktbhFxrpYtW7Jx40Zyc3PtLiXsBXxxSzqwBFgKbAHcQAPgvMOvduW81+12M2rUKN555x2WLFlCixYt/F5vIKnHJ+Jc0dHRNGvWjPXr13PWWWfZXU5YC0jwuYEPgdHAH4c/PlTimf9hup+NgMeAa4FjBy/z8vK4+eab+eOPP1i+fHlYBoTm+ESczTPcqeDzL78PdW4HLgZuAtYCBykdehz+XA6wHrgV6An8efhre/bs4eKLL6agoIAvvvgiLEPv0KFDFBQUkJSUZHcpImITzfMFhl+D71fM0OUSTKhVVA6w7PB752/eTNeuXenSpQvvvvsucXFxfqjUfp75vXBYpCMiVaPgCwy/DXVmAN2APZihzcoqBPa53VySmMhTI0fy8KBBltYXbDS/JyIKvsDwS4/PDdwI7KdqoXekHZeLiORk5g8a5FM7oUDBJyKNGzfmwIED7N271+5Swppfgu9/mFWbBRa0VRQRwUrgAwvaCmZa2CIiLpeLlJQU0tPT7S4lrPkl+J7Ay5xekyawcOHxn8vPh6uvNl9zuWDxYq/t5RxuM5ypxycioOHOQLA8+H4D1lXmDeeeC9OnQ7165T62AbMqNFxp87qIgIIvECwPvqVAhe86j46G4cNN+FXghvRlPtQV7NTjExFQ8AWC5cG3HMi2ulHM/r9wDz7N8YlI27ZtSU9Px+0O9yV99rE8+LZa3eAx/jzxIyFLPT4RAahVqxaJiYls3rzZ7lLCluXB58/t1+G8tVtzfCLioeFO/7I8+JpY3eAxGvmxbbupxyciHikpKQo+P7I8+LoAZZ42WVAAublHX4WFkJdn/gxme0NuLngZ207AnAQTjgoLC9m/fz81a9a0uxQRCQLq8fmX5cF3HuVsXO/TB+Lijr5Gj4YWLcyf//wTevUyf960qdRbiw+3HY727NlDzZo1iazAylYRCX8KPv9yuf2wdKg78LXFbXYCvrW4zWCRnp5O//79WbeuUjsgRSRMHTp0iFq1arF//36io6PtLifs+OXklseAeAvbi8fc5ReutLBFRI4VFxdH48aN+eWXX+wuJSz5JfguAi4DYixoKxpzn18fC9oKVlrYIiIlabjTf/x2H99LQF0qcYqLF5FAbeBVSyoKXtq8LiIlKfj8x2/Blwx8A5xK1Xp+MZjgXA6cZF1ZQUk9PhEpScHnP369gf1UYA1wJZWb84sH+gHphPfePQ/N8YlISQo+//Fr8AHUAGYCnwA9gVjMPr9jT2FxHf5cLHA+MAd4D3DKrjb1+ETkWBnAotNOY9vTT9O6qIjTgTbA9cCLwBZbqwt91QL1jXocfv2JGQJdAWzC3NDeCLPx/RygYaAKCiIKPhEBc63b/cA8IDIigsIBA1h/zNfXYToGIzDbxp4B2ga8ytAXsODzOBW45vBLDC1uEXE2N/AcMBLIwxzYUZZDh/9zIdAZeACzhUzHX1Sc34c65cTU4xNxLjcwGHgUE2rlhV7J9x0CJgBXAIV+qS48Kfhs5na72bNnj3p8Ig71EPAu5s7RqjgILMKEp1SMgs9m+/fvJy4ujpgYK7b7i0goWQ5Moeqh53EQ+ACziFBOTMFnM83viTiTGxjI0Tk7Xx0EbgTyLWovnCn4bKb5PRFnWgzs8vaFJk1g4cKy3zhmDLhcXp/JA2ZbUVyYU/DZTJvXRZxpMpBT2Tdt2ADvvw/163v9cjbwrI91OYGCz2bq8Yk40zeY4c5KGToUxo2Dcq4qWk3FV4Y6lYLPZgo+EefZD+yr7Jvefx9iYsyF3uWIAP6oYl1OEfAN7HK8Xbt2Ua9ePbvLEJEA2ou5cq2gom84cAD+8Q9YsOCEj1YD9gDNqlxd+FOPz2bq8Yk4T6VPWRk9Gm64wSx88Uf7DqPgs5kWt4g4z8mYFZgVtmgRTJ4M9eqZ15Yt0L+/me8rIRdoYFGd4UpDnTZTj0/EeWIxB/KXORdXUAC5uUc/nj8f3McshenUCSZOhEsuKfXWeMxdplI29fhspg3sIs50CeX0PPr0gbi4o6/nnz/a26tXDyIjoWZNSEw87m0uzC04Uj6X2+2u9IpasU5CQgI7duwgKSnJ7lJEJIB+Ac7EDE1aJQH4HOhqYZvhSD0+Gx08eJCioiISS/zWJiLhrwVwLtbNN0UAp2PuNZXyKfhs5FnY4nK5TvywiISdNzDzfVaIwdzyoJ8mJ6bgs5EWtog426nAm0Ccj+3EA5MwvUg5MQWfjbSwRUSuAF6l6uEXD4wFbrOsovCn4LORenwiAnA9sAw4DbNApSLigfrAfGCYn+oKVwo+G2nzuoh4nAWsB57DLFKJB5I4fs4uEROMDTG9vP/DLJCRytEGdhupxycix4oGbgUGA78D3wNrMNcNxQNtgA6YuTwtYqk6BZ+Ndu3aRePGje0uQ0SCjAtzyHQzoL/NtYQjDXXaSD0+EZHAU/DZSHN8IiKBp+CzkXp8IiKBp+CzkfbxiYgEng6ptklBQQFxcXHk5+cTEaHfP0REAkU/cW2yZ88eatWqpdATEQkw/dS1iRa2iIjYQ8FnEy1sERGxh+b4AiAfmHX4lQbsAAqLi3Hl5tIhPp4LgJuAM+wrUUTEMRR8flQETASeBIqBA2U8V+3wqwPwCtAqINWJiDiTgs9PNgKXAxuAnAq+x4W5lHI08AA6i09ExB8UfH7wf0AXIBPT06useMzQ5xQUfiIiVtPiFotlAecB+6ha6AEcBN4AnrGoJhEROUo9PosNAt4Hci1oKw74EXMFiYiIWEPBZ6FVQDdMj80KEZje42KL2hMREQ11WmoCkFfyk02awMKFpR8+eBCGDIHataFGDejevdQjxcAK4A/LKxURcS5dRGuRQuADzBaGCrn9digshPXroVYtWLXK62PFwFvAY1YUKSIiCj6rrAei8dLj8+bnn+F//4OtW6F6dfO5Dh28PpoPfIGCT0TEKhrqtMjqyjz87bfQuDE8/rgZ6mzbFj78sMzH1/pcnYiIeCj4LJKFGe6skK1bIT3dzO1t2wZTpsCNN5phTy+sWiwjIiIKPstEUYnN5nFxEBUFjz4K0dFw/vnQsyd8/rnXx/WPJCJiHf1MtchpmPCrkHbtSn/OVXZsNqxKQSIi4pWCzyLtKWdIsqAAcnOPvrp3h0aN4OmnzcrOZcvgyy+hVy+vb+/mr6JFRBxIwWeRmpRzrVCfPmZ40/P65z9hzhz49FMzz3fbbfDmm9CyZam3JgFX+LFuERGn0cktFnoLGAJkW9hmHWA7EGlhmyIiTqYen4X6A8kWtpeAuctPoSciYh0Fn4VigPcwh0v7qhpwJnCrBW2JiMhRCj6LnQP8E3OnXlVFYoY430f38YmIWE3B5wcPYMKvKj2/OMz2hRVAfSuLEhERQMHnN/cDX2JCLLECz0dhQu9WYB3auyci4i9a1eln+cBHwDggHTMEWgy4MUOahZjhzJuAuylnS4SIiFhCwRdA2ZjLav8ACjArQFMxp75oLk9EJDAUfCIi4iia4xMREUdR8ImIiKMo+ERExFEUfCIi4igKPhERcRQFn4iIOIqCT0REHOX/AXVsjdoWanFUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_soma_limb_concept_network(neuron_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculating the statistics to be stored in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_neuron = neuron_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import numpy as np\n",
    "n_error_limbs = len(nru.error_limb_indexes(recovered_neuron))\n",
    "\n",
    "n_somas = len(recovered_neuron.get_soma_node_names())\n",
    "\n",
    "n_limbs = len(recovered_neuron.get_limb_node_names())\n",
    "\n",
    "n_branches_per_limb = [len(ex_limb.get_branch_names()) for ex_limb in recovered_neuron]\n",
    "n_branches = np.sum(n_branches_per_limb)\n",
    "\n",
    "n_spines = len(recovered_neuron.spines)\n",
    "\n",
    "#for total skeletal length\n",
    "sk_len_per_branch = [sk.calculate_skeleton_distance(limb.skeleton) for limb in recovered_neuron]\n",
    "skeletal_length = np.sum(sk_len_per_branch)\n",
    "\n",
    "if skeletal_length > 0:\n",
    "    spine_density = n_spines/skeletal_length\n",
    "else:\n",
    "    spine_density = 0\n",
    "\n",
    "max_limb_skeletal_length = np.max(sk_len_per_branch)\n",
    "\n",
    "max_limb_n_branches = np.max(n_branches_per_limb)\n",
    "\n",
    "new_key = dict(n_error_limbs=n_error_limbs,\n",
    "                n_somas=n_somas,\n",
    "                n_limbs=n_limbs,\n",
    "                n_branches=n_branches,\n",
    "                n_spines=n_spines,\n",
    "                skeletal_length=skeletal_length,\n",
    "                spine_density=spine_density,\n",
    "                max_limb_skeletal_length=max_limb_skeletal_length,\n",
    "                max_limb_n_branches=max_limb_n_branches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jake Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median \n",
    "\n",
    "all_skeletal_lengths = []\n",
    "all_widths_no_spine = []\n",
    "all_widths = []\n",
    "\n",
    "n_spine_eligible_branches = 0\n",
    "spine_eligible_branch_lengths = []\n",
    "\n",
    "for curr_limb in recovered_neuron:\n",
    "    for curr_branch in curr_limb:\n",
    "        curr_branch_sk_len = sk.calculate_skeleton_distance(curr_branch.skeleton)\n",
    "        all_skeletal_lengths.append(curr_branch_sk_len)\n",
    "        all_widths_no_spine.append(curr_branch.width_new[\"no_spine_median_mesh_center\"])\n",
    "        all_widths.append(curr_branch.width_new[\"median_mesh_center\"])\n",
    "        \n",
    "        if not curr_branch.spines is None:\n",
    "            spine_eligible_branch_lengths.append(curr_branch_sk_len)\n",
    "            n_spine_eligible_branches += 1\n",
    "            \n",
    "all_skeletal_lengths = np.array(all_skeletal_lengths)\n",
    "median_branch_length = np.round(np.median(all_skeletal_lengths),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spines per branch\n",
    "if n_branches > 0:\n",
    "    spines_per_branch = np.round(n_spines/n_branches,3)\n",
    "else:\n",
    "    spines_per_branch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122.523, 122.523, 483.228, 455.873)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#width data\n",
    "width_median = np.round(np.median(all_widths),3)\n",
    "width_no_spine_median = np.round(np.median(all_widths_no_spine),3)\n",
    "\n",
    "width_90_perc = np.round(np.percentile(all_widths,90),3)\n",
    "width_no_spine_90_perc = np.round(np.percentile(all_widths_no_spine,90),3)\n",
    "\n",
    "\n",
    "width_median,width_no_spine_median,width_90_perc,width_no_spine_90_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3372732.1718796734, 87, 0.0004082743395638728, 15.828)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spine eligible density and per branch\n",
    "skeletal_length_eligible = np.sum(spine_eligible_branch_lengths)\n",
    "if skeletal_length_eligible > 0:\n",
    "    spine_density_eligible = n_spines/skeletal_length_eligible\n",
    "else:\n",
    "    spine_density_eligible = 0\n",
    "\n",
    "if n_branches > 0:\n",
    "    spines_per_branch_eligible = np.round(n_spines/n_spine_eligible_branches,3)\n",
    "else:\n",
    "    spines_per_branch_eligible = 0\n",
    "\n",
    "skeletal_length_eligible,n_spine_eligible_branches,spine_density_eligible,spines_per_branch_eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(134, 3), faces.shape=(263, 3))>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu.split_significant_pieces(total_spines[0],significance_threshold=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spine volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "tu = reload(tu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 1377.,    0.,    0.,    0.,\n",
       "           0.]),\n",
       " array([-2.26657502e+08, -2.26657502e+08, -2.26657502e+08, -2.26657502e+08,\n",
       "        -2.26657502e+08, -2.26657501e+08, -2.26657501e+08, -2.26657501e+08,\n",
       "        -2.26657501e+08, -2.26657501e+08, -2.26657501e+08]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(total_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[1;31m[Open3D ERROR] The mesh is not watertight, and the volume cannot be computed.\u001b[0;m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-4227ff67f0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#                              return_closed_mesh=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#                      verbose=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh_volume_o3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_volume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/trimesh_utils.py\u001b[0m in \u001b[0;36mmesh_volume_o3d\u001b[0;34m(mesh)\u001b[0m\n\u001b[1;32m   2017\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmesh_volume_o3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[0mmesh_o3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_trimesh_to_o3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2019\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmesh_o3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_manifold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D ERROR] The mesh is not watertight, and the volume cannot be computed.\u001b[0;m"
     ]
    }
   ],
   "source": [
    "tu = reload(tu)\n",
    "spine_time = time.time()\n",
    "total_spines = recovered_neuron.spines\n",
    "total_volume =[]\n",
    "for ts in total_spines:\n",
    "#     vol = tu.mesh_volume(total_spines[0],\n",
    "#                              watertight_method=None,\n",
    "#                              return_closed_mesh=False,\n",
    "#                      verbose=False)\n",
    "    vol = tu.mesh_volume_o3d(ts)\n",
    "    total_volume.append(vol)\n",
    "    \n",
    "print(f\"Total time for calculating spine volume = {time.time() - spine_time}\")\n",
    "total_volume = np.array(total_volume)\n",
    "\n",
    "spine_volume_median = np.median(total_volume)\n",
    "\n",
    "total_spine_volume = np.sum(total_volume)\n",
    "\n",
    "if skeletal_length > 0:\n",
    "    spine_volume_density = total_spine_volume/skeletal_length\n",
    "else:\n",
    "    spine_volume_density = 0\n",
    "\n",
    "\n",
    "if skeletal_length_eligible > 0:\n",
    "    spine_volume_density_eligible = total_spine_volume/skeletal_length_eligible\n",
    "else:\n",
    "    spine_volume_density_eligible = 0\n",
    "\n",
    "if n_branches > 0:\n",
    "    spine_volume_per_branch_eligible = np.round(total_spine_volume/n_spine_eligible_branches,3)\n",
    "else:\n",
    "    spine_volume_per_branch_eligible = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_key = dict(         n_error_limbs=n_error_limbs,\n",
    "                        n_somas=n_somas,\n",
    "                        n_limbs=n_limbs,\n",
    "                        n_branches=n_branches,\n",
    "                        max_limb_n_branches=max_limb_n_branches,\n",
    "                       \n",
    "                        skeletal_length=skeletal_length,\n",
    "                        max_limb_skeletal_length=max_limb_skeletal_length,\n",
    "                        median_branch_length=median_branch_length,\n",
    "\n",
    "                        width_median=width_median, #median width from mesh center without spines removed\n",
    "                        width_no_spine_median=width_no_spine_median, #median width from mesh center with spines removed\n",
    "                        width_90_perc=width_90_perc, # 90th percentile for width without spines removed\n",
    "                        width_no_spine_90_perc=width_no_spine_90_perc,  # 90th percentile for width with spines removed\n",
    "\n",
    "                        n_spines=n_spines,\n",
    "\n",
    "                        spine_density=spine_density, # n_spines/ skeletal_length\n",
    "                        spines_per_branch=spines_per_branch,\n",
    "\n",
    "                        skeletal_length_eligible=skeletal_length_eligible, # the skeletal length for all branches searched for spines\n",
    "                        n_spine_eligible_branches=n_spine_eligible_branches,\n",
    "\n",
    "                        total_spine_volume=total_spine_volume, # the sum of all spine volume\n",
    "                        spine_volume_density=spine_volume_density, #total_spine_volume/skeletal_length\n",
    "                        spine_volume_density_eligible=spine_volume_density_eligible, #total_spine_volume/skeletal_length_eligible\n",
    "                        spine_volume_per_branch_eligible=spine_volume_per_branch_eligible, #total_spine_volume/n_spine_eligible_branche\n",
    "\n",
    "                       \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_error_limbs': 2,\n",
       " 'n_somas': 2,\n",
       " 'n_limbs': 9,\n",
       " 'n_branches': 220,\n",
       " 'max_limb_n_branches': 52,\n",
       " 'skeletal_length': 6364170.693847561,\n",
       " 'max_limb_skeletal_length': 1624520.8964276644,\n",
       " 'median_branch_length': 14473.069,\n",
       " 'width_median': 122.523,\n",
       " 'width_no_spine_median': 122.523,\n",
       " 'width_90_perc': 483.228,\n",
       " 'width_no_spine_90_perc': 455.873,\n",
       " 'n_spines': 1377,\n",
       " 'spine_density': 0.00021636754673019505,\n",
       " 'spines_per_branch': 6.259,\n",
       " 'skeletal_length_eligible': 3372732.1718796734,\n",
       " 'n_spine_eligible_branches': 87,\n",
       " 'total_spine_volume': -312107379521.103,\n",
       " 'spine_volume_density': -49041.32754057442,\n",
       " 'spine_volume_density_eligible': -92538.4417189465,\n",
       " 'spine_volume_per_branch_eligible': -3587441143.921}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Concept Network Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limb_correspondence = limb_correspondence_with_floating_pieces[curr_limb_idx]\n",
    "# touching_verts_list = limb_network_stating_info[curr_limb_idx][\"touching_verts_list\"]\n",
    "# endpoints_must_keep = limb_network_stating_info[curr_limb_idx][\"endpoints_must_keep\"]\n",
    "# run_concept_network_checks=True\n",
    "# \"\"\"\n",
    "# Can take a limb correspondence and the starting vertices and endpoints\n",
    "# and create a list of concept networks organized by \n",
    "# [soma_idx] --> list of concept networks \n",
    "#                 (because could possibly have mulitple starting points on the same soma)\n",
    "\n",
    "# \"\"\"\n",
    "# curr_touching_verts_list = touching_verts_list\n",
    "# curr_endpoints_must_keep = endpoints_must_keep\n",
    "# limb_correspondence_individual = limb_correspondence\n",
    "# divided_skeletons = np.array([limb_correspondence_individual[k][\"branch_skeleton\"] for k in np.sort(list(limb_correspondence_individual.keys()))])\n",
    "\n",
    "\n",
    "\n",
    "# # -------------- Part 18: Getting Concept Networks  [soma_idx] --> list of concept networks -------#\n",
    "\n",
    "# \"\"\"\n",
    "# Concept Network Pseudocode:\n",
    "\n",
    "# Step 0: Compile the Limb correspondence into final form\n",
    "\n",
    "# Make sure these have the same list\n",
    "# limb_to_soma_touching_vertices_list,limb_to_endpoints_must_keep_list\n",
    "\n",
    "# For every dictionary in zip(limb_to_soma_touching_vertices_list,\n",
    "#                         limb_to_endpoints_must_keep_list):\n",
    "\n",
    "#     #make sure the dicts have same keys\n",
    "#     For every key (represents the soma) in the dictionary:\n",
    "\n",
    "#         #make sure the lists have the same sizes\n",
    "#         For every item in the list (which would be a list of endpoints or list of groups of vertexes):\n",
    "#             #At this point have the soma, the endpoint and the touching vertices\n",
    "\n",
    "#             1) find the branch with the endoint that must keep\n",
    "#                 --> if multiple endpoints then error\n",
    "#             2) Call the branches_to_concept_network with the\n",
    "#                a. divided skeletons\n",
    "#                b. closest endpoint\n",
    "#                c. endpoints of branch (from the branch found)\n",
    "#                d. touching soma vertices\n",
    "\n",
    "#             3) Run the checks on the concept network\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# limb_to_soma_concept_networks = dict()\n",
    "\n",
    "# if len(curr_touching_verts_list) != len(curr_endpoints_must_keep):\n",
    "#     raise Exception(f\"curr_touching_verts_list ({curr_touching_verts_list}) not same size as curr_endpoints_must_keep ({len(curr_endpoints_must_keep)})\")\n",
    "\n",
    "# for touch_vert_dict,endpoints_keep_dict in zip(curr_touching_verts_list,curr_endpoints_must_keep):\n",
    "#     if not np.array_equal(list(touch_vert_dict.keys()),list(endpoints_keep_dict.keys())):\n",
    "#         raise Exception(f\"touch_vert_dict keys ({touch_vert_dict.keys()}) don't match endpoints_keep_dict keys ({endpoints_keep_dict.keys()})\")\n",
    "#     for soma_idx in touch_vert_dict.keys():\n",
    "#         soma_t_verts_list = touch_vert_dict[soma_idx]\n",
    "#         soma_endpt_list = endpoints_keep_dict[soma_idx]\n",
    "\n",
    "#         if soma_idx not in list(limb_to_soma_concept_networks.keys()):\n",
    "#             limb_to_soma_concept_networks[soma_idx] = []\n",
    "\n",
    "#         if len(soma_t_verts_list) != len(soma_endpt_list):\n",
    "#             raise Exception(f\"soma_t_verts_list length ({len(soma_t_verts_list)}) not equal to soma_endpt_list length ({soma_endpt_list})\")\n",
    "#         for soma_group_idx,(t_verts,endpt) in enumerate(zip(soma_t_verts_list,soma_endpt_list)):\n",
    "\n",
    "\n",
    "\n",
    "#             #1) find the branch with the endoint that must keep\n",
    "#             start_branch = sk.find_branch_skeleton_with_specific_coordinate(divded_skeleton=divided_skeletons,\n",
    "#                                                             current_coordinate=endpt)[0]\n",
    "#             #print(f\"Starting_branch = {start_branch}\")\n",
    "#             #print(f\"Start endpt = {endpt}\")\n",
    "#             start_branch_endpoints = sk.find_branch_endpoints(divided_skeletons[start_branch])\n",
    "#             #print(f\"Starting_branch endpoints = {start_branch_endpoints}\")\n",
    "\n",
    "#             #2) Call the branches_to_concept_network with the\n",
    "#             curr_limb_concept_network = nru.branches_to_concept_network(curr_branch_skeletons=divided_skeletons,\n",
    "#                                                                   starting_coordinate=endpt,\n",
    "#                                                                   starting_edge=start_branch_endpoints,\n",
    "#                                                                   touching_soma_vertices=t_verts,\n",
    "#                                                                        soma_group_idx=soma_group_idx)\n",
    "#             print(\"Done generating concept network \\n\\n\")\n",
    "\n",
    "\n",
    "#             run_checks = True\n",
    "#             check_print_flag = True\n",
    "\n",
    "#             if run_concept_network_checks:\n",
    "#                 #3) Run the checks on the concept network\n",
    "#                 #3.1: check to make sure the starting coordinate was recovered\n",
    "\n",
    "#                 recovered_touching_piece = xu.get_nodes_with_attributes_dict(curr_limb_concept_network,dict(starting_coordinate=endpt))\n",
    "\n",
    "#                 if check_print_flag:\n",
    "#                     print(f\"recovered_touching_piece = {recovered_touching_piece}\")\n",
    "#                 if recovered_touching_piece[0] != start_branch:\n",
    "#                     raise Exception(f\"For limb and soma {soma_idx} the recovered_touching and original touching do not match\\n\"\n",
    "#                                    f\"recovered_touching_piece = {recovered_touching_piece}, original_touching_pieces = {start_branch}\")\n",
    "\n",
    "\n",
    "#                 #3.2: Check number of nodes match the number of divided skeletons\n",
    "#                 if len(curr_limb_concept_network.nodes()) != len(divided_skeletons):\n",
    "#                     raise Exception(\"The number of nodes in the concept graph and number of branches passed to it did not match\\n\"\n",
    "#                                   f\"len(curr_limb_concept_network.nodes())={len(curr_limb_concept_network.nodes())}, len(curr_limb_divided_skeletons)= {len(divided_skeletons)}\")\n",
    "\n",
    "#                 #3.3: Check that concept network is a connected component\n",
    "#                 if nx.number_connected_components(curr_limb_concept_network) > 1:\n",
    "#                     raise Exception(\"There was more than 1 connected components in the concept network\")\n",
    "\n",
    "\n",
    "#                 #3.4 Make sure the oriiginal divided skeleton endpoints match the concept map endpoints\n",
    "#                 for j,un_resized_b in enumerate(divided_skeletons):\n",
    "#                     \"\"\"\n",
    "#                     Pseudocode: \n",
    "#                     1) get the endpoints of the current branch\n",
    "#                     2) get the endpoints in the concept map\n",
    "#                     3) compare\n",
    "#                     - if not equalt then break\n",
    "#                     \"\"\"\n",
    "#                     #1) get the endpoints of the current branch\n",
    "#                     b_endpoints = neuron.Branch(un_resized_b).endpoints\n",
    "#                     #2) get the endpoints in the concept map\n",
    "#                     graph_endpoints = xu.get_node_attributes(curr_limb_concept_network,attribute_name=\"endpoints\",node_list=[j])[0]\n",
    "#                     #print(f\"original_branch_endpoints = {b_endpoints}, concept graph node endpoints = {graph_endpoints}\")\n",
    "#                     if not xu.compare_endpoints(b_endpoints,graph_endpoints):\n",
    "#                         raise Exception(f\"The node {j} in concept graph endpoints do not match the endpoints of the original branch\\n\"\n",
    "#                                        f\"original_branch_endpoints = {b_endpoints}, concept graph node endpoints = {graph_endpoints}\")\n",
    "\n",
    "#             limb_to_soma_concept_networks[soma_idx].append(curr_limb_concept_network)\n",
    "\n",
    "# return_value = limb_to_soma_concept_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=seperate_soma_meshes,\n",
    "                  skeletons=divided_skeletons,\n",
    "                 skeletons_colors=\"random\",\n",
    "                 scatters=[endpt.reshape(-1,3)],\n",
    "                 scatter_size=0.1,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.find_branch_skeleton_with_specific_coordinate(divded_skeleton=divided_skeletons,\n",
    "                                                            current_coordinate=endpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = reload(neuron)\n",
    "nru = reload(nru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.visualize_neuron(neuron_obj,\n",
    "                      visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_spines(neuron_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_soma_limb_concept_network(neuron_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=neuron_obj.not_processed_soma_containing_meshes + neuron_obj.inside_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nru = reload(nru)\n",
    "neuron = reload(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_obj.save_compressed_neuron(output_folder=\"/notebooks/test_neurons/Fusion_decomp/\",file_name=\"seperated_somas\",return_file_path=True,export_mesh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = \"/notebooks/test_neurons/Fusion_decomp/seperated_somas\"\n",
    "recov_neuron = nru.decompress_neuron(my_file,my_file,suppress_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.visualize_neuron(recov_neuron,\n",
    "                      visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Decompress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(neuron_obj[0][61].mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Limb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_vp2 import *\n",
    "sk = reload(sk)\n",
    "pre=reload(pre)\n",
    "xu = reload(xu)\n",
    "\n",
    "\n",
    "\n",
    "#Arguments to pass to the specific function (when working with a limb)\n",
    "soma_touching_vertices_dict = piece_to_soma_touching_vertices[curr_limb_idx]\n",
    "curr_limb_idx = 0\n",
    "mesh=current_mesh_data[0][\"branch_meshes\"][curr_limb_idx]\n",
    "\n",
    "\n",
    "\n",
    "distance_by_mesh_center=True #how the distance is calculated for mesh correspondence\n",
    "meshparty_segment_size = 100\n",
    "meshparty_n_surface_downsampling = 2\n",
    "combine_close_skeleton_nodes=True\n",
    "combine_close_skeleton_nodes_threshold=700\n",
    "filter_end_node_length=1500\n",
    "use_meshafterparty=True\n",
    "perform_cleaning_checks = True\n",
    "\n",
    "#for controlling the pieces processed by MAP\n",
    "width_threshold_MAP = 450\n",
    "size_threshold_MAP = 1000\n",
    "\n",
    "#parameters for MP skeletonization,\n",
    "\n",
    "#Parameters for setting how the MAP skeletonization takes place\n",
    "use_surface_after_CGAL=False\n",
    "surface_reconstruction_size = 500\n",
    "\n",
    "#parametrers for stitching the MAP and MP pieces together\n",
    "move_MAP_stitch_to_end_or_branch = True\n",
    "distance_to_move_point_threshold=500\n",
    "\n",
    "#concept_network parameters\n",
    "run_concept_network_checks = True\n",
    "return_concept_network = True\n",
    "return_concept_network_starting_info=False\n",
    "\n",
    "#printing controls\n",
    "verbose = True\n",
    "print_fusion_steps=True\n",
    "\n",
    "\n",
    "#arguments\n",
    "return_concept_network = False\n",
    "return_concept_network_starting_info=True\n",
    "width_threshold_MAP=500\n",
    "size_threshold_MAP=2000\n",
    "surface_reconstruction_size=1000\n",
    "                    \n",
    "                   \n",
    "    \n",
    "curr_limb_time = time.time()\n",
    "    \n",
    "limb_mesh_mparty = mesh\n",
    "\n",
    "\n",
    "#will store a list of all the endpoints tha tmust be kept:\n",
    "limb_to_endpoints_must_keep_list = []\n",
    "limb_to_soma_touching_vertices_list = []\n",
    "\n",
    "# --------------- Part 1 and 2: Getting Border Vertices and Setting the Root------------- #\n",
    "fusion_time = time.time()\n",
    "#will eventually get the current root from soma_to_piece_touching_vertices[i]\n",
    "if not soma_touching_vertices_dict is None:\n",
    "    root_curr = soma_touching_vertices_dict[list(soma_touching_vertices_dict.keys())[0]][0][0]\n",
    "else:\n",
    "    root_curr = None\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Time for preparing soma vertices and root: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "# --------------- Part 3: Meshparty skeletonization and Decomposition ------------- #\n",
    "sk_meshparty_obj = m_sk.skeletonize_mesh_largest_component(limb_mesh_mparty,\n",
    "                                                        root=root_curr,\n",
    "                                                          filter_mesh=False)\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Time for 1st pass MP skeletonization: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "(segment_branches, #skeleton branches\n",
    "divided_submeshes, divided_submeshes_idx, #mesh correspondence (mesh and indices)\n",
    "segment_widths_median) = m_sk.skeleton_obj_to_branches(sk_meshparty_obj,\n",
    "                                                      mesh = limb_mesh_mparty,\n",
    "                                                      meshparty_segment_size=meshparty_segment_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Decomposing first pass: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "\n",
    "if use_meshafterparty:\n",
    "    print(\"Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\")\n",
    "    # --------------- Part 4: Find Individual Branches that could be MAP processed because of width ------------- #\n",
    "    #gettin the branches that should be passed through MAP skeletonization\n",
    "    pieces_above_threshold = np.where(segment_widths_median>width_threshold_MAP)[0]\n",
    "\n",
    "    #getting the correspondnece info for those MAP qualifying\n",
    "    width_large = segment_widths_median[pieces_above_threshold]\n",
    "    sk_large = [segment_branches[k] for k in pieces_above_threshold]\n",
    "    mesh_large_idx = [divided_submeshes_idx[k] for k in pieces_above_threshold]\n",
    "else:\n",
    "    print(\"Only Using MeshParty Skeletonization and Mesh Correspondence\")\n",
    "    mesh_large_idx = []\n",
    "    width_large = []\n",
    "    sk_large = []\n",
    "\n",
    "\n",
    "print(\"Another print\")\n",
    "mesh_pieces_for_MAP = []\n",
    "mesh_pieces_for_MAP_face_idx = []\n",
    "\n",
    "\n",
    "if len(mesh_large_idx) > 0: #will only continue processing if found MAP candidates\n",
    "\n",
    "    # --------------- Part 5: Find mesh connectivity and group MAP branch candidates into MAP sublimbs ------------- #\n",
    "    print(f\"Found len(mesh_large_idx) MAP candidates: {[len(k) for k in mesh_large_idx]}\")\n",
    "\n",
    "    #finds the connectivity edges of all the MAP candidates\n",
    "    mesh_large_connectivity = tu.mesh_list_connectivity(meshes = mesh_large_idx,\n",
    "                            main_mesh = limb_mesh_mparty,\n",
    "                            print_flag = False)\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_large_connectivity: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "    \"\"\"\n",
    "    --------------- Grouping MAP candidates ----------------\n",
    "    Purpose: Will see what mesh pieces should be grouped together\n",
    "    to pass through CGAL skeletonization\n",
    "\n",
    "\n",
    "    Pseudocode: \n",
    "    1) build a networkx graph with all nodes for mesh_large_idx indexes\n",
    "    2) Add the edges\n",
    "    3) Find the connected components\n",
    "    4) Find sizes of connected components\n",
    "    5) For all those connected components that are of a large enough size, \n",
    "    add the mesh branches and skeletons to the final list\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(np.arange(len(mesh_large_idx)))\n",
    "    G.add_edges_from(mesh_large_connectivity)\n",
    "    conn_comp = list(nx.connected_components(G))\n",
    "\n",
    "    filtered_pieces = []\n",
    "\n",
    "    sk_large_size_filt = []\n",
    "    mesh_large_idx_size_filt = []\n",
    "    width_large_size_filt = []\n",
    "\n",
    "    for cc in conn_comp:\n",
    "        total_cc_size = np.sum([len(mesh_large_idx[k]) for k in cc])\n",
    "        if total_cc_size>size_threshold_MAP:\n",
    "            #print(f\"cc ({cc}) passed the size threshold because size was {total_cc_size}\")\n",
    "            filtered_pieces.append(pieces_above_threshold[list(cc)])\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"Finding MAP candidates connected components: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    #filtered_pieces: will have the indexes of all the branch candidates that should  be \n",
    "    #grouped together and passed through MAP skeletonization\n",
    "\n",
    "    if len(filtered_pieces) > 0:\n",
    "        # --------------- Part 6: If Found MAP sublimbs, Get the meshes and mesh_idxs of the sublimbs ------------- #\n",
    "        print(f\"len(filtered_pieces) = {len(filtered_pieces)}\")\n",
    "        #all the pieces that will require MAP mesh correspondence and skeletonization\n",
    "        #(already organized into their components)\n",
    "        mesh_pieces_for_MAP = [limb_mesh_mparty.submesh([np.concatenate(divided_submeshes_idx[k])],append=True,repair=False) for k in filtered_pieces]\n",
    "        mesh_pieces_for_MAP_face_idx = [np.concatenate(divided_submeshes_idx[k]) for k in filtered_pieces]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Old Way: Finding connectivity of pieces through\n",
    "        mesh_idx_MP = [divided_submeshes_idx[k] for k in pieces_idx_MP]\n",
    "\n",
    "        mesh_large_connectivity_MP = tu.mesh_list_connectivity(meshes = mesh_idx_MP,\n",
    "                                main_mesh = limb_mesh_mparty,\n",
    "                                print_flag = False)\n",
    "\n",
    "        New Way: going to use skeleton connectivity to determine\n",
    "        connectivity of pieces\n",
    "\n",
    "        Pseudocode: \n",
    "        1)\n",
    "\n",
    "        \"\"\"\n",
    "        # --------------- Part 7: If Found MAP sublimbs, Get the meshes and mesh_idxs of the sublimbs ------------- #\n",
    "        # ********* if there are no pieces leftover then will automatically make all the lists below just empty (don't need to if.. else.. the case)****\n",
    "        pieces_idx_MP = np.setdiff1d(np.arange(len(divided_submeshes_idx)),np.concatenate(filtered_pieces))\n",
    "\n",
    "        skeleton_MP = [segment_branches[k] for k in pieces_idx_MP]\n",
    "        skeleton_connectivity_MP = sk.skeleton_list_connectivity(\n",
    "                                        skeletons=skeleton_MP\n",
    "                                        )\n",
    "        if print_fusion_steps:\n",
    "            print(f\"skeleton_connectivity_MP : {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(np.arange(len(skeleton_MP)))\n",
    "        G.add_edges_from(skeleton_connectivity_MP)\n",
    "        sublimbs_MP = list(nx.connected_components(G))\n",
    "        sublimbs_MP_orig_idx = [pieces_idx_MP[list(k)] for k in sublimbs_MP]\n",
    "\n",
    "\n",
    "        #concatenate into sublimbs the skeletons and meshes\n",
    "        sublimb_mesh_idx_branches_MP = [divided_submeshes_idx[k] for k in sublimbs_MP_orig_idx]\n",
    "        sublimb_mesh_branches_MP = [[limb_mesh_mparty.submesh([ki],append=True,repair=False)\n",
    "                                    for ki in k] for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_meshes_MP = [limb_mesh_mparty.submesh([np.concatenate(k)],append=True,repair=False)\n",
    "                                                     for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_meshes_MP_face_idx = [np.concatenate(k)\n",
    "                                                     for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_skeleton_branches = [segment_branches[k] for k in sublimbs_MP_orig_idx]\n",
    "        widths_MP = [segment_widths_median[k] for k in sublimbs_MP_orig_idx]\n",
    "\n",
    "        if print_fusion_steps:\n",
    "            print(f\"Grouping MP Sublimbs by Graph: {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "\n",
    "# else: #if no pieces were determine to need MAP processing\n",
    "#     print(\"No MAP processing needed: just returning the Meshparty skeletonization and mesh correspondence\")\n",
    "#     raise Exception(\"Returning MP correspondence\")\n",
    "\n",
    "\n",
    "# nviz.plot_objects(main_mesh=tu.combine_meshes([limb_mesh_mparty,current_neuron[\"S0\"].mesh]),\n",
    "#                   main_mesh_color=\"green\",\n",
    "#     skeletons=sk_large_size_filt,\n",
    "#      meshes=[limb_mesh_mparty.submesh([k],append=True) for k in mesh_large_idx_size_filt],\n",
    "#       meshes_colors=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------- Part 8: If No MAP sublimbs found, set the MP sublimb lists to just the whole MP branch decomposition ------------- #\n",
    "\n",
    "#if no sublimbs need to be decomposed with MAP then just reassign all of the previous MP processing to the sublimb_MPs\n",
    "if len(mesh_pieces_for_MAP) == 0:\n",
    "    sublimb_meshes_MP = [limb_mesh_mparty] #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "    # -- the decomposition information ---\n",
    "    sublimb_mesh_branches_MP = [divided_submeshes] #the mesh branches for all the disconnected sublimbs\n",
    "    sublimb_mesh_idx_branches_MP = [divided_submeshes_idx] #The mesh branches idx that have already passed through MP skeletonization\n",
    "    sublimb_skeleton_branches = [segment_branches]#the skeleton bnraches for all the sublimbs\n",
    "    widths_MP = [segment_widths_median] #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "    MAP_flag = False\n",
    "else:\n",
    "    MAP_flag = True\n",
    "\n",
    "\n",
    "\n",
    "mesh_pieces_for_MAP #trimesh pieces that should go through CGAL skeletonization\n",
    "sublimb_meshes_MP #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "\n",
    "# -- the decomposition information ---\n",
    "sublimb_mesh_branches_MP #the mesh branches for all the disconnected sublimbs\n",
    "sublimb_mesh_idx_branches_MP #The mesh branches idx that have already passed through MP skeletonization\n",
    "sublimb_skeleton_branches #the skeleton bnraches for all the sublimbs\n",
    "widths_MP #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Divinding into MP and MAP pieces: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------- At this point have the correct division between MAP and MP ------------------------\n",
    "\n",
    "# -------------- Part 9: Doing the MAP decomposition ------------------ #\n",
    "global_start_time = time.time()\n",
    "endpoints_must_keep = dict()\n",
    "\n",
    "\n",
    "\n",
    "limb_correspondence_MAP = dict()\n",
    "\n",
    "for sublimb_idx,(mesh,mesh_idx) in enumerate(zip(mesh_pieces_for_MAP,mesh_pieces_for_MAP_face_idx)):\n",
    "    print(f\"--- Working on MAP piece {sublimb_idx}---\")\n",
    "    mesh_start_time = time.time()\n",
    "    curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "    mesh = mesh,\n",
    "    curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "    )\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MAP Filtering Soma Pieces: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 0) Generating the Clean skeletons  -------------------------------------------#\n",
    "    if not curr_soma_to_piece_touching_vertices is None:\n",
    "        curr_total_border_vertices = dict([(k,np.vstack(v)) for k,v in curr_soma_to_piece_touching_vertices.items()])\n",
    "    else:\n",
    "        curr_total_border_vertices = None\n",
    "\n",
    "\n",
    "    cleaned_branch,curr_limb_endpoints_must_keep = sk.skeletonize_and_clean_connected_branch_CGAL(\n",
    "        mesh=mesh,\n",
    "        curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices,\n",
    "        total_border_vertices=curr_total_border_vertices,\n",
    "        filter_end_node_length=filter_end_node_length,\n",
    "        perform_cleaning_checks=perform_cleaning_checks,\n",
    "        combine_close_skeleton_nodes = combine_close_skeleton_nodes,\n",
    "        combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold,\n",
    "    use_surface_after_CGAL=use_surface_after_CGAL,\n",
    "    surface_reconstruction_size=surface_reconstruction_size)\n",
    "\n",
    "    if not curr_limb_endpoints_must_keep is None:\n",
    "        limb_to_endpoints_must_keep_list.append(curr_limb_endpoints_must_keep)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices)\n",
    "    else:\n",
    "        print(\"Inside MAP decomposition and curr_limb_endpoints_must_keep was None\")\n",
    "\n",
    "    if len(cleaned_branch) == 0:\n",
    "        raise Exception(f\"Found a zero length skeleton for limb {z} of trmesh {branch}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"skeletonize_and_clean_connected_branch_CGAL: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 1) Generating Initial Mesh Correspondence -------------------------------------------#\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Working on limb correspondence for #{sublimb_idx} MAP piece\")\n",
    "    local_correspondence = mesh_correspondence_first_pass(mesh=mesh,\n",
    "                                                         skeleton=cleaned_branch,\n",
    "                                                         distance_by_mesh_center=distance_by_mesh_center)\n",
    "\n",
    "\n",
    "    print(f\"Total time for decomposition = {time.time() - start_time}\")\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_correspondence_first_pass: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "\n",
    "    #------------- 2) Doing Some checks on the initial corespondence -------- #\n",
    "\n",
    "\n",
    "    if perform_cleaning_checks:\n",
    "        check_skeletonization_and_decomp(skeleton=cleaned_branch,\n",
    "                                        local_correspondence=local_correspondence)\n",
    "\n",
    "    # -------3) Finishing off the face correspondence so get 1-to-1 correspondence of mesh face to skeletal piece\n",
    "    local_correspondence_revised = correspondence_1_to_1(mesh=mesh,\n",
    "                                    local_correspondence=local_correspondence,\n",
    "                                    curr_limb_endpoints_must_keep=curr_limb_endpoints_must_keep,\n",
    "                                    curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices)\n",
    "\n",
    "    # -------3b) Fixing the mesh indices to correspond to the larger mesh as a whole\n",
    "    for k,v in local_correspondence_revised.items():\n",
    "        local_correspondence_revised[k][\"branch_face_idx\"] = mesh_idx[local_correspondence_revised[k][\"branch_face_idx\"]]\n",
    "\n",
    "    print(f\"Total time for MAP sublimb #{sublimb_idx} mesh processing = {time.time() - mesh_start_time}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"correspondence_1_to_1: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    limb_correspondence_MAP[sublimb_idx] = local_correspondence_revised\n",
    "\n",
    "print(f\"Total time for MAP sublimb processing {time.time() - global_start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- Part 10: Doing the MP Decomposition ---------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sublimb_meshes_MP #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "# -- the decomposition information ---\n",
    "sublimb_mesh_branches_MP #the mesh branches for all the disconnected sublimbs\n",
    "sublimb_mesh_idx_branches_MP #The mesh branches idx that have already passed through MP skeletonization\n",
    "sublimb_skeleton_branches #the skeleton bnraches for all the sublimbs\n",
    "widths_MP #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "limb_correspondence_MP = dict()\n",
    "\n",
    "for sublimb_idx,mesh in enumerate(sublimb_meshes_MP):\n",
    "    print(f\"---- Working on MP Decomposition #{sublimb_idx} ----\")\n",
    "    mesh_start_time = time.time()\n",
    "\n",
    "    if len(sublimb_meshes_MP) == 1 and MAP_flag == False:\n",
    "        print(\"Using Quicker soma_to_piece_touching_vertices because no MAP and only one sublimb_mesh piece \")\n",
    "        curr_soma_to_piece_touching_vertices = soma_touching_vertices_dict\n",
    "    else:\n",
    "        if not soma_touching_vertices_dict is None:\n",
    "            print(\"Computing the current soma touching verts dict manually\")\n",
    "            curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "                                                mesh = mesh,\n",
    "                                                curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "                                                )\n",
    "        else:\n",
    "            curr_soma_to_piece_touching_vertices = None\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MP filtering soma verts: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    #creating all of the sublimb groups\n",
    "    segment_branches = np.array(sublimb_skeleton_branches[sublimb_idx])\n",
    "    whole_sk_MP = sk.stack_skeletons(segment_branches)\n",
    "    branch = mesh\n",
    "    divided_submeshes = np.array(sublimb_mesh_branches_MP[sublimb_idx])\n",
    "    divided_submeshes_idx = sublimb_mesh_idx_branches_MP[sublimb_idx]\n",
    "    segment_widths_median = widths_MP[sublimb_idx]\n",
    "\n",
    "\n",
    "    if curr_soma_to_piece_touching_vertices is None:\n",
    "        print(f\"Do Not Need to Fix MP Decomposition {sublimb_idx} so just continuing\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # ------- 11/9 addition: Fixing error where creating soma touching branch on mesh that doesn't touch border ------------------- #\n",
    "        print(f\"Fixing Possible Soma Extension Branch for Sublimb {sublimb_idx}\")\n",
    "        no_soma_extension_add = True \n",
    "        \n",
    "        endpts_total = dict()\n",
    "        curr_soma_to_piece_touching_vertices_total = dict()\n",
    "        for sm_idx,sm_bord_verts_list in curr_soma_to_piece_touching_vertices.items():\n",
    "            #will be used for later\n",
    "            endpts_total[sm_idx] = []\n",
    "            curr_soma_to_piece_touching_vertices_total[sm_idx] = []\n",
    "            \n",
    "            for sm_bord_verts in sm_bord_verts_list:\n",
    "                #1) Get the mesh pieces that are touching the border\n",
    "                matching_mesh_idx = tu.filter_meshes_by_containing_coordinates(mesh_list=divided_submeshes,\n",
    "                                           nullifying_points=sm_bord_verts,\n",
    "                                            filter_away=False,\n",
    "                                           distance_threshold=0,\n",
    "                                           return_indices=True)\n",
    "                #2) concatenate all meshes and skeletons that are touching\n",
    "                if len(matching_mesh_idx) <= 0:\n",
    "                    raise Exception(\"None of branches were touching the border vertices when fixing MP pieces\")\n",
    "                \n",
    "                touch_mesh = tu.combine_meshes(divided_submeshes[matching_mesh_idx])\n",
    "                touch_sk = sk.stack_skeletons(segment_branches[matching_mesh_idx])\n",
    "                \n",
    "                local_curr_soma_to_piece_touching_vertices = {sm_idx:[sm_bord_verts]}\n",
    "                new_sk,endpts,new_branch_info = sk.create_soma_extending_branches(current_skeleton=touch_sk,\n",
    "                                      skeleton_mesh=touch_mesh,\n",
    "                                      soma_to_piece_touching_vertices=local_curr_soma_to_piece_touching_vertices,\n",
    "                                      return_endpoints_must_keep=True,\n",
    "                                      return_created_branch_info=True,\n",
    "                                      check_connected_skeleton=False)\n",
    "                \n",
    "                #3) Add the info to the new running lists\n",
    "                endpts_total[sm_idx].append(endpts[sm_idx][0])\n",
    "                curr_soma_to_piece_touching_vertices_total[sm_idx].append(sm_bord_verts)\n",
    "                \n",
    "                \n",
    "                #4) Skip if no new branch was added\n",
    "                br_info = new_branch_info[sm_idx][0]\n",
    "                if br_info is None:\n",
    "                    print(\"The new branch info was none so skipping \\n\")\n",
    "                    continue\n",
    "                    \n",
    "                #4 If new branch was made then \n",
    "                no_soma_extension_add=False\n",
    "\n",
    "                #1) Get the newly added branch (and the original vertex which is the first row)\n",
    "                br_new,sm_bord_verts = br_info[\"new_branch\"],br_info[\"border_verts\"] #this will hold the new branch and the border vertices corresponding to it\n",
    "\n",
    "                curr_soma_to_piece_touching_vertices_MP = {sm_idx:[sm_bord_verts]}\n",
    "                endpoints_must_keep_MP = {sm_idx:[br_new[0][1]]}\n",
    "\n",
    "\n",
    "                orig_vertex = br_new[0][0]\n",
    "                print(f\"orig_vertex = {orig_vertex}\")\n",
    "\n",
    "                #2) Find the branches that have that coordinate (could be multiple)\n",
    "                match_sk_branches = sk.find_branch_skeleton_with_specific_coordinate(segment_branches,\n",
    "                    current_coordinate=orig_vertex)\n",
    "\n",
    "                print(f\"match_sk_branches = {match_sk_branches}\")\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\" ******************* THIS NEEDS TO BE FIXED WITH THE SAME METHOD OF STITCHING ********************  \"\"\"\n",
    "                \"\"\"\n",
    "                Pseudocode:\n",
    "                1) Find if branch point will require split or not\n",
    "                2) If does require split then split the skeleton\n",
    "                3) Gather mesh pieces for correspondence and the skeletons\n",
    "                4) Run the mesh correspondence\n",
    "                - this case calculate the new widths after run \n",
    "                5) Replace the old branch parts with the new ones\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                stitch_point_on_end_or_branch = find_if_stitch_point_on_end_or_branch(\n",
    "                                                        matched_branches_skeletons= segment_branches[match_sk_branches],\n",
    "                                                         stitch_coordinate=orig_vertex,\n",
    "                                                          verbose=False)\n",
    "\n",
    "\n",
    "                if not stitch_point_on_end_or_branch:\n",
    "                    matching_branch_sk = sk.cut_skeleton_at_coordinate(skeleton=segment_branches[match_sk_branches][0],\n",
    "                                                                      cut_coordinate = orig_vertex)\n",
    "                else:\n",
    "                    matching_branch_sk = segment_branches[match_sk_branches]\n",
    "\n",
    "\n",
    "                #3) Find the mesh and skeleton of the winning branch\n",
    "                matching_branch_meshes = np.array(divided_submeshes)[match_sk_branches]\n",
    "                matching_branch_mesh_idx = np.array(divided_submeshes_idx)[match_sk_branches]\n",
    "                extend_soma_mesh_idx = np.concatenate(matching_branch_mesh_idx)\n",
    "                extend_soma_mesh = limb_mesh_mparty.submesh([extend_soma_mesh_idx ],append=True,repair=False)\n",
    "\n",
    "                #4) Add newly created branch to skeleton and divide the skeleton into branches (could make 2 or 3)\n",
    "                #extended_skeleton_to_soma = sk.stack_skeletons([list(matching_branch_sk),br_new])\n",
    "\n",
    "                sk.check_skeleton_connected_component(sk.stack_skeletons(list(matching_branch_sk) + [br_new]))\n",
    "\n",
    "                #5) Run Adaptive mesh correspondnece using branches and mesh\n",
    "                local_correspondnece_MP = mesh_correspondence_first_pass(mesh=extend_soma_mesh,\n",
    "                                                                         skeleton_branches = list(matching_branch_sk) + [br_new]\n",
    "                                              #skeleton=extended_skeleton_to_soma\n",
    "                                                                        )\n",
    "\n",
    "                # GETTING MESHES THAT ARE NOT FULLY CONNECTED!!\n",
    "                local_correspondence_revised = correspondence_1_to_1(mesh=extend_soma_mesh,\n",
    "                                                            local_correspondence=local_correspondnece_MP,\n",
    "                                                            curr_limb_endpoints_must_keep=endpoints_must_keep_MP,\n",
    "                                                            curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices_MP)\n",
    "\n",
    "                # All the things that should be revised:\n",
    "            #     segment_branches, #skeleton branches\n",
    "            #     divided_submeshes, divided_submeshes_idx, #mesh correspondence (mesh and indices)\n",
    "            #     segment_widths_median\n",
    "\n",
    "\n",
    "                new_submeshes = [k[\"branch_mesh\"] for k in local_correspondence_revised.values()]\n",
    "                new_submeshes_idx = [extend_soma_mesh_idx[k[\"branch_face_idx\"]] for k in local_correspondence_revised.values()]\n",
    "                new_skeletal_branches = [k[\"branch_skeleton\"] for k in local_correspondence_revised.values()]\n",
    "\n",
    "                #calculate the new width\n",
    "                ray_inter = tu.ray_pyembree.RayMeshIntersector(limb_mesh_mparty)\n",
    "                new_widths = []\n",
    "                for new_s_idx in new_submeshes_idx:\n",
    "                    curr_ray_distance = tu.ray_trace_distance(mesh=limb_mesh_mparty, \n",
    "                                        face_inds=new_s_idx,\n",
    "                                       ray_inter=ray_inter)\n",
    "                    curr_width_median = np.median(curr_ray_distance[curr_ray_distance!=0])\n",
    "                    print(f\"curr_width_median = {curr_width_median}\")\n",
    "                    if (not np.isnan(curr_width_median)) and (curr_width_median > 0):\n",
    "                        new_widths.append(curr_width_median)\n",
    "                    else:\n",
    "                        print(f\"USING A DEFAULT WIDTH BECAUSE THE NEWLY COMPUTED ONE WAS {curr_width_median}: {segment_widths_median[match_sk_branches[0]]}\")\n",
    "                        new_widths.append(segment_widths_median[match_sk_branches[0]])\n",
    "\n",
    "\n",
    "                #6) Remove the original branch and mesh correspondence and replace with the multiples\n",
    "#                     print(f\"match_sk_branches BEFORE = {match_sk_branches}\")\n",
    "#                     print(f\"segment_branches BEFORE = {segment_branches}\")\n",
    "#                     print(f\"len(new_skeletal_branches) = {len(new_skeletal_branches)}\")\n",
    "#                     print(f\"new_skeletal_branches BEFORE= {new_skeletal_branches}\")\n",
    "\n",
    "\n",
    "                #segment_branches = np.delete(segment_branches,match_sk_branches,axis=0)\n",
    "                #segment_branches = np.append(segment_branches,new_skeletal_branches,axis=0)\n",
    "\n",
    "                segment_branches = np.array([k for i,k in enumerate(segment_branches) if i not in match_sk_branches] + new_skeletal_branches)\n",
    "\n",
    "\n",
    "                divided_submeshes = np.delete(divided_submeshes,match_sk_branches,axis=0)\n",
    "                divided_submeshes = np.append(divided_submeshes,new_submeshes,axis=0)\n",
    "\n",
    "\n",
    "                #divided_submeshes_idx = np.delete(divided_submeshes_idx,match_sk_branches,axis=0)\n",
    "                #divided_submeshes_idx = np.append(divided_submeshes_idx,new_submeshes_idx,axis=0)\n",
    "                divided_submeshes_idx = np.array([k for i,k in enumerate(divided_submeshes_idx) if i not in match_sk_branches] + new_submeshes_idx)\n",
    "\n",
    "                segment_widths_median = np.delete(segment_widths_median,match_sk_branches,axis=0)\n",
    "                segment_widths_median = np.append(segment_widths_median,new_widths,axis=0)\n",
    "\n",
    "                try:\n",
    "                    debug = False\n",
    "                    if debug:\n",
    "                        print(f\"segment_branches.shape = {segment_branches.shape}\")\n",
    "                        print(f\"segment_branches = {segment_branches}\")\n",
    "                        print(f\"new_skeletal_branches = {new_skeletal_branches}\")\n",
    "                    sk.check_skeleton_connected_component(sk.stack_skeletons(segment_branches))\n",
    "                except:\n",
    "                    su.compressed_pickle(local_correspondence_revised,\"local_correspondence_revised\")\n",
    "                print(\"checked segment branches after soma add on\")\n",
    "                return_find = sk.find_branch_skeleton_with_specific_coordinate(segment_branches,\n",
    "                                             orig_vertex)\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\" ******************* END OF HOW CAN DO STITCHING ********************  \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "        limb_to_endpoints_must_keep_list.append(endpts_total)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices_total)\n",
    "        \n",
    "        # ------------------- 11/9 addition ------------------- #\n",
    "\n",
    "        if no_soma_extension_add:\n",
    "            print(\"No soma extending branch was added for this sublimb even though it had a soma border (means they already existed)\")\n",
    "\n",
    "        if print_fusion_steps:\n",
    "            print(f\"MP (because soma touching verts) soma extension add: {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "    #building the limb correspondence\n",
    "    limb_correspondence_MP[sublimb_idx] = dict()\n",
    "\n",
    "    for zz,b_sk in enumerate(segment_branches):\n",
    "        limb_correspondence_MP[sublimb_idx][zz] = dict(\n",
    "            branch_skeleton = b_sk,\n",
    "            width_from_skeleton = segment_widths_median[zz],\n",
    "            branch_mesh = divided_submeshes[zz],\n",
    "            branch_face_idx = divided_submeshes_idx[zz]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "#limb_correspondence_MP_saved = copy.deepcopy(limb_correspondence_MP)\n",
    "#limb_correspondence_MAP_saved = copy.deepcopy(limb_correspondence_MAP)\n",
    "\n",
    "# ------------------------------------- Part C: Will make sure the correspondences can all be stitched together --------------- #\n",
    "\n",
    "# Only want to perform this step if both MP and MAP pieces\n",
    "if len(limb_correspondence_MAP)>0 and len(limb_correspondence_MP)>0:\n",
    "\n",
    "    # -------------- Part 11: Getting Sublimb Mesh and Skeletons and Gets connectivitiy by Mesh -------#\n",
    "    # -------------(filtering connections to only MP to MAP edges)--------------- #\n",
    "\n",
    "    # ---- Doing the mesh connectivity ---------#\n",
    "    sublimb_meshes_MP = []\n",
    "    sublimb_skeletons_MP = []\n",
    "\n",
    "    for sublimb_key,sublimb_v in limb_correspondence_MP.items():\n",
    "        sublimb_meshes_MP.append(tu.combine_meshes([branch_v[\"branch_mesh\"] for branch_v in sublimb_v.values()]))\n",
    "        sublimb_skeletons_MP.append(sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in sublimb_v.values()]))\n",
    "\n",
    "        \n",
    "        \n",
    "    sublimb_meshes_MAP = []\n",
    "    sublimb_skeletons_MAP = []\n",
    "\n",
    "\n",
    "    for sublimb_key,sublimb_v in limb_correspondence_MAP.items():\n",
    "        sublimb_meshes_MAP.append(tu.combine_meshes([branch_v[\"branch_mesh\"] for branch_v in sublimb_v.values()]))\n",
    "        sublimb_skeletons_MAP.append(sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in sublimb_v.values()]))\n",
    "\n",
    "    sublimb_skeletons_MP_saved = copy.deepcopy(sublimb_skeletons_MP)\n",
    "    sublimb_skeletons_MAP_saved = copy.deepcopy(sublimb_skeletons_MAP)\n",
    "\n",
    "    mesh_conn,mesh_conn_vertex_groups = tu.mesh_list_connectivity(meshes = sublimb_meshes_MP + sublimb_meshes_MAP,\n",
    "                                        main_mesh = limb_mesh_mparty,\n",
    "                                        min_common_vertices=1,\n",
    "                                        return_vertex_connection_groups=True,\n",
    "                                        return_largest_vertex_connection_group=True,\n",
    "                                        print_flag = False)\n",
    "    mesh_conn_old = copy.deepcopy(mesh_conn)\n",
    "\n",
    "\n",
    "\n",
    "    #check that every MAP piece mapped to a MP piece\n",
    "    mesh_conn_filt = []\n",
    "    mesh_conn_vertex_groups_filt = []\n",
    "    for j,(m1,m2) in enumerate(mesh_conn):\n",
    "        if m1 < len(sublimb_meshes_MP) and m2 >=len(sublimb_meshes_MP):\n",
    "            mesh_conn_filt.append([m1,m2])\n",
    "            mesh_conn_vertex_groups_filt.append(mesh_conn_vertex_groups[j])\n",
    "    mesh_conn_filt = np.array(mesh_conn_filt)\n",
    "\n",
    "    mesh_conn = mesh_conn_filt\n",
    "    mesh_conn_vertex_groups = mesh_conn_vertex_groups_filt\n",
    "\n",
    "    #check that the mapping should create only one connected component\n",
    "    G = nx.from_edgelist(mesh_conn)\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        if len(G) != len(sublimb_meshes_MP) + len(sublimb_meshes_MAP):\n",
    "            raise Exception(\"Number of nodes in mesh connectivity graph is not equal to number of  MAP and MP sublimbs\")\n",
    "\n",
    "        connect_comp = list(nx.connected_components(G))\n",
    "        if len(connect_comp)>1:\n",
    "            raise Exception(f\"Mesh connectivity was not one component, instead it was ({len(connect_comp)}): {connect_comp} \")\n",
    "    except:\n",
    "        print(f\"mesh_conn_filt = {mesh_conn_filt}\")\n",
    "        print(f\"mesh_conn_old = {mesh_conn_old}\")\n",
    "        mesh_conn_adjusted = np.vstack([mesh_conn[:,0],mesh_conn[:,1]-len(sublimb_meshes_MP)]).T\n",
    "        print(f\"mesh_conn_adjusted = {mesh_conn_adjusted}\")\n",
    "        print(f\"len(sublimb_meshes_MP) = {len(sublimb_meshes_MP)}\")\n",
    "        print(f\"len(sublimb_meshes_MAP) = {len(sublimb_meshes_MAP)}\")\n",
    "        meshes = sublimb_meshes_MP + sublimb_meshes_MAP\n",
    "        #su.compressed_pickle(meshes,\"meshes\")\n",
    "        su.compressed_pickle(sublimb_meshes_MP,\"sublimb_meshes_MP\")\n",
    "        su.compressed_pickle(sublimb_meshes_MAP,\"sublimb_meshes_MAP\")\n",
    "        su.compressed_pickle(limb_mesh_mparty,\"limb_mesh_mparty\")\n",
    "        su.compressed_pickle(sublimb_skeletons_MP,\"sublimb_skeletons_MP\")\n",
    "        su.compressed_pickle(sublimb_skeletons_MAP,\"sublimb_skeletons_MAP\")\n",
    "\n",
    "\n",
    "        raise Exception(\"Something went wrong in the connectivity\")\n",
    "\n",
    "\n",
    "    #adjust the connection indices for MP and MAP indices\n",
    "    mesh_conn_adjusted = np.vstack([mesh_conn[:,0],mesh_conn[:,1]-len(sublimb_meshes_MP)]).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Pseudocode:\n",
    "    For each connection edge:\n",
    "        For each vertex connection group:\n",
    "            1) Get the endpoint vertices of the MP skeleton\n",
    "            2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "            3) Find the closest skeletal point on MAP pairing (MAP stitch) \n",
    "            4) Find the branches that have that MAP stitch point:\n",
    "            5A) If the number of branches corresponding to stitch point is multipled\n",
    "                --> then we are stitching at a branching oint\n",
    "                i) Just add the skeletal segment from MP_stitch to MAP stitch to the MP skeletal segment\n",
    "                ii) \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    # -------------- STITCHING PHASE -------#\n",
    "    stitch_counter = 0\n",
    "    all_map_stitch_points = []\n",
    "    for (MP_idx,MAP_idx),v_g in zip(mesh_conn_adjusted,mesh_conn_vertex_groups):\n",
    "        print(f\"\\n---- Working on {(MP_idx,MAP_idx)} connection-----\")\n",
    "\n",
    "        \"\"\"\n",
    "        This old way of getting the endpoints was not good because could possibly just need\n",
    "        a stitching done between original branch junction\n",
    "\n",
    "        skeleton_MP_graph = sk.convert_skeleton_to_graph(curr_skeleton_MP)\n",
    "        endpoint_nodes = xu.get_nodes_of_degree_k(skeleton_MP_graph,1)\n",
    "        endpoint_nodes_coordinates = xu.get_node_attributes(skeleton_MP_graph,node_list=endpoint_nodes)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # -------------- Part 12: Find the MP and MAP stitching point and branches that contain the stitching point-------#\n",
    "\n",
    "        \"\"\"  OLD WAY THAT ALLOWED STITICHING POINTS TO NOT BE CONNECTED AT THE CONNECTING BRANCHES\n",
    "        #getting the skeletons that should be stitched\n",
    "        curr_skeleton_MP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MP[MP_idx].values()])\n",
    "        curr_skeleton_MAP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MAP[MAP_idx].values()])\n",
    "\n",
    "        #1) Get the endpoint vertices of the MP skeleton branches (so every endpoint or high degree node)\n",
    "        #(needs to be inside loop because limb correspondence will change)\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in np.sort(list(limb_correspondence_MP[MP_idx].keys()))]\n",
    "        endpoint_nodes_coordinates = np.array([sk.find_branch_endpoints(k) for k in curr_MP_branch_skeletons])\n",
    "        endpoint_nodes_coordinates = np.unique(endpoint_nodes_coordinates.reshape(-1,3),axis=0)\n",
    "\n",
    "        #2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "        av_vert = np.mean(v_g,axis=0)\n",
    "        winning_vertex = endpoint_nodes_coordinates[np.argmin(np.linalg.norm(endpoint_nodes_coordinates-av_vert,axis=1))]\n",
    "        print(f\"winning_vertex = {winning_vertex}\")\n",
    "\n",
    "\n",
    "        #2b) Find the branch points where the winning vertex is located\n",
    "        MP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MP_branch_skeletons,\n",
    "            current_coordinate = winning_vertex\n",
    "        )\n",
    "        print(f\"MP_branches_with_stitch_point = {MP_branches_with_stitch_point}\")\n",
    "\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP.reshape(-1,3),axis=0)\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-winning_vertex,axis=1))]\n",
    "\n",
    "\n",
    "        #3b) Consider if the stitch point is close enough to end or branch node in skeleton:\n",
    "        # and if so then reassign\n",
    "        if move_MAP_stitch_to_end_or_branch:\n",
    "            MAP_stitch_point_new,change_status = sk.move_point_to_nearest_branch_end_point_within_threshold(\n",
    "                                                    skeleton=curr_skeleton_MAP,\n",
    "                                                    coordinate=MAP_stitch_point,\n",
    "                                                    distance_to_move_point_threshold = distance_to_move_point_threshold,\n",
    "                                                    verbose=True\n",
    "\n",
    "                                                    )\n",
    "            MAP_stitch_point=MAP_stitch_point_new\n",
    "\n",
    "\n",
    "        #4) Find the branches that have that MAP stitch point:\n",
    "        curr_MAP_branch_skeletons = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"]\n",
    "                                         for k in np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))]\n",
    "\n",
    "        MAP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MAP_branch_skeletons,\n",
    "            current_coordinate = MAP_stitch_point\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        MAP_stitch_point_on_end_or_branch = False\n",
    "        if len(MAP_branches_with_stitch_point)>1:\n",
    "            MAP_stitch_point_on_end_or_branch = True\n",
    "        elif len(MAP_branches_with_stitch_point)==1:\n",
    "            if len(nu.matching_rows(sk.find_branch_endpoints(curr_MAP_branch_skeletons[MAP_branches_with_stitch_point[0]]),\n",
    "                                    MAP_stitch_point))>0:\n",
    "                MAP_stitch_point_on_end_or_branch=True\n",
    "        else:\n",
    "            raise Exception(\"No matching MAP values\")\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "        #*****should only get branches that are touching....****\n",
    "\n",
    "        #getting the skeletons that should be stitched\n",
    "        curr_skeleton_MP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MP[MP_idx].values()])\n",
    "        curr_skeleton_MAP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MAP[MAP_idx].values()])\n",
    "\n",
    "\n",
    "        av_vert = np.mean(v_g,axis=0)\n",
    "\n",
    "        # ---------------- Doing the MAP part first -------------- #\n",
    "        \"\"\"\n",
    "        The previous way did not ensure that the MAP point found will have a branch mesh that is touching the border vertices\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP.reshape(-1,3),axis=0)\n",
    "\n",
    "        #this does not guarentee that the MAP branch associated with the MAP stitch point is touching the border group\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-av_vert,axis=1))]\n",
    "        \"\"\"\n",
    "\n",
    "        # -------------- 11/9 NEW METHOD FOR FINDING MAP STITCH POINT ------------ #\n",
    "        o_keys = np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))\n",
    "        curr_MAP_branch_meshes = np.array([limb_correspondence_MAP[MAP_idx][k][\"branch_mesh\"]\n",
    "                                         for k in o_keys])\n",
    "        curr_MAP_branch_skeletons = np.array([limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"]\n",
    "                                         for k in o_keys])\n",
    "\n",
    "        MAP_pieces_idx_touching_border = tu.filter_meshes_by_containing_coordinates(mesh_list=curr_MAP_branch_meshes,\n",
    "                                       nullifying_points=v_g,\n",
    "                                        filter_away=False,\n",
    "                                       distance_threshold=0,\n",
    "                                       return_indices=True)\n",
    "\n",
    "        MAP_branches_considered = curr_MAP_branch_skeletons[MAP_pieces_idx_touching_border]\n",
    "        curr_skeleton_MAP_for_stitch = sk.stack_skeletons(MAP_branches_considered)\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP_for_stitch.reshape(-1,3),axis=0)\n",
    "\n",
    "        #this does not guarentee that the MAP branch associated with the MAP stitch point is touching the border group\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-av_vert,axis=1))]\n",
    "        \n",
    "        # --------- 11/13: Making so could possibly stitch to another point that was already stitched to\n",
    "        curr_br_endpts = np.array([sk.find_branch_endpoints(k) for k in MAP_branches_considered]).reshape(-1,3)\n",
    "        curr_br_endpts_unique = np.unique(curr_br_endpts,axis=0)\n",
    "        \n",
    "\n",
    "\n",
    "        #3b) Consider if the stitch point is close enough to end or branch node in skeleton:\n",
    "        # and if so then reassign\n",
    "        if move_MAP_stitch_to_end_or_branch:\n",
    "            MAP_stitch_point_new,change_status = sk.move_point_to_nearest_branch_end_point_within_threshold(\n",
    "                                                    skeleton=curr_skeleton_MAP,\n",
    "                                                    coordinate=MAP_stitch_point,\n",
    "                                                    distance_to_move_point_threshold = distance_to_move_point_threshold,\n",
    "                                                    verbose=True,\n",
    "                                                    possible_node_coordinates=curr_br_endpts_unique,\n",
    "                                                    )\n",
    "            MAP_stitch_point=MAP_stitch_point_new\n",
    "\n",
    "\n",
    "        #4) Find the branches that have that MAP stitch point:\n",
    "\n",
    "        MAP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MAP_branch_skeletons,\n",
    "            current_coordinate = MAP_stitch_point\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        MAP_stitch_point_on_end_or_branch = False\n",
    "        if len(MAP_branches_with_stitch_point)>1:\n",
    "            MAP_stitch_point_on_end_or_branch = True\n",
    "        elif len(MAP_branches_with_stitch_point)==1:\n",
    "            if len(nu.matching_rows(sk.find_branch_endpoints(curr_MAP_branch_skeletons[MAP_branches_with_stitch_point[0]]),\n",
    "                                    MAP_stitch_point))>0:\n",
    "                MAP_stitch_point_on_end_or_branch=True\n",
    "        else:\n",
    "            raise Exception(\"No matching MAP values\")\n",
    "            \n",
    "        #add the map stitch point to the history\n",
    "        all_map_stitch_points.append(MAP_stitch_point)\n",
    "\n",
    "        # ---------------- Doing the MP Part --------------------- #\n",
    "\n",
    "\n",
    "\n",
    "        ord_keys = np.sort(list(limb_correspondence_MP[MP_idx].keys()))\n",
    "        curr_MP_branch_meshes = [limb_correspondence_MP[MP_idx][k][\"branch_mesh\"] for k in ord_keys]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" old way of filtering MP pieces just to those touching the MAP, but just want the ones touching the connection group\n",
    "\n",
    "        MAP_meshes_with_stitch_point = tu.combine_meshes([limb_correspondence_MAP[MAP_idx][k][\"branch_mesh\"] for k in MAP_branches_with_stitch_point])\n",
    "\n",
    "        conn = tu.mesh_pieces_connectivity(main_mesh=limb_mesh_mparty,\n",
    "                                   central_piece=MAP_meshes_with_stitch_point,\n",
    "                                   periphery_pieces=curr_MP_branch_meshes)\n",
    "        \"\"\"\n",
    "        # 11/9 Addition: New way that filters meshes by their touching of the vertex connection group (this could possibly be an empty group)\n",
    "        conn = tu.filter_meshes_by_containing_coordinates(mesh_list=curr_MP_branch_meshes,\n",
    "                                       nullifying_points=v_g,\n",
    "                                        filter_away=False,\n",
    "                                       distance_threshold=0,\n",
    "                                       return_indices=True)\n",
    "\n",
    "        if len(conn) == 0:\n",
    "            print(\"Connectivity was 0 for the MP mesh groups touching the vertex group so not restricting by that anymore\")\n",
    "            conn = np.arange(0,len(curr_MP_branch_meshes))\n",
    "        \n",
    "        print(f\"conn = {conn}\")\n",
    "\n",
    "\n",
    "        #1) Get the endpoint vertices of the MP skeleton branches (so every endpoint or high degree node)\n",
    "        #(needs to be inside loop because limb correspondence will change)\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in conn]\n",
    "        endpoint_nodes_coordinates = np.array([sk.find_branch_endpoints(k) for k in curr_MP_branch_skeletons])\n",
    "        endpoint_nodes_coordinates = np.unique(endpoint_nodes_coordinates.reshape(-1,3),axis=0)\n",
    "\n",
    "\n",
    "        #2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "\n",
    "        winning_vertex = endpoint_nodes_coordinates[np.argmin(np.linalg.norm(endpoint_nodes_coordinates-av_vert,axis=1))]\n",
    "        print(f\"winning_vertex = {winning_vertex}\")\n",
    "\n",
    "\n",
    "        #2b) Find the branch points where the winning vertex is located\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in np.sort(list(limb_correspondence_MP[MP_idx].keys()))]\n",
    "        MP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MP_branch_skeletons,\n",
    "            current_coordinate = winning_vertex\n",
    "        )\n",
    "        print(f\"MP_branches_with_stitch_point = {MP_branches_with_stitch_point}\")\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"MAP_branches_with_stitch_point = {MAP_branches_with_stitch_point}\")\n",
    "        print(f\"MAP_stitch_point_on_end_or_branch = {MAP_stitch_point_on_end_or_branch}\")\n",
    "\n",
    "\n",
    "        # -------- 11/13 addition: Will see if the MP stitch point was already a MAP stitch point ---- #\n",
    "        if len(nu.matching_rows(np.array(all_map_stitch_points),winning_vertex)) > 0:\n",
    "            keep_MP_stitch_static = True\n",
    "        else:\n",
    "            keep_MP_stitch_static = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------- This part does the stitching -------------------- #\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        1) For all MP branches\n",
    "            a) Get neighbor coordinates to MP stitch points\n",
    "            b) Delete the MP Stitch points on each \n",
    "            c) Add skeleton segment from neighbor to MAP stitch point\n",
    "        2) Get skeletons and meshes from MP and MAP pieces\n",
    "        3) Run mesh correspondence to get new meshes and mesh_idx and widths\n",
    "        4a) If MAP_stitch_point_on_end_or_branch is False\n",
    "        - Delete the old MAP branch parts and replace with new MAP ones\n",
    "        4b) Revise the meshes,  mesh_idx, and widths of the MAP pieces\n",
    "        5) Revise the meshes,  mesh_idx, and widths of the MP pieces\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # -------------- Part 13: Will Adjust the MP branches that have the stitch point so extends to the MAP stitch point -------#\n",
    "        curr_MP_sk = []\n",
    "        for b_idx in MP_branches_with_stitch_point:\n",
    "            if not keep_MP_stitch_static:\n",
    "                #a) Get neighbor coordinates to MP stitch points\n",
    "                MP_stitch_branch_graph = sk.convert_skeleton_to_graph(curr_MP_branch_skeletons[b_idx])\n",
    "                stitch_node = xu.get_nodes_with_attributes_dict(MP_stitch_branch_graph,dict(coordinates=winning_vertex))[0]\n",
    "                stitch_neighbors = xu.get_neighbors(MP_stitch_branch_graph,stitch_node)\n",
    "\n",
    "                if len(stitch_neighbors) != 1:\n",
    "                    raise Exception(\"Not just one neighbor for stitch point of MP branch\")\n",
    "                keep_neighbor = stitch_neighbors[0]  \n",
    "                keep_neighbor_coordinates = xu.get_node_attributes(MP_stitch_branch_graph,node_list=[keep_neighbor])[0]\n",
    "\n",
    "                #b) Delete the MP Stitch points on each \n",
    "                MP_stitch_branch_graph.remove_node(stitch_node)\n",
    "\n",
    "                \"\"\" Old way that does not do smoothing\n",
    "\n",
    "                #c) Add skeleton segment from neighbor to MAP stitch point\n",
    "                new_node_name = np.max(MP_stitch_branch_graph.nodes())+1\n",
    "\n",
    "                MP_stitch_branch_graph.add_nodes_from([(int(new_node_name),{\"coordinates\":MAP_stitch_point})])\n",
    "                MP_stitch_branch_graph.add_weighted_edges_from([(keep_neighbor,new_node_name,np.linalg.norm(MAP_stitch_point - keep_neighbor_coordinates))])\n",
    "\n",
    "                new_MP_skeleton = sk.convert_graph_to_skeleton(MP_stitch_branch_graph)\n",
    "\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    if len(MP_stitch_branch_graph)>1:\n",
    "                        new_MP_skeleton = sk.add_and_smooth_segment_to_branch(skeleton=sk.convert_graph_to_skeleton(MP_stitch_branch_graph),\n",
    "                                                        skeleton_stitch_point=keep_neighbor_coordinates,\n",
    "                                                         new_stitch_point=MAP_stitch_point)\n",
    "                    else:\n",
    "                        print(\"Not even attempting smoothing segment because once keep_neighbor_coordinates\")\n",
    "                        new_MP_skeleton = np.vstack([keep_neighbor_coordinates,MAP_stitch_point]).reshape(-1,2,3)\n",
    "                except:\n",
    "                    su.compressed_pickle(MP_stitch_branch_graph,\"MP_stitch_branch_graph\")\n",
    "                    su.compressed_pickle(keep_neighbor_coordinates,\"keep_neighbor_coordinates\")\n",
    "                    su.compressed_pickle(MAP_stitch_point,\"MAP_stitch_point\")\n",
    "\n",
    "\n",
    "                    raise Exception(\"Something went wrong with add_and_smooth_segment_to_branch\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #smooth over the new skeleton\n",
    "                new_MP_skeleton_smooth = sk.resize_skeleton_branch(new_MP_skeleton,\n",
    "                                                                  segment_width=meshparty_segment_size)\n",
    "\n",
    "                curr_MP_sk.append(new_MP_skeleton_smooth)\n",
    "            else:\n",
    "                print(f\"Not adjusting MP skeletons because keep_MP_stitch_static = {keep_MP_stitch_static}\")\n",
    "                curr_MP_sk.append(curr_MP_branch_skeletons[b_idx])\n",
    "            \n",
    "\n",
    "\n",
    "        #2) Get skeletons and meshes from MP and MAP pieces\n",
    "        curr_MAP_sk = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"] for k in MAP_branches_with_stitch_point]\n",
    "\n",
    "        #2.1) Going to break up the MAP skeleton if need be\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        a) check to see if it needs to be broken up\n",
    "        If it does:\n",
    "        b) Convert the skeleton into a graph\n",
    "        c) Find the node of the MAP stitch point (where need to do the breaking)\n",
    "        d) Find the degree one nodes\n",
    "        e) For each degree one node:\n",
    "        - Find shortest path from stitch node to end node\n",
    "        - get a subgraph from that path\n",
    "        - convert graph to a skeleton and save as new skeletons\n",
    "\n",
    "        \"\"\"\n",
    "        # -------------- Part 14: Breaks Up MAP skeleton into 2 pieces if Needs (because MAP stitch point not on endpoint or branch point)  -------#\n",
    "\n",
    "        #a) check to see if it needs to be broken up\n",
    "        cut_flag = False\n",
    "        if not MAP_stitch_point_on_end_or_branch:\n",
    "            if len(curr_MAP_sk) > 1:\n",
    "                raise Exception(f\"There was more than one skeleton for MAP skeletons even though MAP_stitch_point_on_end_or_branch = {MAP_stitch_point_on_end_or_branch}\")\n",
    "\n",
    "\n",
    "            skeleton_to_cut = curr_MAP_sk[0]\n",
    "            curr_MAP_sk = sk.cut_skeleton_at_coordinate(skeleton=skeleton_to_cut,\n",
    "                                                        cut_coordinate=MAP_stitch_point)\n",
    "            cut_flag=True\n",
    "            \n",
    "            \n",
    "        # ------ 11/13 Addition: need to adjust the MAP points if have to keep MP static\n",
    "        if keep_MP_stitch_static:\n",
    "            curr_MAP_sk_final = []\n",
    "            for map_skel in curr_MAP_sk:\n",
    "                #a) Get neighbor coordinates to MP stitch points\n",
    "                MP_stitch_branch_graph = sk.convert_skeleton_to_graph(map_skel)\n",
    "                stitch_node = xu.get_nodes_with_attributes_dict(MP_stitch_branch_graph,dict(coordinates=MAP_stitch_point))[0]\n",
    "                stitch_neighbors = xu.get_neighbors(MP_stitch_branch_graph,stitch_node)\n",
    "\n",
    "                if len(stitch_neighbors) != 1:\n",
    "                    raise Exception(\"Not just one neighbor for stitch point of MP branch\")\n",
    "                keep_neighbor = stitch_neighbors[0]  \n",
    "                keep_neighbor_coordinates = xu.get_node_attributes(MP_stitch_branch_graph,node_list=[keep_neighbor])[0]\n",
    "\n",
    "                #b) Delete the MP Stitch points on each \n",
    "                MP_stitch_branch_graph.remove_node(stitch_node)\n",
    "\n",
    "                \"\"\" Old way that does not do smoothing\n",
    "\n",
    "                #c) Add skeleton segment from neighbor to MAP stitch point\n",
    "                new_node_name = np.max(MP_stitch_branch_graph.nodes())+1\n",
    "\n",
    "                MP_stitch_branch_graph.add_nodes_from([(int(new_node_name),{\"coordinates\":MAP_stitch_point})])\n",
    "                MP_stitch_branch_graph.add_weighted_edges_from([(keep_neighbor,new_node_name,np.linalg.norm(MAP_stitch_point - keep_neighbor_coordinates))])\n",
    "\n",
    "                new_MP_skeleton = sk.convert_graph_to_skeleton(MP_stitch_branch_graph)\n",
    "\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    if len(MP_stitch_branch_graph)>1:\n",
    "                        new_MP_skeleton = sk.add_and_smooth_segment_to_branch(skeleton=sk.convert_graph_to_skeleton(MP_stitch_branch_graph),\n",
    "                                                        skeleton_stitch_point=keep_neighbor_coordinates,\n",
    "                                                         new_stitch_point=winning_vertex)\n",
    "                    else:\n",
    "                        print(\"Not even attempting smoothing segment because once keep_neighbor_coordinates\")\n",
    "                        new_MP_skeleton = np.vstack([keep_neighbor_coordinates,MAP_stitch_point]).reshape(-1,2,3)\n",
    "                except:\n",
    "                    su.compressed_pickle(MP_stitch_branch_graph,\"MP_stitch_branch_graph\")\n",
    "                    su.compressed_pickle(keep_neighbor_coordinates,\"keep_neighbor_coordinates\")\n",
    "                    su.compressed_pickle(MAP_stitch_point,\"MAP_stitch_point\")\n",
    "\n",
    "\n",
    "                    raise Exception(\"Something went wrong with add_and_smooth_segment_to_branch\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #smooth over the new skeleton\n",
    "                new_MP_skeleton_smooth = sk.resize_skeleton_branch(new_MP_skeleton,\n",
    "                                                                  segment_width=meshparty_segment_size)\n",
    "\n",
    "                curr_MAP_sk_final.append(new_MP_skeleton_smooth)\n",
    "            curr_MAP_sk = copy.deepcopy(curr_MAP_sk_final)\n",
    "\n",
    "\n",
    "\n",
    "        # -------------- Part 15: Gets all of the skeletons and Mesh to divide u and does mesh correspondence -------#\n",
    "        # ------------- revise IDX so still references the whole limb mesh -----------#\n",
    "\n",
    "        # -------------- 11/10 Addition accounting for not all MAP pieces always touching each other --------------------#\n",
    "        if len(MAP_branches_with_stitch_point) > 1:\n",
    "            print(\"\\nRevising the MAP pieces index:\")\n",
    "            print(f\"MAP_pieces_idx_touching_border = {MAP_pieces_idx_touching_border}, MAP_branches_with_stitch_point = {MAP_branches_with_stitch_point}\")\n",
    "            MAP_pieces_for_correspondence = nu.intersect1d(MAP_pieces_idx_touching_border,MAP_branches_with_stitch_point)\n",
    "            print(f\"MAP_pieces_for_correspondence = {MAP_pieces_for_correspondence}\")\n",
    "            curr_MAP_sk = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"] for k in MAP_pieces_for_correspondence]\n",
    "        else:\n",
    "            MAP_pieces_for_correspondence = MAP_branches_with_stitch_point\n",
    "\n",
    "        curr_MAP_meshes_idx = [limb_correspondence_MAP[MAP_idx][k][\"branch_face_idx\"] for k in MAP_pieces_for_correspondence]\n",
    "        \n",
    "        # Have to adjust based on if the skeleton were split\n",
    "        \n",
    "        if cut_flag:\n",
    "            #Then it was cut and have to do mesh correspondence to find what label to cut\n",
    "            if len(curr_MAP_meshes_idx) > 1:\n",
    "                raise Exception(\"MAP_pieces_for_correspondence was longer than 1 and cut flag was set\")\n",
    "            pre_stitch_mesh_idx = curr_MAP_meshes_idx[0]\n",
    "            pre_stitch_mesh = limb_mesh_mparty.submesh([pre_stitch_mesh_idx],append=True,repair=False)\n",
    "            local_correspondnece_stitch = mesh_correspondence_first_pass(mesh=pre_stitch_mesh,\n",
    "                                      skeleton_branches=curr_MAP_sk)\n",
    "            local_correspondence_stitch_revised = correspondence_1_to_1(mesh=pre_stitch_mesh,\n",
    "                                                        local_correspondence=local_correspondnece_stitch,\n",
    "                                                        curr_limb_endpoints_must_keep=None,\n",
    "                                                        curr_soma_to_piece_touching_vertices=None)\n",
    "            \n",
    "            curr_MAP_meshes_idx = [pre_stitch_mesh_idx[local_correspondence_stitch_revised[nn][\"branch_face_idx\"]] for \n",
    "                                           nn in local_correspondence_stitch_revised.keys()]\n",
    "            \n",
    "        \n",
    "        #To make sure that the MAP never gives up ground on the labels\n",
    "        must_keep_labels_MAP = dict()\n",
    "        must_keep_counter = 0\n",
    "        for kk,b_idx in enumerate(curr_MAP_meshes_idx):\n",
    "            #must_keep_labels_MAP.update(dict([(ii,kk) for ii in range(must_keep_counter,must_keep_counter+len(b_idx))]))\n",
    "            must_keep_labels_MAP[kk] = np.arange(must_keep_counter,must_keep_counter+len(b_idx))\n",
    "            must_keep_counter += len(b_idx)\n",
    "        \n",
    "            \n",
    "\n",
    "        #this is where should send only the MP that apply\n",
    "        MP_branches_for_correspondence,conn_idx,MP_branches_with_stitch_point_idx = nu.intersect1d(conn,MP_branches_with_stitch_point,return_indices=True)\n",
    "\n",
    "        curr_MP_meshes_idx = [limb_correspondence_MP[MP_idx][k][\"branch_face_idx\"] for k in MP_branches_for_correspondence]\n",
    "        curr_MP_sk_for_correspondence = [curr_MP_sk[zz] for zz in MP_branches_with_stitch_point_idx]\n",
    "\n",
    "        stitching_mesh_idx = np.concatenate(curr_MAP_meshes_idx + curr_MP_meshes_idx)\n",
    "        stitching_mesh = limb_mesh_mparty.submesh([stitching_mesh_idx],append=True,repair=False)\n",
    "        stitching_skeleton_branches = curr_MAP_sk + curr_MP_sk_for_correspondence\n",
    "        \"\"\"\n",
    "\n",
    "        ****** NEED TO GET THE RIGHT MESH TO RUN HE IDX ON SO GETS A GOOD MESH (CAN'T BE LIMB_MESH_MPARTY)\n",
    "        BUT MUST BE THE ORIGINAL MAP MESH\n",
    "\n",
    "        mesh_pieces_for_MAP\n",
    "        sublimb_meshes_MP\n",
    "\n",
    "        mesh_pieces_for_MAP_face_idx\n",
    "        sublimb_meshes_MP_face_idx\n",
    "\n",
    "        stitching_mesh = tu.combine_meshes(curr_MAP_meshes + curr_MP_meshes)\n",
    "        stitching_skeleton_branches = curr_MAP_sk + curr_MP_sk\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #3) Run mesh correspondence to get new meshes and mesh_idx and widths\n",
    "        local_correspondnece_stitch = mesh_correspondence_first_pass(mesh=stitching_mesh,\n",
    "                                      skeleton_branches=stitching_skeleton_branches)\n",
    "\n",
    "        try:\n",
    "\n",
    "            local_correspondence_stitch_revised = correspondence_1_to_1(mesh=stitching_mesh,\n",
    "                                                        local_correspondence=local_correspondnece_stitch,\n",
    "                                                        curr_limb_endpoints_must_keep=None,\n",
    "                                                        curr_soma_to_piece_touching_vertices=None,\n",
    "                                                        must_keep_labels=must_keep_labels_MAP)\n",
    "        except:\n",
    "            su.compressed_pickle(stitching_skeleton_branches,\"stitching_skeleton_branches\")\n",
    "            su.compressed_pickle(stitching_mesh,\"stitching_mesh\")\n",
    "            su.compressed_pickle(local_correspondnece_stitch,\"local_correspondnece_stitch\")\n",
    "            raise Exception(\"Something went wrong with 1 to 1 correspondence\")\n",
    "\n",
    "\n",
    "        #Need to readjust the mesh correspondence idx\n",
    "        for k,v in local_correspondence_stitch_revised.items():\n",
    "            local_correspondence_stitch_revised[k][\"branch_face_idx\"] = stitching_mesh_idx[local_correspondence_stitch_revised[k][\"branch_face_idx\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # -------------- Part 16: Overwrite old branch entries (and add on one new to MAP if required a split) -------#\n",
    "\n",
    "\n",
    "        #4a) If MAP_stitch_point_on_end_or_branch is False\n",
    "        #- Delete the old MAP branch parts and replace with new MAP ones\n",
    "        if not MAP_stitch_point_on_end_or_branch:\n",
    "            print(\"Deleting branches from dictionary\")\n",
    "            del limb_correspondence_MAP[MAP_idx][MAP_branches_with_stitch_point[0]]\n",
    "            #adding the two new branches created from the stitching\n",
    "            limb_correspondence_MAP[MAP_idx][MAP_branches_with_stitch_point[0]] = local_correspondence_stitch_revised[0]\n",
    "            limb_correspondence_MAP[MAP_idx][np.max(list(limb_correspondence_MAP[MAP_idx].keys()))+1] = local_correspondence_stitch_revised[1]\n",
    "\n",
    "            #have to reorder the keys\n",
    "            #limb_correspondence_MAP[MAP_idx] = dict([(k,limb_correspondence_MAP[MAP_idx][k]) for k in np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))])\n",
    "            limb_correspondence_MAP[MAP_idx] = gu.order_dict_by_keys(limb_correspondence_MAP[MAP_idx])\n",
    "\n",
    "        else: #4b) Revise the meshes,  mesh_idx, and widths of the MAP pieces if weren't broken up\n",
    "            for j,curr_MAP_idx_fixed in enumerate(MAP_pieces_for_correspondence): \n",
    "                limb_correspondence_MAP[MAP_idx][curr_MAP_idx_fixed] = local_correspondence_stitch_revised[j]\n",
    "            #want to update all of the skeletons just in case was altered by keep_MP_stitch_static and not included in correspondence\n",
    "            if keep_MP_stitch_static:\n",
    "                if len(MAP_branches_with_stitch_point) != len(curr_MAP_sk_final):\n",
    "                    raise Exception(\"MAP_branches_with_stitch_point not same size as curr_MAP_sk_final\")\n",
    "                for gg,map_idx_curr in enumerate(MAP_branches_with_stitch_point):\n",
    "                    limb_correspondence_MAP[MAP_idx][map_idx_curr][\"branch_skeleton\"] = curr_MAP_sk_final[gg]\n",
    "            \n",
    "\n",
    "        for j,curr_MP_idx_fixed in enumerate(MP_branches_for_correspondence): #************** right here just need to make only the ones that applied\n",
    "            limb_correspondence_MP[MP_idx][curr_MP_idx_fixed] = local_correspondence_stitch_revised[j+len(curr_MAP_sk)]\n",
    "\n",
    "\n",
    "        #5b) Fixing the branch skeletons that were not included in the correspondence\n",
    "        MP_leftover,MP_leftover_idx = nu.setdiff1d(MP_branches_with_stitch_point,MP_branches_for_correspondence)\n",
    "        print(f\"MP_branches_with_stitch_point= {MP_branches_with_stitch_point}\")\n",
    "        print(f\"MP_branches_for_correspondence = {MP_branches_for_correspondence}\")\n",
    "        print(f\"MP_leftover = {MP_leftover}, MP_leftover_idx = {MP_leftover_idx}\")\n",
    "\n",
    "        for curr_MP_leftover,curr_MP_leftover_idx in zip(MP_leftover,MP_leftover_idx):\n",
    "            limb_correspondence_MP[MP_idx][curr_MP_leftover][\"branch_skeleton\"] = curr_MP_sk[curr_MP_leftover_idx]\n",
    "\n",
    "\n",
    "        print(f\" Finished with {(MP_idx,MAP_idx)} \\n\\n\\n\")\n",
    "        stitch_counter += 1\n",
    "#         if cut_flag:\n",
    "#             raise Exception(\"Cut flag was activated\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"There were not both MAP and MP pieces so skipping the stitch resolving phase\")\n",
    "\n",
    "print(f\"Time for decomp of Limb = {time.time() - curr_limb_time}\")\n",
    "#     # ------------- Saving the MAP and MP Decompositions ---------------- #\n",
    "#     proper_limb_mesh_correspondence_MAP[curr_limb_idx] = limb_correspondence_MAP\n",
    "#     proper_limb_mesh_correspondence_MP[curr_limb_idx] = limb_correspondence_MP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------- Part 17: Grouping the MP and MAP Correspondence into one correspondence dictionary -------#\n",
    "limb_correspondence_individual = dict()\n",
    "counter = 0\n",
    "\n",
    "for sublimb_idx,sublimb_branches in limb_correspondence_MAP.items():\n",
    "    for branch_dict in sublimb_branches.values():\n",
    "        limb_correspondence_individual[counter]= branch_dict\n",
    "        counter += 1\n",
    "for sublimb_idx,sublimb_branches in limb_correspondence_MP.items():\n",
    "    for branch_dict in sublimb_branches.values():\n",
    "        limb_correspondence_individual[counter]= branch_dict\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "#info that may be used for concept networks\n",
    "network_starting_info = dict(\n",
    "            touching_verts_list = limb_to_soma_touching_vertices_list,\n",
    "            endpoints_must_keep = limb_to_endpoints_must_keep_list\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# -------------- Part 18: 11-17 Addition that filters the network starting info into a more clean presentation ------------ #\n",
    "\"\"\"\n",
    "Pseudocode: \n",
    "1) Rearrange the network starting info into a ditionary mapping\n",
    "  soma_idx --> branch_broder_group --> list of dict(touching_vertices,endpoint)\n",
    "  \n",
    "2) iterate through all the somas and border vertex groups\n",
    "a. filter to only those with an endpoint that is on a branch of the skeleton\n",
    "b1: If 1 --> then keep that one\n",
    "b2: If more --> pick the one with the endpoint closest to the average fo the vertex group\n",
    "b3: If 0 --> find the best available soma extending branch endpoint\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Part 1: Rearrange network info\n",
    "\n",
    "\n",
    "t_verts_list_total,enpts_list_total = network_starting_info.values()\n",
    "network_starting_info_revised = dict()\n",
    "for j,(v_list_dict,enpts_list_dict) in enumerate(zip(t_verts_list_total,enpts_list_total)):\n",
    "    #print(f\"---- Working on {j} -----\")\n",
    "#     print(v_list_dict)\n",
    "#     print(enpts_list_dict)\n",
    "    if set(list(v_list_dict.keys())) != set(list(enpts_list_dict)):\n",
    "        raise Exception(\"Soma keys not match for touching vertices and endpoints\")\n",
    "    for sm_idx in v_list_dict.keys():\n",
    "        v_list_soma = v_list_dict[sm_idx]\n",
    "        endpt_soma = enpts_list_dict[sm_idx]\n",
    "        if len(v_list_soma) != len(endpt_soma):\n",
    "            raise Exception(f\"touching vertices list and endpoint list not match size for soma {sm_idx}\")\n",
    "        \n",
    "        all_border_vertex_groups = soma_touching_vertices_dict[sm_idx]\n",
    "        \n",
    "        for v_l,endpt in zip(v_list_soma,endpt_soma):\n",
    "\n",
    "            matching_border_group  = []\n",
    "            for i,curr_border_group in enumerate(all_border_vertex_groups):\n",
    "                if nu.test_matching_vertices_in_lists(curr_border_group,v_l,verbose=True):\n",
    "                    matching_border_group.append(i)\n",
    "\n",
    "            if len(matching_border_group) == 0 or len(matching_border_group)>1:\n",
    "                raise Exception(f\"Matching border groups was not exactly 1: {matching_border_group}\")\n",
    "\n",
    "            winning_border_group = matching_border_group[0]\n",
    "\n",
    "            if sm_idx not in network_starting_info_revised.keys():\n",
    "                network_starting_info_revised[sm_idx] = dict()\n",
    "\n",
    "            if winning_border_group not in network_starting_info_revised[sm_idx].keys():\n",
    "                network_starting_info_revised[sm_idx][winning_border_group] = []\n",
    "            network_starting_info_revised[sm_idx][winning_border_group].append(dict(touching_verts=v_l,endpoint=endpt))\n",
    "\n",
    "            \n",
    "# Part 2 Filter\n",
    "\"\"\"\n",
    "2) iterate through all the somas and border vertex groups\n",
    "a. filter to only those with an endpoint that is on a branch of the skeleton\n",
    "b1: If 1 --> then keep that one\n",
    "b2: If more --> pick the one with the endpoint closest to the average fo the vertex group\n",
    "b3: If 0 --> find the best available soma extending branch endpoint\n",
    "\n",
    "Pseudocode for b3:\n",
    "i) get all meshes that touch the vertex group (and keep the vertices that overlap)\n",
    "--> error if none\n",
    "ii) Get all of the endpoints of all matching branches\n",
    "iii) Filter the endpoints to only those that are degree 1 in the overall skeleton\n",
    "--> if none then just keep all endpoints\n",
    "iv) Find the closest viable endpoint to the mean of the boundary group\n",
    "v) save the overlap vertices and the winning endpoint as a dictionary\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sorted_keys = np.sort(list(limb_correspondence_individual.keys()))\n",
    "curr_branches = [limb_correspondence_individual[k][\"branch_skeleton\"] for k in sorted_keys]\n",
    "curr_meshes = [limb_correspondence_individual[k][\"branch_mesh\"] for k in sorted_keys]\n",
    "\n",
    "network_starting_info_revised_cleaned = dict()\n",
    "for soma_idx in network_starting_info_revised.keys():\n",
    "    network_starting_info_revised_cleaned[soma_idx] = dict()\n",
    "    for bound_g_idx,endpoint_list in network_starting_info_revised[soma_idx].items():\n",
    "        endpoint_list = np.array(endpoint_list)\n",
    "        \n",
    "        filter_on_skeleton_list = []\n",
    "        for zz,endpt_dict in enumerate(endpoint_list):\n",
    "            #a. filter to only those with an endpoint that is on a branch of the skeleton\n",
    "            sk_indices = sk.find_branch_skeleton_with_specific_coordinate(divded_skeleton=curr_branches,\n",
    "                                                                        current_coordinate=endpt_dict[\"endpoint\"])\n",
    "            if len(sk_indices) > 0:\n",
    "                filter_on_skeleton_list.append(zz)\n",
    "                \n",
    "        endpoint_list_filt = endpoint_list[filter_on_skeleton_list]\n",
    "        \n",
    "        \n",
    "        \n",
    "        curr_border_group_coordinates = soma_touching_vertices_dict[soma_idx][bound_g_idx]\n",
    "        boundary_mean = np.mean(curr_border_group_coordinates,axis=0)\n",
    "            \n",
    "        if len(endpoint_list_filt) == 1:\n",
    "            print(\"Only one endpoint after filtering away the endpoints that are not on the skeleton\")\n",
    "            winning_dict = endpoint_list_filt[0]\n",
    "        #b2: If more --> pick the one with the endpoint closest to the average fo the vertex group\n",
    "        elif len(endpoint_list_filt) > 1:\n",
    "            print(f\"MORE THAN one endpoint after filtering away the endpoints that are not on the skeleton: {len(endpoint_list_filt)}\")\n",
    "            viable_endpoints = [endpt_dict[\"endpoint\"] for endpt_dict in endpoint_list_filt]\n",
    "\n",
    "            \n",
    "            distanes_from_mean = np.linalg.norm(viable_endpoints-boundary_mean,axis=1)\n",
    "            winning_endpoint_idx = np.argmin(distanes_from_mean)\n",
    "            winning_dict = endpoint_list_filt[winning_endpoint_idx]\n",
    "            \n",
    "        #if there was no clear winner\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Pseudocode for no viable options:\n",
    "            i) get all meshes that touch the vertex group (and keep the vertices that overlap)\n",
    "            --> error if none\n",
    "            ii) Get all of the endpoints of all matching branches\n",
    "            iii) Filter the endpoints to only those that are degree 1 in the overall skeleton\n",
    "            --> if none then just keep all endpoints\n",
    "            iv) Find the closest viable endpoint to the mean of the boundary group\n",
    "            v) save the overlap vertices and the winning endpoint as a dictionary\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            print(\"Having to find a new branch point\")\n",
    "            #i) get all meshes that touch the vertex group (and keep the vertices that overlap)\n",
    "            mesh_indices_on_border = tu.filter_meshes_by_containing_coordinates(curr_meshes,\n",
    "                                          nullifying_points=curr_border_group_coordinates,\n",
    "                                          filter_away=False,\n",
    "                                          distance_threshold=0,\n",
    "                                          return_indices=True)\n",
    "            if len(mesh_indices_on_border) == 0:\n",
    "                raise Exception(\"There were no meshes that were touching the boundary group\")\n",
    "\n",
    "            total_skeleton_graph = sk.convert_skeleton_to_graph(sk.stack_skeletons(curr_branches))\n",
    "            skeleton_branches_on_border = [k for n,k in enumerate(curr_branches) if n in mesh_indices_on_border]\n",
    "            skeleton_branches_on_border_endpoints = np.array([sk.find_branch_endpoints(k) for k in skeleton_branches_on_border])\n",
    "\n",
    "\n",
    "\n",
    "            viable_endpoints = []\n",
    "            for enpt in skeleton_branches_on_border_endpoints.reshape(-1,3):\n",
    "                curr_enpt_node = xu.get_graph_node_by_coordinate(total_skeleton_graph,enpt,return_single_value=True)\n",
    "                curr_enpt_degree = xu.get_node_degree(total_skeleton_graph,curr_enpt_node)\n",
    "                #print(f\"curr_enpt_degree = {curr_enpt_degree}\")\n",
    "                if curr_enpt_degree == 1:\n",
    "                    viable_endpoints.append(enpt)\n",
    "\n",
    "            if len(viable_endpoints) == 0:\n",
    "                print(\"No branch endpoints were degree 1 so just using all endpoints\")\n",
    "                viable_endpoints = skeleton_branches_on_border_endpoints.reshape(-1,3)\n",
    "\n",
    "            distanes_from_mean = np.linalg.norm(viable_endpoints-boundary_mean,axis=1)\n",
    "            winning_endpoint = viable_endpoints[np.argmin(distanes_from_mean)]\n",
    "\n",
    "\n",
    "            sk_indices = sk.find_branch_skeleton_with_specific_coordinate(divded_skeleton=curr_branches,\n",
    "                                                                                    current_coordinate=winning_endpoint)\n",
    "\n",
    "            winning_branch = np.intersect1d(mesh_indices_on_border,sk_indices)\n",
    "            if len(winning_branch) == 0:\n",
    "                raise Exception(\"There was no winning branch for the creation of a new soma extending branch\")\n",
    "            else:\n",
    "                winning_branch_single = winning_branch[0]\n",
    "\n",
    "\n",
    "            winning_touching_vertices = tu.filter_vertices_by_mesh(curr_meshes[winning_branch_single],curr_border_group_coordinates)\n",
    "            winning_dict = dict(touching_verts=winning_touching_vertices,endpoint=winning_endpoint)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        network_starting_info_revised_cleaned[soma_idx][bound_g_idx] = winning_dict\n",
    "\n",
    "        \n",
    "# -------------- Part 18: End ------------ #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not return_concept_network:\n",
    "    if return_concept_network_starting_info: #because may want to calculate the concept networks later\n",
    "        return_value= limb_correspondence_individual,network_starting_info_revised_cleaned\n",
    "    else:\n",
    "        return_value= limb_correspondence_individual\n",
    "else:\n",
    "    limb_to_soma_concept_networks = calculate_limb_concept_networks(limb_correspondence_individual,\n",
    "                                                                    network_starting_info_revised_cleaned,\n",
    "                                                                    run_concept_network_checks=run_concept_network_checks,\n",
    "                                                                \n",
    "                                                                   )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return_value = limb_correspondence_individual,limb_to_soma_concept_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_starting_info_revised_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_starting_info_revised_cleaned[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skeleton_utilsils as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ii) Get all of the endpoints of all matching branches\n",
    "iii) Filter the endpoints to only those that are degree 1 in the overall skeleton\n",
    "--> if none then just keep all endpoints\n",
    "iv) Find the closest viable endpoint to the mean of the boundary group\n",
    "v) save the overlap vertices and the winning endpoint as a dictionary\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#find the branch that had the winning endpoint and the connecting vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_branches_on_border_endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "mesh_indices_on_border\n",
    "\n",
    "total_skeleton = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
