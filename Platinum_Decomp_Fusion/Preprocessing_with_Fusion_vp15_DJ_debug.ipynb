{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To make sure the fusion decomposition works\n",
    "up to the part where we would stitch the sublimbs together into one limb\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Need to pip install annotationframeworkclient to repair mesh with pychunkedgraph\n",
      "WARNING:root:Need to pip install annotationframeworkclient to use dataset_name parameters\n"
     ]
    }
   ],
   "source": [
    "import skeleton_utils as sk\n",
    "import soma_extraction_utils as sm\n",
    "import trimesh_utils as tu\n",
    "import trimesh\n",
    "import numpy_utils as nu\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import networkx as nx\n",
    "import time\n",
    "import compartment_utils as cu\n",
    "import networkx_utils as xu\n",
    "import matplotlib_utils as mu\n",
    "import neuron_utils as nru\n",
    "\n",
    "#importing at the bottom so don't get any conflicts\n",
    "import itertools\n",
    "from tqdm_utils import tqdm\n",
    "\n",
    "#for meshparty preprocessing\n",
    "import meshparty_skeletonize as m_sk\n",
    "import general_utils as gu\n",
    "import compartment_utils as cu\n",
    "from meshparty import trimesh_io\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from neuron_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datajoint.settings:Setting database.host to at-database.ad.bcm.edu\n",
      "INFO:datajoint.settings:Setting database.user to celiib\n",
      "INFO:datajoint.settings:Setting database.password to newceliipass\n",
      "INFO:datajoint.settings:Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO:datajoint.settings:Setting enable_python_native_blobs to True\n",
      "INFO:datajoint.settings:Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    }
   ],
   "source": [
    "import datajoint_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_segment_id = 864691135608655300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7638b0fc3a454dda8f423ec46100fee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segment_id = 864691135608655300\n",
    "\n",
    "print(f\"curr_segment_id = {segment_id}\")\n",
    "current_neuron = du.fetch_segment_id_mesh(segment_id)\n",
    "nviz.plot_objects(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"pasta_mess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "somas = du.get_soma_mesh_list(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<trimesh.Trimesh(vertices.shape=(1018, 3), faces.shape=(2000, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(736, 3), faces.shape=(1568, 3))>],\n",
       " [166.9132, 166.9132],\n",
       " [0.328, 0.657]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import trimesh_utils as tu\n",
    "# curent_neuron = tu.load_mesh_no_processing(\"/notebooks/test_neurons/Segmentation_2/864691135738362516_thin_long_down_axon.off\")\n",
    "# segment_id = 864691135738362516\n",
    "# description = \"thin_long_down_axon\"\n",
    "\n",
    "# import neuron_visualizations as nviz\n",
    "# nviz.plot_objects(main_mesh=curent_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Arguments that would be present inside a preprocessing function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predefined arguments for the Neuron constructor\n",
    "\n",
    "decomposition_type=\"meshafterparty\"\n",
    "mesh_correspondence=\"meshparty\" #meshafterparty_adaptive\n",
    "distance_by_mesh_center=True #how the distance is calculated for mesh correspondence\n",
    "meshparty_segment_size = 100\n",
    "meshparty_n_surface_downsampling = 2\n",
    "meshparty_adaptive_correspondence_after_creation=False\n",
    "suppress_preprocessing_print=True\n",
    "computed_attribute_dict=None\n",
    "#somas = None\n",
    "branch_skeleton_data=None\n",
    "combine_close_skeleton_nodes = True\n",
    "combine_close_skeleton_nodes_threshold=700\n",
    "ignore_warnings=True\n",
    "suppress_output=False\n",
    "calculate_spines=True\n",
    "widths_to_calculate=[\"no_spine_median_mesh_center\"]\n",
    "fill_hole_size=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments for the preprocess neuron\n",
    "mesh = current_neuron\n",
    "segment_id=segment_id\n",
    "description=description\n",
    "\n",
    "sig_th_initial_split=15 #for significant splitting meshes in the intial mesh split\n",
    "limb_threshold = 2000 #the mesh faces threshold for a mesh to be qualified as a limb (otherwise too small)\n",
    "filter_end_node_length=4001 #used in cleaning the skeleton during skeletonizations\n",
    "return_no_somas = False\n",
    "\n",
    "decomposition_type=decomposition_type\n",
    "mesh_correspondence=mesh_correspondence\n",
    "distance_by_mesh_center=distance_by_mesh_center\n",
    "meshparty_segment_size =meshparty_segment_size\n",
    "meshparty_n_surface_downsampling = meshparty_n_surface_downsampling\n",
    "somas=somas\n",
    "branch_skeleton_data=branch_skeleton_data\n",
    "combine_close_skeleton_nodes = combine_close_skeleton_nodes\n",
    "combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the soma finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from soma_extraction_utils import *\n",
    "\n",
    "# current_mesh_verts=current_neuron.vertices\n",
    "# current_mesh_faces=current_neuron.faces\n",
    "# outer_decimation_ratio= 0.25\n",
    "# large_mesh_threshold = 60000\n",
    "# large_mesh_threshold_inner = 40000\n",
    "# soma_width_threshold = 0.32\n",
    "# soma_size_threshold = 15000\n",
    "# inner_decimation_ratio = 0.25\n",
    "# volume_mulitplier=9# old 8\n",
    "# #side_length_ratio_threshold=3,\n",
    "# side_length_ratio_threshold=9\n",
    "# soma_size_threshold_max=192000 #this puts at 12000 once decimated\n",
    "# delete_files=True\n",
    "# backtrack_soma_mesh_to_original=True #should either be None or \n",
    "# boundary_vertices_threshold=None#700 the previous threshold used\n",
    "# poisson_backtrack_distance_threshold=None#1500 the previous threshold used\n",
    "# close_holes=False\n",
    "\n",
    "# global_start_time = time.time()\n",
    "\n",
    "# #Adjusting the thresholds based on the decimations\n",
    "# large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "# large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "# soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "# soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "\n",
    "# #adjusting for inner decimation\n",
    "# soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "# soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "# print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "#              f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "#               f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "#              f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "#              f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "#              f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\")\n",
    "\n",
    "\n",
    "# # ------------------------------\n",
    "\n",
    "\n",
    "# temp_folder = f\"./{segment_id}\"\n",
    "# temp_object = Path(temp_folder)\n",
    "# #make the temp folder if it doesn't exist\n",
    "# temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "# #making the decimation and poisson objections\n",
    "# Dec_outer = Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "# Dec_inner = Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "# Poisson_obj = Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "# #Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "# new_mesh,output_obj = Dec_outer(vertices=current_mesh_verts,\n",
    "#          faces=current_mesh_faces,\n",
    "#          segment_id=segment_id,\n",
    "#          return_mesh=True,\n",
    "#          delete_temp_files=False)\n",
    "\n",
    "# #preforming the splits of the decimated mesh\n",
    "\n",
    "# mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "# #get the largest mesh\n",
    "# mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "# total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "# ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "# list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "# print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "# #if no significant pieces were found then will use smaller threshold\n",
    "# if len(list_of_largest_mesh)<=0:\n",
    "#     print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "#     list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "# total_soma_list = []\n",
    "# total_classifier_list = []\n",
    "# total_poisson_list = []\n",
    "# total_soma_list_sdf = []\n",
    "\n",
    "# #start iterating through where go through all pieces before the poisson reconstruction\n",
    "# no_somas_found_in_big_loop = 0\n",
    "# for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "#     print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "#     somas_found_in_big_loop = False\n",
    "\n",
    "#     largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "#     pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "#     pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "#     print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "#     # ******* This ERRORED AND CALLED OUR NERUON NONE: 77697401493989254 *********\n",
    "#     new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "#                faces=largest_mesh.faces,\n",
    "#                return_mesh=True,\n",
    "#                mesh_filename=largest_file_name,\n",
    "#                delete_temp_files=False)\n",
    "\n",
    "\n",
    "#     #splitting the Poisson into the largest pieces and ordering them\n",
    "#     mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "#     total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "#     ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "#     list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "#     print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "#     n_failed_inner_soma_loops = 0\n",
    "#     for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "#         print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "#         largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "#         #Decimate the inner poisson piece\n",
    "#         largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "#                             vertices=largest_mesh_inner.vertices,\n",
    "#                              faces=largest_mesh_inner.faces,\n",
    "#                             mesh_filename=largest_mesh_path_inner,\n",
    "#                              return_mesh=True,\n",
    "#                              delete_temp_files=False)\n",
    "\n",
    "#         print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "#         faces = np.array(largest_mesh_path_inner_decimated.faces)\n",
    "#         verts = np.array(largest_mesh_path_inner_decimated.vertices)\n",
    "\n",
    "#         segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "\n",
    "#         verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "#                                 import_Off_Flag=False,\n",
    "#                                 segment_id=segment_id_new,\n",
    "#                                 vertices=verts,\n",
    "#                                  triangles=faces,\n",
    "#                                 pymeshfix_Flag=False,\n",
    "#                                  import_CGAL_Flag=False,\n",
    "#                                  return_Only_Labels=True,\n",
    "#                                  clusters=3,\n",
    "#                                  smoothness=0.2,\n",
    "#                                 soma_only=True,\n",
    "#                                 return_classifier = True\n",
    "#                                 )\n",
    "#         print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "#         total_classifier_list.append(classifier)\n",
    "#         #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "#         # Save all of the portions that resemble a soma\n",
    "#         median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "#         segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "#         #order the compartments by greatest to smallest\n",
    "#         sorted_medians = np.flip(np.argsort(median_values))\n",
    "#         print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "#         print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "\n",
    "#         valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "#                                                             and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "#                                                             and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "#         valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "#                                                             and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "#                                                             and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "#         print(\"valid_soma_segments_width\")\n",
    "#         to_add_list = []\n",
    "#         to_add_list_sdf = []\n",
    "#         if len(valid_soma_segments_width) > 0:\n",
    "#             print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "#             somas_found_in_big_loop = True\n",
    "#             #get the meshes only if signfiicant length\n",
    "#             labels_list = classifier.labels_list\n",
    "\n",
    "#             for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "#                 submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "#                 soma_mesh = largest_mesh_path_inner_decimated.submesh([submesh_face_list],append=True)\n",
    "\n",
    "#                 # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "#                 curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "#                 curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "#                 if curr_side_len_check and curr_volume_check:\n",
    "#                     to_add_list.append(soma_mesh)\n",
    "#                     to_add_list_sdf.append(sdf)\n",
    "\n",
    "#                 else:\n",
    "#                     print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "#                          f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "#                     continue\n",
    "\n",
    "#             n_failed_inner_soma_loops = 0\n",
    "\n",
    "#         else:\n",
    "#             n_failed_inner_soma_loops += 1\n",
    "\n",
    "#         total_soma_list_sdf += to_add_list_sdf\n",
    "#         total_soma_list += to_add_list\n",
    "\n",
    "#         # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "#         if n_failed_inner_soma_loops >= 2:\n",
    "#             print(\"breaking inner loop because 2 soma fails in a row\")\n",
    "#             break\n",
    "\n",
    "\n",
    "#     # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "#     if somas_found_in_big_loop == False:\n",
    "#         no_somas_found_in_big_loop += 1\n",
    "#         if no_somas_found_in_big_loop >= 2:\n",
    "#             print(\"breaking because 2 fails in a row in big loop\")\n",
    "#             break\n",
    "\n",
    "#     else:\n",
    "#         no_somas_found_in_big_loop = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "# pairings = []\n",
    "# for y,soma_1 in enumerate(total_soma_list):\n",
    "#     for z,soma_2 in enumerate(total_soma_list):\n",
    "#         if y<z:\n",
    "#             mesh_tree = KDTree(soma_1.vertices)\n",
    "#             distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "#             if np.min(distances) < 4000:\n",
    "#                 pairings.append([y,z])\n",
    "\n",
    "\n",
    "# #creating the combined meshes from the list\n",
    "# total_soma_list_revised = []\n",
    "# total_soma_list_revised_sdf = []\n",
    "# if len(pairings) > 0:\n",
    "#     \"\"\"\n",
    "#     Pseudocode: \n",
    "#     Use a network function to find components\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "#     import networkx as nx\n",
    "#     new_graph = nx.Graph()\n",
    "#     new_graph.add_edges_from(pairings)\n",
    "#     grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "#     somas_being_combined = []\n",
    "#     print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "#     for comp in grouped_somas:\n",
    "#         comp = list(comp)\n",
    "#         somas_being_combined += list(comp)\n",
    "#         current_mesh = total_soma_list[comp[0]]\n",
    "#         for i in range(1,len(comp)):\n",
    "#             current_mesh += total_soma_list[comp[i]]\n",
    "\n",
    "#         total_soma_list_revised.append(current_mesh)\n",
    "#         #where can average all of the sdf values\n",
    "#         total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "#     #add those that weren't combined to total_soma_list_revised\n",
    "#     leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "#     leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "#     if len(leftover_somas) > 0:\n",
    "#         total_soma_list_revised += leftover_somas\n",
    "#         total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "#     print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "#     print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "# if len(total_soma_list_revised) == 0:\n",
    "#     total_soma_list_revised = total_soma_list\n",
    "#     total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "# run_time = time.time() - global_start_time\n",
    "\n",
    "# print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "# print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "# #     import system_utils as su\n",
    "# #     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "# #     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "# #need to erase all of the temporary files ******\n",
    "# #import shutil\n",
    "# #shutil.rmtree(directory)\n",
    "\n",
    "# \"\"\"\n",
    "# Running the extra tests that depend on\n",
    "# - border vertices\n",
    "# - how well the poisson matches the backtracked soma to the real mesh\n",
    "# - other size checks\n",
    "\n",
    "# \"\"\"\n",
    "# filtered_soma_list = []\n",
    "# filtered_soma_list_sdf = []\n",
    "# for soma_mesh,curr_soma_sdf in zip(total_soma_list_revised,total_soma_list_revised_sdf):\n",
    "#     if backtrack_soma_mesh_to_original:\n",
    "#         print(\"Performing Soma Mesh Backtracking to original mesh\")\n",
    "#         soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "#         try:\n",
    "#             #print(\"About to find original mesh\")\n",
    "#             soma_mesh = original_mesh_soma(\n",
    "#                                             mesh = new_mesh,\n",
    "#                                             soma_meshes=[soma_mesh_poisson],\n",
    "#                                             sig_th_initial_split=15)[0]\n",
    "#         except:\n",
    "#             import traceback\n",
    "#             traceback.print_exc()\n",
    "#             print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "#             continue\n",
    "#         else:\n",
    "#             if soma_mesh is None:\n",
    "#                 print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "#                 continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "#         #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "#         if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "#             #soma_mesh.export(\"soma_mesh.off\")\n",
    "#             if close_holes: \n",
    "#                 print(\"Using the close holes feature\")\n",
    "#                 fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "#                                                  self_itersect_faces=False)\n",
    "\n",
    "#                 soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "#                                                     vertices=soma_mesh.vertices,\n",
    "#                                                      faces=soma_mesh.faces,\n",
    "#                                                      return_mesh=True,\n",
    "#                                                      delete_temp_files=True,\n",
    "#                                                     )\n",
    "#             else:\n",
    "#                 soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "#             #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "#             print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "#             mesh_1 = soma_mesh_filled_holes\n",
    "#             mesh_2 = soma_mesh_poisson\n",
    "\n",
    "#             poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "#                                                               verbose=True)\n",
    "#             print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "#             if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "#                 print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "#                   f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "#                 continue\n",
    "\n",
    "\n",
    "#     #do the boundary check:\n",
    "#     if not boundary_vertices_threshold is None:\n",
    "#         print(\"USING boundary_vertices_threshold CHECK\")\n",
    "#         soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "#         print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "#         large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "#         print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "#         if len(large_boundary_groups)>0:\n",
    "#             print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "#                   f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "#             continue\n",
    "\n",
    "#     curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "#     curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "#     if (not curr_side_len_check) or (not curr_volume_check):\n",
    "#         print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "#              f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "#         continue\n",
    "\n",
    "#     #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "#     #If made it through all the checks then add to final list\n",
    "#     filtered_soma_list.append(soma_mesh)\n",
    "#     filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# Need to delete all files in the temp folder *****\n",
    "# \"\"\"\n",
    "\n",
    "# if delete_files:\n",
    "#     #now erase all of the files used\n",
    "#     from shutil import rmtree\n",
    "\n",
    "#     #remove the directory with the meshes\n",
    "#     rmtree(str(temp_object.absolute()))\n",
    "\n",
    "#     #removing the temporary files\n",
    "#     temp_folder = Path(\"./temp\")\n",
    "#     temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "#     seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "#     for f in seg_temp_files:\n",
    "#         f.unlink()\n",
    "\n",
    "# #return total_soma_list, run_time\n",
    "# #return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "# return_value = filtered_soma_list,run_time,filtered_soma_list_sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neuron_visualizations as nviz\n",
    "# nviz.plot_objects(meshes=total_soma_list,\n",
    "#                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh was not none\n"
     ]
    }
   ],
   "source": [
    "whole_processing_tiempo = time.time()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: To process the mesh into a format that can be loaded into the neuron class\n",
    "and used for higher order processing (how to visualize is included)\n",
    "\n",
    "\"\"\"\n",
    "if description is None:\n",
    "    description = \"no_description\"\n",
    "if segment_id is None:\n",
    "    #pick a random segment id\n",
    "    segment_id = np.random.randint(100000000)\n",
    "    print(f\"picking a random 7 digit segment id: {segment_id}\")\n",
    "    description += \"_random_id\"\n",
    "\n",
    "\n",
    "if mesh is None:\n",
    "    if current_mesh_file is None:\n",
    "        raise Exception(\"No mesh or mesh_file file were given\")\n",
    "    else:\n",
    "        current_neuron = trimesh.load_mesh(current_mesh_file)\n",
    "else:\n",
    "    print(\"Mesh was not none\")\n",
    "    current_neuron = mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ************************ Phase A: Soma and Limb Identification ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed somas\n",
      "Soma List = [<trimesh.Trimesh(vertices.shape=(1018, 3), faces.shape=(2000, 3))>, <trimesh.Trimesh(vertices.shape=(736, 3), faces.shape=(1568, 3))>]\n",
      "soma_mesh_list_centers = [array([1160020.14047151, 1105483.63064833,  945249.58644401]), array([1081755.27581522, 1104010.67663043,  939945.94605978])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6aa25575214c5f95a7cd3af5dfddfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1) Doing the soma detection\n",
    "if somas is None:\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                             current_neuron.vertices,\n",
    "                                             current_neuron.faces)\n",
    "else:\n",
    "    print(\"Using preprocessed somas\")\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = somas\n",
    "\n",
    "# geting the soma centers\n",
    "if len(soma_mesh_list) <= 0:\n",
    "    print(f\"**** No Somas Found for Mesh {segment_id} so just one mesh\")\n",
    "    soma_mesh_list_centers = []\n",
    "    if return_no_somas:\n",
    "        return_value= soma_mesh_list_centers\n",
    "    raise Exception(\"Processing of No Somas is not yet implemented yet\")\n",
    "else:\n",
    "    #compute the soma centers\n",
    "    print(f\"Soma List = {soma_mesh_list}\")\n",
    "\n",
    "    soma_mesh_list_centers = sm.find_soma_centroids(soma_mesh_list)\n",
    "    print(f\"soma_mesh_list_centers = {soma_mesh_list_centers}\")\n",
    "    \n",
    "nviz.plot_objects(meshes=soma_mesh_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 16\n",
      "There were 15 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "#--- 2) getting the soma submeshes that are connected to each soma and identifiying those that aren't (and eliminating any mesh pieces inside the soma)\n",
    "\n",
    "main_mesh_total = current_neuron\n",
    "\n",
    "\n",
    "#finding the mesh pieces that contain the soma\n",
    "#splitting the current neuron into distinct pieces\n",
    "split_meshes = tu.split_significant_pieces(\n",
    "                            main_mesh_total,\n",
    "                            significance_threshold=sig_th_initial_split,\n",
    "                            print_flag=False)\n",
    "\n",
    "print(f\"# total split meshes = {len(split_meshes)}\")\n",
    "\n",
    "\n",
    "#returns the index of the split_meshes index that contains each soma    \n",
    "containing_mesh_indices = sm.find_soma_centroid_containing_meshes(soma_mesh_list,\n",
    "                                        split_meshes)\n",
    "\n",
    "# filtering away any of the inside floating pieces: \n",
    "non_soma_touching_meshes = [m for i,m in enumerate(split_meshes)\n",
    "                 if i not in list(containing_mesh_indices.values())]\n",
    "\n",
    "\n",
    "#Adding the step that will filter away any pieces that are inside the soma\n",
    "if len(non_soma_touching_meshes) > 0 and len(soma_mesh_list) > 0:\n",
    "    \"\"\"\n",
    "    *** want to save these pieces that are inside of the soma***\n",
    "    \"\"\"\n",
    "\n",
    "    non_soma_touching_meshes,inside_pieces = sm.filter_away_inside_soma_pieces(soma_mesh_list,non_soma_touching_meshes,\n",
    "                                    significance_threshold=sig_th_initial_split,\n",
    "                                    return_inside_pieces = True)                                                      \n",
    "\n",
    "\n",
    "split_meshes # the meshes of the original mesh\n",
    "containing_mesh_indices #the mapping of each soma centroid to the correct split mesh\n",
    "soma_containing_meshes = sm.grouping_containing_mesh_indices(containing_mesh_indices)\n",
    "\n",
    "soma_touching_meshes = [split_meshes[k] for k in soma_containing_meshes.keys()]\n",
    "\n",
    "\n",
    "#     print(f\"# of non soma touching seperate meshes = {len(non_soma_touching_meshes)}\")\n",
    "#     print(f\"# of inside pieces = {len(inside_pieces)}\")\n",
    "print(f\"# of soma containing seperate meshes = {len(soma_touching_meshes)}\")\n",
    "print(f\"meshes with somas = {soma_containing_meshes}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(432930, 3), faces.shape=(880335, 3))>, <trimesh.Trimesh(vertices.shape=(2083, 3), faces.shape=(4224, 3))>, <trimesh.Trimesh(vertices.shape=(974, 3), faces.shape=(1892, 3))>, <trimesh.Trimesh(vertices.shape=(841, 3), faces.shape=(1660, 3))>]\n",
      "There were 4 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(432930, 3), faces.shape=(880335, 3))>, <trimesh.Trimesh(vertices.shape=(2083, 3), faces.shape=(4224, 3))>, <trimesh.Trimesh(vertices.shape=(974, 3), faces.shape=(1892, 3))>, <trimesh.Trimesh(vertices.shape=(841, 3), faces.shape=(1660, 3))>]\n",
      "Total Time for soma mesh cancellation = 2.123\n",
      "Total time for Subtract Soam = 2.1237804889678955\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.8244259357452393\n",
      "Total time for Original_mesh_faces_map for somas= 0.5394818782806396\n",
      "Total time for sig_non_soma_pieces= 1.2351374626159668\n",
      "Total time for split= 0.030780792236328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for mesh_pieces_connectivity= 12.119032859802246\n",
      "# of insignificant_limbs = 2 with trimesh : [<trimesh.Trimesh(vertices.shape=(974, 3), faces.shape=(1892, 3))>, <trimesh.Trimesh(vertices.shape=(841, 3), faces.shape=(1660, 3))>]\n"
     ]
    }
   ],
   "source": [
    "tu = reload(tu)\n",
    "#--- 3)  Soma Extraction was great (but it wasn't the original soma faces), so now need to get the original soma faces and the original non-soma faces of original pieces\n",
    "\n",
    "#     sk.graph_skeleton_and_mesh(other_meshes=[soma_meshes])\n",
    "\n",
    "\"\"\"\n",
    "for each soma touching mesh get the following:\n",
    "1) original soma meshes\n",
    "2) significant mesh pieces touching these somas\n",
    "3) The soma connectivity to each of the significant mesh pieces\n",
    "-- later will just translate the \n",
    "\n",
    "\n",
    "Process: \n",
    "\n",
    "1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "2) Subtact all soma faces from original mesh\n",
    "3) Find all significant mesh pieces\n",
    "4) Backtrack significant mesh pieces to orignal mesh and find connectivity of each to all\n",
    "   the available somas\n",
    "Conclusion: Will have connectivity map\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "soma_touching_mesh_data = dict()\n",
    "\n",
    "for z,(mesh_idx, soma_idxes) in enumerate(soma_containing_meshes.items()):\n",
    "    soma_touching_mesh_data[z] = dict()\n",
    "    print(f\"\\n\\n----Working on soma-containing mesh piece {z}----\")\n",
    "\n",
    "    #1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "    current_mesh = split_meshes[mesh_idx]\n",
    "\n",
    "    current_soma_mesh_list = [soma_mesh_list[k] for k in soma_idxes]\n",
    "\n",
    "    current_time = time.time()\n",
    "    mesh_pieces_without_soma = sm.subtract_soma(current_soma_mesh_list,current_mesh,\n",
    "                                                significance_threshold=250)\n",
    "    print(f\"Total time for Subtract Soam = {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    mesh_pieces_without_soma_stacked = tu.combine_meshes(mesh_pieces_without_soma)\n",
    "\n",
    "    # find the original soma faces of mesh\n",
    "    soma_faces = tu.original_mesh_faces_map(current_mesh,mesh_pieces_without_soma_stacked,matching=False)\n",
    "    print(f\"Total time for Original_mesh_faces_map for mesh_pieces without soma= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "    soma_meshes = current_mesh.submesh([soma_faces],append=True,repair=False)\n",
    "\n",
    "    # finding the non-soma original faces\n",
    "    non_soma_faces = tu.original_mesh_faces_map(current_mesh,soma_meshes,matching=False)\n",
    "    non_soma_stacked_mesh = current_mesh.submesh([non_soma_faces],append=True,repair=False)\n",
    "\n",
    "    print(f\"Total time for Original_mesh_faces_map for somas= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    # 3) Find all significant mesh pieces\n",
    "    sig_non_soma_pieces,insignificant_limbs = tu.split_significant_pieces(non_soma_stacked_mesh,significance_threshold=limb_threshold,\n",
    "                                                     return_insignificant_pieces=True)\n",
    "\n",
    "    print(f\"Total time for sig_non_soma_pieces= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    soma_touching_mesh_data[z][\"branch_meshes\"] = sig_non_soma_pieces\n",
    "\n",
    "    #4) Backtrack significant mesh pieces to orignal mesh and find connectivity of each to all the available somas\n",
    "    # get all the seperate mesh faces\n",
    "\n",
    "    #How to seperate the mesh faces\n",
    "    seperate_soma_meshes,soma_face_components = tu.split(soma_meshes,only_watertight=False)\n",
    "    #take the top largest ones depending how many were originally in the soma list\n",
    "    seperate_soma_meshes = seperate_soma_meshes[:len(soma_mesh_list)]\n",
    "    soma_face_components = soma_face_components[:len(soma_mesh_list)]\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_meshes\"] = seperate_soma_meshes\n",
    "\n",
    "    print(f\"Total time for split= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    soma_to_piece_connectivity = dict()\n",
    "    soma_to_piece_touching_vertices = dict()\n",
    "    soma_to_piece_touching_vertices_idx = dict()\n",
    "    limb_root_nodes = dict()\n",
    "    \n",
    "    m_vert_graph = tu.mesh_vertex_graph(current_mesh)\n",
    "    \n",
    "    for i,curr_soma in enumerate(seperate_soma_meshes):\n",
    "        (connected_mesh_pieces,\n",
    "         connected_mesh_pieces_vertices,\n",
    "         connected_mesh_pieces_vertices_idx) = tu.mesh_pieces_connectivity(\n",
    "                        main_mesh=current_mesh,\n",
    "                        central_piece=curr_soma,\n",
    "                        periphery_pieces = sig_non_soma_pieces,\n",
    "                        return_vertices = True,\n",
    "                        return_vertices_idx=True)\n",
    "        #print(f\"soma {i}: connected_mesh_pieces = {connected_mesh_pieces}\")\n",
    "        soma_to_piece_connectivity[i] = connected_mesh_pieces\n",
    "\n",
    "        soma_to_piece_touching_vertices[i] = dict()\n",
    "        for piece_index,piece_idx in enumerate(connected_mesh_pieces):\n",
    "            limb_root_nodes[piece_idx] = connected_mesh_pieces_vertices[piece_index][0]\n",
    "            \n",
    "            \"\"\" Old way of finding vertex connected components on a mesh without trimesh function\n",
    "            #find the number of touching groups and save those \n",
    "            soma_touching_graph = m_vert_graph.subgraph(connected_mesh_pieces_vertices_idx[piece_index])\n",
    "            soma_con_comp = [current_mesh.vertices[np.array(list(k)).astype(\"int\")] for k in list(nx.connected_components(soma_touching_graph))]\n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = soma_con_comp\n",
    "            \"\"\"\n",
    "            \n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = tu.split_vertex_list_into_connected_components(\n",
    "                                                vertex_indices_list=connected_mesh_pieces_vertices_idx[piece_index],\n",
    "                                                mesh=current_mesh, \n",
    "                                                vertex_graph=m_vert_graph, \n",
    "                                                return_coordinates=True\n",
    "                                               )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#         border_debug = False\n",
    "#         if border_debug:\n",
    "#             print(f\"soma_to_piece_connectivity = {soma_to_piece_connectivity}\")\n",
    "#             print(f\"soma_to_piece_touching_vertices = {soma_to_piece_touching_vertices}\")\n",
    "\n",
    "\n",
    "    print(f\"Total time for mesh_pieces_connectivity= {time.time() - current_time}\")\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_to_piece_connectivity\"] = soma_to_piece_connectivity\n",
    "\n",
    "print(f\"# of insignificant_limbs = {len(insignificant_limbs)} with trimesh : {insignificant_limbs}\")\n",
    "\n",
    "\n",
    "\n",
    "# Lets have an alert if there was more than one soma disconnected meshes\n",
    "if len(soma_touching_mesh_data.keys()) > 1:\n",
    "    raise Exception(\"More than 1 disconnected meshes that contain somas\")\n",
    "\n",
    "current_mesh_data = soma_touching_mesh_data\n",
    "soma_containing_idx = 0\n",
    "\n",
    "#doing inversion of the connectivity and touching vertices\n",
    "piece_to_soma_touching_vertices = gu.flip_key_orders_for_dict(soma_to_piece_touching_vertices)\n",
    "\n",
    "\n",
    "# ****Soma Touching mesh Data has the branches and the connectivity (So this is where you end up skipping if you don't have somas)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_touching_vertices_dict = piece_to_soma_touching_vertices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac48965ac7324397bcf1c7195f13bd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=soma_meshes,\n",
    "                  scatters=[np.vstack(k) for k in soma_touching_vertices_dict.values()],\n",
    "                 scatters_colors=[\"red\",\"blue\"],\n",
    "                 scatter_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process that will start for each limb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Limb Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for preparing soma vertices and root: 0.0001304149627685547\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21285c4b462344808ddc9e99676e7c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=432929.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:19<00:00, 79.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1st pass MP skeletonization: 84.08281826972961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:895: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:933: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting at the root\n",
      "branches_touching_root = [531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:965: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 42779\n",
      "Working on path [2344. 2355. 2364. 2376. 2387. 2400. 2410. 2417.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [5447. 5452. 5455.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [9466. 9501. 9503.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [42781.  9542.  9580.  9621.  9662.  9698.  9738.  9750.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [12225. 12250. 12265.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [14594. 14627. 14644.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [15332. 15364. 15386.]\n",
      "path_degrees = [3, 2, 3]\n",
      "Working on path [15636. 15664. 15689. 15714. 15740.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [16565. 16607. 16644. 16718. 16770. 16833. 16882.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [16665. 16727. 16750. 16796. 16829. 16859.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [19630. 19659. 19687. 19724. 19737.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [19653. 19669. 19681. 19693. 19711. 19721. 19729. 42789.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 4]\n",
      "Working on path [20483. 20540. 20599. 20651. 20690.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [22542. 22557. 22572. 22590. 22610. 22633. 22640.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [22827. 22872. 22914. 22927.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [42793. 22982. 23035. 23089. 23150. 23168.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 3]\n",
      "Working on path [23355. 23394. 23433. 23462.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [24857. 24905. 24944. 24965.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [26822. 26859. 26898. 26919.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [27543. 27548. 27555. 27559. 27558. 27557.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [27856. 27874. 27894. 27922. 27957. 27985. 28015. 28052.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [28303. 28347. 28395. 28441. 28452.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [28571. 28621. 28673. 28711. 28753. 28763.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [28603. 28656. 28701. 28740. 28785. 28827. 28872. 28904.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [29152. 29165.]\n",
      "path_degrees = [3, 3]\n",
      "Working on path [32310. 32315. 32323. 32332. 32345. 32346.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [33028. 33067. 33105. 33135.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [33732. 33760. 33791. 33793.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [34212. 34231. 34249. 34267. 34284. 34297. 34314. 34320.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [42807. 34240. 34264. 34289. 34317. 34334. 34351.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [35026. 35049. 35067. 35091. 35113. 35120.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [38137. 38138. 38140. 38141.]\n",
      "path_degrees = [3, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:990: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(kept_branches_idx) = 531, len(kept_branches_idx) = 500\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.038525715468636076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a720b1c1cd4ce9ad167eb93f4948f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a1ddce8b7141088fc2d5197f333ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 78.56290411949158\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [181, 1063, 3248, 1366, 2369, 999, 3827, 407, 542, 794, 7861, 2192, 1373, 1792, 347, 810, 1110, 1598, 271, 227, 1455, 565, 4087, 486, 1712, 49, 180, 1337, 859, 3383, 1061, 84, 1433, 2473, 129, 420, 614, 2069, 410, 296, 365, 594, 3909, 3215, 135, 1985, 248, 189, 3695, 536, 678, 3496, 697, 374, 641, 4044]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:972: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_large_connectivity: 0.9208769798278809\n",
      "Finding MAP candidates connected components: 0.0008020401000976562\n",
      "len(filtered_pieces) = 11\n",
      "skeleton_connectivity_MP : 1.8099775314331055\n",
      "Grouping MP Sublimbs by Graph: 0.7590897083282471\n",
      "Divinding into MP and MAP pieces: 0.0003509521484375\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.0030400753021240234\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 1936 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_132652.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 6835 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_49100.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_49100_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_927754.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_49100.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_49100_fill_holes.off\n",
      "-----Time for Screened Poisson= 10.540716171264648\n",
      "     Starting Calcification\n",
      "node_degrees = [3 2 6 2 3]\n",
      "node_degrees = [3 4 2 4]\n",
      "node_degrees = [4 2 3]\n",
      "node_degrees = [3 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:500: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10c083503f54174a3c269705e39dd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08e219c4eea432f91ace83c53e31390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.026891708374023438\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "node_degrees = [3 2 6 2 3]\n",
      "node_degrees = [3 4 2 4]\n",
      "    Total time for skeletonizing branch: 12.59719467163086\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.007560253143310547\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51b6d17245b4d6db75b68e6726f5469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (104, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 12.767908096313477\n",
      "Working on limb correspondence for #0 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1df9f2b35314f378f7f065bd5180654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 2.9958336353302\n",
      "mesh_correspondence_first_pass: 2.995866298675537\n",
      "Limb decomposed into 18 branches\n",
      "divided_skeleton_graph_recovered = (104, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (104, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "**** Warning: There were redundant edges in the skeleton*****\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (17, 18)\n",
      "empty_indices % = 0.20796758946657665\n",
      " conflict_indices % = 0.3711006076975017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3538620afc14b52aacc03563b18f151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07661d8681f4430ab0bd22d731134dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 18.02639102935791\n",
      "correspondence_1_to_1: 2.2602345943450928\n",
      "--- Working on MAP piece 1---\n",
      "MAP Filtering Soma Pieces: 0.006039142608642578\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 1763 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_980264.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 2282 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_13837.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_13837_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_695491.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_13837.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_13837_fill_holes.off\n",
      "-----Time for Screened Poisson= 8.270545482635498\n",
      "     Starting Calcification\n",
      "node_degrees = [3 2 3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62fc6e2461e4abbbb2aa4eaae463dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf3a9a899ee405a8a0da4b5708f92d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.023078203201293945\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 9.139300107955933\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.002562999725341797\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f5f5c6364740c3aa7423efd0b16e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (39, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 9.202231645584106\n",
      "Working on limb correspondence for #1 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2582180a39664cc088e9986f5a759a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.42154979705810547\n",
      "mesh_correspondence_first_pass: 0.4215860366821289\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (39, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (39, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.2810157735764627\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab45b223314b4cb6b6e78ac11b95b1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266d7f0962e844d3bfd3c59ac982b0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #1 mesh processing = 9.85888957977295\n",
      "correspondence_1_to_1: 0.229034423828125\n",
      "--- Working on MAP piece 2---\n",
      "MAP Filtering Soma Pieces: 0.021218538284301758\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 3109 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_302384.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 9532 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_80653.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_80653_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_414059.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_80653.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_80653_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.254600286483765\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02433743166e4b9fb3f63e2ea0dcd02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7733a5687d847e590e3d12f8f3afab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.021850109100341797\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 6.598674774169922\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.0015158653259277344\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523b194869c54dfb87bb1e541ad303d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (12, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 6.640939474105835\n",
      "Working on limb correspondence for #2 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb98a85a34e4957839d83430dd9c79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.2164316177368164\n",
      "mesh_correspondence_first_pass: 0.21646618843078613\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (12, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (12, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.1168032786885246\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1a8e3747f5428d8dc21ee855ff681b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e4354dec174426ad06b2cd1b97d1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #2 mesh processing = 6.978696346282959\n",
      "correspondence_1_to_1: 0.10000896453857422\n",
      "--- Working on MAP piece 3---\n",
      "MAP Filtering Soma Pieces: 0.01998138427734375\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 6452 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_217321.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 7707 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_78708.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_78708_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_791678.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_78708.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_78708_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.442514419555664\n",
      "     Starting Calcification\n",
      "node_degrees = [3 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6adeff816e14629bfdce922a74a2495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9767f0e7af7486b808b00dcf84fe717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.021434307098388672\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 6.825337171554565\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.001924753189086914\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ada62716a80403281c98b329d0885d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (17, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 6.871056318283081\n",
      "Working on limb correspondence for #3 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b87f1c8c2e47c5839fcca65e51e1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.23237919807434082\n",
      "mesh_correspondence_first_pass: 0.23241400718688965\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (17, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (17, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.2495731360273193\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e619b081fc04eb89a2026eef9114dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784dbaff4fff4d31a11789fead65504e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #3 mesh processing = 7.247003078460693\n",
      "correspondence_1_to_1: 0.12358832359313965\n",
      "--- Working on MAP piece 4---\n",
      "MAP Filtering Soma Pieces: 0.04100799560546875\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 1128 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_518581.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 270 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_64355.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_64355_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_17301.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_64355.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_64355_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.557605266571045\n",
      "     Starting Calcification\n",
      "node_degrees = [4 2 2 3 2 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b431d037f043e5be81bbcf1b4a2df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd72fb767e24109915f3ed788835849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.02780938148498535\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 7.080902099609375\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.001981019973754883\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fe92f679f04aea9df8fcf1b62fe042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (19, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.1239213943481445\n",
      "Working on limb correspondence for #4 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4017677011468fa7df90ed25b708d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.26425766944885254\n",
      "mesh_correspondence_first_pass: 0.26429057121276855\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (19, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (19, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.5803078710426953\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a65c9c6184424d92392e17889decf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104a497723604d5c91997b4da16773de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #4 mesh processing = 7.569148778915405\n",
      "correspondence_1_to_1: 0.13997721672058105\n",
      "--- Working on MAP piece 5---\n",
      "MAP Filtering Soma Pieces: 0.02302384376525879\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 9888 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_475111.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 4618 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_89833.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_89833_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_220968.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_89833.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_89833_fill_holes.off\n",
      "-----Time for Screened Poisson= 7.837820291519165\n",
      "     Starting Calcification\n",
      "node_degrees = [3 3 2 3 2 2 2 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f32b53595455b91c974d998a66fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b5768a91874129b67c24186a2afbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.034732818603515625\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "node_degrees = [3 3 2 3 2 2 2 2 2]\n",
      "    Total time for skeletonizing branch: 8.629765748977661\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.0027523040771484375\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f8c838cd3f4bcb8a55eab63bca4b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (40, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 8.701149463653564\n",
      "Working on limb correspondence for #5 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d35daff8ba4c9780c99fddf0f4043c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.5688331127166748\n",
      "mesh_correspondence_first_pass: 0.5688676834106445\n",
      "Limb decomposed into 4 branches\n",
      "divided_skeleton_graph_recovered = (40, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (40, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "**** Warning: There were redundant edges in the skeleton*****\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.18363584798638685\n",
      " conflict_indices % = 0.1920022688598979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b49562bd75b4ad4b7769aa449e0becb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a0d30e1bf24404bc72349ca6361179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #5 mesh processing = 9.609972715377808\n",
      "correspondence_1_to_1: 0.31690263748168945\n",
      "--- Working on MAP piece 6---\n",
      "MAP Filtering Soma Pieces: 0.020110368728637695\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 9447 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_347260.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8442 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_53442.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_53442_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_481172.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_53442.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_53442_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.9203736782073975\n",
      "     Starting Calcification\n",
      "node_degrees = [2 2 2 3 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ef0271ba61488d9bb34335739e8024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fbb85bb1e4444d9937d7eaaaecc52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.022227764129638672\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 7.443208932876587\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.002576112747192383\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e1f620774643e79feee75c5e294929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (33, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.510633230209351\n",
      "Working on limb correspondence for #6 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9dfcce7ae6409983b576bab99138eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.38981008529663086\n",
      "mesh_correspondence_first_pass: 0.3898444175720215\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (33, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (33, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.15947136563876652\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc2de42ff20426db6acf9196765cf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e0adbc4cfe4c2b84aa2a168f62ee58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #6 mesh processing = 8.076781272888184\n",
      "correspondence_1_to_1: 0.15626311302185059\n",
      "--- Working on MAP piece 7---\n",
      "MAP Filtering Soma Pieces: 0.016793489456176758\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 8994 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_27544.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 6789 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_23369.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_23369_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_679911.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_23369.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_23369_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.463848829269409\n",
      "     Starting Calcification\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e21a09ab0c2466286da4173dca3f168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28960fdc3eaa4f1696ddf24759e34bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.02340221405029297\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 6.9079508781433105\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.0022754669189453125\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb4f2ef788240a5ab57f20a594f3395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (18, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 6.957609176635742\n",
      "Working on limb correspondence for #7 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9daeacb04444cd926b29539192d01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.284470796585083\n",
      "mesh_correspondence_first_pass: 0.28450489044189453\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (18, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (18, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.7371613424989891\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508708245e144683bf214e461affd7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6846c47329e840c5882ebd0922f32248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #7 mesh processing = 7.384456634521484\n",
      "correspondence_1_to_1: 0.12557077407836914\n",
      "--- Working on MAP piece 8---\n",
      "MAP Filtering Soma Pieces: 0.02240276336669922\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 4466 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_222028.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 9142 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_6925.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_6925_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_858158.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_6925.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_6925_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.779918432235718\n",
      "     Starting Calcification\n",
      "node_degrees = [3 2 2 2 2 2 2 4 3]\n",
      "node_degrees = [2 2 4]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf6d3dcdcec4faf908e49ffa3922c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b410aa3da3740a8aaea9482b0ab1792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.023248672485351562\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "node_degrees = [3 2 2 2 2 2 2 2 3]\n",
      "    Total time for skeletonizing branch: 7.279787540435791\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.002481222152709961\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b291aa8613f54c5e8afbd754b522f61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (30, 2, 3)\n",
      "type(branch_subgraph) = <class 'networkx_utils.GraphOrderedEdges'>\n",
      "in remove edge\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.334268808364868\n",
      "Working on limb correspondence for #8 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c737eee41cdd4b738fbc9b672fbe2723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.25988197326660156\n",
      "mesh_correspondence_first_pass: 0.2599167823791504\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (29, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (29, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.5300588385776414\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d33e395564d417e8125b154303319d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b77985792042f38c27177837bf9565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #8 mesh processing = 7.765854120254517\n",
      "correspondence_1_to_1: 0.14922571182250977\n",
      "--- Working on MAP piece 9---\n",
      "MAP Filtering Soma Pieces: 0.01915431022644043\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 6684 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_635501.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 9195 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_99875.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_99875_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_893249.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_99875.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_99875_fill_holes.off\n",
      "-----Time for Screened Poisson= 7.37745213508606\n",
      "     Starting Calcification\n",
      "node_degrees = [3 3 3 2 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d10e2b18af43adad380b6ba3bea515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d1f207193c4ac9acd6211c4a03d2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.02310037612915039\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "node_degrees = [3 3 3 2 2 2]\n",
      "    Total time for skeletonizing branch: 7.752926826477051\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.0017774105072021484\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282118c0d80445d49f23b1531d30b504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (6, 2, 3)\n",
      "type(branch_subgraph) = <class 'networkx_utils.GraphOrderedEdges'>\n",
      "in remove edge\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.792288303375244\n",
      "Working on limb correspondence for #9 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e049180fed8427aa56b486a585df43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.14448237419128418\n",
      "mesh_correspondence_first_pass: 0.14451813697814941\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (5, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (5, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.6652232746955345\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bd8d6367014dacb995105504e6eb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784fbaf046c343f1a8e902d8086e7ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #9 mesh processing = 8.11310863494873\n",
      "correspondence_1_to_1: 0.15715551376342773\n",
      "--- Working on MAP piece 10---\n",
      "MAP Filtering Soma Pieces: 0.022732973098754883\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 9679 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/None.off -o /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off -s /notebooks/Platinum_Decomp_Fusion/temp/poisson_302772.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/None.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "xvfb-run -n 8565 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Decomp_Fusion/temp/neuron_78398.off -o /notebooks/Platinum_Decomp_Fusion/temp/neuron_78398_fill_holes.off -s /notebooks/Platinum_Decomp_Fusion/temp/fill_holes_764503.mls\n",
      "removed temporary input file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_78398.off\n",
      "removed temporary output file: /notebooks/Platinum_Decomp_Fusion/temp/neuron_78398_fill_holes.off\n",
      "-----Time for Screened Poisson= 6.663300275802612\n",
      "     Starting Calcification\n",
      "node_degrees = [4 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897b80a9c7c24e09a2b3c552c27c284b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afaa41e11cb1460ab97585090526ea0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.02932000160217285\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 7.189788818359375\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.003087759017944336\n",
      "filter_end_node_length = 4001\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86776292fe524160a7981b22be6d053a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (24, 2, 3)\n",
      "type(branch_subgraph) = <class 'networkx_utils.GraphOrderedEdges'>\n",
      "in remove edge\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.250624895095825\n",
      "Working on limb correspondence for #10 MAP piece\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8681e4ee1b3455c8169bf3eb89ef4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 0.47875070571899414\n",
      "mesh_correspondence_first_pass: 0.47878527641296387\n",
      "Limb decomposed into 3 branches\n",
      "divided_skeleton_graph_recovered = (23, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (23, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.1949489707663034\n",
      " conflict_indices % = 0.2428645563051375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376cf29c3b1249a5b9b84c0e4c718beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e84fea917b4cbe80fd7ed7ab9a6975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #10 mesh processing = 7.954784870147705\n",
      "correspondence_1_to_1: 0.20248746871948242\n",
      "Total time for MAP sublimb processing 98.58735990524292\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.02446126937866211\n",
      "Fixing Possible Soma Extension Branch for Sublimb 0\n",
      "Total time for mesh KDTree = 0.054700374603271484\n",
      "sbv[0].reshape(-1,3) = [[1157668.  1103661.   946524.8]]\n",
      "closest_sk_pt_coord BEFORE = [1157823.93355028 1103655.95718551  946779.88612528]\n",
      "current_skeleton.shape = (88, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3799.452946820341\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1157823.93355028 1103655.95718551  946779.88612528]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [1157854.71428571 1103656.85714286  946665.07142857]\n",
      "endpoints_must_keep = {0: array([[1157854.71428571, 1103656.85714286,  946665.07142857]])}\n",
      "orig_vertex = [1157823.93355028 1103655.95718551  946779.88612528]\n",
      "match_sk_branches = [158]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9f160684d04cb7a3d8e83c3bc7abe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.35707240086802133\n",
      " conflict_indices % = 0.009863878477017163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9a551b51d34ca5a2b32b774adc42c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dfa6cee4ea4a6a970625bac0f80654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b93a0926e54ea0b6ca75e1cfc7a0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curr_width_median = 127.20806312253453\n",
      "curr_width_median = 228.82403296745775\n",
      "curr_width_median = 94.69945614471574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:578: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:587: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked segment branches after soma add on\n",
      "Total time for mesh KDTree = 0.18422412872314453\n",
      "sbv[0].reshape(-1,3) = [[1159840.  1107550.   946081.5]]\n",
      "closest_sk_pt_coord BEFORE = [1157577.41037874 1108094.09937323  945225.25431808]\n",
      "current_skeleton.shape = (512, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 7358.905693423984\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1157577.41037874 1108094.09937323  945225.25431808]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [1157621.68161435 1107690.9955157   944939.25112108]\n",
      "endpoints_must_keep = {0: array([[1157621.68161435, 1107690.9955157 ,  944939.25112108]])}\n",
      "orig_vertex = [1157577.41037874 1108094.09937323  945225.25431808]\n",
      "match_sk_branches = [146]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca3edcde9d14afc8a2a2963c369df86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.7397820163487738\n",
      " conflict_indices % = 0.005903723887375113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb31204a43f42e09dafe96620ebd71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14a7c3a34a0434eb6e551ed2a5caa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd8612365084436939b51af8f247612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curr_width_median = 240.5204260814723\n",
      "curr_width_median = 320.3149451029016\n",
      "curr_width_median = 128.64440249820916\n",
      "checked segment branches after soma add on\n",
      "Total time for mesh KDTree = 0.0400700569152832\n",
      "sbv[0].reshape(-1,3) = [[1158430. 1105598.  946865.]]\n",
      "closest_sk_pt_coord BEFORE = [1158378.70600419 1103687.59723528  946993.47541561]\n",
      "current_skeleton.shape = (51, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 599.7459374166921\n",
      "Changing the stitch point becasue the distance to end or branch node was 599.7459374166921\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [1157823.93355028 1103655.95718551  946779.88612528]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1157823.93355028, 1103655.95718551,  946779.88612528]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "Total time for mesh KDTree = 0.06800603866577148\n",
      "sbv[0].reshape(-1,3) = [[1155721.  1104980.   943139.3]]\n",
      "closest_sk_pt_coord BEFORE = [1155843.75592306 1104842.22993919  942864.20764046]\n",
      "current_skeleton.shape = (302, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 7242.658467867552\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1155843.75592306 1104842.22993919  942864.20764046]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [1156014.77227723 1104585.23762376  944155.15247525]\n",
      "endpoints_must_keep = {0: array([[1156014.77227723, 1104585.23762376,  944155.15247525]])}\n",
      "orig_vertex = [1155843.75592306 1104842.22993919  942864.20764046]\n",
      "match_sk_branches = [21]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe169af2c1ed4873889a52115a15555d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.09869298479594558\n",
      " conflict_indices % = 0.00240064017071219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b858514d4e914289af99990cd30ba7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 7 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f324e8b9f44238852a6ec6ca9a2aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddfd8f04260448bbef812ac02194608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curr_width_median = 199.7678519187471\n",
      "curr_width_median = 292.7518308646539\n",
      "curr_width_median = 122.9799230985054\n",
      "checked segment branches after soma add on\n",
      "Total time for mesh KDTree = 0.040673017501831055\n",
      "sbv[0].reshape(-1,3) = [[1160707.  1103719.   947219.6]]\n",
      "closest_sk_pt_coord BEFORE = [1160411.23426025 1103816.69574614  947364.91540062]\n",
      "current_skeleton.shape = (51, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2316.803116007706\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1160411.23426025 1103816.69574614  947364.91540062]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [1160588.72222222 1103695.81944444  947032.62916667]\n",
      "endpoints_must_keep = {0: array([[1160588.72222222, 1103695.81944444,  947032.62916667]])}\n",
      "orig_vertex = [1160411.23426025 1103816.69574614  947364.91540062]\n",
      "match_sk_branches = [157]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9be5833a9da42189079763723132b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.36604842864502835\n",
      " conflict_indices % = 0.09763008758371973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5630f6e67e4b6098f30a93fd96cd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7f5ab585448a9869b8fcac73d354e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdb2e0830f14313bf39952f244baed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curr_width_median = 247.94677416881797\n",
      "curr_width_median = 184.1747409287987\n",
      "curr_width_median = 257.79799846572666\n",
      "checked segment branches after soma add on\n",
      "Total time for mesh KDTree = 0.003844738006591797\n",
      "sbv[0].reshape(-1,3) = [[1157129.  1105469.   946701.9]]\n",
      "closest_sk_pt_coord BEFORE = [1156780.49968748 1105567.86377109  946569.0752271 ]\n",
      "current_skeleton.shape = (42, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 261.37249686215534\n",
      "Changing the stitch point becasue the distance to end or branch node was 261.37249686215534\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [1157012.19582869 1105496.54134728  946665.80872687]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1157012.19582869, 1105496.54134728,  946665.80872687]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "Total time for mesh KDTree = 0.021666288375854492\n",
      "sbv[0].reshape(-1,3) = [[1159510.  1107172.   946005.1]]\n",
      "closest_sk_pt_coord BEFORE = [1158824.27190459 1108398.3791389   945260.53850011]\n",
      "current_skeleton.shape = (79, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1299.3062328778824\n",
      "Changing the stitch point becasue the distance to end or branch node was 1299.3062328778824\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [1157577.41037874 1108094.09937323  945225.25431808]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1157577.41037874, 1108094.09937323,  945225.25431808]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "Total time for mesh KDTree = 0.006071329116821289\n",
      "sbv[0].reshape(-1,3) = [[1161871.  1105294.   947516.2]]\n",
      "closest_sk_pt_coord BEFORE = [1161865.77186466 1105195.0576899   947567.8655774 ]\n",
      "current_skeleton.shape = (24, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 18.08601172567525\n",
      "Changing the stitch point becasue the distance to end or branch node was 18.08601172567525\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [1161869.32953684 1105209.83465947  947558.06313082]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1161869.32953684, 1105209.83465947,  947558.06313082]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "Total time for mesh KDTree = 0.03848576545715332\n",
      "sbv[0].reshape(-1,3) = [[1160901. 1105608.  947100.]]\n",
      "closest_sk_pt_coord BEFORE = [1161869.32953684 1105209.83465947  947558.06313082]\n",
      "current_skeleton.shape = (51, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1161869.32953684 1105209.83465947  947558.06313082]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1161869.32953684, 1105209.83465947,  947558.06313082]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "Total time for mesh KDTree = 0.004147052764892578\n",
      "sbv[0].reshape(-1,3) = [[1165710.  1104091.   943671.8]]\n",
      "closest_sk_pt_coord BEFORE = [1166440.15889748 1103761.44978806  943694.78571491]\n",
      "current_skeleton.shape = (22, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 100.00000000003253\n",
      "Changing the stitch point becasue the distance to end or branch node was 100.00000000003253\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [1166395.16282639 1103699.25627753  943758.8740979 ]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[1166395.16282639, 1103699.25627753,  943758.8740979 ]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "MP (because soma touching verts) soma extension add: 12.589115142822266\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0069658756256103516\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.009479284286499023\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "---- Working on MP Decomposition #3 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0038514137268066406\n",
      "Do Not Need to Fix MP Decomposition 3 so just continuing\n",
      "---- Working on MP Decomposition #4 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.003922700881958008\n",
      "Do Not Need to Fix MP Decomposition 4 so just continuing\n",
      "---- Working on MP Decomposition #5 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0014867782592773438\n",
      "Do Not Need to Fix MP Decomposition 5 so just continuing\n",
      "---- Working on MP Decomposition #6 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0039556026458740234\n",
      "Do Not Need to Fix MP Decomposition 6 so just continuing\n",
      "---- Working on MP Decomposition #7 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.003017425537109375\n",
      "Do Not Need to Fix MP Decomposition 7 so just continuing\n",
      "---- Working on MP Decomposition #8 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.00841379165649414\n",
      "Do Not Need to Fix MP Decomposition 8 so just continuing\n",
      "---- Working on MP Decomposition #9 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.002378225326538086\n",
      "Do Not Need to Fix MP Decomposition 9 so just continuing\n",
      "---- Working on MP Decomposition #10 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0017507076263427734\n",
      "Do Not Need to Fix MP Decomposition 10 so just continuing\n",
      "---- Working on MP Decomposition #11 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0026628971099853516\n",
      "Do Not Need to Fix MP Decomposition 11 so just continuing\n",
      "---- Working on MP Decomposition #12 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0022568702697753906\n",
      "Do Not Need to Fix MP Decomposition 12 so just continuing\n",
      "---- Working on MP Decomposition #13 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.006489753723144531\n",
      "Do Not Need to Fix MP Decomposition 13 so just continuing\n",
      "---- Working on MP Decomposition #14 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0023496150970458984\n",
      "Do Not Need to Fix MP Decomposition 14 so just continuing\n",
      "---- Working on MP Decomposition #15 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0013501644134521484\n",
      "Do Not Need to Fix MP Decomposition 15 so just continuing\n",
      "---- Working on MP Decomposition #16 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.005291938781738281\n",
      "Do Not Need to Fix MP Decomposition 16 so just continuing\n",
      "---- Working on MP Decomposition #17 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0030193328857421875\n",
      "Fixing Possible Soma Extension Branch for Sublimb 17\n",
      "Total time for mesh KDTree = 0.05710411071777344\n",
      "sbv[0].reshape(-1,3) = [[1086876. 1103067.  940296.]]\n",
      "closest_sk_pt_coord BEFORE = [1087261.29802232 1104760.27309108  939490.57328369]\n",
      "current_skeleton.shape = (85, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1099.848274954465\n",
      "Changing the stitch point becasue the distance to end or branch node was 1099.848274954465\n",
      "New stitch point has degree 1\n",
      "change_status for create soma extending pieces = True\n",
      "closest_sk_pt_coord AFTER = [1086214.3744198  1105028.98590529  939305.53769105]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[1086214.3744198 , 1105028.98590529,  939305.53769105]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "Total time for mesh KDTree = 0.05698728561401367\n",
      "sbv[0].reshape(-1,3) = [[1087668.  1103631.   939633.2]]\n",
      "closest_sk_pt_coord BEFORE = [1087754.04922507 1104677.94436079  939499.49383292]\n",
      "current_skeleton.shape = (85, 2, 3)\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1599.8091785248007\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1087754.04922507 1104677.94436079  939499.49383292]\n",
      "Adding new branch to skeleton\n",
      "border_average_coordinate = [1087619.6        1103916.13333333  939429.93333333]\n",
      "endpoints_must_keep = {1: array([[1087619.6       , 1103916.13333333,  939429.93333333]])}\n",
      "orig_vertex = [1087754.04922507 1104677.94436079  939499.49383292]\n",
      "match_sk_branches = [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb9d94cb49841fbbd7208351416456b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.30449764236488935\n",
      " conflict_indices % = 0.06927820094305405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5911cc8657a64a97a8595e681106a8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd47d4790ad41268eabcea2d1491580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8abac8c987484ab552c283f99b4ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curr_width_median = 316.9363427041857\n",
      "curr_width_median = 479.95128248329183\n",
      "curr_width_median = 655.5093128404195\n",
      "checked segment branches after soma add on\n",
      "Total time for mesh KDTree = 0.010113239288330078\n",
      "sbv[0].reshape(-1,3) = [[1080072.  1103498.   941419.5]]\n",
      "closest_sk_pt_coord BEFORE = [1080086.36300507 1103625.89766092  941736.00966424]\n",
      "current_skeleton.shape = (141, 2, 3)\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [1080086.36300507 1103625.89766092  941736.00966424]\n",
      "skipping soma 1 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {1: array([[1080086.36300507, 1103625.89766092,  941736.00966424]])}\n",
      "The new branch info was none so skipping \n",
      "\n",
      "MP (because soma touching verts) soma extension add: 2.384605646133423\n",
      "---- Working on MP Decomposition #18 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0028426647186279297\n",
      "Do Not Need to Fix MP Decomposition 18 so just continuing\n",
      "---- Working on MP Decomposition #19 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001905202865600586\n",
      "Do Not Need to Fix MP Decomposition 19 so just continuing\n",
      "---- Working on MP Decomposition #20 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0020589828491210938\n",
      "Do Not Need to Fix MP Decomposition 20 so just continuing\n",
      "---- Working on MP Decomposition #21 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0013270378112792969\n",
      "Do Not Need to Fix MP Decomposition 21 so just continuing\n",
      "---- Working on MP Decomposition #22 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001398324966430664\n",
      "Do Not Need to Fix MP Decomposition 22 so just continuing\n",
      "---- Working on MP Decomposition #23 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0015387535095214844\n",
      "Do Not Need to Fix MP Decomposition 23 so just continuing\n",
      "---- Working on MP Decomposition #24 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0011942386627197266\n",
      "Do Not Need to Fix MP Decomposition 24 so just continuing\n",
      "---- Working on MP Decomposition #25 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0018243789672851562\n",
      "Do Not Need to Fix MP Decomposition 25 so just continuing\n",
      "---- Working on MP Decomposition #26 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0018105506896972656\n",
      "Do Not Need to Fix MP Decomposition 26 so just continuing\n",
      "---- Working on MP Decomposition #27 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0019145011901855469\n",
      "Do Not Need to Fix MP Decomposition 27 so just continuing\n",
      "---- Working on MP Decomposition #28 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0012500286102294922\n",
      "Do Not Need to Fix MP Decomposition 28 so just continuing\n",
      "---- Working on MP Decomposition #29 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0011687278747558594\n",
      "Do Not Need to Fix MP Decomposition 29 so just continuing\n",
      "---- Working on MP Decomposition #30 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001220703125\n",
      "Do Not Need to Fix MP Decomposition 30 so just continuing\n",
      "---- Working on MP Decomposition #31 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0012781620025634766\n",
      "Do Not Need to Fix MP Decomposition 31 so just continuing\n",
      "---- Working on MP Decomposition #32 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0012848377227783203\n",
      "Do Not Need to Fix MP Decomposition 32 so just continuing\n",
      "---- Working on MP Decomposition #33 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0014157295227050781\n",
      "Do Not Need to Fix MP Decomposition 33 so just continuing\n",
      "---- Working on MP Decomposition #34 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001444101333618164\n",
      "Do Not Need to Fix MP Decomposition 34 so just continuing\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 393.7270628239822\n",
      "Changing the stitch point becasue the distance to end or branch node was 393.7270628239822\n",
      "New stitch point has degree 3\n",
      "conn = [14]\n",
      "winning_vertex = [1121770.07487933 1096826.94205307  942385.3357946 ]\n",
      "MP_branches_with_stitch_point = [14]\n",
      "MAP_branches_with_stitch_point = [8, 13, 14]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (783.0454856141715) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "\n",
      "Revising the MAP pieces index:\n",
      "MAP_pieces_idx_touching_border = [8, 15, 17], MAP_branches_with_stitch_point = [8, 13, 14]\n",
      "MAP_pieces_for_correspondence = [8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8269f8cd7dba4c3db24ece82ed7692a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.31217994425358137\n",
      " conflict_indices % = 0.11415051533026511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453fe96d19014e2c9ef73e4219dbf019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd1ccecf1a41a9a00384ac305c3268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [14]\n",
      "MP_branches_for_correspondence = [14]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 4031.664023505307\n",
      "conn = [11, 12]\n",
      "winning_vertex = [1128060.86591481 1101020.66163041  941892.75592517]\n",
      "MP_branches_with_stitch_point = [4, 5, 11]\n",
      "MAP_branches_with_stitch_point = [8]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5054.1524018205855) \n",
      "Found winning edge: [21, 22.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5167.3343674476355) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5069.144431891061) \n",
      "Found winning edge: [39, 40.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5426730a5374ef6862a2a95294ec96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.39781757798600403\n",
      " conflict_indices % = 0.05930494603249911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18025471f2284f71bb14005e1ce21845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660a86530df14ecd8d31944c414711c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c1e2a0568b425394cc05e275d75623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.2891079100328532\n",
      " conflict_indices % = 0.032410917361637606\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c8af4093094984bfafc3d7b1a6b806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bc9bc1dfbf48748b2bc5922056dec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [4, 5, 11]\n",
      "MP_branches_for_correspondence = [11]\n",
      "MP_leftover = [4 5], MP_leftover_idx = [0 1]\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (3, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "conn = [6]\n",
      "winning_vertex = [1116241.30242467 1096515.57962817  946232.11386802]\n",
      "MP_branches_with_stitch_point = [6]\n",
      "MAP_branches_with_stitch_point = [3, 4, 5]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1098.4586918144514) \n",
      "Found winning edge: [11, 12.0]\n",
      "in remove edge\n",
      "\n",
      "Revising the MAP pieces index:\n",
      "MAP_pieces_idx_touching_border = [3], MAP_branches_with_stitch_point = [3, 4, 5]\n",
      "MAP_pieces_for_correspondence = [3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b9f3474bf149c9b10a5885bbd1ab3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.09952830188679246\n",
      " conflict_indices % = 0.15330188679245282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c8492ac04c4c49a9fb9d7dedb70aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b870728962fb47269c044d5577610612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [6]\n",
      "MP_branches_for_correspondence = [6]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (3, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 566.4591776995055\n",
      "conn = [0]\n",
      "winning_vertex = [1117666.41088245 1095300.04901548  943975.05527805]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1245.4592702027367) \n",
      "Found winning edge: [89, 90.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b745bcc4143344278b65c846ffded6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.16676384839650146\n",
      " conflict_indices % = 0.014577259475218658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ca0de094854ae89e519ced59780349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8b39161dfd4feaa5b2263d173f7587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1038cbd06bbb424886e985f2b8692be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.08508732646663682\n",
      " conflict_indices % = 0.09628302731751008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144110bf7bdc4805adff61036d6ee1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d0fc7798d34a7f98c57ca442bfc8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (6, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 829.2851984097983\n",
      "conn = [9, 10]\n",
      "winning_vertex = [1108899.16329631 1095301.29526653  945701.22097059]\n",
      "MP_branches_with_stitch_point = [9, 10]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (860.0354520225027) \n",
      "Found winning edge: [139, 140.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (920.4364666467442) \n",
      "Found winning edge: [21, 24.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ee072da5714104935a17d179beb26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.16218637992831542\n",
      " conflict_indices % = 0.015232974910394265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92720f8169684d3e9543f58f6fbdf0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b838a2ffa60428aaf55be4aaf18b476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821de9defbfc43c9b525e4a0ef6f41fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.3759746864052435\n",
      " conflict_indices % = 0.073793648999887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc698175bba34acea9ce26255ce90484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3194894baa743a6adfe7422ec829e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [9, 10]\n",
      "MP_branches_for_correspondence = [ 9 10]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (6, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (15, 0) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "conn = [1, 2]\n",
      "winning_vertex = [1118838.58467258 1100961.79546226  941809.12130422]\n",
      "MP_branches_with_stitch_point = [1, 2]\n",
      "MAP_branches_with_stitch_point = [8]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Found winning edge: [24, 25.0]\n",
      "in remove edge\n",
      "Found winning edge: [80, 90.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24a7ad7aa1b4ac3addc81cd7985f7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.3009950248756219\n",
      " conflict_indices % = 0.03897180762852405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4c5ef6684e42639bf4421562375e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ada41ea390940f2883eb58958ea12c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [1, 2]\n",
      "MP_branches_for_correspondence = [1 2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (15, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (20, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2612.7903190989955\n",
      "conn = [1]\n",
      "winning_vertex = [1121326.0572757  1099816.89376769  942334.07369578]\n",
      "MP_branches_with_stitch_point = [1]\n",
      "MAP_branches_with_stitch_point = [8]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1073.719766454079) \n",
      "Found winning edge: [35, 36.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91444052226e4b3ebeefeb84e18239b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.0603448275862069\n",
      " conflict_indices % = 0.14655172413793102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4967f76ccee8453eae66d9626834936f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d48e5417ba744e8abea8117363b3027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ed64516b0948aba42c6f9d24eaaf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty mesh_correspondence_indices_2 returned so returning original mesh correspondence\n",
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.4957418198117436\n",
      " conflict_indices % = 0.020170327207530255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6974750a5199455883c7d6274bd96fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401789e0a04c437ebaa460a22bda4c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1]\n",
      "MP_branches_for_correspondence = [1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (20, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (24, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 497.98493953130753\n",
      "Changing the stitch point becasue the distance to end or branch node was 497.98493953130753\n",
      "New stitch point has degree 3\n",
      "conn = [0]\n",
      "winning_vertex = [1121694.66657053 1096159.21594858  946874.26213595]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [10, 11, 17]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2081.7555953561878) \n",
      "Found winning edge: [8, 9.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2009.8375077963278) \n",
      "Found winning edge: [82, 84.0]\n",
      "in remove edge\n",
      "\n",
      "Revising the MAP pieces index:\n",
      "MAP_pieces_idx_touching_border = [10, 17, 18], MAP_branches_with_stitch_point = [10, 11, 17]\n",
      "MAP_pieces_for_correspondence = [10 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77a07083464445ab8577210b3e80049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.27020506634499397\n",
      " conflict_indices % = 0.07334137515078408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4966ee1f97442bab01f80ab34e532f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee279f4b047341f5bb4d370fb48866e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [1], MP_leftover_idx = [1]\n",
      " Finished with (24, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (33, 0) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2711.8682908672677\n",
      "conn = [0, 2]\n",
      "winning_vertex = [1109904.87208384 1092393.4584974   944307.71046041]\n",
      "MP_branches_with_stitch_point = [0, 2]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1631.4974142234894) \n",
      "Found winning edge: [66, 68.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1733.4533069388128) \n",
      "Found winning edge: [34, 35.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d129f72f61049149d08833e7c376d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3170731707317073\n",
      " conflict_indices % = 0.11798071469086784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fae29370a934b46a213ad1ac1873459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef08ecdb189467f80ce4215c428837e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a6f27848374bf7b52a3fdb7093239c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.06714839619316179\n",
      " conflict_indices % = 0.3327458583010222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc7235564fe42189463a5b1fc975481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d00b54280f485e833a8b6fab59bf52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 2]\n",
      "MP_branches_for_correspondence = [0 2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (33, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (0, 1) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 238.03571160647303\n",
      "Changing the stitch point becasue the distance to end or branch node was 238.03571160647303\n",
      "New stitch point has degree 1\n",
      "conn = [14]\n",
      "winning_vertex = [1146222.84977758 1104930.8226302   943444.82281289]\n",
      "MP_branches_with_stitch_point = [14]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1743.0384809269835) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69413baf9f004aa1ac67c36e23205929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.23259615384615384\n",
      " conflict_indices % = 0.12182692307692308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50e1f1f7084456e907985f01e544103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74527142a3a64492af0e53db0217b9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [14]\n",
      "MP_branches_for_correspondence = [14]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 1) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "conn = [5, 9, 11]\n",
      "winning_vertex = [1130469.65860421 1101112.28648725  940930.48619865]\n",
      "MP_branches_with_stitch_point = [5, 9]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2224.965102795856) \n",
      "Found winning edge: [65, 66.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2206.606823067086) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37424b9ab91d4df1bb0041f2e0279a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.11141722193746796\n",
      " conflict_indices % = 0.29202972834443874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e788d88ba838434481659b6899de4545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23f3af1c66144ee829155d9f5f96c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [5, 9]\n",
      "MP_branches_for_correspondence = [5 9]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (8, 1) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 332.29655430052236\n",
      "Changing the stitch point becasue the distance to end or branch node was 332.29655430052236\n",
      "New stitch point has degree 1\n",
      "conn = [19, 24]\n",
      "winning_vertex = [1134556.9398971  1101589.32028985  941657.29969404]\n",
      "MP_branches_with_stitch_point = [24]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2526.1246851703095) \n",
      "Found winning edge: [3, 4.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4af0f3afa4d47f29c5e425714317aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.28455714034160945\n",
      " conflict_indices % = 0.17045254446205318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c64a3159444808bed0099e6a9f7d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86a42f84934413c954bf1d78800efb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [24]\n",
      "MP_branches_for_correspondence = [24]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (8, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (13, 1) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 4632.113732934418\n",
      "conn = [29]\n",
      "winning_vertex = [1143301.17771803 1101762.039031    947119.35422789]\n",
      "MP_branches_with_stitch_point = [28, 29, 31]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5155.668980072154) \n",
      "Found winning edge: [43, 44.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5078.466334078597) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5012.895798652265) \n",
      "Found winning edge: [45, 46.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c290fea3f7e4ccaa55f862c00fbb8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3238516063702476\n",
      " conflict_indices % = 0.004878946883917886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b470ad391d9d4311b585b6bc1d1dec04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d265327d9345c3adebb4f998922f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddf2c190b284692bf530aafa8f2ccc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.3000588680514675\n",
      " conflict_indices % = 0.0044571524682533005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81758298420b4c40af38d222c8835f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbea701d641f419e9d043250f3202c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [28, 29, 31]\n",
      "MP_branches_for_correspondence = [29]\n",
      "MP_leftover = [28 31], MP_leftover_idx = [0 2]\n",
      " Finished with (13, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (19, 1) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 6119.952919038626\n",
      "conn = [0]\n",
      "winning_vertex = [1137988.05440857 1101984.26813531  942215.01218842]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (560.4419722709538) \n",
      "Found winning edge: [45, 48.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1d5e7401804a309a83ef13096735fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.38803263825929285\n",
      " conflict_indices % = 0.0031084056469369253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1857bd4214124f9fb9bfb01e3df92e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d67bb3e17e49109210e69e13f9d88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6239758a74824a20964c68e59f2eec97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.3311633767324654\n",
      " conflict_indices % = 0.030554388912221755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9eaeb2896a347c2b9eab968301e2e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853866d308bb4214a0edf35a038e6838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (19, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (26, 1) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2483.136058852657\n",
      "conn = [2]\n",
      "winning_vertex = [1144387.90334938 1104062.22614959  942924.53973265]\n",
      "MP_branches_with_stitch_point = [2]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (834.5397522730239) \n",
      "Found winning edge: [24, 25.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f02616b90f44e1faf0c9247e25bf46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.27983539094650206\n",
      " conflict_indices % = 0.0389363722697056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31a75e05cfc4eea81ad3ed9b71fafe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcec5940ab904d7db1832f15c5a99fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb531cf8629645538493ca1f4747ecdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.20716582452916857\n",
      " conflict_indices % = 0.3125861276986679\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da73fa8da5c74e0f9ce0181c78195674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e92f6cda11431faaf86a8000355e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [2]\n",
      "MP_branches_for_correspondence = [2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (26, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (5, 2) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2094.0413037016297\n",
      "conn = [4]\n",
      "winning_vertex = [1097542.35662591 1099758.43403785  940258.42216247]\n",
      "MP_branches_with_stitch_point = [4]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1497.695744810131) \n",
      "Found winning edge: [53, 54.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1282f3a7a24846ff9373656ba03a3752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.12950819672131147\n",
      " conflict_indices % = 0.0430327868852459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fccf14bc7346dcb5ec4c1b3569cb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a638b6381b3944339f3f47b54e07390a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41684173c99a45a383280c8c5f59937c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.2311332503113325\n",
      " conflict_indices % = 0.07970112079701121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21392127e0f5457b80f8c2daa0323e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bce2f480470405dbd6c80849f113bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [4]\n",
      "MP_branches_for_correspondence = [4]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (5, 2) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (6, 2) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1392.1093588633273\n",
      "conn = [1, 13, 15]\n",
      "winning_vertex = [1102809.01590488 1099197.02598385  941451.884125  ]\n",
      "MP_branches_with_stitch_point = [1, 15]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2325.855057211134) \n",
      "Only 2 skeleton nodes so cannot do smoothing\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2245.3274870875916) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [329, 330.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ea90b060be42d398454e34b7464f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.2722736992159658\n",
      " conflict_indices % = 0.007840342124019958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d2f77c0fc04330900ddd15f70b2aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071616a908b84df3b1960e6ed20082fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47c3b4ece554fedaf149da2fc8ee77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.02164402486760304\n",
      " conflict_indices % = 0.09210223347916187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c672ce216bdc4c7a99d8feac4a6907eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aae91c63b8c40d0b3bf4e8ad81128d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1, 15]\n",
      "MP_branches_for_correspondence = [ 1 15]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (6, 2) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (25, 2) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1345.9042841657697\n",
      "conn = [0, 1]\n",
      "winning_vertex = [1096555.8293492  1099926.42834993  940097.7416273 ]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2112.389755226704) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found winning edge: [309, 310.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2110.402268812711) \n",
      "Found winning edge: [122, 123.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842983e36e6a46d3b928185df0aa890e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3362598770851624\n",
      " conflict_indices % = 0.10359964881474978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedcbef9d4d944ebb8a51f57757fa602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d862a8dfce4212bb8ead170317d3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440154b0e9be466c988d683d7a631042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.2735958983919832\n",
      " conflict_indices % = 0.022955022139361455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c49731d9124e6d904effd3a87ca882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529036bdac874bc2a2a2cc12c7614897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (25, 2) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (7, 3) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2225.059224769991\n",
      "conn = [11, 14]\n",
      "winning_vertex = [1132344.89959571 1104050.89878338  955950.32121556]\n",
      "MP_branches_with_stitch_point = [11, 14]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (508.49241177316753) \n",
      "Found winning edge: [79, 80.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (520.708704933816) \n",
      "Found winning edge: [48, 49.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c18ca090d9449ab8be0cf7cc44f7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.22225384177575414\n",
      " conflict_indices % = 0.017928286852589643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94899c7c6fd423f887ef6e3c1ad149e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05468507626d4874bd1aa90859cc9d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f7a2f4cfff4bbca7b0eec3cdfa8c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.32099162910495815\n",
      " conflict_indices % = 0.05505473277527367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a76b1407af9444287148819c22adde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0f314fc3ed47bb9133abd15d62bd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [11, 14]\n",
      "MP_branches_for_correspondence = [11 14]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (7, 3) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (8, 3) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2099.9682743366193\n",
      "conn = [12, 41]\n",
      "winning_vertex = [1135314.05299327 1101859.05198244  950760.78649586]\n",
      "MP_branches_with_stitch_point = [12, 20, 41]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3063.5174740808457) \n",
      "Found winning edge: [62, 63.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3469.3012100300966) \n",
      "Found winning edge: [22, 24.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3445.530253597823) \n",
      "Found winning edge: [17, 19.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851cbd4a01354a7eb7c55da978134664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3482142857142857\n",
      " conflict_indices % = 0.023478835978835978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665b22b47f734e62a61f89c434d2e0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caea7ddcec954954a5fbab64fb5beaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8829c2c947a94747a52466a19301ff0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.2993835088620601\n",
      " conflict_indices % = 0.16298484459285897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85294801b806486ab1cf4321f1481eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed94b6f501b4ecd8bbb2a8ec7ace732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [12, 20, 41]\n",
      "MP_branches_for_correspondence = [12 41]\n",
      "MP_leftover = [20], MP_leftover_idx = [1]\n",
      " Finished with (8, 3) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (10, 3) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "conn = [2, 5]\n",
      "winning_vertex = [1137771.58821722 1103914.30159376  954174.76559079]\n",
      "MP_branches_with_stitch_point = [2, 5]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (844.937283289183) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (796.2094627970225) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56c5f5371df47b2a930731253f2db62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.4109287429943955\n",
      " conflict_indices % = 0.04543634907926341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ab9ea277e94ca99a6c4d100d7ed6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b0ecd565e049ad8ba05e5fffe8b751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [2, 5]\n",
      "MP_branches_for_correspondence = [2 5]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (10, 3) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (16, 3) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3011.788432043171\n",
      "conn = [8, 11]\n",
      "winning_vertex = [1135357.60293153 1103411.63024184  955165.38730657]\n",
      "MP_branches_with_stitch_point = [8]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1188.8771018059456) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56470a940e294630a291eb6b2b7c402e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3107937841243175\n",
      " conflict_indices % = 0.06593868122637547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6861856fb7b94a0c83585ceb1c474433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025313b0ecfb49eb9eeed5561b6853d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80e6d3020704c4386c3c5bf2d87d4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.26480836236933797\n",
      " conflict_indices % = 0.21447928765001936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0c65b10cc54b36a1abe5bf5f7b7f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf06fd52b49421b9d038b7085c65df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [8]\n",
      "MP_branches_for_correspondence = [8]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (16, 3) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 4) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 309.3541659651604\n",
      "Changing the stitch point becasue the distance to end or branch node was 309.3541659651604\n",
      "New stitch point has degree 1\n",
      "conn = [2, 3, 9, 12, 15]\n",
      "winning_vertex = [1132243.34885976 1097050.73262535  940340.77681283]\n",
      "MP_branches_with_stitch_point = [3, 9]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2069.5612623630323) \n",
      "Only 2 skeleton nodes so cannot do smoothing\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2108.1791082825325) \n",
      "Found winning edge: [41, 43.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ce689ba6fb425688ba32614ccb2a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.218969197926197\n",
      " conflict_indices % = 0.1596523330283623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b39a64a8f2452e9b8ad372ef55333c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35824c2bd20f4d24af52819b06eef187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [3, 9]\n",
      "MP_branches_for_correspondence = [3 9]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 4) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (9, 4) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3004.5163911285745\n",
      "conn = [0, 1]\n",
      "winning_vertex = [1132761.38778033 1091823.41172282  939727.1813176 ]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1423.6720997528032) \n",
      "Found winning edge: [40, 41.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1815.092127263512) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d390ea152f944d3090dd17877692ad19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.26248864668483196\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f27ad03bc6e468d82bf26cdb961ed73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab6a39603fb437da4d74915bebc3fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff963eb6c344d43abd0186fc3e5e586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.32907725321888415\n",
      " conflict_indices % = 0.015021459227467811\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4205e75b9e9b40d5bf01f5af6e33dbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa4d1b2db3b4919ac3629a7808cf2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (9, 4) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (11, 4) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3968.846121346519\n",
      "conn = [1]\n",
      "winning_vertex = [1133466.40929088 1093526.44780106  939237.61512555]\n",
      "MP_branches_with_stitch_point = [1]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1506.1705387971037) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fdb32999ab4b3992ecc092b4f7f629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3350114416475973\n",
      " conflict_indices % = 0.011441647597254004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2849e8f8e4864dacbc48dc50e19c5399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77418875b274cd186893173a02fd058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c592ffb96ca4999991df689b658d99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.37157271331432334\n",
      " conflict_indices % = 0.06075893836367625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7f64ae2e8540c48f249cd50a874416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70322c25208b4525bc44479ddfb479d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1]\n",
      "MP_branches_for_correspondence = [1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (11, 4) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (12, 4) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2510.265021346147\n",
      "conn = [1, 2]\n",
      "winning_vertex = [1135508.91790737 1091971.92086395  941956.71305389]\n",
      "MP_branches_with_stitch_point = [1, 2]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1990.2022513446875) \n",
      "Only 2 skeleton nodes so cannot do smoothing\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1935.1335297632563) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac701a074b2436eb4fabcd90ff0b245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.28906999041227227\n",
      " conflict_indices % = 0.007190795781399808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2df2e2162e648cf8bed6ea49e9b07a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53885c4cb834493992a705b3ddc750b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c738d13d7c4defbf7feae6d6c41b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.26393972012917116\n",
      " conflict_indices % = 0.056189451022604954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7f08f3b1e14c578c7d263d53af0dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bceb8fc4aa54a78bd1e4d406dc7cd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1, 2]\n",
      "MP_branches_for_correspondence = [1 2]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (12, 4) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (23, 4) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3658.4159594446487\n",
      "conn = [0]\n",
      "winning_vertex = [1133337.02487451 1091782.05846162  940320.44634289]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (578.7413578587369) \n",
      "Found winning edge: [121, 122.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9895ed1a28a54bf7a807b8fad81df705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.5943988411395461\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6090df714ff7450f914a5ac81a0114b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c54f8fdff6430c9e8d24a064c092ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad21e70b6fe446eaed8f76aaae35808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.45491663831235113\n",
      " conflict_indices % = 0.09322898945219463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3255c0b40db5424bb34a072880263038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50284eb0e57c4061b3ef098671777199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (23, 4) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 5) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 203.03940504246953\n",
      "Changing the stitch point becasue the distance to end or branch node was 203.03940504246953\n",
      "New stitch point has degree 1\n",
      "conn = [22]\n",
      "winning_vertex = [1129439.83068629 1093529.36315702  948088.81202283]\n",
      "MP_branches_with_stitch_point = [12, 13, 22]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (4564.5225805692) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (4480.242275449557) \n",
      "Found winning edge: [32, 33.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (4478.603601600615) \n",
      "Found winning edge: [65, 67.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c878bb63981b40319796039cfca88e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.28924112778790856\n",
      " conflict_indices % = 0.006592790012624491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f66751111040f895530e998c2f9e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3527d6a7537e46d79a0d808de7071f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [12, 13, 22]\n",
      "MP_branches_for_correspondence = [22]\n",
      "MP_leftover = [12 13], MP_leftover_idx = [0 1]\n",
      " Finished with (1, 5) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (12, 5) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2360.2748421699494\n",
      "conn = [0, 1]\n",
      "winning_vertex = [1136175.36878381 1092016.02091359  942688.53062098]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2097.919642500321) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2111.942463195562) \n",
      "Found winning edge: [19, 20.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00742833762e45879a3c261ca044781e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.27073515551366634\n",
      " conflict_indices % = 0.05631479736098021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b58ba295a5c4e42bb203716828bc921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eefc2a7a5984ca29877a385b926e2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02435a58a2e94e1eac6ba2f433befeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.10368663594470046\n",
      " conflict_indices % = 0.15885063702900515\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc797c7d1a64b64a41d40ace84397bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d22a793009a4368bee1eb56795223cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (12, 5) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (22, 5) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1603.2157819292831\n",
      "conn = [0, 1]\n",
      "winning_vertex = [1135972.56192085 1093883.83010655  945654.93322811]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1610.1048412142416) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1604.1086689908016) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab67ffe7f3c48fc9ddce7806d7f3c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.24773139745916514\n",
      " conflict_indices % = 0.029643073200241985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc11b62c3e5437fa770787a88d2f449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46f8031520e42e6bbdd4c843ec276c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a865fe8d3f482c8265f0120101b5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.16634463376075884\n",
      " conflict_indices % = 0.1315650799227121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c19e1c90084405b7a44365afedd8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb6deaa5a3a4c86a5d4e019b1e2bee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (22, 5) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (31, 5) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3529.2956190229897\n",
      "conn = [0]\n",
      "winning_vertex = [1136474.36155283 1093096.83880354  944770.7997419 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [5]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (959.2739039455205) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694d37a1acdc4ab6a5ad0e47e2715af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.2749017038007864\n",
      " conflict_indices % = 0.03571428571428571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727e8e70d92b45ed9b945256074352d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ac1b6fd1a84320a8a73260de8ae855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae3ecf1e2e04bfe9ec6402348ec78c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.17785169242809626\n",
      " conflict_indices % = 0.06711015456857758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7bbdd22e8345f682ae567ce95f28f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd136b336b204ec9840b5380b10333db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (31, 5) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (14, 6) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1835.2553705583723\n",
      "conn = [1, 2, 5]\n",
      "winning_vertex = [1104466.22447276 1102236.43537489  941466.01478905]\n",
      "MP_branches_with_stitch_point = [1, 4, 5]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2012.0890016001006) \n",
      "Found winning edge: [29, 30.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2034.1706295876836) \n",
      "Found winning edge: [139, 141.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1953.187549029908) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3a2ca4405a4723954ffca19b8cf00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.1809691629955947\n",
      " conflict_indices % = 0.006696035242290749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958afe4f2ce746ac88ba73c065776bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ca670387f94e1fab8203b65a1be90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ef614705264fc1a3f00d2f1fe7fbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.07860635696821516\n",
      " conflict_indices % = 0.34877750611246944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369972a6c4aa4413be47a3d5aea809be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604da698c1d745b18fb512215bf000e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1, 4, 5]\n",
      "MP_branches_for_correspondence = [1 5]\n",
      "MP_leftover = [4], MP_leftover_idx = [1]\n",
      " Finished with (14, 6) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (15, 6) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1766.984976708957\n",
      "conn = [0, 1]\n",
      "winning_vertex = [1115820.01946352 1102230.78957401  941172.14406366]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1476.5730890568598) \n",
      "Found winning edge: [41, 42.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1577.389721237189) \n",
      "Found winning edge: [8, 9.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce7b44562fb4843bf8466064a38b2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.276555023923445\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a6195603e1436ab1aab7d1a6d5dc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dd4d359c714256bac8d97d4363ecd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff5be292a8f4f35af3b4c0a5c2edabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.18796592119275826\n",
      " conflict_indices % = 0.11128860489882854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5723f2b2d0af4ccf89ed414e15ccecb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdd5bc60d284a468f4c40eeb523d3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (15, 6) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (17, 6) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1013.1391087217644\n",
      "conn = [1, 3]\n",
      "winning_vertex = [1102856.12356391 1103490.43226194  939397.46357973]\n",
      "MP_branches_with_stitch_point = [1, 3]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (876.7300864946935) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (930.0638178214339) \n",
      "Found winning edge: [82, 83.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c1578188634f0ebac290e8ace4e10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got nothing from first pass so expanding the mesh correspondnece parameters \n",
      "empty mesh_correspondence_indices_2 returned so returning original mesh correspondence\n",
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.5495495495495496\n",
      " conflict_indices % = 0.009009009009009009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d479e38024422b9efbe323c1ce58f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b397faf68d74de087a92c255f1da4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db18d6f12584b44b237091b997ea29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.25742489270386265\n",
      " conflict_indices % = 0.005064377682403433\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbf893809bb401081634da074ae2d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a54b1d62a544ef381896715e08cebf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1, 3]\n",
      "MP_branches_for_correspondence = [1 3]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (17, 6) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (21, 6) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 7596.701722432496\n",
      "conn = [0]\n",
      "winning_vertex = [1107953.02936321 1102693.67313061  940142.13041949]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (916.4407234786298) \n",
      "Found winning edge: [48, 49.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729122e686b6492ebe74e9e16bcbc25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.29730092654760304\n",
      " conflict_indices % = 0.00523700819121794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba112bc3193448c28c7c9846a51d5aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f508950b533f4ab1b78d3f706c669841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b87dc8653e64453880584d0c31b915d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.26163198503624036\n",
      " conflict_indices % = 0.023848491933598316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e57c48aa3f1433a95726336d4add187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c22bd4ed70744eda3860b5b507d46a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (21, 6) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (8, 7) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3640.957324889524\n",
      "conn = [5, 45]\n",
      "winning_vertex = [1153831.70285781 1094163.59805257  951803.60269589]\n",
      "MP_branches_with_stitch_point = [5, 45]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1309.7629524323581) \n",
      "Found winning edge: [41, 42.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1372.1807350114552) \n",
      "Found winning edge: [1, 2.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d38dc6e3fb64c08a3abba1f031da0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.17306914678528104\n",
      " conflict_indices % = 0.014152850788515973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f13a6c91354b359b7d121afeb5ffea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dac4e9ee6fb4548b4f6375315790e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e37b0a01a984a94a876e68f3d1ee5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.1085231635525979\n",
      " conflict_indices % = 0.17737394420271307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fcc397e4a14cd89ffe046f60261b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4896acb0a94e1eb09bb88d3ae578be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [5, 45]\n",
      "MP_branches_for_correspondence = [ 5 45]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (8, 7) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (18, 7) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1580.2829153058346\n",
      "conn = [5, 13]\n",
      "winning_vertex = [1156651.12595224 1092918.9672683   952084.94128523]\n",
      "MP_branches_with_stitch_point = [5, 13]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1030.8806517530913) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1109.596215983581) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e48c0a4eaa4857bc94fad16f65ed74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.348695652173913\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6787bd007b0542a287fbf32f455bf9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ad337285284f1493f4bb0dd826012c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47153f7af6c646bc8c8167a12b8ea1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.32085561497326204\n",
      " conflict_indices % = 0.057754010695187166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77d2bf9ea504bac94f33c8e0b28c4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d47e44dee6a45199e2d09591b70c8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [5, 13]\n",
      "MP_branches_for_correspondence = [ 5 13]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (18, 7) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (7, 8) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 3501.292814836531\n",
      "conn = [9, 10, 17]\n",
      "winning_vertex = [1120305.61523949 1106745.99901803  962887.00604766]\n",
      "MP_branches_with_stitch_point = [9, 10, 17]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (4038.845582767895) \n",
      "Found winning edge: [11, 17.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (4064.793842896578) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (4005.3522506227623) \n",
      "Found winning edge: [66, 67.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1cd643c0e246ab890ae15fbecc3024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.5228958812995651\n",
      " conflict_indices % = 0.039907904834996163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080418c84088473fbd7a78e8523ec29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b659fd75c64753b720c58537959930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d1b341b84948c0a066f766c083f7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (4, 5)\n",
      "empty_indices % = 0.4807239819004525\n",
      " conflict_indices % = 0.020271493212669682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d52a0be03c044d49d493b8b95edc224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b1da813d6f4998aaf5aeadb0d61fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [9, 10, 17]\n",
      "MP_branches_for_correspondence = [ 9 10 17]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (7, 8) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (0, 9) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1110.2570437762233\n",
      "conn = [127]\n",
      "winning_vertex = [1148799.18449862 1111022.13465901  950649.41524178]\n",
      "MP_branches_with_stitch_point = [85, 86, 127]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3987.619613647672) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3909.8734843405978) \n",
      "Only 2 skeleton nodes so cannot do smoothing\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (3871.944580510888) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d624ef80afce4fcb910ce00b1cc04fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.5994587280108254\n",
      " conflict_indices % = 0.19702300405953993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a1e939a23c4f14b34a748f80d42ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6246b30b93f843ab9c7a97be28901d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f226e18dbb194f7b9521d17a1a8c1a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.18276444111027756\n",
      " conflict_indices % = 0.12190547636909227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0514405eff74913a8679b9f73f731b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e756ac71e98b4a4297ff9bc0d94b14f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [85, 86, 127]\n",
      "MP_branches_for_correspondence = [127]\n",
      "MP_leftover = [85 86], MP_leftover_idx = [0 1]\n",
      " Finished with (0, 9) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (27, 9) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "conn = [3]\n",
      "winning_vertex = [1143950.32063784 1115287.18865444  949111.64993019]\n",
      "MP_branches_with_stitch_point = [0, 2, 3]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2526.108743969636) \n",
      "Found winning edge: [70, 71.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2462.328487790521) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (2409.1318007134214) \n",
      "Found winning edge: [24, 25.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ee0e5040944429baf5d1f2ce796859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.386041439476554\n",
      " conflict_indices % = 0.020719738276990186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ab507395d8416aadc56e3f49540eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da7e889db6649aa8d7d797b422031ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 2, 3]\n",
      "MP_branches_for_correspondence = [3]\n",
      "MP_leftover = [0 2], MP_leftover_idx = [0 1]\n",
      " Finished with (27, 9) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (0, 10) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "conn = [75]\n",
      "winning_vertex = [1148463.52457537 1105185.6795542   944948.54028033]\n",
      "MP_branches_with_stitch_point = [75, 76, 125]\n",
      "MAP_branches_with_stitch_point = [0, 1, 2]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5583.659676792503) \n",
      "Found winning edge: [21, 23.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5771.488719166127) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (5773.563504102382) \n",
      "Only 2 skeleton nodes so cannot do smoothing\n",
      "\n",
      "Revising the MAP pieces index:\n",
      "MAP_pieces_idx_touching_border = [0], MAP_branches_with_stitch_point = [0, 1, 2]\n",
      "MAP_pieces_for_correspondence = [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e3bc9949a7491e95e4cf41330f841e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.2792253521126761\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a56dd114c54edcb5b8bdd694bb07f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cbd2045255434bac0c8d55ae08ccf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [75, 76, 125]\n",
      "MP_branches_for_correspondence = [75]\n",
      "MP_leftover = [ 76 125], MP_leftover_idx = [1 2]\n",
      " Finished with (0, 10) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (26, 10) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1611.675494861665\n",
      "conn = [0, 1, 2, 3]\n",
      "winning_vertex = [1143303.21624927 1106192.17070817  940761.47125958]\n",
      "MP_branches_with_stitch_point = [1, 2, 3]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1603.7188903764152) \n",
      "Found winning edge: [1, 2.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1552.186002473452) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1688.7808855211586) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeec4943e2fc4397ac39b0f9ae81a665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.4462854088722608\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e294596edc7d453d9e0391140021f3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9623bd890b65479f86cf982aa769f9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1216809554c47a6adab58398806bf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (4, 5)\n",
      "empty_indices % = 0.3683712121212121\n",
      " conflict_indices % = 0.20197510822510822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b02f405c4e04a28b51ad469a62c9d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e43ed200d048d08562915eb1bd294c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1, 2, 3]\n",
      "MP_branches_for_correspondence = [1 2 3]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (26, 10) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (28, 10) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2486.862325403144\n",
      "conn = [0, 1]\n",
      "winning_vertex = [1142559.52937291 1103233.80009735  947719.47903084]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1679.6817654066456) \n",
      "Found winning edge: [42, 44.0]\n",
      "in remove edge\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1611.037172212013) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0a4ec4b9444dab81579f33a32369e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.2671257702065966\n",
      " conflict_indices % = 0.04276911924610366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4940eab4171742d8a18c60f59fe172ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb07d65f16e4fda8e340714d12c1a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533dfa5d39b44a088d7f0b7dc54557c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (3, 4)\n",
      "empty_indices % = 0.20676229508196722\n",
      " conflict_indices % = 0.1165983606557377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bffc15abbd41c1a11a4300b8d3d553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f94873a65fd4ad7a9b4fb3c3d888867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (28, 10) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (29, 10) connection-----\n",
      "Current stitch point was a branch or endpoint\n",
      "conn = [0]\n",
      "winning_vertex = [1141176.85429822 1105615.56578054  942864.49361477]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (609.6156477843268) \n",
      "Found winning edge: [56, 57.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92dee0335944a11bee6d8ff67ade86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.09360518999073215\n",
      " conflict_indices % = 0.013901760889712697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d1f1fcc0a480e8850f6b6f4de67ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8905724f53f1423cb20ad4b1f1d5db19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (29, 10) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (30, 10) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2486.862325403144\n",
      "conn = [0]\n",
      "winning_vertex = [1143848.8336726  1104698.93000676  948246.49361964]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [2, 4]\n",
      "MAP_stitch_point_on_end_or_branch = True\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1114.8547266201329) \n",
      "Found winning edge: [9, 10.0]\n",
      "in remove edge\n",
      "\n",
      "Revising the MAP pieces index:\n",
      "MAP_pieces_idx_touching_border = [2, 4], MAP_branches_with_stitch_point = [2, 4]\n",
      "MAP_pieces_for_correspondence = [2 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2518cd74314c4712b0b8dde63ad7bdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.29168778509883425\n",
      " conflict_indices % = 0.05220476431829701\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2908b3a1094e55bf3659d4aaecf8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5404c63759bb47a1b5899a0dd23806e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (30, 10) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (32, 10) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 955.2541362816748\n",
      "conn = [0]\n",
      "winning_vertex = [1141540.70747719 1105591.44800294  941039.36528393]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1180.9057714076255) \n",
      "Found winning edge: [82, 83.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc809b63c7548cebe96183110a6ccf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.655315232397607\n",
      " conflict_indices % = 0.014265991716520939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0ba6d8a2de431b981aa32a76c9bb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57567f33b724fd2a78374e930d59e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3350ef3fcc484db711f099d3f89364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.3982926829268293\n",
      " conflict_indices % = 0.09365853658536585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b3f726200040c59cb179117327bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964056f570ec492687542f8a2b19f780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (32, 10) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (34, 10) connection-----\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 1877.0090643640642\n",
      "conn = [0]\n",
      "winning_vertex = [1143060.27032723 1104275.61473915  948544.6278077 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [4]\n",
      "MAP_stitch_point_on_end_or_branch = False\n",
      "Using max stitch distance (300) for smoothing because stitch_distance greater (1195.9921932527598) \n",
      "Found winning edge: [50, 51.0]\n",
      "in remove edge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:850: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26906065e2f34dd087aebcfbae94f4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:318: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.4215189873417722\n",
      " conflict_indices % = 0.02911392405063291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42337fc047c7477d8fd10019f9aff4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28cb129153f40cca6c5d14db0eb7a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d9679dcbae49429554e002d1ab8f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.5308794466403162\n",
      " conflict_indices % = 0.0649703557312253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd668fa4ef45483d91bced3059168aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0db23cb63b4decb0266d092523ce23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (34, 10) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 366.76448798179626\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'limb_to_soma_concept_networks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-47fbde46bebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimb_correspondence_individual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimb_to_soma_concept_networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'limb_to_soma_concept_networks' is not defined"
     ]
    }
   ],
   "source": [
    "from preprocessing_vp2 import *\n",
    "sk = reload(sk)\n",
    "pre=reload(pre)\n",
    "\n",
    "mesh=limb_mesh_mparty\n",
    "soma_touching_vertices_dict = soma_touching_vertices_dict\n",
    "\n",
    "\n",
    "distance_by_mesh_center=True #how the distance is calculated for mesh correspondence\n",
    "meshparty_segment_size = 100\n",
    "meshparty_n_surface_downsampling = 2\n",
    "combine_close_skeleton_nodes=True\n",
    "combine_close_skeleton_nodes_threshold=700\n",
    "filter_end_node_length=4001\n",
    "use_meshafterparty=True\n",
    "perform_cleaning_checks = True\n",
    "\n",
    "#for controlling the pieces processed by MAP\n",
    "width_threshold_MAP = 450\n",
    "size_threshold_MAP = 1000\n",
    "\n",
    "#parameters for MP skeletonization,\n",
    "\n",
    "#Parameters for setting how the MAP skeletonization takes place\n",
    "use_surface_after_CGAL=False\n",
    "surface_reconstruction_size = 500\n",
    "\n",
    "#parametrers for stitching the MAP and MP pieces together\n",
    "move_MAP_stitch_to_end_or_branch = True\n",
    "distance_to_move_point_threshold=500\n",
    "\n",
    "#concept_network parameters\n",
    "run_concept_network_checks = True\n",
    "return_concept_network = True\n",
    "return_concept_network_starting_info=False\n",
    "\n",
    "#printing controls\n",
    "verbose = True\n",
    "print_fusion_steps=True\n",
    "\n",
    "\n",
    "#arguments\n",
    "return_concept_network = False\n",
    "return_concept_network_starting_info=True\n",
    "width_threshold_MAP=500\n",
    "size_threshold_MAP=2000\n",
    "surface_reconstruction_size=1000\n",
    "                    \n",
    "                   \n",
    "    \n",
    "curr_limb_time = time.time()\n",
    "    \n",
    "limb_mesh_mparty = mesh\n",
    "\n",
    "\n",
    "#will store a list of all the endpoints tha tmust be kept:\n",
    "limb_to_endpoints_must_keep_list = []\n",
    "limb_to_soma_touching_vertices_list = []\n",
    "\n",
    "# --------------- Part 1 and 2: Getting Border Vertices and Setting the Root------------- #\n",
    "fusion_time = time.time()\n",
    "#will eventually get the current root from soma_to_piece_touching_vertices[i]\n",
    "if not soma_touching_vertices_dict is None:\n",
    "    root_curr = soma_touching_vertices_dict[list(soma_touching_vertices_dict.keys())[0]][0][0]\n",
    "else:\n",
    "    root_curr = None\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Time for preparing soma vertices and root: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "# --------------- Part 3: Meshparty skeletonization and Decomposition ------------- #\n",
    "sk_meshparty_obj = m_sk.skeletonize_mesh_largest_component(limb_mesh_mparty,\n",
    "                                                        root=root_curr,\n",
    "                                                          filter_mesh=False)\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Time for 1st pass MP skeletonization: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "(segment_branches, #skeleton branches\n",
    "divided_submeshes, divided_submeshes_idx, #mesh correspondence (mesh and indices)\n",
    "segment_widths_median) = m_sk.skeleton_obj_to_branches(sk_meshparty_obj,\n",
    "                                                      mesh = limb_mesh_mparty,\n",
    "                                                      meshparty_segment_size=meshparty_segment_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Decomposing first pass: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "\n",
    "if use_meshafterparty:\n",
    "    print(\"Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\")\n",
    "    # --------------- Part 4: Find Individual Branches that could be MAP processed because of width ------------- #\n",
    "    #gettin the branches that should be passed through MAP skeletonization\n",
    "    pieces_above_threshold = np.where(segment_widths_median>width_threshold_MAP)[0]\n",
    "\n",
    "    #getting the correspondnece info for those MAP qualifying\n",
    "    width_large = segment_widths_median[pieces_above_threshold]\n",
    "    sk_large = [segment_branches[k] for k in pieces_above_threshold]\n",
    "    mesh_large_idx = [divided_submeshes_idx[k] for k in pieces_above_threshold]\n",
    "else:\n",
    "    print(\"Only Using MeshParty Skeletonization and Mesh Correspondence\")\n",
    "    mesh_large_idx = []\n",
    "    width_large = []\n",
    "    sk_large = []\n",
    "\n",
    "\n",
    "print(\"Another print\")\n",
    "mesh_pieces_for_MAP = []\n",
    "mesh_pieces_for_MAP_face_idx = []\n",
    "\n",
    "\n",
    "if len(mesh_large_idx) > 0: #will only continue processing if found MAP candidates\n",
    "\n",
    "    # --------------- Part 5: Find mesh connectivity and group MAP branch candidates into MAP sublimbs ------------- #\n",
    "    print(f\"Found len(mesh_large_idx) MAP candidates: {[len(k) for k in mesh_large_idx]}\")\n",
    "\n",
    "    #finds the connectivity edges of all the MAP candidates\n",
    "    mesh_large_connectivity = tu.mesh_list_connectivity(meshes = mesh_large_idx,\n",
    "                            main_mesh = limb_mesh_mparty,\n",
    "                            print_flag = False)\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_large_connectivity: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "    \"\"\"\n",
    "    --------------- Grouping MAP candidates ----------------\n",
    "    Purpose: Will see what mesh pieces should be grouped together\n",
    "    to pass through CGAL skeletonization\n",
    "\n",
    "\n",
    "    Pseudocode: \n",
    "    1) build a networkx graph with all nodes for mesh_large_idx indexes\n",
    "    2) Add the edges\n",
    "    3) Find the connected components\n",
    "    4) Find sizes of connected components\n",
    "    5) For all those connected components that are of a large enough size, \n",
    "    add the mesh branches and skeletons to the final list\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(np.arange(len(mesh_large_idx)))\n",
    "    G.add_edges_from(mesh_large_connectivity)\n",
    "    conn_comp = list(nx.connected_components(G))\n",
    "\n",
    "    filtered_pieces = []\n",
    "\n",
    "    sk_large_size_filt = []\n",
    "    mesh_large_idx_size_filt = []\n",
    "    width_large_size_filt = []\n",
    "\n",
    "    for cc in conn_comp:\n",
    "        total_cc_size = np.sum([len(mesh_large_idx[k]) for k in cc])\n",
    "        if total_cc_size>size_threshold_MAP:\n",
    "            #print(f\"cc ({cc}) passed the size threshold because size was {total_cc_size}\")\n",
    "            filtered_pieces.append(pieces_above_threshold[list(cc)])\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"Finding MAP candidates connected components: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    #filtered_pieces: will have the indexes of all the branch candidates that should  be \n",
    "    #grouped together and passed through MAP skeletonization\n",
    "\n",
    "    if len(filtered_pieces) > 0:\n",
    "        # --------------- Part 6: If Found MAP sublimbs, Get the meshes and mesh_idxs of the sublimbs ------------- #\n",
    "        print(f\"len(filtered_pieces) = {len(filtered_pieces)}\")\n",
    "        #all the pieces that will require MAP mesh correspondence and skeletonization\n",
    "        #(already organized into their components)\n",
    "        mesh_pieces_for_MAP = [limb_mesh_mparty.submesh([np.concatenate(divided_submeshes_idx[k])],append=True,repair=False) for k in filtered_pieces]\n",
    "        mesh_pieces_for_MAP_face_idx = [np.concatenate(divided_submeshes_idx[k]) for k in filtered_pieces]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Old Way: Finding connectivity of pieces through\n",
    "        mesh_idx_MP = [divided_submeshes_idx[k] for k in pieces_idx_MP]\n",
    "\n",
    "        mesh_large_connectivity_MP = tu.mesh_list_connectivity(meshes = mesh_idx_MP,\n",
    "                                main_mesh = limb_mesh_mparty,\n",
    "                                print_flag = False)\n",
    "\n",
    "        New Way: going to use skeleton connectivity to determine\n",
    "        connectivity of pieces\n",
    "\n",
    "        Pseudocode: \n",
    "        1)\n",
    "\n",
    "        \"\"\"\n",
    "        # --------------- Part 7: If Found MAP sublimbs, Get the meshes and mesh_idxs of the sublimbs ------------- #\n",
    "        # ********* if there are no pieces leftover then will automatically make all the lists below just empty (don't need to if.. else.. the case)****\n",
    "        pieces_idx_MP = np.setdiff1d(np.arange(len(divided_submeshes_idx)),np.concatenate(filtered_pieces))\n",
    "\n",
    "        skeleton_MP = [segment_branches[k] for k in pieces_idx_MP]\n",
    "        skeleton_connectivity_MP = sk.skeleton_list_connectivity(\n",
    "                                        skeletons=skeleton_MP\n",
    "                                        )\n",
    "        if print_fusion_steps:\n",
    "            print(f\"skeleton_connectivity_MP : {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(np.arange(len(skeleton_MP)))\n",
    "        G.add_edges_from(skeleton_connectivity_MP)\n",
    "        sublimbs_MP = list(nx.connected_components(G))\n",
    "        sublimbs_MP_orig_idx = [pieces_idx_MP[list(k)] for k in sublimbs_MP]\n",
    "\n",
    "\n",
    "        #concatenate into sublimbs the skeletons and meshes\n",
    "        sublimb_mesh_idx_branches_MP = [divided_submeshes_idx[k] for k in sublimbs_MP_orig_idx]\n",
    "        sublimb_mesh_branches_MP = [[limb_mesh_mparty.submesh([ki],append=True,repair=False)\n",
    "                                    for ki in k] for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_meshes_MP = [limb_mesh_mparty.submesh([np.concatenate(k)],append=True,repair=False)\n",
    "                                                     for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_meshes_MP_face_idx = [np.concatenate(k)\n",
    "                                                     for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_skeleton_branches = [segment_branches[k] for k in sublimbs_MP_orig_idx]\n",
    "        widths_MP = [segment_widths_median[k] for k in sublimbs_MP_orig_idx]\n",
    "\n",
    "        if print_fusion_steps:\n",
    "            print(f\"Grouping MP Sublimbs by Graph: {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "\n",
    "# else: #if no pieces were determine to need MAP processing\n",
    "#     print(\"No MAP processing needed: just returning the Meshparty skeletonization and mesh correspondence\")\n",
    "#     raise Exception(\"Returning MP correspondence\")\n",
    "\n",
    "\n",
    "# nviz.plot_objects(main_mesh=tu.combine_meshes([limb_mesh_mparty,current_neuron[\"S0\"].mesh]),\n",
    "#                   main_mesh_color=\"green\",\n",
    "#     skeletons=sk_large_size_filt,\n",
    "#      meshes=[limb_mesh_mparty.submesh([k],append=True) for k in mesh_large_idx_size_filt],\n",
    "#       meshes_colors=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------- Part 8: If No MAP sublimbs found, set the MP sublimb lists to just the whole MP branch decomposition ------------- #\n",
    "\n",
    "#if no sublimbs need to be decomposed with MAP then just reassign all of the previous MP processing to the sublimb_MPs\n",
    "if len(mesh_pieces_for_MAP) == 0:\n",
    "    sublimb_meshes_MP = [limb_mesh_mparty] #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "    # -- the decomposition information ---\n",
    "    sublimb_mesh_branches_MP = [divided_submeshes] #the mesh branches for all the disconnected sublimbs\n",
    "    sublimb_mesh_idx_branches_MP = [divided_submeshes_idx] #The mesh branches idx that have already passed through MP skeletonization\n",
    "    sublimb_skeleton_branches = [segment_branches]#the skeleton bnraches for all the sublimbs\n",
    "    widths_MP = [segment_widths_median] #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "    MAP_flag = False\n",
    "else:\n",
    "    MAP_flag = True\n",
    "\n",
    "\n",
    "\n",
    "mesh_pieces_for_MAP #trimesh pieces that should go through CGAL skeletonization\n",
    "sublimb_meshes_MP #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "\n",
    "# -- the decomposition information ---\n",
    "sublimb_mesh_branches_MP #the mesh branches for all the disconnected sublimbs\n",
    "sublimb_mesh_idx_branches_MP #The mesh branches idx that have already passed through MP skeletonization\n",
    "sublimb_skeleton_branches #the skeleton bnraches for all the sublimbs\n",
    "widths_MP #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Divinding into MP and MAP pieces: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------- At this point have the correct division between MAP and MP ------------------------\n",
    "\n",
    "# -------------- Part 9: Doing the MAP decomposition ------------------ #\n",
    "global_start_time = time.time()\n",
    "endpoints_must_keep = dict()\n",
    "\n",
    "\n",
    "\n",
    "limb_correspondence_MAP = dict()\n",
    "\n",
    "for sublimb_idx,(mesh,mesh_idx) in enumerate(zip(mesh_pieces_for_MAP,mesh_pieces_for_MAP_face_idx)):\n",
    "    print(f\"--- Working on MAP piece {sublimb_idx}---\")\n",
    "    mesh_start_time = time.time()\n",
    "    curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "    mesh = mesh,\n",
    "    curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "    )\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MAP Filtering Soma Pieces: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 0) Generating the Clean skeletons  -------------------------------------------#\n",
    "    if not curr_soma_to_piece_touching_vertices is None:\n",
    "        curr_total_border_vertices = dict([(k,np.vstack(v)) for k,v in curr_soma_to_piece_touching_vertices.items()])\n",
    "    else:\n",
    "        curr_total_border_vertices = None\n",
    "\n",
    "\n",
    "    cleaned_branch,curr_limb_endpoints_must_keep = sk.skeletonize_and_clean_connected_branch_CGAL(\n",
    "        mesh=mesh,\n",
    "        curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices,\n",
    "        total_border_vertices=curr_total_border_vertices,\n",
    "        filter_end_node_length=filter_end_node_length,\n",
    "        perform_cleaning_checks=perform_cleaning_checks,\n",
    "        combine_close_skeleton_nodes = combine_close_skeleton_nodes,\n",
    "        combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold,\n",
    "    use_surface_after_CGAL=use_surface_after_CGAL,\n",
    "    surface_reconstruction_size=surface_reconstruction_size)\n",
    "\n",
    "    if not curr_limb_endpoints_must_keep is None:\n",
    "        limb_to_endpoints_must_keep_list.append(curr_limb_endpoints_must_keep)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices)\n",
    "    else:\n",
    "        print(\"Inside MAP decomposition and curr_limb_endpoints_must_keep was None\")\n",
    "\n",
    "    if len(cleaned_branch) == 0:\n",
    "        raise Exception(f\"Found a zero length skeleton for limb {z} of trmesh {branch}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"skeletonize_and_clean_connected_branch_CGAL: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 1) Generating Initial Mesh Correspondence -------------------------------------------#\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Working on limb correspondence for #{sublimb_idx} MAP piece\")\n",
    "    local_correspondence = mesh_correspondence_first_pass(mesh=mesh,\n",
    "                                                         skeleton=cleaned_branch,\n",
    "                                                         distance_by_mesh_center=distance_by_mesh_center)\n",
    "\n",
    "\n",
    "    print(f\"Total time for decomposition = {time.time() - start_time}\")\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_correspondence_first_pass: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "\n",
    "    #------------- 2) Doing Some checks on the initial corespondence -------- #\n",
    "\n",
    "\n",
    "    if perform_cleaning_checks:\n",
    "        check_skeletonization_and_decomp(skeleton=cleaned_branch,\n",
    "                                        local_correspondence=local_correspondence)\n",
    "\n",
    "    # -------3) Finishing off the face correspondence so get 1-to-1 correspondence of mesh face to skeletal piece\n",
    "    local_correspondence_revised = correspondence_1_to_1(mesh=mesh,\n",
    "                                    local_correspondence=local_correspondence,\n",
    "                                    curr_limb_endpoints_must_keep=curr_limb_endpoints_must_keep,\n",
    "                                    curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices)\n",
    "\n",
    "    # -------3b) Fixing the mesh indices to correspond to the larger mesh as a whole\n",
    "    for k,v in local_correspondence_revised.items():\n",
    "        local_correspondence_revised[k][\"branch_face_idx\"] = mesh_idx[local_correspondence_revised[k][\"branch_face_idx\"]]\n",
    "\n",
    "    print(f\"Total time for MAP sublimb #{sublimb_idx} mesh processing = {time.time() - mesh_start_time}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"correspondence_1_to_1: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    limb_correspondence_MAP[sublimb_idx] = local_correspondence_revised\n",
    "\n",
    "print(f\"Total time for MAP sublimb processing {time.time() - global_start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- Part 10: Doing the MP Decomposition ---------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sublimb_meshes_MP #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "# -- the decomposition information ---\n",
    "sublimb_mesh_branches_MP #the mesh branches for all the disconnected sublimbs\n",
    "sublimb_mesh_idx_branches_MP #The mesh branches idx that have already passed through MP skeletonization\n",
    "sublimb_skeleton_branches #the skeleton bnraches for all the sublimbs\n",
    "widths_MP #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "limb_correspondence_MP = dict()\n",
    "\n",
    "for sublimb_idx,mesh in enumerate(sublimb_meshes_MP):\n",
    "    print(f\"---- Working on MP Decomposition #{sublimb_idx} ----\")\n",
    "    mesh_start_time = time.time()\n",
    "\n",
    "    if len(sublimb_meshes_MP) == 1 and MAP_flag == False:\n",
    "        print(\"Using Quicker soma_to_piece_touching_vertices because no MAP and only one sublimb_mesh piece \")\n",
    "        curr_soma_to_piece_touching_vertices = soma_touching_vertices_dict\n",
    "    else:\n",
    "        if not soma_touching_vertices_dict is None:\n",
    "            print(\"Computing the current soma touching verts dict manually\")\n",
    "            curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "                                                mesh = mesh,\n",
    "                                                curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "                                                )\n",
    "        else:\n",
    "            curr_soma_to_piece_touching_vertices = None\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MP filtering soma verts: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    #creating all of the sublimb groups\n",
    "    segment_branches = np.array(sublimb_skeleton_branches[sublimb_idx])\n",
    "    whole_sk_MP = sk.stack_skeletons(segment_branches)\n",
    "    branch = mesh\n",
    "    divided_submeshes = np.array(sublimb_mesh_branches_MP[sublimb_idx])\n",
    "    divided_submeshes_idx = sublimb_mesh_idx_branches_MP[sublimb_idx]\n",
    "    segment_widths_median = widths_MP[sublimb_idx]\n",
    "\n",
    "\n",
    "    if curr_soma_to_piece_touching_vertices is None:\n",
    "        print(f\"Do Not Need to Fix MP Decomposition {sublimb_idx} so just continuing\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # ------- 11/9 addition: Fixing error where creating soma touching branch on mesh that doesn't touch border ------------------- #\n",
    "        print(f\"Fixing Possible Soma Extension Branch for Sublimb {sublimb_idx}\")\n",
    "        no_soma_extension_add = True \n",
    "        \n",
    "        endpts_total = dict()\n",
    "        curr_soma_to_piece_touching_vertices_total = dict()\n",
    "        for sm_idx,sm_bord_verts_list in curr_soma_to_piece_touching_vertices.items():\n",
    "            #will be used for later\n",
    "            endpts_total[sm_idx] = []\n",
    "            curr_soma_to_piece_touching_vertices_total[sm_idx] = []\n",
    "            \n",
    "            for sm_bord_verts in sm_bord_verts_list:\n",
    "                #1) Get the mesh pieces that are touching the border\n",
    "                matching_mesh_idx = tu.filter_meshes_by_containing_coordinates(mesh_list=divided_submeshes,\n",
    "                                           nullifying_points=sm_bord_verts,\n",
    "                                            filter_away=False,\n",
    "                                           distance_threshold=0,\n",
    "                                           return_indices=True)\n",
    "                #2) concatenate all meshes and skeletons that are touching\n",
    "                if len(matching_mesh_idx) <= 0:\n",
    "                    raise Exception(\"None of branches were touching the border vertices when fixing MP pieces\")\n",
    "                \n",
    "                touch_mesh = tu.combine_meshes(divided_submeshes[matching_mesh_idx])\n",
    "                touch_sk = sk.stack_skeletons(segment_branches[matching_mesh_idx])\n",
    "                \n",
    "                local_curr_soma_to_piece_touching_vertices = {sm_idx:[sm_bord_verts]}\n",
    "                new_sk,endpts,new_branch_info = sk.create_soma_extending_branches(current_skeleton=touch_sk,\n",
    "                                      skeleton_mesh=touch_mesh,\n",
    "                                      soma_to_piece_touching_vertices=local_curr_soma_to_piece_touching_vertices,\n",
    "                                      return_endpoints_must_keep=True,\n",
    "                                      return_created_branch_info=True,\n",
    "                                      check_connected_skeleton=False)\n",
    "                \n",
    "                #3) Add the info to the new running lists\n",
    "                endpts_total[sm_idx].append(endpts[sm_idx][0])\n",
    "                curr_soma_to_piece_touching_vertices_total[sm_idx].append(sm_bord_verts)\n",
    "                \n",
    "                \n",
    "                #4) Skip if no new branch was added\n",
    "                br_info = new_branch_info[sm_idx][0]\n",
    "                if br_info is None:\n",
    "                    print(\"The new branch info was none so skipping \\n\")\n",
    "                    continue\n",
    "                    \n",
    "                #4 If new branch was made then \n",
    "                no_soma_extension_add=False\n",
    "\n",
    "                #1) Get the newly added branch (and the original vertex which is the first row)\n",
    "                br_new,sm_bord_verts = br_info[\"new_branch\"],br_info[\"border_verts\"] #this will hold the new branch and the border vertices corresponding to it\n",
    "\n",
    "                curr_soma_to_piece_touching_vertices_MP = {sm_idx:[sm_bord_verts]}\n",
    "                endpoints_must_keep_MP = {sm_idx:[br_new[0][1]]}\n",
    "\n",
    "\n",
    "                orig_vertex = br_new[0][0]\n",
    "                print(f\"orig_vertex = {orig_vertex}\")\n",
    "\n",
    "                #2) Find the branches that have that coordinate (could be multiple)\n",
    "                match_sk_branches = sk.find_branch_skeleton_with_specific_coordinate(segment_branches,\n",
    "                    current_coordinate=orig_vertex)\n",
    "\n",
    "                print(f\"match_sk_branches = {match_sk_branches}\")\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\" ******************* THIS NEEDS TO BE FIXED WITH THE SAME METHOD OF STITCHING ********************  \"\"\"\n",
    "                \"\"\"\n",
    "                Pseudocode:\n",
    "                1) Find if branch point will require split or not\n",
    "                2) If does require split then split the skeleton\n",
    "                3) Gather mesh pieces for correspondence and the skeletons\n",
    "                4) Run the mesh correspondence\n",
    "                - this case calculate the new widths after run \n",
    "                5) Replace the old branch parts with the new ones\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                stitch_point_on_end_or_branch = find_if_stitch_point_on_end_or_branch(\n",
    "                                                        matched_branches_skeletons= segment_branches[match_sk_branches],\n",
    "                                                         stitch_coordinate=orig_vertex,\n",
    "                                                          verbose=False)\n",
    "\n",
    "\n",
    "                if not stitch_point_on_end_or_branch:\n",
    "                    matching_branch_sk = sk.cut_skeleton_at_coordinate(skeleton=segment_branches[match_sk_branches][0],\n",
    "                                                                      cut_coordinate = orig_vertex)\n",
    "                else:\n",
    "                    matching_branch_sk = segment_branches[match_sk_branches]\n",
    "\n",
    "\n",
    "                #3) Find the mesh and skeleton of the winning branch\n",
    "                matching_branch_meshes = np.array(divided_submeshes)[match_sk_branches]\n",
    "                matching_branch_mesh_idx = np.array(divided_submeshes_idx)[match_sk_branches]\n",
    "                extend_soma_mesh_idx = np.concatenate(matching_branch_mesh_idx)\n",
    "                extend_soma_mesh = limb_mesh_mparty.submesh([extend_soma_mesh_idx ],append=True,repair=False)\n",
    "\n",
    "                #4) Add newly created branch to skeleton and divide the skeleton into branches (could make 2 or 3)\n",
    "                #extended_skeleton_to_soma = sk.stack_skeletons([list(matching_branch_sk),br_new])\n",
    "\n",
    "                sk.check_skeleton_connected_component(sk.stack_skeletons(list(matching_branch_sk) + [br_new]))\n",
    "\n",
    "                #5) Run Adaptive mesh correspondnece using branches and mesh\n",
    "                local_correspondnece_MP = mesh_correspondence_first_pass(mesh=extend_soma_mesh,\n",
    "                                                                         skeleton_branches = list(matching_branch_sk) + [br_new]\n",
    "                                              #skeleton=extended_skeleton_to_soma\n",
    "                                                                        )\n",
    "\n",
    "                # GETTING MESHES THAT ARE NOT FULLY CONNECTED!!\n",
    "                local_correspondence_revised = correspondence_1_to_1(mesh=extend_soma_mesh,\n",
    "                                                            local_correspondence=local_correspondnece_MP,\n",
    "                                                            curr_limb_endpoints_must_keep=endpoints_must_keep_MP,\n",
    "                                                            curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices_MP)\n",
    "\n",
    "                # All the things that should be revised:\n",
    "            #     segment_branches, #skeleton branches\n",
    "            #     divided_submeshes, divided_submeshes_idx, #mesh correspondence (mesh and indices)\n",
    "            #     segment_widths_median\n",
    "\n",
    "\n",
    "                new_submeshes = [k[\"branch_mesh\"] for k in local_correspondence_revised.values()]\n",
    "                new_submeshes_idx = [extend_soma_mesh_idx[k[\"branch_face_idx\"]] for k in local_correspondence_revised.values()]\n",
    "                new_skeletal_branches = [k[\"branch_skeleton\"] for k in local_correspondence_revised.values()]\n",
    "\n",
    "                #calculate the new width\n",
    "                ray_inter = tu.ray_pyembree.RayMeshIntersector(limb_mesh_mparty)\n",
    "                new_widths = []\n",
    "                for new_s_idx in new_submeshes_idx:\n",
    "                    curr_ray_distance = tu.ray_trace_distance(mesh=limb_mesh_mparty, \n",
    "                                        face_inds=new_s_idx,\n",
    "                                       ray_inter=ray_inter)\n",
    "                    curr_width_median = np.median(curr_ray_distance[curr_ray_distance!=0])\n",
    "                    print(f\"curr_width_median = {curr_width_median}\")\n",
    "                    if (not np.isnan(curr_width_median)) and (curr_width_median > 0):\n",
    "                        new_widths.append(curr_width_median)\n",
    "                    else:\n",
    "                        print(f\"USING A DEFAULT WIDTH BECAUSE THE NEWLY COMPUTED ONE WAS {curr_width_median}: {segment_widths_median[match_sk_branches[0]]}\")\n",
    "                        new_widths.append(segment_widths_median[match_sk_branches[0]])\n",
    "\n",
    "\n",
    "                #6) Remove the original branch and mesh correspondence and replace with the multiples\n",
    "#                     print(f\"match_sk_branches BEFORE = {match_sk_branches}\")\n",
    "#                     print(f\"segment_branches BEFORE = {segment_branches}\")\n",
    "#                     print(f\"len(new_skeletal_branches) = {len(new_skeletal_branches)}\")\n",
    "#                     print(f\"new_skeletal_branches BEFORE= {new_skeletal_branches}\")\n",
    "\n",
    "\n",
    "                #segment_branches = np.delete(segment_branches,match_sk_branches,axis=0)\n",
    "                #segment_branches = np.append(segment_branches,new_skeletal_branches,axis=0)\n",
    "\n",
    "                segment_branches = np.array([k for i,k in enumerate(segment_branches) if i not in match_sk_branches] + new_skeletal_branches)\n",
    "\n",
    "\n",
    "                divided_submeshes = np.delete(divided_submeshes,match_sk_branches,axis=0)\n",
    "                divided_submeshes = np.append(divided_submeshes,new_submeshes,axis=0)\n",
    "\n",
    "\n",
    "                #divided_submeshes_idx = np.delete(divided_submeshes_idx,match_sk_branches,axis=0)\n",
    "                #divided_submeshes_idx = np.append(divided_submeshes_idx,new_submeshes_idx,axis=0)\n",
    "                divided_submeshes_idx = np.array([k for i,k in enumerate(divided_submeshes_idx) if i not in match_sk_branches] + new_submeshes_idx)\n",
    "\n",
    "                segment_widths_median = np.delete(segment_widths_median,match_sk_branches,axis=0)\n",
    "                segment_widths_median = np.append(segment_widths_median,new_widths,axis=0)\n",
    "\n",
    "                try:\n",
    "                    debug = False\n",
    "                    if debug:\n",
    "                        print(f\"segment_branches.shape = {segment_branches.shape}\")\n",
    "                        print(f\"segment_branches = {segment_branches}\")\n",
    "                        print(f\"new_skeletal_branches = {new_skeletal_branches}\")\n",
    "                    sk.check_skeleton_connected_component(sk.stack_skeletons(segment_branches))\n",
    "                except:\n",
    "                    su.compressed_pickle(local_correspondence_revised,\"local_correspondence_revised\")\n",
    "                print(\"checked segment branches after soma add on\")\n",
    "                return_find = sk.find_branch_skeleton_with_specific_coordinate(segment_branches,\n",
    "                                             orig_vertex)\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\" ******************* END OF HOW CAN DO STITCHING ********************  \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "        limb_to_endpoints_must_keep_list.append(endpts_total)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices_total)\n",
    "        \n",
    "        # ------------------- 11/9 addition ------------------- #\n",
    "\n",
    "        if no_soma_extension_add:\n",
    "            print(\"No soma extending branch was added for this sublimb even though it had a soma border (means they already existed)\")\n",
    "\n",
    "        if print_fusion_steps:\n",
    "            print(f\"MP (because soma touching verts) soma extension add: {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "    #building the limb correspondence\n",
    "    limb_correspondence_MP[sublimb_idx] = dict()\n",
    "\n",
    "    for zz,b_sk in enumerate(segment_branches):\n",
    "        limb_correspondence_MP[sublimb_idx][zz] = dict(\n",
    "            branch_skeleton = b_sk,\n",
    "            width_from_skeleton = segment_widths_median[zz],\n",
    "            branch_mesh = divided_submeshes[zz],\n",
    "            branch_face_idx = divided_submeshes_idx[zz]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "#limb_correspondence_MP_saved = copy.deepcopy(limb_correspondence_MP)\n",
    "#limb_correspondence_MAP_saved = copy.deepcopy(limb_correspondence_MAP)\n",
    "\n",
    "# ------------------------------------- Part C: Will make sure the correspondences can all be stitched together --------------- #\n",
    "\n",
    "# Only want to perform this step if both MP and MAP pieces\n",
    "if len(limb_correspondence_MAP)>0 and len(limb_correspondence_MP)>0:\n",
    "\n",
    "    # -------------- Part 11: Getting Sublimb Mesh and Skeletons and Gets connectivitiy by Mesh -------#\n",
    "    # -------------(filtering connections to only MP to MAP edges)--------------- #\n",
    "\n",
    "    # ---- Doing the mesh connectivity ---------#\n",
    "    sublimb_meshes_MP = []\n",
    "    sublimb_skeletons_MP = []\n",
    "\n",
    "    for sublimb_key,sublimb_v in limb_correspondence_MP.items():\n",
    "        sublimb_meshes_MP.append(tu.combine_meshes([branch_v[\"branch_mesh\"] for branch_v in sublimb_v.values()]))\n",
    "        sublimb_skeletons_MP.append(sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in sublimb_v.values()]))\n",
    "\n",
    "    sublimb_meshes_MAP = []\n",
    "    sublimb_skeletons_MAP = []\n",
    "\n",
    "    for sublimb_key,sublimb_v in limb_correspondence_MAP.items():\n",
    "        sublimb_meshes_MAP.append(tu.combine_meshes([branch_v[\"branch_mesh\"] for branch_v in sublimb_v.values()]))\n",
    "        sublimb_skeletons_MAP.append(sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in sublimb_v.values()]))\n",
    "\n",
    "\n",
    "\n",
    "    mesh_conn,mesh_conn_vertex_groups = tu.mesh_list_connectivity(meshes = sublimb_meshes_MP + sublimb_meshes_MAP,\n",
    "                                        main_mesh = limb_mesh_mparty,\n",
    "                                        min_common_vertices=1,\n",
    "                                        return_vertex_connection_groups=True,\n",
    "                                        return_largest_vertex_connection_group=True,\n",
    "                                        print_flag = False)\n",
    "    mesh_conn_old = copy.deepcopy(mesh_conn)\n",
    "\n",
    "\n",
    "\n",
    "    #check that every MAP piece mapped to a MP piece\n",
    "    mesh_conn_filt = []\n",
    "    mesh_conn_vertex_groups_filt = []\n",
    "    for j,(m1,m2) in enumerate(mesh_conn):\n",
    "        if m1 < len(sublimb_meshes_MP) and m2 >=len(sublimb_meshes_MP):\n",
    "            mesh_conn_filt.append([m1,m2])\n",
    "            mesh_conn_vertex_groups_filt.append(mesh_conn_vertex_groups[j])\n",
    "    mesh_conn_filt = np.array(mesh_conn_filt)\n",
    "\n",
    "    mesh_conn = mesh_conn_filt\n",
    "    mesh_conn_vertex_groups = mesh_conn_vertex_groups_filt\n",
    "\n",
    "    #check that the mapping should create only one connected component\n",
    "    G = nx.from_edgelist(mesh_conn)\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        if len(G) != len(sublimb_meshes_MP) + len(sublimb_meshes_MAP):\n",
    "            raise Exception(\"Number of nodes in mesh connectivity graph is not equal to number of  MAP and MP sublimbs\")\n",
    "\n",
    "        connect_comp = list(nx.connected_components(G))\n",
    "        if len(connect_comp)>1:\n",
    "            raise Exception(f\"Mesh connectivity was not one component, instead it was ({len(connect_comp)}): {connect_comp} \")\n",
    "    except:\n",
    "        print(f\"mesh_conn_filt = {mesh_conn_filt}\")\n",
    "        print(f\"mesh_conn_old = {mesh_conn_old}\")\n",
    "        mesh_conn_adjusted = np.vstack([mesh_conn[:,0],mesh_conn[:,1]-len(sublimb_meshes_MP)]).T\n",
    "        print(f\"mesh_conn_adjusted = {mesh_conn_adjusted}\")\n",
    "        print(f\"len(sublimb_meshes_MP) = {len(sublimb_meshes_MP)}\")\n",
    "        print(f\"len(sublimb_meshes_MAP) = {len(sublimb_meshes_MAP)}\")\n",
    "        meshes = sublimb_meshes_MP + sublimb_meshes_MAP\n",
    "        #su.compressed_pickle(meshes,\"meshes\")\n",
    "        su.compressed_pickle(sublimb_meshes_MP,\"sublimb_meshes_MP\")\n",
    "        su.compressed_pickle(sublimb_meshes_MAP,\"sublimb_meshes_MAP\")\n",
    "        su.compressed_pickle(limb_mesh_mparty,\"limb_mesh_mparty\")\n",
    "        su.compressed_pickle(sublimb_skeletons_MP,\"sublimb_skeletons_MP\")\n",
    "        su.compressed_pickle(sublimb_skeletons_MAP,\"sublimb_skeletons_MAP\")\n",
    "\n",
    "\n",
    "        raise Exception(\"Something went wrong in the connectivity\")\n",
    "\n",
    "\n",
    "    #adjust the connection indices for MP and MAP indices\n",
    "    mesh_conn_adjusted = np.vstack([mesh_conn[:,0],mesh_conn[:,1]-len(sublimb_meshes_MP)]).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Pseudocode:\n",
    "    For each connection edge:\n",
    "        For each vertex connection group:\n",
    "            1) Get the endpoint vertices of the MP skeleton\n",
    "            2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "            3) Find the closest skeletal point on MAP pairing (MAP stitch) \n",
    "            4) Find the branches that have that MAP stitch point:\n",
    "            5A) If the number of branches corresponding to stitch point is multipled\n",
    "                --> then we are stitching at a branching oint\n",
    "                i) Just add the skeletal segment from MP_stitch to MAP stitch to the MP skeletal segment\n",
    "                ii) \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    # -------------- STITCHING PHASE -------#\n",
    "    stitch_counter = 0\n",
    "    for (MP_idx,MAP_idx),v_g in zip(mesh_conn_adjusted,mesh_conn_vertex_groups):\n",
    "        print(f\"\\n---- Working on {(MP_idx,MAP_idx)} connection-----\")\n",
    "\n",
    "        \"\"\"\n",
    "        This old way of getting the endpoints was not good because could possibly just need\n",
    "        a stitching done between original branch junction\n",
    "\n",
    "        skeleton_MP_graph = sk.convert_skeleton_to_graph(curr_skeleton_MP)\n",
    "        endpoint_nodes = xu.get_nodes_of_degree_k(skeleton_MP_graph,1)\n",
    "        endpoint_nodes_coordinates = xu.get_node_attributes(skeleton_MP_graph,node_list=endpoint_nodes)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # -------------- Part 12: Find the MP and MAP stitching point and branches that contain the stitching point-------#\n",
    "\n",
    "        \"\"\"  OLD WAY THAT ALLOWED STITICHING POINTS TO NOT BE CONNECTED AT THE CONNECTING BRANCHES\n",
    "        #getting the skeletons that should be stitched\n",
    "        curr_skeleton_MP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MP[MP_idx].values()])\n",
    "        curr_skeleton_MAP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MAP[MAP_idx].values()])\n",
    "\n",
    "        #1) Get the endpoint vertices of the MP skeleton branches (so every endpoint or high degree node)\n",
    "        #(needs to be inside loop because limb correspondence will change)\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in np.sort(list(limb_correspondence_MP[MP_idx].keys()))]\n",
    "        endpoint_nodes_coordinates = np.array([sk.find_branch_endpoints(k) for k in curr_MP_branch_skeletons])\n",
    "        endpoint_nodes_coordinates = np.unique(endpoint_nodes_coordinates.reshape(-1,3),axis=0)\n",
    "\n",
    "        #2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "        av_vert = np.mean(v_g,axis=0)\n",
    "        winning_vertex = endpoint_nodes_coordinates[np.argmin(np.linalg.norm(endpoint_nodes_coordinates-av_vert,axis=1))]\n",
    "        print(f\"winning_vertex = {winning_vertex}\")\n",
    "\n",
    "\n",
    "        #2b) Find the branch points where the winning vertex is located\n",
    "        MP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MP_branch_skeletons,\n",
    "            current_coordinate = winning_vertex\n",
    "        )\n",
    "        print(f\"MP_branches_with_stitch_point = {MP_branches_with_stitch_point}\")\n",
    "\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP.reshape(-1,3),axis=0)\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-winning_vertex,axis=1))]\n",
    "\n",
    "\n",
    "        #3b) Consider if the stitch point is close enough to end or branch node in skeleton:\n",
    "        # and if so then reassign\n",
    "        if move_MAP_stitch_to_end_or_branch:\n",
    "            MAP_stitch_point_new,change_status = sk.move_point_to_nearest_branch_end_point_within_threshold(\n",
    "                                                    skeleton=curr_skeleton_MAP,\n",
    "                                                    coordinate=MAP_stitch_point,\n",
    "                                                    distance_to_move_point_threshold = distance_to_move_point_threshold,\n",
    "                                                    verbose=True\n",
    "\n",
    "                                                    )\n",
    "            MAP_stitch_point=MAP_stitch_point_new\n",
    "\n",
    "\n",
    "        #4) Find the branches that have that MAP stitch point:\n",
    "        curr_MAP_branch_skeletons = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"]\n",
    "                                         for k in np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))]\n",
    "\n",
    "        MAP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MAP_branch_skeletons,\n",
    "            current_coordinate = MAP_stitch_point\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        MAP_stitch_point_on_end_or_branch = False\n",
    "        if len(MAP_branches_with_stitch_point)>1:\n",
    "            MAP_stitch_point_on_end_or_branch = True\n",
    "        elif len(MAP_branches_with_stitch_point)==1:\n",
    "            if len(nu.matching_rows(sk.find_branch_endpoints(curr_MAP_branch_skeletons[MAP_branches_with_stitch_point[0]]),\n",
    "                                    MAP_stitch_point))>0:\n",
    "                MAP_stitch_point_on_end_or_branch=True\n",
    "        else:\n",
    "            raise Exception(\"No matching MAP values\")\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "        #*****should only get branches that are touching....****\n",
    "\n",
    "        #getting the skeletons that should be stitched\n",
    "        curr_skeleton_MP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MP[MP_idx].values()])\n",
    "        curr_skeleton_MAP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MAP[MAP_idx].values()])\n",
    "\n",
    "\n",
    "        av_vert = np.mean(v_g,axis=0)\n",
    "\n",
    "        # ---------------- Doing the MAP part first -------------- #\n",
    "        \"\"\"\n",
    "        The previous way did not ensure that the MAP point found will have a branch mesh that is touching the border vertices\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP.reshape(-1,3),axis=0)\n",
    "\n",
    "        #this does not guarentee that the MAP branch associated with the MAP stitch point is touching the border group\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-av_vert,axis=1))]\n",
    "        \"\"\"\n",
    "\n",
    "        # -------------- 11/9 NEW METHOD FOR FINDING MAP STITCH POINT ------------ #\n",
    "        o_keys = np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))\n",
    "        curr_MAP_branch_meshes = np.array([limb_correspondence_MAP[MAP_idx][k][\"branch_mesh\"]\n",
    "                                         for k in o_keys])\n",
    "        curr_MAP_branch_skeletons = np.array([limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"]\n",
    "                                         for k in o_keys])\n",
    "\n",
    "        MAP_pieces_idx_touching_border = tu.filter_meshes_by_containing_coordinates(mesh_list=curr_MAP_branch_meshes,\n",
    "                                       nullifying_points=v_g,\n",
    "                                        filter_away=False,\n",
    "                                       distance_threshold=0,\n",
    "                                       return_indices=True)\n",
    "\n",
    "        curr_skeleton_MP_for_stitch = sk.stack_skeletons(curr_MAP_branch_skeletons[MAP_pieces_idx_touching_border])\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MP_for_stitch.reshape(-1,3),axis=0)\n",
    "\n",
    "        #this does not guarentee that the MAP branch associated with the MAP stitch point is touching the border group\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-av_vert,axis=1))]\n",
    "\n",
    "\n",
    "        #3b) Consider if the stitch point is close enough to end or branch node in skeleton:\n",
    "        # and if so then reassign\n",
    "        if move_MAP_stitch_to_end_or_branch:\n",
    "            MAP_stitch_point_new,change_status = sk.move_point_to_nearest_branch_end_point_within_threshold(\n",
    "                                                    skeleton=curr_skeleton_MAP,\n",
    "                                                    coordinate=MAP_stitch_point,\n",
    "                                                    distance_to_move_point_threshold = distance_to_move_point_threshold,\n",
    "                                                    verbose=True\n",
    "\n",
    "                                                    )\n",
    "            MAP_stitch_point=MAP_stitch_point_new\n",
    "\n",
    "\n",
    "        #4) Find the branches that have that MAP stitch point:\n",
    "\n",
    "\n",
    "        MAP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MAP_branch_skeletons,\n",
    "            current_coordinate = MAP_stitch_point\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        MAP_stitch_point_on_end_or_branch = False\n",
    "        if len(MAP_branches_with_stitch_point)>1:\n",
    "            MAP_stitch_point_on_end_or_branch = True\n",
    "        elif len(MAP_branches_with_stitch_point)==1:\n",
    "            if len(nu.matching_rows(sk.find_branch_endpoints(curr_MAP_branch_skeletons[MAP_branches_with_stitch_point[0]]),\n",
    "                                    MAP_stitch_point))>0:\n",
    "                MAP_stitch_point_on_end_or_branch=True\n",
    "        else:\n",
    "            raise Exception(\"No matching MAP values\")\n",
    "\n",
    "\n",
    "        # ---------------- Doing the MP Part --------------------- #\n",
    "\n",
    "\n",
    "\n",
    "        ord_keys = np.sort(list(limb_correspondence_MP[MP_idx].keys()))\n",
    "        curr_MP_branch_meshes = [limb_correspondence_MP[MP_idx][k][\"branch_mesh\"] for k in ord_keys]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" old way of filtering MP pieces just to those touching the MAP, but just want the ones touching the connection group\n",
    "\n",
    "        MAP_meshes_with_stitch_point = tu.combine_meshes([limb_correspondence_MAP[MAP_idx][k][\"branch_mesh\"] for k in MAP_branches_with_stitch_point])\n",
    "\n",
    "        conn = tu.mesh_pieces_connectivity(main_mesh=limb_mesh_mparty,\n",
    "                                   central_piece=MAP_meshes_with_stitch_point,\n",
    "                                   periphery_pieces=curr_MP_branch_meshes)\n",
    "        \"\"\"\n",
    "        # 11/9 Addition: New way that filters meshes by their touching of the vertex connection group\n",
    "        conn = tu.filter_meshes_by_containing_coordinates(mesh_list=curr_MP_branch_meshes,\n",
    "                                       nullifying_points=v_g,\n",
    "                                        filter_away=False,\n",
    "                                       distance_threshold=0,\n",
    "                                       return_indices=True)\n",
    "\n",
    "        print(f\"conn = {conn}\")\n",
    "\n",
    "\n",
    "        #1) Get the endpoint vertices of the MP skeleton branches (so every endpoint or high degree node)\n",
    "        #(needs to be inside loop because limb correspondence will change)\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in conn]\n",
    "        endpoint_nodes_coordinates = np.array([sk.find_branch_endpoints(k) for k in curr_MP_branch_skeletons])\n",
    "        endpoint_nodes_coordinates = np.unique(endpoint_nodes_coordinates.reshape(-1,3),axis=0)\n",
    "\n",
    "\n",
    "        #2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "\n",
    "        winning_vertex = endpoint_nodes_coordinates[np.argmin(np.linalg.norm(endpoint_nodes_coordinates-av_vert,axis=1))]\n",
    "        print(f\"winning_vertex = {winning_vertex}\")\n",
    "\n",
    "\n",
    "        #2b) Find the branch points where the winning vertex is located\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in np.sort(list(limb_correspondence_MP[MP_idx].keys()))]\n",
    "        MP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MP_branch_skeletons,\n",
    "            current_coordinate = winning_vertex\n",
    "        )\n",
    "        print(f\"MP_branches_with_stitch_point = {MP_branches_with_stitch_point}\")\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"MAP_branches_with_stitch_point = {MAP_branches_with_stitch_point}\")\n",
    "        print(f\"MAP_stitch_point_on_end_or_branch = {MAP_stitch_point_on_end_or_branch}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------- This part does the stitching -------------------- #\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        1) For all MP branches\n",
    "            a) Get neighbor coordinates to MP stitch points\n",
    "            b) Delete the MP Stitch points on each \n",
    "            c) Add skeleton segment from neighbor to MAP stitch point\n",
    "        2) Get skeletons and meshes from MP and MAP pieces\n",
    "        3) Run mesh correspondence to get new meshes and mesh_idx and widths\n",
    "        4a) If MAP_stitch_point_on_end_or_branch is False\n",
    "        - Delete the old MAP branch parts and replace with new MAP ones\n",
    "        4b) Revise the meshes,  mesh_idx, and widths of the MAP pieces\n",
    "        5) Revise the meshes,  mesh_idx, and widths of the MP pieces\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # -------------- Part 13: Will Adjust the MP branches that have the stitch point so extends to the MAP stitch point -------#\n",
    "        curr_MP_sk = []\n",
    "        for b_idx in MP_branches_with_stitch_point:\n",
    "\n",
    "            #a) Get neighbor coordinates to MP stitch points\n",
    "            MP_stitch_branch_graph = sk.convert_skeleton_to_graph(curr_MP_branch_skeletons[b_idx])\n",
    "            stitch_node = xu.get_nodes_with_attributes_dict(MP_stitch_branch_graph,dict(coordinates=winning_vertex))[0]\n",
    "            stitch_neighbors = xu.get_neighbors(MP_stitch_branch_graph,stitch_node)\n",
    "\n",
    "            if len(stitch_neighbors) != 1:\n",
    "                raise Exception(\"Not just one neighbor for stitch point of MP branch\")\n",
    "            keep_neighbor = stitch_neighbors[0]  \n",
    "            keep_neighbor_coordinates = xu.get_node_attributes(MP_stitch_branch_graph,node_list=[keep_neighbor])[0]\n",
    "\n",
    "            #b) Delete the MP Stitch points on each \n",
    "            MP_stitch_branch_graph.remove_node(stitch_node)\n",
    "\n",
    "            \"\"\" Old way that does not do smoothing\n",
    "\n",
    "            #c) Add skeleton segment from neighbor to MAP stitch point\n",
    "            new_node_name = np.max(MP_stitch_branch_graph.nodes())+1\n",
    "\n",
    "            MP_stitch_branch_graph.add_nodes_from([(int(new_node_name),{\"coordinates\":MAP_stitch_point})])\n",
    "            MP_stitch_branch_graph.add_weighted_edges_from([(keep_neighbor,new_node_name,np.linalg.norm(MAP_stitch_point - keep_neighbor_coordinates))])\n",
    "\n",
    "            new_MP_skeleton = sk.convert_graph_to_skeleton(MP_stitch_branch_graph)\n",
    "\n",
    "            \"\"\"\n",
    "            try:\n",
    "                if len(MP_stitch_branch_graph)>1:\n",
    "                    new_MP_skeleton = sk.add_and_smooth_segment_to_branch(skeleton=sk.convert_graph_to_skeleton(MP_stitch_branch_graph),\n",
    "                                                    skeleton_stitch_point=keep_neighbor_coordinates,\n",
    "                                                     new_stitch_point=MAP_stitch_point)\n",
    "                else:\n",
    "                    print(\"Not even attempting smoothing segment because once keep_neighbor_coordinates\")\n",
    "                    new_MP_skeleton = np.vstack([keep_neighbor_coordinates,MAP_stitch_point]).reshape(-1,2,3)\n",
    "            except:\n",
    "                su.compressed_pickle(MP_stitch_branch_graph,\"MP_stitch_branch_graph\")\n",
    "                su.compressed_pickle(keep_neighbor_coordinates,\"keep_neighbor_coordinates\")\n",
    "                su.compressed_pickle(MAP_stitch_point,\"MAP_stitch_point\")\n",
    "\n",
    "\n",
    "                raise Exception(\"Something went wrong with add_and_smooth_segment_to_branch\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #smooth over the new skeleton\n",
    "            new_MP_skeleton_smooth = sk.resize_skeleton_branch(new_MP_skeleton,\n",
    "                                                              segment_width=meshparty_segment_size)\n",
    "\n",
    "            curr_MP_sk.append(new_MP_skeleton_smooth)\n",
    "\n",
    "\n",
    "\n",
    "        #2) Get skeletons and meshes from MP and MAP pieces\n",
    "        curr_MAP_sk = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"] for k in MAP_branches_with_stitch_point]\n",
    "\n",
    "        #2.1) Going to break up the MAP skeleton if need be\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        a) check to see if it needs to be broken up\n",
    "        If it does:\n",
    "        b) Convert the skeleton into a graph\n",
    "        c) Find the node of the MAP stitch point (where need to do the breaking)\n",
    "        d) Find the degree one nodes\n",
    "        e) For each degree one node:\n",
    "        - Find shortest path from stitch node to end node\n",
    "        - get a subgraph from that path\n",
    "        - convert graph to a skeleton and save as new skeletons\n",
    "\n",
    "        \"\"\"\n",
    "        # -------------- Part 14: Breaks Up MAP skeleton into 2 pieces if Needs (because MAP stitch point not on endpoint or branch point)  -------#\n",
    "\n",
    "        #a) check to see if it needs to be broken up\n",
    "        cut_flag = False\n",
    "        if not MAP_stitch_point_on_end_or_branch:\n",
    "            if len(curr_MAP_sk) > 1:\n",
    "                raise Exception(f\"There was more than one skeleton for MAP skeletons even though MAP_stitch_point_on_end_or_branch = {MAP_stitch_point_on_end_or_branch}\")\n",
    "\n",
    "\n",
    "            skeleton_to_cut = curr_MAP_sk[0]\n",
    "            curr_MAP_sk = sk.cut_skeleton_at_coordinate(skeleton=skeleton_to_cut,\n",
    "                                                        cut_coordinate=MAP_stitch_point)\n",
    "            cut_flag=True\n",
    "\n",
    "\n",
    "\n",
    "        # -------------- Part 15: Gets all of the skeletons and Mesh to divide u and does mesh correspondence -------#\n",
    "        # ------------- revise IDX so still references the whole limb mesh -----------#\n",
    "\n",
    "        # -------------- 11/10 Addition accounting for not all MAP pieces always touching each other --------------------#\n",
    "        if len(MAP_branches_with_stitch_point) > 1:\n",
    "            print(\"\\nRevising the MAP pieces index:\")\n",
    "            print(f\"MAP_pieces_idx_touching_border = {MAP_pieces_idx_touching_border}, MAP_branches_with_stitch_point = {MAP_branches_with_stitch_point}\")\n",
    "            MAP_pieces_for_correspondence = nu.intersect1d(MAP_pieces_idx_touching_border,MAP_branches_with_stitch_point)\n",
    "            print(f\"MAP_pieces_for_correspondence = {MAP_pieces_for_correspondence}\")\n",
    "            curr_MAP_sk = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"] for k in MAP_pieces_for_correspondence]\n",
    "        else:\n",
    "            MAP_pieces_for_correspondence = MAP_branches_with_stitch_point\n",
    "\n",
    "        curr_MAP_meshes_idx = [limb_correspondence_MAP[MAP_idx][k][\"branch_face_idx\"] for k in MAP_pieces_for_correspondence]\n",
    "        \n",
    "        # Have to adjust based on if the skeleton were split\n",
    "        \n",
    "        if cut_flag:\n",
    "            #Then it was cut and have to do mesh correspondence to find what label to cut\n",
    "            if len(curr_MAP_meshes_idx) > 1:\n",
    "                raise Exception(\"MAP_pieces_for_correspondence was longer than 1 and cut flag was set\")\n",
    "            pre_stitch_mesh_idx = curr_MAP_meshes_idx[0]\n",
    "            pre_stitch_mesh = limb_mesh_mparty.submesh([pre_stitch_mesh_idx],append=True,repair=False)\n",
    "            local_correspondnece_stitch = mesh_correspondence_first_pass(mesh=pre_stitch_mesh,\n",
    "                                      skeleton_branches=curr_MAP_sk)\n",
    "            local_correspondence_stitch_revised = correspondence_1_to_1(mesh=pre_stitch_mesh,\n",
    "                                                        local_correspondence=local_correspondnece_stitch,\n",
    "                                                        curr_limb_endpoints_must_keep=None,\n",
    "                                                        curr_soma_to_piece_touching_vertices=None)\n",
    "            \n",
    "            curr_MAP_meshes_idx = [pre_stitch_mesh_idx[local_correspondence_stitch_revised[nn][\"branch_face_idx\"]] for \n",
    "                                           nn in local_correspondence_stitch_revised.keys()]\n",
    "            \n",
    "                                   \n",
    "        must_keep_labels_MAP = dict()\n",
    "        must_keep_counter = 0\n",
    "        for kk,b_idx in enumerate(curr_MAP_meshes_idx):\n",
    "            #must_keep_labels_MAP.update(dict([(ii,kk) for ii in range(must_keep_counter,must_keep_counter+len(b_idx))]))\n",
    "            must_keep_labels_MAP[kk] = np.arange(must_keep_counter,must_keep_counter+len(b_idx))\n",
    "            must_keep_counter += len(b_idx)\n",
    "        \n",
    "            \n",
    "\n",
    "        #this is where should send only the MP that apply\n",
    "        MP_branches_for_correspondence,conn_idx,MP_branches_with_stitch_point_idx = nu.intersect1d(conn,MP_branches_with_stitch_point,return_indices=True)\n",
    "\n",
    "        curr_MP_meshes_idx = [limb_correspondence_MP[MP_idx][k][\"branch_face_idx\"] for k in MP_branches_for_correspondence]\n",
    "        curr_MP_sk_for_correspondence = [curr_MP_sk[zz] for zz in MP_branches_with_stitch_point_idx]\n",
    "\n",
    "        stitching_mesh_idx = np.concatenate(curr_MAP_meshes_idx + curr_MP_meshes_idx)\n",
    "        stitching_mesh = limb_mesh_mparty.submesh([stitching_mesh_idx],append=True,repair=False)\n",
    "        stitching_skeleton_branches = curr_MAP_sk + curr_MP_sk_for_correspondence\n",
    "        \"\"\"\n",
    "\n",
    "        ****** NEED TO GET THE RIGHT MESH TO RUN HE IDX ON SO GETS A GOOD MESH (CAN'T BE LIMB_MESH_MPARTY)\n",
    "        BUT MUST BE THE ORIGINAL MAP MESH\n",
    "\n",
    "        mesh_pieces_for_MAP\n",
    "        sublimb_meshes_MP\n",
    "\n",
    "        mesh_pieces_for_MAP_face_idx\n",
    "        sublimb_meshes_MP_face_idx\n",
    "\n",
    "        stitching_mesh = tu.combine_meshes(curr_MAP_meshes + curr_MP_meshes)\n",
    "        stitching_skeleton_branches = curr_MAP_sk + curr_MP_sk\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #3) Run mesh correspondence to get new meshes and mesh_idx and widths\n",
    "        local_correspondnece_stitch = mesh_correspondence_first_pass(mesh=stitching_mesh,\n",
    "                                      skeleton_branches=stitching_skeleton_branches)\n",
    "\n",
    "        try:\n",
    "\n",
    "            local_correspondence_stitch_revised = correspondence_1_to_1(mesh=stitching_mesh,\n",
    "                                                        local_correspondence=local_correspondnece_stitch,\n",
    "                                                        curr_limb_endpoints_must_keep=None,\n",
    "                                                        curr_soma_to_piece_touching_vertices=None,\n",
    "                                                        must_keep_labels=must_keep_labels_MAP)\n",
    "        except:\n",
    "            su.compressed_pickle(stitching_skeleton_branches,\"stitching_skeleton_branches\")\n",
    "            su.compressed_pickle(stitching_mesh,\"stitching_mesh\")\n",
    "            su.compressed_pickle(local_correspondnece_stitch,\"local_correspondnece_stitch\")\n",
    "            raise Exception(\"Something went wrong with 1 to 1 correspondence\")\n",
    "\n",
    "\n",
    "        #Need to readjust the mesh correspondence idx\n",
    "        for k,v in local_correspondence_stitch_revised.items():\n",
    "            local_correspondence_stitch_revised[k][\"branch_face_idx\"] = stitching_mesh_idx[local_correspondence_stitch_revised[k][\"branch_face_idx\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # -------------- Part 16: Overwrite old branch entries (and add on one new to MAP if required a split) -------#\n",
    "\n",
    "\n",
    "        #4a) If MAP_stitch_point_on_end_or_branch is False\n",
    "        #- Delete the old MAP branch parts and replace with new MAP ones\n",
    "        if not MAP_stitch_point_on_end_or_branch:\n",
    "            print(\"Deleting branches from dictionary\")\n",
    "            del limb_correspondence_MAP[MAP_idx][MAP_branches_with_stitch_point[0]]\n",
    "            #adding the two new branches created from the stitching\n",
    "            limb_correspondence_MAP[MAP_idx][MAP_branches_with_stitch_point[0]] = local_correspondence_stitch_revised[0]\n",
    "            limb_correspondence_MAP[MAP_idx][np.max(list(limb_correspondence_MAP[MAP_idx].keys()))+1] = local_correspondence_stitch_revised[1]\n",
    "\n",
    "            #have to reorder the keys\n",
    "            #limb_correspondence_MAP[MAP_idx] = dict([(k,limb_correspondence_MAP[MAP_idx][k]) for k in np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))])\n",
    "            limb_correspondence_MAP[MAP_idx] = gu.order_dict_by_keys(limb_correspondence_MAP[MAP_idx])\n",
    "\n",
    "        else: #4b) Revise the meshes,  mesh_idx, and widths of the MAP pieces if weren't broken up\n",
    "            for j,curr_MAP_idx_fixed in enumerate(MAP_pieces_for_correspondence): \n",
    "                limb_correspondence_MAP[MAP_idx][curr_MAP_idx_fixed] = local_correspondence_stitch_revised[j]\n",
    "\n",
    "        #5) Revise the meshes,  mesh_idx, and widths of the MP pieces\n",
    "        for j,curr_MP_idx_fixed in enumerate(MP_branches_for_correspondence): #************** right here just need to make only the ones that applied\n",
    "            limb_correspondence_MP[MP_idx][curr_MP_idx_fixed] = local_correspondence_stitch_revised[j+len(curr_MAP_sk)]\n",
    "\n",
    "\n",
    "        #5b) Fixing the branch skeletons that were not included in the correspondence\n",
    "        MP_leftover,MP_leftover_idx = nu.setdiff1d(MP_branches_with_stitch_point,MP_branches_for_correspondence)\n",
    "        print(f\"MP_branches_with_stitch_point= {MP_branches_with_stitch_point}\")\n",
    "        print(f\"MP_branches_for_correspondence = {MP_branches_for_correspondence}\")\n",
    "        print(f\"MP_leftover = {MP_leftover}, MP_leftover_idx = {MP_leftover_idx}\")\n",
    "\n",
    "        for curr_MP_leftover,curr_MP_leftover_idx in zip(MP_leftover,MP_leftover_idx):\n",
    "            limb_correspondence_MP[MP_idx][curr_MP_leftover][\"branch_skeleton\"] = curr_MP_sk[curr_MP_leftover_idx]\n",
    "\n",
    "\n",
    "        print(f\" Finished with {(MP_idx,MAP_idx)} \\n\\n\\n\")\n",
    "        stitch_counter += 1\n",
    "#         if cut_flag:\n",
    "#             raise Exception(\"Cut flag was activated\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"There were not both MAP and MP pieces so skipping the stitch resolving phase\")\n",
    "\n",
    "print(f\"Time for decomp of Limb = {time.time() - curr_limb_time}\")\n",
    "#     # ------------- Saving the MAP and MP Decompositions ---------------- #\n",
    "#     proper_limb_mesh_correspondence_MAP[curr_limb_idx] = limb_correspondence_MAP\n",
    "#     proper_limb_mesh_correspondence_MP[curr_limb_idx] = limb_correspondence_MP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------- Part 17: Grouping the MP and MAP Correspondence into one correspondence dictionary -------#\n",
    "limb_correspondence_individual = dict()\n",
    "counter = 0\n",
    "\n",
    "for sublimb_idx,sublimb_branches in limb_correspondence_MAP.items():\n",
    "    for branch_dict in sublimb_branches.values():\n",
    "        limb_correspondence_individual[counter]= branch_dict\n",
    "        counter += 1\n",
    "for sublimb_idx,sublimb_branches in limb_correspondence_MP.items():\n",
    "    for branch_dict in sublimb_branches.values():\n",
    "        limb_correspondence_individual[counter]= branch_dict\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "#info that may be used for concept networks\n",
    "network_starting_info = dict(\n",
    "            touching_verts_list = limb_to_soma_touching_vertices_list,\n",
    "            endpoints_must_keep = limb_to_endpoints_must_keep_list\n",
    ")\n",
    "\n",
    "if not return_concept_network:\n",
    "    if return_concept_network_starting_info: #because may want to calculate the concept networks later\n",
    "        return_value= limb_correspondence_individual,network_starting_info\n",
    "    else:\n",
    "        return_value= limb_correspondence_individual\n",
    "else:\n",
    "    limb_to_soma_concept_networks = calculate_limb_concept_networks(limb_correspondence_individual,\n",
    "                                                                    run_concept_network_checks=run_concept_network_checks,\n",
    "                                                                   **network_starting_info)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "return_value = limb_correspondence_individual,limb_to_soma_concept_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.visualize_neuron(neuron_obj,\n",
    "                      visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending the data to the Neuron Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nru = reload(nru)\n",
    "save_time = time.time()\n",
    "neuron_obj.save_compressed_neuron(output_folder=\"/notebooks/test_neurons/Fusion_decomp/\",\n",
    "                                 export_mesh=True,\n",
    "                                 suppress_output=True)\n",
    "print(f\"Save time = {time.time() - save_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_visualizations as nviz\n",
    "returned_colors = nviz.visualize_neuron(neuron_obj,\n",
    "                     visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=dict(L6=\"all\"),\n",
    "                                       return_color_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
