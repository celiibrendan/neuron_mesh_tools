{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo create the function that will do the filtering \\nfunction for the AutoProofreadNeuron table\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To create the function that will do the filtering \n",
    "function for the AutoProofreadNeuron table\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-16 00:26:28,198 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-02-16 00:26:28,201 - settings - Setting database.user to celiib\n",
      "INFO - 2021-02-16 00:26:28,202 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-02-16 00:26:28,206 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-02-16 00:26:28,207 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-02-16 00:26:28,222 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-16 00:26:28,538 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-16 00:26:28,657 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-02-16 00:26:28,980 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import datajoint_utils as du\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_segment_id = 864691135012431606\n",
    "curr_split_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_obj = du.decomposition_with_spine_recalculation(segment_id=curr_segment_id,\n",
    "#                                          split_index=curr_split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nviz.visualize_neuron(neuron_obj,\n",
    "#                      limb_branch_dict=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that will do proofreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dict(segment_id=curr_segment_id)\n",
    "verbose=True\n",
    "proof_version = 0\n",
    "compute_synapse_to_soma_skeletal_distance = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135012431606  ----------\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Pulled from Table Decomposition so setting split_index = 0\n",
      "Number of Neurons found = 1\n",
      "Number of Neurons found =1\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [553798]\n",
      "nucleus_centers = [[1271552  476288  971040]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Axon Classification = 19.77967381477356\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Did not pass final filters to continuing\n",
      "Inhibitory Excitatory Classification = 8.86283564567566\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={5: {0: 166.80806361041965}}\n",
      "n_axons=1\n",
      "n_apicals=1\n",
      "neuron_spine_density=0.0007039278693363126\n",
      "n_branches_processed=66\n",
      "skeletal_length_processed=4025200.4013470314\n",
      "n_branches_in_search_radius=96\n",
      "skeletal_length_in_search_radius=4425974.773983242\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L0': [0, 1, 2, 4, 51, 57]}\n",
      "total_sk_distance = 105.67144439771742, total_area = 201.52489420519615\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "local_results = {'axon_on_dendrite_merges_neuron': <neuron.Neuron object at 0x7f9947b73630>, 'axon_on_dendrite_merges_time': 23.3654465675354, 'axon_on_dendrite_merges_error_area': 201.52489420519615, 'axon_on_dendrite_merges_error_length': 105.67144439771742}\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = low_branch_clusters\n",
      "function __name__ = filter_away_low_branch_length_clusters\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_restriction = {'L0': array([34, 42, 45]), 'L1': array([6]), 'L3': array([0]), 'L5': array([ 4, 15, 19])}\n",
      "--- Working on Limb L0 ---\n",
      "nodes_to_keep = [34 42 45]\n",
      "--- Working on Limb L1 ---\n",
      "nodes_to_keep = [6]\n",
      "--- Working on Limb L3 ---\n",
      "nodes_to_keep = [0]\n",
      "--- Working on Limb L5 ---\n",
      "nodes_to_keep = [ 4 15 19]\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter low_branch_clusters Results --\n",
      "local_results = {'low_branch_clusters_neuron': <neuron.Neuron object at 0x7f99a6cdb080>, 'low_branch_clusters_time': 0.5871663093566895, 'low_branch_clusters_error_area': 0, 'low_branch_clusters_error_length': 0}\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = dendrite_on_axon_merges\n",
      "function __name__ = filter_away_dendrite_on_axon_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "Using pre-existing axon and axon-like labels\n",
      "dendritic_branches_merged_on_axon = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter dendrite_on_axon_merges Results --\n",
      "local_results = {'dendrite_on_axon_merges_neuron': <neuron.Neuron object at 0x7f99cf4bb908>, 'dendrite_on_axon_merges_time': 0.49991750717163086, 'dendrite_on_axon_merges_error_area': 0, 'dendrite_on_axon_merges_error_length': 0}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = double_back_and_width_change\n",
      "function __name__ = filter_away_large_double_back_or_width_changes\n",
      "function arguments = {'perform_double_back_errors': True, 'skip_double_back_errors_for_axon': False, 'width_jump_threshold': 250, 'running_width_jump_method': True, 'double_back_axon_like_threshold': 145, 'double_back_threshold': 120}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "\n",
      "After edges deleted and created: \n",
      "kept_branches= [0, 1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "removed_branches = [2, 3, 4, 5, 6]\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L5': [2, 3, 4, 5, 6]}\n",
      "total_sk_distance = 78.25468712058337, total_area = 51.14835488692928\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_and_width_change Results --\n",
      "local_results = {'double_back_and_width_change_neuron': <neuron.Neuron object at 0x7f994f7a2ba8>, 'double_back_and_width_change_time': 35.000659465789795, 'double_back_and_width_change_error_area': 51.14835488692928, 'double_back_and_width_change_error_length': 78.25468712058337}\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = crossovers\n",
      "function __name__ = filter_away_crossovers\n",
      "function arguments = {'axon_dependent': True, 'match_threshold': 30}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = [[1263760.  488791.  980440.]]\n",
      "branch 2 did not have one of the following in their labels : ['axon', 'axon-like']\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter crossovers Results --\n",
      "local_results = {'crossovers_neuron': <neuron.Neuron object at 0x7f9950016198>, 'crossovers_time': 6.016148567199707, 'crossovers_error_area': 0, 'crossovers_error_length': 0}\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = high_degree_coordinates\n",
      "function __name__ = filter_away_high_degree_coordinates\n",
      "function arguments = {'axon_dependent': True, 'min_degree_to_find': 4}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = [2784]\n",
      "curr_high_degree_coordinates = [[1263760.  488791.  980440.]]\n",
      "high_degree_branch_groups = [[2, 3, 4, 5]]\n",
      "branch 2 did not have one of the following in their labels : ['axon', 'axon-like']\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_coordinates Results --\n",
      "local_results = {'high_degree_coordinates_neuron': <neuron.Neuron object at 0x7f9862a6dac8>, 'high_degree_coordinates_time': 5.920706748962402, 'high_degree_coordinates_error_area': 0, 'high_degree_coordinates_error_length': 0}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 71.39302277565002 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 100.03655338287354\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [1271591  477299  970384]\n",
      "nuclei_within_radius = [553798]\n",
      "nuclei_within_radius_distance = [1205.81010114]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 553798\n",
      "winning_nuclei_distance = 1205.8101011353322\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [553798]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 553798\n",
      "winning_nuclei_distance = 1205.8101011353322\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 553798, 'nuclei_distance': 1205.81, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 553798\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135012431606_0_proofread.pbz2\n",
      "File size is 2.438824 MB\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 25, # error synapses  = 14, # error presyns = 12\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 349, # error synapses  = 0, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n"
     ]
    }
   ],
   "source": [
    "import classification_utils as clu\n",
    "from pykdtree.kdtree import KDTree\n",
    "import proofreading_utils as pru\n",
    "import neuron_utils as nru\n",
    "import time\n",
    "import trimesh_utils as tu\n",
    "import datajoint_utils as du\n",
    "import numpy as np\n",
    "\n",
    "def proofreading_table_processing(key,\n",
    "                                  proof_version,\n",
    "                                  compute_synapse_to_soma_skeletal_distance=True,\n",
    "                                 verbose=True,)\n",
    "    \"\"\"\n",
    "    Purpose: To do the proofreading and synapse filtering \n",
    "    for the datajoint tables\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Pull Down All of the Neurons\n",
    "    segment_id = key[\"segment_id\"]\n",
    "\n",
    "    print(f\"\\n\\n------- AutoProofreadNeuron {segment_id}  ----------\")\n",
    "\n",
    "    neuron_objs,neuron_split_idxs = du.decomposition_with_spine_recalculation(segment_id)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Number of Neurons found ={len(neuron_objs)}\")\n",
    "\n",
    "\n",
    "    # 2)  ----- Pre-work ------\n",
    "\n",
    "    nucleus_ids,nucleus_centers = du.segment_to_nuclei(segment_id)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Number of Corresponding Nuclei = {len(nucleus_ids)}\")\n",
    "        print(f\"nucleus_ids = {nucleus_ids}\")\n",
    "        print(f\"nucleus_centers = {nucleus_centers}\")\n",
    "\n",
    "\n",
    "\n",
    "    original_mesh = du.fetch_segment_id_mesh(segment_id)\n",
    "    original_mesh_kdtree = KDTree(original_mesh.triangles_center)\n",
    "\n",
    "\n",
    "\n",
    "    # 3) ----- Iterate through all of the Neurons and Proofread --------\n",
    "\n",
    "    # lists to help save stats until write to ProofreadStats Table\n",
    "    filtering_info_list = []\n",
    "    synapse_stats_list = []\n",
    "    total_error_synapse_ids_list = []\n",
    "\n",
    "\n",
    "    for split_index,neuron_obj_pre_split in zip(neuron_split_idxs,neuron_objs):\n",
    "\n",
    "        whole_pass_time = time.time()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n-----Working on Neuron Split {split_index}-----\")\n",
    "\n",
    "\n",
    "\n",
    "        neuron_obj = neuron_obj_pre_split\n",
    "    #             if neuron_obj_pre_split.n_error_limbs > 0:\n",
    "    #                 if verbose:\n",
    "    #                     print(f\"   ---> Pre-work: Splitting Neuron Limbs Because still error limbs exist--- \")\n",
    "    #                 neuron_objs_split = pru.split_neuron(neuron_obj_pre_split,\n",
    "    #                                              verbose=False)\n",
    "\n",
    "    #                 if len(neuron_objs_split) > 1:\n",
    "    #                     raise Exception(f\"After splitting the neuron there were more than 1: {neuron_objs_split}\")\n",
    "\n",
    "    #                 neuron_obj= neuron_objs_split[0]\n",
    "    #             else:\n",
    "    #                 neuron_obj = neuron_obj_pre_split\n",
    "\n",
    "\n",
    "\n",
    "        # Part A: Proofreading the Neuron\n",
    "        if verbose:\n",
    "            print(f\"\\n   --> Part A: Proofreading the Neuron ----\")\n",
    "\n",
    "\n",
    "    #     nviz.visualize_neuron(neuron_obj,\n",
    "    #                       limb_branch_dict=\"all\")\n",
    "\n",
    "\n",
    "\n",
    "        output_dict= pru.proofread_neuron(neuron_obj,\n",
    "                            plot_limb_branch_filter_with_disconnect_effect=False,\n",
    "                            plot_final_filtered_neuron=False,\n",
    "                            verbose=True)\n",
    "\n",
    "        filtered_neuron = output_dict[\"filtered_neuron\"]\n",
    "        cell_type_info = output_dict[\"cell_type_info\"]\n",
    "        filtering_info = output_dict[\"filtering_info\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Part B: Getting Soma Centers and Matching To Nuclei\n",
    "        if verbose:\n",
    "            print(f\"\\n\\n    --> Part B: Getting Soma Centers and Matching To Nuclei ----\")\n",
    "\n",
    "\n",
    "        winning_nucleus_id, nucleus_info = nru.pair_neuron_obj_to_nuclei(filtered_neuron,\n",
    "                                 \"S0\",\n",
    "                                  nucleus_ids,\n",
    "                                  nucleus_centers,\n",
    "                                 nuclei_distance_threshold = 15000,\n",
    "                                  return_matching_info = True,\n",
    "                                 verbose=True)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"nucleus_info = {nucleus_info}\")\n",
    "            print(f\"winning_nucleus_id = {winning_nucleus_id}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Part C: Getting the Faces of the Original Mesh\n",
    "        if verbose:\n",
    "            print(f\"\\n\\n    --> Part C: Getting the Faces of the Original Mesh ----\")\n",
    "\n",
    "        original_mesh_faces = tu.original_mesh_faces_map(original_mesh,\n",
    "                                                    filtered_neuron.mesh,\n",
    "                                                    exact_match=True,\n",
    "                                                    original_mesh_kdtree=original_mesh_kdtree)\n",
    "\n",
    "        original_mesh_faces_file = du.save_proofread_faces(original_mesh_faces,\n",
    "                                                          segment_id=segment_id,\n",
    "                                                          split_index=split_index,\n",
    "                                    file_name_ending=f\"proofv{proof_version}_neuron\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     nviz.plot_objects(recovered_mesh)\n",
    "\n",
    "\n",
    "        # Part C.2: Getting the axon information to use for the synapse erroring\n",
    "        axon_limb_branch_dict = clu.axon_limb_branch_dict(filtered_neuron)\n",
    "\n",
    "        axon_skeletal_length = nru.sum_feature_over_limb_branch_dict(filtered_neuron,\n",
    "                                         limb_branch_dict=axon_limb_branch_dict,\n",
    "                                         feature=\"skeletal_length\")\n",
    "\n",
    "        axon_mesh_area = nru.sum_feature_over_limb_branch_dict(filtered_neuron,\n",
    "                                             limb_branch_dict=axon_limb_branch_dict,\n",
    "                                             feature=\"area\")\n",
    "\n",
    "        axon_face_labels = clu.axon_faces_from_labels_on_original_mesh(filtered_neuron,\n",
    "                                               original_mesh=original_mesh,\n",
    "                                               original_mesh_kdtree=original_mesh_kdtree,\n",
    "                                                plot_axon=False,\n",
    "                                               verbose=False,)\n",
    "\n",
    "        original_mesh_faces_file_axon = du.save_proofread_faces(original_mesh_faces,\n",
    "                                                          segment_id=segment_id,\n",
    "                                                          split_index=split_index,\n",
    "                                                    file_name_ending=f\"proofv{proof_version}_axon\")\n",
    "\n",
    "        # Part D: Getting the Synapse Information\n",
    "        if verbose:\n",
    "            print(f\"\\n\\n    --> Part D: Getting the Synapse Information ----\")\n",
    "\n",
    "\n",
    "        (keys_to_write_without_version,\n",
    "         synapse_stats,\n",
    "         total_error_synapse_ids\n",
    "        ) = pru.synapse_filtering(filtered_neuron,\n",
    "                        split_index,\n",
    "                        nucleus_id=winning_nucleus_id,\n",
    "                        segment_id=None,\n",
    "                        return_synapse_filter_info = True,\n",
    "                        return_synapse_center_data = False,\n",
    "                        return_error_synapse_ids = True,\n",
    "                       return_valid_synapse_centers=compute_synapse_to_soma_skeletal_distance,\n",
    "                        mapping_threshold = 500,\n",
    "                          plot_synapses=False,\n",
    "                        verbose = True,\n",
    "                        original_mesh_method = True,\n",
    "                        original_mesh = original_mesh,\n",
    "                        original_mesh_kdtree = original_mesh_kdtree,\n",
    "                        valid_faces_on_original_mesh=original_mesh_faces, \n",
    "                        axon_faces_on_original_mesh=axon_face_labels,\n",
    "\n",
    "                        )\n",
    "\n",
    "        # -- 2/15: Will calculate the synapse distances ---- #\n",
    "\n",
    "        keys_to_write = [dict(k,ver=key[\"ver\"])\n",
    "                                     for k in keys_to_write_without_version]\n",
    "\n",
    "\n",
    "\n",
    "        soma_x,soma_y,soma_z = nru.soma_centers(filtered_neuron,\n",
    "                                           soma_name=\"S0\",\n",
    "                                           voxel_adjustment=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #7) Creating the dictionary to insert into the AutoProofreadNeuron\n",
    "        new_key = dict(key,\n",
    "                       split_index = split_index,\n",
    "                       proof_version = proof_version,\n",
    "\n",
    "                       multiplicity = len(neuron_objs),\n",
    "\n",
    "                       # -------- Important Excitatory Inhibitory Classfication ------- #\n",
    "                    cell_type_predicted = cell_type_info[\"inh_exc_class\"],\n",
    "                    spine_category=cell_type_info[\"spine_category\"],\n",
    "\n",
    "                    n_axons=cell_type_info[\"n_axons\"],\n",
    "                    n_apicals=cell_type_info[\"n_axons\"],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # ----- Soma Information ----#\n",
    "                    nucleus_id         = nucleus_info[\"nuclei_id\"],\n",
    "                    nuclei_distance      = np.round(nucleus_info[\"nuclei_distance\"],2),\n",
    "                    n_nuclei_in_radius   = nucleus_info[\"n_nuclei_in_radius\"],\n",
    "                    n_nuclei_in_bbox     = nucleus_info[\"n_nuclei_in_bbox\"],\n",
    "\n",
    "                    soma_x           = soma_x,\n",
    "                    soma_y           =soma_y,\n",
    "                    soma_z           =soma_z,\n",
    "\n",
    "                    # ---------- Mesh Faces ------ #\n",
    "                    mesh_faces = original_mesh_faces_file,\n",
    "\n",
    "\n",
    "                    # ------------- The Regular Neuron Information (will be computed in the stats dict) ----------------- #\n",
    "\n",
    "\n",
    "\n",
    "                       # ------ Information Used For Excitatory Inhibitory Classification -------- \n",
    "                    axon_angle_maximum=cell_type_info[\"axon_angle_maximum\"],\n",
    "                    spine_density_classifier=cell_type_info[\"neuron_spine_density\"],\n",
    "                    n_branches_processed=cell_type_info[\"n_branches_processed\"],\n",
    "                    skeletal_length_processed=cell_type_info[\"skeletal_length_processed\"],\n",
    "                    n_branches_in_search_radius=cell_type_info[\"n_branches_in_search_radius\"],\n",
    "                    skeletal_length_in_search_radius=cell_type_info[\"skeletal_length_in_search_radius\"],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                       run_time=np.round(time.time() - whole_pass_time,4)\n",
    "                      )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        stats_dict = filtered_neuron.neuron_stats()\n",
    "        new_key.update(stats_dict)\n",
    "\n",
    "\n",
    "#     # ------ Writing the Data To the Tables ----- #\n",
    "#     SynapseProofread.insert(keys_to_write,skip_duplicates=True)\n",
    "\n",
    "#     self.insert1(new_key,skip_duplicates=True,allow_direct_insert=True)\n",
    "\n",
    "\n",
    "\n",
    "#     #saving following information for later processing:\n",
    "#     filtering_info_list.append(filtering_info)\n",
    "#     synapse_stats_list.append(synapse_stats)\n",
    "#     total_error_synapse_ids_list.append(total_error_synapse_ids)\n",
    "\n",
    "\n",
    "\n",
    "# # Once have inserted all the new neurons need to compute the stats\n",
    "# if verbose:\n",
    "#     print(\"Computing the overall stats\")\n",
    "\n",
    "# overall_syn_error_rates = pru.calculate_error_rate(total_error_synapse_ids_list,\n",
    "#                 synapse_stats_list,\n",
    "#                 verbose=True)\n",
    "\n",
    "\n",
    "# # Final Part: Create the stats table entries and insert\n",
    "\n",
    "# proofread_stats_entries = []\n",
    "\n",
    "# stats_to_make_sure_in_proofread_stats = [\n",
    "\n",
    "#  'axon_on_dendrite_merges_error_area',\n",
    "#  'axon_on_dendrite_merges_error_length',\n",
    "#  'low_branch_clusters_error_area',\n",
    "#  'low_branch_clusters_error_length',\n",
    "#  'dendrite_on_axon_merges_error_area',\n",
    "#  'dendrite_on_axon_merges_error_length',\n",
    "#  'double_back_and_width_change_error_area',\n",
    "#  'double_back_and_width_change_error_length',\n",
    "#  'crossovers_error_area',\n",
    "#  'crossovers_error_length',\n",
    "#  'high_degree_coordinates_error_area',\n",
    "#  'high_degree_coordinates_error_length',\n",
    "# ]\n",
    "\n",
    "\n",
    "# for sp_idx,split_index in enumerate(neuron_split_idxs):\n",
    "#     synapse_stats = synapse_stats_list[sp_idx]\n",
    "#     filtering_info = filtering_info_list[sp_idx]\n",
    "\n",
    "#     curr_key = dict(key,\n",
    "#                    split_index = split_index,\n",
    "#                    proof_version = proof_version,\n",
    "\n",
    "\n",
    "#                     # ------------ For local valid synapses to that split_index\n",
    "#                     n_valid_syn_presyn_for_split=synapse_stats[\"n_valid_syn_presyn\"],\n",
    "#                     n_valid_syn_postsyn_for_split=synapse_stats[\"n_valid_syn_postsyn\"],\n",
    "#                     n_presyn_error_syn_non_axon = synapse_stats[\"n_errored_syn_presyn_non_axon\"],\n",
    "\n",
    "\n",
    "\n",
    "#                    )\n",
    "\n",
    "\n",
    "#     for s in stats_to_make_sure_in_proofread_stats:\n",
    "#         if s not in filtering_info.keys():\n",
    "#             curr_key[s] = None\n",
    "\n",
    "#     filter_key = {k:np.round(v,2) for k,v in filtering_info.items() if \"area\" in k or \"length\" in k}\n",
    "#     curr_key.update(filter_key)\n",
    "#     curr_key.update(overall_syn_error_rates)\n",
    "\n",
    "#     proofread_stats_entries.append(curr_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135012431606  ----------\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Pulled from Table Decomposition so setting split_index = 0\n",
      "Number of Neurons found = 1\n",
      "Number of Neurons found =1\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [553798]\n",
      "nucleus_centers = [[1271552  476288  971040]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Axon Classification = 20.526360273361206\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Did not pass final filters to continuing\n",
      "Inhibitory Excitatory Classification = 9.175243377685547\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={5: {0: 166.80806361041965}}\n",
      "n_axons=1\n",
      "n_apicals=1\n",
      "neuron_spine_density=0.0007039278693363126\n",
      "n_branches_processed=66\n",
      "skeletal_length_processed=4025200.4013470314\n",
      "n_branches_in_search_radius=96\n",
      "skeletal_length_in_search_radius=4425974.773983242\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L0': [0, 1, 2, 4, 51, 57]}\n",
      "total_sk_distance = 105.67144439771742, total_area = 201.52489420519615\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "local_results = {'axon_on_dendrite_merges_neuron': <neuron.Neuron object at 0x7f972db59908>, 'axon_on_dendrite_merges_time': 24.18493151664734, 'axon_on_dendrite_merges_error_area': 201.52489420519615, 'axon_on_dendrite_merges_error_length': 105.67144439771742}\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = low_branch_clusters\n",
      "function __name__ = filter_away_low_branch_length_clusters\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_restriction = {'L0': array([34, 42, 45]), 'L1': array([6]), 'L3': array([0]), 'L5': array([ 4, 15, 19])}\n",
      "--- Working on Limb L0 ---\n",
      "nodes_to_keep = [34 42 45]\n",
      "--- Working on Limb L1 ---\n",
      "nodes_to_keep = [6]\n",
      "--- Working on Limb L3 ---\n",
      "nodes_to_keep = [0]\n",
      "--- Working on Limb L5 ---\n",
      "nodes_to_keep = [ 4 15 19]\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter low_branch_clusters Results --\n",
      "local_results = {'low_branch_clusters_neuron': <neuron.Neuron object at 0x7f974c520ba8>, 'low_branch_clusters_time': 0.3782055377960205, 'low_branch_clusters_error_area': 0, 'low_branch_clusters_error_length': 0}\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = dendrite_on_axon_merges\n",
      "function __name__ = filter_away_dendrite_on_axon_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "Using pre-existing axon and axon-like labels\n",
      "dendritic_branches_merged_on_axon = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter dendrite_on_axon_merges Results --\n",
      "local_results = {'dendrite_on_axon_merges_neuron': <neuron.Neuron object at 0x7f9862081828>, 'dendrite_on_axon_merges_time': 0.3487563133239746, 'dendrite_on_axon_merges_error_area': 0, 'dendrite_on_axon_merges_error_length': 0}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = double_back_and_width_change\n",
      "function __name__ = filter_away_large_double_back_or_width_changes\n",
      "function arguments = {'perform_double_back_errors': True, 'skip_double_back_errors_for_axon': False, 'width_jump_threshold': 250, 'running_width_jump_method': True, 'double_back_axon_like_threshold': 145, 'double_back_threshold': 120}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "\n",
      "After edges deleted and created: \n",
      "kept_branches= [0, 1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "removed_branches = [2, 3, 4, 5, 6]\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L5': [2, 3, 4, 5, 6]}\n",
      "total_sk_distance = 78.25468712058337, total_area = 51.14835488692928\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_and_width_change Results --\n",
      "local_results = {'double_back_and_width_change_neuron': <neuron.Neuron object at 0x7f971c4d0cc0>, 'double_back_and_width_change_time': 35.57221555709839, 'double_back_and_width_change_error_area': 51.14835488692928, 'double_back_and_width_change_error_length': 78.25468712058337}\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = crossovers\n",
      "function __name__ = filter_away_crossovers\n",
      "function arguments = {'axon_dependent': True, 'match_threshold': 30}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = [[1263760.  488791.  980440.]]\n",
      "branch 2 did not have one of the following in their labels : ['axon', 'axon-like']\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "crossover_coordinates = []\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter crossovers Results --\n",
      "local_results = {'crossovers_neuron': <neuron.Neuron object at 0x7f970a69f9b0>, 'crossovers_time': 6.371774911880493, 'crossovers_error_area': 0, 'crossovers_error_length': 0}\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = high_degree_coordinates\n",
      "function __name__ = filter_away_high_degree_coordinates\n",
      "function arguments = {'axon_dependent': True, 'min_degree_to_find': 4}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = [2784]\n",
      "curr_high_degree_coordinates = [[1263760.  488791.  980440.]]\n",
      "high_degree_branch_groups = [[2, 3, 4, 5]]\n",
      "branch 2 did not have one of the following in their labels : ['axon', 'axon-like']\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "curr_high_degree_nodes for get_nodes_greater_or_equal_degree_k = []\n",
      "high_degree_branch_groups = []\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "edges_to_create = []\n",
      "edges_to_create = []\n",
      "\n",
      "--- Working on Limb L0 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L1 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L2 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L3 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L4 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L5 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L6 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L7 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "\n",
      "--- Working on Limb L8 ---\n",
      "\n",
      "skipping because was not in the limb_edge dict\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_coordinates Results --\n",
      "local_results = {'high_degree_coordinates_neuron': <neuron.Neuron object at 0x7f974d4cd240>, 'high_degree_coordinates_time': 5.1442131996154785, 'high_degree_coordinates_error_area': 0, 'high_degree_coordinates_error_length': 0}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 72.00070929527283 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 101.70322346687317\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [1271591  477299  970384]\n",
      "nuclei_within_radius = [553798]\n",
      "nuclei_within_radius_distance = [1205.81010114]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 553798\n",
      "winning_nuclei_distance = 1205.8101011353322\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [553798]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 553798\n",
      "winning_nuclei_distance = 1205.8101011353322\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 553798, 'nuclei_distance': 1205.81, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 553798\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135012431606_0_proofv2_neuron_proofread.pbz2\n",
      "File size is 2.438824 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135012431606_0_proofv2_axon_proofread.pbz2\n",
      "File size is 2.438824 MB\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 25, # error synapses  = 14, # error presyns = 12\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 349, # error synapses  = 0, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n"
     ]
    }
   ],
   "source": [
    "key[\"ver\"] = 30\n",
    "curr_output = pru.proofreading_table_processing(key,\n",
    "                                  proof_version=2,\n",
    "                                  compute_synapse_to_soma_skeletal_distance=True,\n",
    "                                 verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AutoProofreadSynapse_keys', 'AutoProofreadNeurons_keys', 'filtering_info_list', 'synapse_stats_list', 'total_error_synapse_ids_list', 'neuron_mesh_list', 'axon_mesh_list'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoProofreadSynapse_keys = curr_output[\"AutoProofreadSynapse_keys\"]\n",
    "AutoProofreadNeurons_keys = curr_output[\"AutoProofreadNeurons_keys\"]\n",
    "filtering_info_list = curr_output[\"filtering_info_list\"]\n",
    "synapse_stats_list = curr_output[\"synapse_stats_list\"]\n",
    "total_error_synapse_ids_list = curr_output[\"total_error_synapse_ids_list\"]\n",
    "neuron_mesh_list = curr_output[\"neuron_mesh_list\"]\n",
    "axon_mesh_list = curr_output[\"axon_mesh_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135012431606_0_proofv2_axon_proofread.pbz2')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axon_mesh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_valid_syn_presyn': 25,\n",
       " 'n_errored_syn_presyn': 14,\n",
       " 'n_errored_syn_presyn_non_axon': 12,\n",
       " 'n_valid_syn_postsyn': 349,\n",
       " 'n_errored_syn_postsyn': 0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synapse_stats = synapse_stats_list[0]\n",
    "synapse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recieved another instance of Neuron class in init -- so just copying data\n"
     ]
    }
   ],
   "source": [
    "import neuron\n",
    "filtered_neuron = neuron.Neuron(filtered_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nru.clear_all_branch_labels(filtered_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 25, # error synapses  = 14, # error presyns = 12\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 349, # error synapses  = 0, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n"
     ]
    }
   ],
   "source": [
    "# Part D: Getting the Synapse Information\n",
    "if verbose:\n",
    "    print(f\"\\n\\n    --> Part D: Getting the Synapse Information ----\")\n",
    "\n",
    "\n",
    "(keys_to_write,\n",
    " synapse_stats,\n",
    " total_error_synapse_ids\n",
    ") = pru.synapse_filtering(filtered_neuron,\n",
    "                split_index,\n",
    "                nucleus_id=winning_nucleus_id,\n",
    "                segment_id=None,\n",
    "                return_synapse_filter_info = True,\n",
    "                return_synapse_center_data = False,\n",
    "                return_error_synapse_ids = True,\n",
    "               return_valid_synapse_centers=compute_synapse_to_soma_skeletal_distance,\n",
    "                mapping_threshold = 500,\n",
    "                  plot_synapses=False,\n",
    "                verbose = True,\n",
    "                original_mesh_method = True,\n",
    "                original_mesh = original_mesh,\n",
    "                original_mesh_kdtree = original_mesh_kdtree,\n",
    "                valid_faces_on_original_mesh=original_mesh_faces, \n",
    "                axon_faces_on_original_mesh=axon_face_labels,\n",
    "\n",
    "                )\n",
    "\n",
    "# # -- 2/15: Will calculate the synapse distances ---- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# soma_x,soma_y,soma_z = nru.soma_centers(filtered_neuron,\n",
    "#                                    soma_name=\"S0\",\n",
    "#                                    voxel_adjustment=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #7) Creating the dictionary to insert into the AutoProofreadNeuron\n",
    "# new_key = dict(key,\n",
    "#                split_index = split_index,\n",
    "#                proof_version = proof_version,\n",
    "\n",
    "#                multiplicity = len(neuron_objs),\n",
    "\n",
    "#                # -------- Important Excitatory Inhibitory Classfication ------- #\n",
    "#             cell_type_predicted = cell_type_info[\"inh_exc_class\"],\n",
    "#             spine_category=cell_type_info[\"spine_category\"],\n",
    "\n",
    "#             n_axons=cell_type_info[\"n_axons\"],\n",
    "#             n_apicals=cell_type_info[\"n_axons\"],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             # ----- Soma Information ----#\n",
    "#             nucleus_id         = nucleus_info[\"nuclei_id\"],\n",
    "#             nuclei_distance      = np.round(nucleus_info[\"nuclei_distance\"],2),\n",
    "#             n_nuclei_in_radius   = nucleus_info[\"n_nuclei_in_radius\"],\n",
    "#             n_nuclei_in_bbox     = nucleus_info[\"n_nuclei_in_bbox\"],\n",
    "\n",
    "#             soma_x           = soma_x,\n",
    "#             soma_y           =soma_y,\n",
    "#             soma_z           =soma_z,\n",
    "\n",
    "#             # ---------- Mesh Faces ------ #\n",
    "#             mesh_faces = original_mesh_faces_file,\n",
    "\n",
    "\n",
    "#             # ------------- The Regular Neuron Information (will be computed in the stats dict) ----------------- #\n",
    "\n",
    "\n",
    "\n",
    "#                # ------ Information Used For Excitatory Inhibitory Classification -------- \n",
    "#             axon_angle_maximum=cell_type_info[\"axon_angle_maximum\"],\n",
    "#             spine_density_classifier=cell_type_info[\"neuron_spine_density\"],\n",
    "#             n_branches_processed=cell_type_info[\"n_branches_processed\"],\n",
    "#             skeletal_length_processed=cell_type_info[\"skeletal_length_processed\"],\n",
    "#             n_branches_in_search_radius=cell_type_info[\"n_branches_in_search_radius\"],\n",
    "#             skeletal_length_in_search_radius=cell_type_info[\"skeletal_length_in_search_radius\"],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                run_time=np.round(time.time() - whole_pass_time,4)\n",
    "#               )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# stats_dict = filtered_neuron.neuron_stats()\n",
    "# new_key.update(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'synapse_id': 346660423,\n",
       " 'synapse_type': 'presyn',\n",
       " 'nucleus_id': 553798,\n",
       " 'segment_id': 864691135012431606,\n",
       " 'split_index': 0,\n",
       " 'skeletal_distance_to_soma': 412.54,\n",
       " 'syn_center': array([1147376,  787064,  904120])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_to_write[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1267216,  479936,  972040],\n",
       "       [1267500,  476940,  976120],\n",
       "       [1267424,  480608,  972200],\n",
       "       [1269300,  482876,  972320],\n",
       "       [1273304,  480880,  974880],\n",
       "       [1273156,  482000,  973600],\n",
       "       [1275160,  473596,  973320],\n",
       "       [1266288,  481528,  968880],\n",
       "       [1266392,  480176,  969400],\n",
       "       [1267016,  477764,  970200],\n",
       "       [1267064,  475632,  969200],\n",
       "       [1267296,  477608,  967960],\n",
       "       [1267496,  482200,  970320],\n",
       "       [1267472,  484040,  967600],\n",
       "       [1267752,  473864,  968280],\n",
       "       [1268368,  478456,  965920],\n",
       "       [1268456,  472192,  967640],\n",
       "       [1268812,  479308,  965760],\n",
       "       [1269008,  471456,  966400],\n",
       "       [1269808,  472120,  965840],\n",
       "       [1271808,  476988,  964560],\n",
       "       [1272120,  479536,  964160],\n",
       "       [1273120,  483160,  971080],\n",
       "       [1274904,  473952,  969200],\n",
       "       [1275152,  482176,  971160],\n",
       "       [1269696,  470596,  965840],\n",
       "       [1270624,  470024,  971520],\n",
       "       [1271400,  469820,  971240],\n",
       "       [1276048,  481656,  971120],\n",
       "       [1277552,  479232,  970520]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synapse_dict_no_path = [k for k in keys_to_write if k[\"skeletal_distance_to_soma\"] == -1]\n",
    "centers_to_plot = np.array([k[\"syn_center\"] for k in synapse_dict_no_path])\n",
    "centers_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c4c1258b284aa9a58f7e2de303be4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), projectionMatrix=(1.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(filtered_neuron.mesh,\n",
    "                 scatters=[centers_to_plot],\n",
    "                 scatters_colors=\"red\",\n",
    "                 scatter_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
