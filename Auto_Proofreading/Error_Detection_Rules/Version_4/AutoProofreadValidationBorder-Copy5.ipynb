{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To decompose the multi-somas for splitting\n",
    "using the new decomposition method\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the contains method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import neuron_utils as nru\n",
    "\n",
    "import neuron\n",
    "\n",
    "import neuron_visualizations as nviz\n",
    "\n",
    "import time\n",
    "\n",
    "import datajoint_utils as du\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import preprocessing_vp2 as pre\n",
    "\n",
    "# -- For the axon classification --\n",
    "\n",
    "import neuron_searching as ns\n",
    "\n",
    "import skeleton_utils as sk\n",
    "\n",
    "import numpy_utils as nu\n",
    "\n",
    "import networkx_utils as xu\n",
    "\n",
    "import system_utils as su\n",
    "\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "import trimesh_utils as tu\n",
    "import proofreading_utils as pru\n",
    "import numpy as np\n",
    "import axon_utils as au\n",
    "import validation_utils as vu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Auto Proofread Neuron Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minnie,schema = du.configure_minnie_vm()\n",
    "# minnie.AutoProofreadValidationBorderNeurons.drop()\n",
    "# minnie.AutoProofreadValidationBorder.drop()\n",
    "# minnie.schema.external['decomposition'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class AutoProofreadValidationBorderNeurons(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.AutoProofreadValidationStats3()\n",
    "    ---\n",
    "    decomposition: <decomposition>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "verbose = True\n",
    "axon_version = 0\n",
    "@schema\n",
    "class AutoProofreadValidationBorder(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.AutoProofreadValidationStats3()\n",
    "    axon_version    : tinyint unsigned \n",
    "    parent_idx: smallint unsigned\n",
    "    ---\n",
    "    n_downstream=NULL: smallint unsigned\n",
    "    web_size_faces=NULL : smallint unsigned\n",
    "    web_size_volume=NULL : double\n",
    "    web_size_skeleton=NULL : double\n",
    "    web_size_ray_trace_percentile=NULL : double\n",
    "    web_bbox_ratios_max=NULL: double\n",
    "    web_bbox_ratios_min=NULL: double\n",
    "    web_volume_ratio=NULL: double\n",
    "    web_cdf=NULL: double\n",
    "    parent_n_large_boutons=NULL : tinyint unsigned \n",
    "    parent_n_boutons=NULL : tinyint unsigned \n",
    "    parent_no_bouton_median=NULL : double\n",
    "    parent_no_spine_median_mesh_center=NULL : double\n",
    "    child_no_bouton_median_min =NULL: double\n",
    "    child_no_bouton_median_diff_min=NULL : double\n",
    "    child_no_spine_median_mesh_center_min=NULL :double\n",
    "    child_no_spine_median_mesh_center_diff_min=NULL : double\n",
    "    child_angle_min=NULL : double\n",
    "    child_n_boutons_min=NULL : tinyint unsigned\n",
    "    child_n_large_boutons_min=NULL : tinyint unsigned\n",
    "    child_no_bouton_median_max =NULL: double\n",
    "    child_no_bouton_median_diff_max=NULL: double\n",
    "    child_no_spine_median_mesh_center_max=NULL : double\n",
    "    child_no_spine_median_mesh_center_diff_max=NULL :double\n",
    "    child_angle_max=NULL : double\n",
    "    child_n_boutons_max =NULL: tinyint unsigned\n",
    "    child_n_large_boutons_max=NULL : tinyint unsigned\n",
    "    sibling_angles_min=NULL: double\n",
    "    sibling_angles_max=NULL: double\n",
    "    label: varchar(10)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    key_source = du.proofreading_stats_table(validation=True) & \"segment_id = 864691136105498585\"\n",
    "    \n",
    "    \n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        1) Pull down the neuron object\n",
    "        2) Run the complete axon preprocessing on the neuron\n",
    "        3) Run the borders attributes dictionary\n",
    "        4) Save off the neuron object\n",
    "        5) Write the Attribute records\n",
    "\n",
    "        \"\"\"\n",
    "        print(f\"\\n\\n\\n---- Working on Neuron {key['segment_id']} ----\")\n",
    "        \n",
    "        # 1) Pull Down All of the Neurons\n",
    "        segment_id = key[\"segment_id\"]\n",
    "        \n",
    "        whole_pass_time = time.time()\n",
    "        neuron_objs,neuron_split_idxs = du.decomposition_with_spine_recalculation(segment_id)    \n",
    "        neuron_obj = neuron_objs[0]\n",
    "        \n",
    "        #2) Run the complete axon preprocessing on the neuron\n",
    "        neuron_obj_with_web = au.complete_axon_processing(neuron_obj,\n",
    "                                                 verbose=True)\n",
    "        \n",
    "        \n",
    "        branch_attr = vu.neuron_to_border_branching_attributes(neuron_obj_with_web,\n",
    "                                         plot_valid_border_branches=False,\n",
    "                                          plot_invalid_border_branches = False,\n",
    "                                          verbose=False\n",
    "                                         )\n",
    "        \n",
    "        #3) Run the borders attributes dictionary\n",
    "        branch_attr_keys = []\n",
    "        for k in branch_attr:\n",
    "            new_dict  = dict(key)\n",
    "            new_dict.update(k)\n",
    "            new_dict[\"axon_version\"] = axon_version\n",
    "            branch_attr_keys.append(new_dict)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"\\n\\nlen(branch_attr_keys) = {len(branch_attr_keys)}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        #4) Save the file in a certain location\n",
    "        save_time = time.time()\n",
    "        ret_file_path = neuron_obj_with_web.save_compressed_neuron(output_folder=str(du.get_decomposition_path()),\n",
    "                                        file_name=f\"{neuron_obj_with_web.segment_id}_validation_full_axon\",\n",
    "                                          return_file_path=True,\n",
    "                                         export_mesh=False,\n",
    "                                         suppress_output=False)\n",
    "\n",
    "        ret_file_path_str = str(ret_file_path.absolute()) + \".pbz2\"\n",
    "        print(f\"ret_file_path_str = {ret_file_path_str}\")\n",
    "        print(f\"Save time = {time.time() - save_time}\")\n",
    "        \n",
    "        n_dict = dict(key,\n",
    "                     decomposition=ret_file_path_str)\n",
    "        \n",
    "        AutoProofreadValidationBorderNeurons.insert1(n_dict,skip_duplicates=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #5) Write the Attribute records\n",
    "        if len(branch_attr_keys)>0:\n",
    "            AutoProofreadValidationBorder.insert(branch_attr_keys,skip_duplicates=True)\n",
    "\n",
    "    \n",
    "\n",
    "        print(f\"\\n\\n ***------ Total time for {key['segment_id']} = {time.time() - whole_pass_time} ------ ***\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config[\"display.limit\"] = 30\n",
    "curr_table = (minnie.schema.jobs & \"table_name='__auto_proofread_validation_border'\")\n",
    "(curr_table)#.delete()# & \"status='error'\")\n",
    "#curr_table.delete()\n",
    "#(curr_table & \"error_message = 'ValueError: need at least one array to concatenate'\").delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((curr_table & dict(key_hash= \"077ea534023ee66ee5d8e6336bb25774\")).fetch1(\"error_stack\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((curr_table & dict(key_hash= \"077ea534023ee66ee5d8e6336bb25774\")).fetch1(\"key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (curr_table & dict(key_hash= \"077ea534023ee66ee5d8e6336bb25774\")).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import neuron\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "neuron = reload(neuron)\n",
    "import neuron_searching as ns\n",
    "ns = reload(ns)\n",
    "clu = reload(clu)\n",
    "du = reload(du)\n",
    "import axon_utils as au\n",
    "au = reload(au)\n",
    "import random\n",
    "import skeleton_utils as sk\n",
    "sk = reload(sk)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    AutoProofreadValidationBorder.populate(reserve_jobs=True, suppress_errors=True, order=\"random\")\n",
    "else:\n",
    "    AutoProofreadValidationBorder.populate(reserve_jobs=True, suppress_errors=False, order=\"random\")\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for AutoProofreadValidationBorder populate = {time.time() - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
