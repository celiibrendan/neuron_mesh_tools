{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To decompose the multi-somas for splitting\\nusing the new decomposition method\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To decompose the multi-somas for splitting\n",
    "using the new decomposition method\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-08 07:15:03,852 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-02-08 07:15:03,853 - settings - Setting database.user to celiib\n",
      "INFO - 2021-02-08 07:15:03,854 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-02-08 07:15:03,858 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-02-08 07:15:03,859 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-02-08 07:15:03,872 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-08 07:15:04,164 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the contains method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-08 07:15:04,247 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-02-08 07:15:04,249 - settings - Setting database.user to celiib\n",
      "INFO - 2021-02-08 07:15:04,250 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-02-08 07:15:04,252 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 155 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-08 07:15:04,552 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import neuron_utils as nru\n",
    "\n",
    "import neuron\n",
    "\n",
    "import neuron_visualizations as nviz\n",
    "\n",
    "import time\n",
    "\n",
    "import datajoint_utils as du\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import preprocessing_vp2 as pre\n",
    "\n",
    "# -- For the axon classification --\n",
    "\n",
    "import neuron_searching as ns\n",
    "\n",
    "import skeleton_utils as sk\n",
    "\n",
    "import numpy_utils as nu\n",
    "\n",
    "import networkx_utils as xu\n",
    "\n",
    "import system_utils as su\n",
    "\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "import trimesh_utils as tu\n",
    "import proofreading_utils as pru\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 9848\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Synapse Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class SynapseProofread(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    synapse_id           : bigint unsigned              # synapse index within the segmentation\n",
    "    synapse_type: enum('presyn','postsyn')\n",
    "    ---\n",
    "    segment_id           : bigint unsigned              # segment_id of the cell. Equivalent to Allen 'pt_root_id\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'. \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Proofreading Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis table will include the following information:\\n\\n1) Filtering Info\\n2) Synapse Stats for Individual Neuron\\n3) Synapse Stats for Segment\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This table will include the following information:\n",
    "\n",
    "1) Filtering Info\n",
    "2) Synapse Stats for Individual Neuron\n",
    "3) Synapse Stats for Segment\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class ProofreadStats(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    proof_version    : tinyint unsigned             # the version of code used for this cell typing classification\n",
    "    ---\n",
    "    \n",
    "    axon_on_dendrite_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    axon_on_dendrite_merges_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    low_branch_clusters_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    low_branch_clusters_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    dendrite_on_axon_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    dendrite_on_axon_merges_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    double_back_and_width_change_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    double_back_and_width_change_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    crossovers_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    crossovers_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    high_degree_coordinates_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    high_degree_coordinates_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    # ------------ For local valid synapses to that split_index\n",
    "    n_valid_syn_presyn_for_split: int unsigned\n",
    "    n_valid_syn_postsyn_for_split : int unsigned\n",
    "    \n",
    "    # ------------ For global stats belonging to the whole segment\n",
    "    # For the whole segment\n",
    "    n_presyn_error_syn: int unsigned\n",
    "    n_postsyn_error_syn: int unsigned\n",
    "    total_error_synapses: int unsigned\n",
    "    \n",
    "    total_presyns: int unsigned \n",
    "    total_postsyns: int unsigned \n",
    "    total_synapses:int unsigned\n",
    "    \n",
    "    perc_error_presyn=NULL: double\n",
    "    perc_error_postsyn=NULL: double\n",
    "    \n",
    "    overall_percent_error=NULL: double\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Auto Proofread Neuron Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minnie.AutoProofreadNeurons.drop()\n",
    "# minnie.ProofreadStats.drop()\n",
    "# minnie.SynapseProofread.drop()\n",
    "# minnie.schema.external['faces'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import classification_utils as clu\n",
    "\n",
    "proof_version = 0\n",
    "\n",
    "verbose = True\n",
    "\n",
    "@schema\n",
    "class AutoProofreadNeurons(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    proof_version    : tinyint unsigned             # the version of code used for this cell typing classification\n",
    "    ---\n",
    "    multiplicity  : tinyint unsigned   # the total number of neurons that came from the parent segment id\n",
    "    # -------- Important Excitatory Inhibitory Classfication ------- #\n",
    "    cell_type_predicted: enum('excitatory','inhibitory','other','unknown') # morphology predicted by classifier\n",
    "    spine_category: enum('no_spined','sparsely_spined','densely_spined')\n",
    "    \n",
    "    n_axons: tinyint unsigned             # Number of axon candidates identified\n",
    "    n_apicals: tinyint unsigned             # Number of apicals identified\n",
    "    \n",
    "    \n",
    "    # ----- Soma Information ----#\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'.\n",
    "    nuclei_distance      : double                    # the distance to the closest nuclei (even if no matching nuclei found)\n",
    "    n_nuclei_in_radius   : tinyint unsigned          # the number of nuclei within the search radius of 15000 belonging to that segment\n",
    "    n_nuclei_in_bbox     : tinyint unsigned          # the number of nuclei within the bounding box of that soma\n",
    "    \n",
    "    soma_x            : int unsigned                 # x coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    soma_y            : int unsigned                 # y coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    soma_z            : int unsigned                 # z coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    \n",
    "    max_soma_n_faces     : int unsigned                 # The largest number of faces of the somas\n",
    "    max_soma_volume      : int unsigned                 # The largest volume of the somas the (volume in billions (10*9 nm^3))\n",
    "    \n",
    "    # ---- Stores Neuron Mesh Faces --------\n",
    "    mesh_faces: <faces>                      # faces indices that were saved off as belonging to proofread neuron (external storage)\n",
    "    \n",
    "    \n",
    "    # ------------- The Regular Neuron Information ----------------- #\n",
    "    n_vertices           : int unsigned                 # number of vertices\n",
    "    n_faces              : int unsigned                 # number of faces\n",
    "    n_not_processed_soma_containing_meshes : int unsigned  #the number of meshes with somas that were not processed\n",
    "    n_error_limbs: int #the number of limbs that are touching multiple somas or 1 soma in multiple places\n",
    "    n_same_soma_multi_touching_limbs: int # number of limbs that touch the same soma multiple times\n",
    "    n_multi_soma_touching_limbs: int # number of limbs that touch multiple somas\n",
    "    n_somas: int #number of soma meshes detected\n",
    "    n_limbs: int\n",
    "    n_branches: int\n",
    "    max_limb_n_branches=NULL:int\n",
    "    \n",
    "    skeletal_length=NULL: double\n",
    "    max_limb_skeletal_length=NULL:double\n",
    "    median_branch_length=NULL:double #gives information on average skeletal length to next branch point\n",
    "    \n",
    "    \n",
    "    width_median=NULL: double #median width from mesh center without spines removed\n",
    "    width_no_spine_median=NULL: double #median width from mesh center with spines removed\n",
    "    width_90_perc=NULL: double # 90th percentile for width without spines removed\n",
    "    width_no_spine_90_perc=NULL: double  # 90th percentile for width with spines removed\n",
    "    \n",
    "    \n",
    "    n_spines: bigint\n",
    "\n",
    "    spine_density=NULL: double # n_spines/ skeletal_length\n",
    "    spines_per_branch=NULL: double\n",
    "    \n",
    "    skeletal_length_eligible=NULL: double # the skeletal length for all branches searched for spines\n",
    "    n_spine_eligible_branches=NULL: int # the number of branches that were checked for spines because passed width threshold\n",
    "    \n",
    "    spine_density_eligible=NULL:double # n_spines/skeletal_length_eligible\n",
    "    spines_per_branch_eligible=NULL:double # n_spines/n_spine_eligible_branches\n",
    "    \n",
    "    total_spine_volume=NULL: double # the sum of all spine volume\n",
    "    spine_volume_median=NULL: double # median of the spine volume for those spines with able to calculate volume\n",
    "    spine_volume_density=NULL: double #total_spine_volume/skeletal_length\n",
    "    spine_volume_density_eligible=NULL: double #total_spine_volume/skeletal_length_eligible\n",
    "    spine_volume_per_branch_eligible=NULL: double #total_spine_volume/n_spine_eligible_branches\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------ Information Used For Excitatory Inhibitory Classification -------- \n",
    "    axon_angle_maximum=NULL:double #the anlge of an identified axon\n",
    "    spine_density_classifier:double              # the number of spines divided by skeletal length for branches analyzed in classification\n",
    "    n_branches_processed: int unsigned                 # the number branches used for the spine density analysis\n",
    "    skeletal_length_processed: double                 # The total skeletal length of the viable branches used for the spine density analysis\n",
    "    n_branches_in_search_radius: int unsigned                 # the number branches existing in the search radius used for spine density\n",
    "    skeletal_length_in_search_radius : double         # The total skeletal length of the branches existing in the search radius used for spine density\n",
    "    \n",
    "    \n",
    "\n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "                             \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    key_source = minnie.Decomposition() & minnie.NucleiSegmentsRun2() & \"segment_id=864691135651861970\"\n",
    "    \n",
    "    \n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        1) Pull Down All of the Neurons\n",
    "        2) Get the nucleus centers and the original mesh\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1) Pull Down All of the Neurons\n",
    "        segment_id = key[\"segment_id\"]\n",
    "        \n",
    "        print(f\"\\n\\n------- AutoProofreadNeuron {segment_id}  ----------\")\n",
    "        \n",
    "        neuron_objs,neuron_split_idxs = du.decomposition_with_spine_recalculation(segment_id)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Number of Neurons found ={len(neuron_objs)}\")\n",
    "        \n",
    "        \n",
    "        # 2)  ----- Pre-work ------\n",
    "\n",
    "        nucleus_ids,nucleus_centers = du.segment_to_nuclei(segment_id)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Number of Corresponding Nuclei = {len(nucleus_ids)}\")\n",
    "            print(f\"nucleus_ids = {nucleus_ids}\")\n",
    "            print(f\"nucleus_centers = {nucleus_centers}\")\n",
    "\n",
    "\n",
    "\n",
    "        original_mesh = du.fetch_segment_id_mesh(segment_id)\n",
    "        original_mesh_kdtree = KDTree(original_mesh.triangles_center)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 3) ----- Iterate through all of the Neurons and Proofread --------\n",
    "        \n",
    "        # lists to help save stats until write to ProofreadStats Table\n",
    "        filtering_info_list = []\n",
    "        synapse_stats_list = []\n",
    "        total_error_synapse_ids_list = []\n",
    "        \n",
    "        \n",
    "        for split_index,neuron_obj_pre_split in zip(neuron_split_idxs,neuron_objs):\n",
    "            \n",
    "            whole_pass_time = time.time()\n",
    "    \n",
    "            if verbose:\n",
    "                print(f\"\\n-----Working on Neuron Split {split_index}-----\")\n",
    "\n",
    "                \n",
    "            \n",
    "            \n",
    "            if neuron_obj_pre_split.n_error_limbs > 0:\n",
    "                if verbose:\n",
    "                    print(f\"   ---> Pre-work: Splitting Neuron Limbs Because still error limbs exist--- \")\n",
    "                neuron_objs_split = pru.split_neuron(neuron_obj_pre_split,\n",
    "                                             verbose=False)\n",
    "                \n",
    "                if len(neuron_objs_split) > 1:\n",
    "                    raise Exception(f\"After splitting the neuron there were more than 1: {neuron_objs_split}\")\n",
    "\n",
    "                neuron_obj= neuron_objs_split[0]\n",
    "            else:\n",
    "                neuron_obj = neuron_obj_pre_split\n",
    "            \n",
    "            \n",
    "\n",
    "            # Part A: Proofreading the Neuron\n",
    "            if verbose:\n",
    "                print(f\"\\n   --> Part A: Proofreading the Neuron ----\")\n",
    "\n",
    "\n",
    "        #     nviz.visualize_neuron(neuron_obj,\n",
    "        #                       limb_branch_dict=\"all\")\n",
    "        \n",
    "        \n",
    "\n",
    "            output_dict= pru.proofread_neuron(neuron_obj,\n",
    "                                plot_limb_branch_filter_with_disconnect_effect=False,\n",
    "                                plot_final_filtered_neuron=False,\n",
    "                                verbose=True)\n",
    "\n",
    "            filtered_neuron = output_dict[\"filtered_neuron\"]\n",
    "            cell_type_info = output_dict[\"cell_type_info\"]\n",
    "            filtering_info = output_dict[\"filtering_info\"]\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            # Part B: Getting Soma Centers and Matching To Nuclei\n",
    "            if verbose:\n",
    "                print(f\"\\n\\n    --> Part B: Getting Soma Centers and Matching To Nuclei ----\")\n",
    "\n",
    "\n",
    "            winning_nucleus_id, nucleus_info = nru.pair_segment_id_to_nuclei(neuron_obj,\n",
    "                                     \"S0\",\n",
    "                                      nucleus_ids,\n",
    "                                      nucleus_centers,\n",
    "                                     nuclei_distance_threshold = 15000,\n",
    "                                      return_matching_info = True,\n",
    "                                     verbose=True)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"nucleus_info = {nucleus_info}\")\n",
    "                print(f\"winning_nucleus_id = {winning_nucleus_id}\")\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Part C: Getting the Faces of the Original Mesh\n",
    "            if verbose:\n",
    "                print(f\"\\n\\n    --> Part C: Getting the Faces of the Original Mesh ----\")\n",
    "\n",
    "            original_mesh_faces = tu.original_mesh_faces_map(original_mesh,\n",
    "                                                        filtered_neuron.mesh,\n",
    "                                                        exact_match=True,\n",
    "                                                        original_mesh_kdtree=original_mesh_kdtree)\n",
    "            \n",
    "            original_mesh_faces_file = du.save_proofread_faces(original_mesh_faces,\n",
    "                                                              segment_id=segment_id,\n",
    "                                                              split_index=split_index)\n",
    "\n",
    "            \n",
    "\n",
    "        #     nviz.plot_objects(recovered_mesh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Part D: Getting the Synapse Information\n",
    "            if verbose:\n",
    "                print(f\"\\n\\n    --> Part D: Getting the Synapse Information ----\")\n",
    "\n",
    "\n",
    "            (keys_to_write,\n",
    "             synapse_stats,\n",
    "             total_error_synapse_ids) = pru.synapse_filtering(filtered_neuron,\n",
    "                            split_index,\n",
    "                            nucleus_id=winning_nucleus_id,\n",
    "                            segment_id=None,\n",
    "                            return_synapse_filter_info = True,\n",
    "                            return_synapse_center_data = False,\n",
    "                            return_error_synapse_ids = True,\n",
    "                            mapping_threshold = 500,\n",
    "                              plot_synapses=False,\n",
    "                            verbose = True,\n",
    "                            original_mesh_method = True,\n",
    "                            original_mesh = original_mesh,\n",
    "                            original_mesh_kdtree = original_mesh_kdtree,\n",
    "                            valid_faces_on_original_mesh=original_mesh_faces, \n",
    "                                                          \n",
    "                            )\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            soma_x,soma_y,soma_z = nru.soma_centers(filtered_neuron,\n",
    "                                               soma_name=\"S0\",\n",
    "                                               voxel_adjustment=True)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            #7) Creating the dictionary to insert into the AutoProofreadNeuron\n",
    "            new_key = dict(key,\n",
    "                           split_index = split_index,\n",
    "                           proof_version = proof_version,\n",
    "                           \n",
    "                           multiplicity = len(neuron_objs),\n",
    "                           \n",
    "                           # -------- Important Excitatory Inhibitory Classfication ------- #\n",
    "                        cell_type_predicted = cell_type_info[\"inh_exc_class\"],\n",
    "                        spine_category=cell_type_info[\"spine_category\"],\n",
    "\n",
    "                        n_axons=cell_type_info[\"n_axons\"],\n",
    "                        n_apicals=cell_type_info[\"n_axons\"],\n",
    "                           \n",
    "                           \n",
    "                        \n",
    "    \n",
    "                        # ----- Soma Information ----#\n",
    "                        nucleus_id         = nucleus_info[\"nuclei_id\"],\n",
    "                        nuclei_distance      = np.round(nucleus_info[\"nuclei_distance\"],2),\n",
    "                        n_nuclei_in_radius   = nucleus_info[\"n_nuclei_in_radius\"],\n",
    "                        n_nuclei_in_bbox     = nucleus_info[\"n_nuclei_in_bbox\"],\n",
    "\n",
    "                        soma_x           = soma_x,\n",
    "                        soma_y           =soma_y,\n",
    "                        soma_z           =soma_z,\n",
    "\n",
    "                        # ---------- Mesh Faces ------ #\n",
    "                        mesh_faces = original_mesh_faces_file,\n",
    "\n",
    "                           \n",
    "                        # ------------- The Regular Neuron Information (will be computed in the stats dict) ----------------- #\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                           # ------ Information Used For Excitatory Inhibitory Classification -------- \n",
    "                        axon_angle_maximum=cell_type_info[\"axon_angle_maximum\"],\n",
    "                        spine_density_classifier=cell_type_info[\"neuron_spine_density\"],\n",
    "                        n_branches_processed=cell_type_info[\"n_branches_processed\"],\n",
    "                        skeletal_length_processed=cell_type_info[\"skeletal_length_processed\"],\n",
    "                        n_branches_in_search_radius=cell_type_info[\"n_branches_in_search_radius\"],\n",
    "                        skeletal_length_in_search_radius=cell_type_info[\"skeletal_length_in_search_radius\"],\n",
    "\n",
    "                           \n",
    "                        \n",
    "                           \n",
    "                           run_time=np.round(time.time() - whole_pass_time,4)\n",
    "                          )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            stats_dict = filtered_neuron.neuron_stats()\n",
    "            new_key.update(stats_dict)\n",
    "\n",
    "            \n",
    "            # ------ Writing the Data To the Tables ----- #\n",
    "            SynapseProofread.insert(keys_to_write,skip_duplicates=True)\n",
    "            \n",
    "            self.insert1(new_key,skip_duplicates=True,allow_direct_insert=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #saving following information for later processing:\n",
    "            filtering_info_list.append(filtering_info)\n",
    "            synapse_stats_list.append(synapse_stats)\n",
    "            total_error_synapse_ids_list.append(total_error_synapse_ids)\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Once have inserted all the new neurons need to compute the stats\n",
    "        if verbose:\n",
    "            print(\"Computing the overall stats\")\n",
    "            \n",
    "        overall_syn_error_rates = pru.calculate_error_rate(total_error_synapse_ids_list,\n",
    "                        synapse_stats_list,\n",
    "                        verbose=True)\n",
    "        \n",
    "        \n",
    "        # Final Part: Create the stats table entries and insert\n",
    "        \n",
    "        proofread_stats_entries = []\n",
    "        \n",
    "        stats_to_make_sure_in_proofread_stats = [\n",
    "            \n",
    "         'axon_on_dendrite_merges_error_area',\n",
    "         'axon_on_dendrite_merges_error_length',\n",
    "         'low_branch_clusters_error_area',\n",
    "         'low_branch_clusters_error_length',\n",
    "         'dendrite_on_axon_merges_error_area',\n",
    "         'dendrite_on_axon_merges_error_length',\n",
    "         'double_back_and_width_change_error_area',\n",
    "         'double_back_and_width_change_error_length',\n",
    "         'crossovers_error_area',\n",
    "         'crossovers_error_length',\n",
    "         'high_degree_coordinates_error_area',\n",
    "         'high_degree_coordinates_error_length',\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        for sp_idx,split_index in enumerate(neuron_split_idxs):\n",
    "            synapse_stats = synapse_stats_list[sp_idx]\n",
    "            filtering_info = filtering_info_list[sp_idx]\n",
    "            \n",
    "            curr_key = dict(key,\n",
    "                           split_index = split_index,\n",
    "                           proof_version = proof_version,\n",
    "                           \n",
    "\n",
    "                            # ------------ For local valid synapses to that split_index\n",
    "                            n_valid_syn_presyn_for_split=synapse_stats[\"n_valid_syn_presyn\"],\n",
    "                            n_valid_syn_postsyn_for_split=synapse_stats[\"n_valid_syn_postsyn\"],\n",
    "\n",
    "                           \n",
    "                           \n",
    "                           )\n",
    "            \n",
    "            \n",
    "            for s in stats_to_make_sure_in_proofread_stats:\n",
    "                if s not in filtering_info.keys():\n",
    "                    curr_key[s] = None\n",
    "            \n",
    "            filter_key = {k:np.round(v,2) for k,v in filtering_info.items() if \"area\" in k or \"length\" in k}\n",
    "            curr_key.update(filter_key)\n",
    "            curr_key.update(overall_syn_error_rates)\n",
    "            \n",
    "            proofread_stats_entries.append(curr_key)\n",
    "            \n",
    "        \n",
    "        ProofreadStats.insert(proofread_stats_entries,skip_duplicates=True)\n",
    "\n",
    "            \n",
    "\n",
    "        print(f\"\\n\\n ***------ Total time for {key['segment_id']} = {time.time() - whole_pass_time} ------ ***\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>job reservation table for `microns_minnie65_02`</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">table_name</p>\n",
       "                                <span class=\"djtooltiptext\">className of the table</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">key_hash</p>\n",
       "                                <span class=\"djtooltiptext\">key hash</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">if tuple is missing, the job is available</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">key</p>\n",
       "                                <span class=\"djtooltiptext\">structure containing the key</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_message</p>\n",
       "                                <span class=\"djtooltiptext\">error message returned if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_stack</p>\n",
       "                                <span class=\"djtooltiptext\">error stack if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">user</p>\n",
       "                                <span class=\"djtooltiptext\">database user</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">host</p>\n",
       "                                <span class=\"djtooltiptext\">system hostname</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">pid</p>\n",
       "                                <span class=\"djtooltiptext\">system process id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">connection_id</p>\n",
       "                                <span class=\"djtooltiptext\">connection_id()</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">timestamp</p>\n",
       "                                <span class=\"djtooltiptext\">automatic timestamp</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>__auto_proofread_neurons</td>\n",
       "<td>00395730cb6c6bbdff1b345794fee7dd</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.64</td>\n",
       "<td>jr-compute001</td>\n",
       "<td>1</td>\n",
       "<td>119013</td>\n",
       "<td>2021-02-05 09:47:40</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>003f2028a8f0f620f4d70361f3a8e614</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>IndexError: index 29821 is out of bounds for axis 0 with size 29075</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.64</td>\n",
       "<td>jr-compute001</td>\n",
       "<td>1</td>\n",
       "<td>117249</td>\n",
       "<td>2021-02-04 13:53:37</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>0050bab10bd7eee70430040c4d1f8f02</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>IndexError: index 1 is out of bounds for axis 0 with size 1</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.81</td>\n",
       "<td>at-compute003</td>\n",
       "<td>1</td>\n",
       "<td>117290</td>\n",
       "<td>2021-02-04 16:48:57</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>00696328a1e9d8ec23bded8346bd9612</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>KeyError: 'skeletal_length'</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.27</td>\n",
       "<td>at-compute005</td>\n",
       "<td>1</td>\n",
       "<td>117165</td>\n",
       "<td>2021-02-05 01:54:44</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>006f7af77d3fe5ad8a421bfbb314bd29</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.64</td>\n",
       "<td>jr-compute001</td>\n",
       "<td>1</td>\n",
       "<td>119024</td>\n",
       "<td>2021-02-05 09:51:06</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>00895a0da8ba62697c121cc031da8927</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>IndexError: index 1 is out of bounds for axis 0 with size 1</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.64</td>\n",
       "<td>jr-compute001</td>\n",
       "<td>1</td>\n",
       "<td>117201</td>\n",
       "<td>2021-02-04 15:29:33</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>0093ac268bde98c847015614eff6ddf9</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>KeyError: 'skeletal_length'</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.150</td>\n",
       "<td>at-node23</td>\n",
       "<td>1</td>\n",
       "<td>117030</td>\n",
       "<td>2021-02-04 18:05:05</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>009e6c8328e3b3bff056b8ce9c524fbc</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>Exception: Segment ID 864691136050302221 should have been in DecompositionSplit but wasnt with n_error_limbs = 2, n_somas = 1 </td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.81</td>\n",
       "<td>at-compute003</td>\n",
       "<td>1</td>\n",
       "<td>117464</td>\n",
       "<td>2021-02-04 19:22:27</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>00b26f1dac943b60dbc62a7dd6636d32</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>IndexError: index 107388 is out of bounds for axis 0 with size 20766</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.83</td>\n",
       "<td>at-compute004</td>\n",
       "<td>1</td>\n",
       "<td>117188</td>\n",
       "<td>2021-02-05 03:09:02</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>00b9d3f7f29aa12a6b1d0a4ce4243f65</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>KeyError: 'skeletal_length'</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.138</td>\n",
       "<td>at-node11</td>\n",
       "<td>1</td>\n",
       "<td>117945</td>\n",
       "<td>2021-02-05 12:59:49</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>00da749b76072c88aa7572a1b72c5993</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>KeyError: 'skeletal_length'</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.83</td>\n",
       "<td>at-compute004</td>\n",
       "<td>1</td>\n",
       "<td>117200</td>\n",
       "<td>2021-02-04 14:56:10</td></tr><tr><td>__auto_proofread_neurons</td>\n",
       "<td>011d264b2163d468d7b62bbf6fc25bf6</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>IndexError: index 113643 is out of bounds for axis 0 with size 113643</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.27</td>\n",
       "<td>at-compute005</td>\n",
       "<td>1</td>\n",
       "<td>117311</td>\n",
       "<td>2021-02-05 08:44:31</td> </tr> </tbody>\n",
       "            </table>\n",
       "            <p>...</p>\n",
       "            <p>Total: 2486</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*table_name    *key_hash      status       key        error_message  error_stac user           host           pid     connection_id  timestamp     \n",
       "+------------+ +------------+ +----------+ +--------+ +------------+ +--------+ +------------+ +------------+ +-----+ +------------+ +------------+\n",
       "__auto_proofre 00395730cb6c6b reserved     =BLOB=                    =BLOB=     celiib@10.66.4 jr-compute001  1       119013         2021-02-05 09:\n",
       "__auto_proofre 003f2028a8f0f6 error        =BLOB=     IndexError: in =BLOB=     celiib@10.66.4 jr-compute001  1       117249         2021-02-04 13:\n",
       "__auto_proofre 0050bab10bd7ee error        =BLOB=     IndexError: in =BLOB=     celiib@10.28.0 at-compute003  1       117290         2021-02-04 16:\n",
       "__auto_proofre 00696328a1e9d8 error        =BLOB=     KeyError: 'ske =BLOB=     celiib@10.66.4 at-compute005  1       117165         2021-02-05 01:\n",
       "__auto_proofre 006f7af77d3fe5 reserved     =BLOB=                    =BLOB=     celiib@10.66.4 jr-compute001  1       119024         2021-02-05 09:\n",
       "__auto_proofre 00895a0da8ba62 error        =BLOB=     IndexError: in =BLOB=     celiib@10.66.4 jr-compute001  1       117201         2021-02-04 15:\n",
       "__auto_proofre 0093ac268bde98 error        =BLOB=     KeyError: 'ske =BLOB=     celiib@10.28.0 at-node23      1       117030         2021-02-04 18:\n",
       "__auto_proofre 009e6c8328e3b3 error        =BLOB=     Exception: Seg =BLOB=     celiib@10.28.0 at-compute003  1       117464         2021-02-04 19:\n",
       "__auto_proofre 00b26f1dac943b error        =BLOB=     IndexError: in =BLOB=     celiib@10.28.0 at-compute004  1       117188         2021-02-05 03:\n",
       "__auto_proofre 00b9d3f7f29aa1 error        =BLOB=     KeyError: 'ske =BLOB=     celiib@10.28.0 at-node11      1       117945         2021-02-05 12:\n",
       "__auto_proofre 00da749b76072c error        =BLOB=     KeyError: 'ske =BLOB=     celiib@10.28.0 at-compute004  1       117200         2021-02-04 14:\n",
       "__auto_proofre 011d264b2163d4 error        =BLOB=     IndexError: in =BLOB=     celiib@10.66.4 at-compute005  1       117311         2021-02-05 08:\n",
       "   ...\n",
       " (Total: 2486)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__auto_proofread_neurons'\")\n",
    "(curr_table)#.delete()# & \"status='error'\")\n",
    "#curr_table.delete()\n",
    "#(curr_table & \"error_message = 'ValueError: need at least one array to concatenate'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n",
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135651861970  ----------\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 2\n",
      "Number of Neurons found =2\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [156347]\n",
      "nucleus_centers = [[522688 582336 602320]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Axon Classification = 0.008477449417114258\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = no_spined\n",
      "spine_category was no_spined so determined as inhibitory\n",
      "Inhibitory Excitatory Classification = 0.0031905174255371094\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=inhibitory\n",
      "spine_category=no_spined\n",
      "axon_angles={}\n",
      "n_axons=0\n",
      "n_apicals=0\n",
      "neuron_spine_density=0\n",
      "n_branches_processed=0\n",
      "skeletal_length_processed=0\n",
      "n_branches_in_search_radius=0\n",
      "skeletal_length_in_search_radius=0\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "--- Working on filter 0:\n",
      "function = low_branch_clusters\n",
      "function __name__ = filter_away_low_branch_length_clusters\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_restriction = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter low_branch_clusters Results --\n",
      "local_results = {'low_branch_clusters_neuron': <neuron.Neuron object at 0x7f4cab2bea58>, 'low_branch_clusters_time': 0.002588987350463867, 'low_branch_clusters_error_area': 0, 'low_branch_clusters_error_length': 0}\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = crossovers\n",
      "function __name__ = filter_away_crossovers\n",
      "function arguments = {'axon_dependent': True, 'match_threshold': 30}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter crossovers Results --\n",
      "local_results = {'crossovers_neuron': <neuron.Neuron object at 0x7f4cab2bedd8>, 'crossovers_time': 0.0016238689422607422, 'crossovers_error_area': 0, 'crossovers_error_length': 0}\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = double_back_and_width_change\n",
      "function __name__ = filter_away_large_double_back_or_width_changes\n",
      "function arguments = {'perform_double_back_errors': False, 'skip_double_back_errors_for_axon': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_and_width_change Results --\n",
      "local_results = {'double_back_and_width_change_neuron': <neuron.Neuron object at 0x7f4cab069b70>, 'double_back_and_width_change_time': 0.0015132427215576172, 'double_back_and_width_change_error_area': 0, 'double_back_and_width_change_error_length': 0}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = high_degree_coordinates\n",
      "function __name__ = filter_away_high_degree_coordinates\n",
      "function arguments = {'axon_dependent': True, 'min_degree_to_find': 4}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_coordinates Results --\n",
      "local_results = {'high_degree_coordinates_neuron': <neuron.Neuron object at 0x7f4caa777a58>, 'high_degree_coordinates_time': 0.0015311241149902344, 'high_degree_coordinates_error_area': 0, 'high_degree_coordinates_error_length': 0}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 0.007857561111450195 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 0.020616769790649414\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [496069 537409 596078]\n",
      "nuclei_within_radius = []\n",
      "nuclei_within_radius_distance = []\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = []\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 0\n",
      "winning_nuclei_distance = 52592.48096448769\n",
      "n_nuclei_in_radius = 0\n",
      "n_nuclei_in_bbox = 0\n",
      "nucleus_info = {'nuclei_id': 0, 'nuclei_distance': 52592.48, 'n_nuclei_in_radius': 0, 'n_nuclei_in_bbox': 0}\n",
      "winning_nucleus_id = 0\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135651861970_0_proofread.pbz2\n",
      "File size is 0.008962 MB\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "For presyn: # valid synapses = 0, # error synapses  = 0\n",
      "For postsyn: # valid synapses = 0, # error synapses  = 0\n",
      "\n",
      "-----Working on Neuron Split 1-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Axon Classification = 0.014057636260986328\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = no_spined\n",
      "spine_category was no_spined so determined as inhibitory\n",
      "Inhibitory Excitatory Classification = 0.004747152328491211\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=inhibitory\n",
      "spine_category=no_spined\n",
      "axon_angles={}\n",
      "n_axons=0\n",
      "n_apicals=0\n",
      "neuron_spine_density=0\n",
      "n_branches_processed=0\n",
      "skeletal_length_processed=0\n",
      "n_branches_in_search_radius=0\n",
      "skeletal_length_in_search_radius=0\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "--- Working on filter 0:\n",
      "function = low_branch_clusters\n",
      "function __name__ = filter_away_low_branch_length_clusters\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_restriction = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter low_branch_clusters Results --\n",
      "local_results = {'low_branch_clusters_neuron': <neuron.Neuron object at 0x7f4caa7769b0>, 'low_branch_clusters_time': 0.0032799243927001953, 'low_branch_clusters_error_area': 0, 'low_branch_clusters_error_length': 0}\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = crossovers\n",
      "function __name__ = filter_away_crossovers\n",
      "function arguments = {'axon_dependent': True, 'match_threshold': 30}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter crossovers Results --\n",
      "local_results = {'crossovers_neuron': <neuron.Neuron object at 0x7f4caa777da0>, 'crossovers_time': 0.0018982887268066406, 'crossovers_error_area': 0, 'crossovers_error_length': 0}\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = double_back_and_width_change\n",
      "function __name__ = filter_away_large_double_back_or_width_changes\n",
      "function arguments = {'perform_double_back_errors': False, 'skip_double_back_errors_for_axon': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_and_width_change Results --\n",
      "local_results = {'double_back_and_width_change_neuron': <neuron.Neuron object at 0x7f4caa77cc88>, 'double_back_and_width_change_time': 0.0018756389617919922, 'double_back_and_width_change_error_area': 0, 'double_back_and_width_change_error_length': 0}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = high_degree_coordinates\n",
      "function __name__ = filter_away_high_degree_coordinates\n",
      "function arguments = {'axon_dependent': True, 'min_degree_to_find': 4}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_coordinates Results --\n",
      "local_results = {'high_degree_coordinates_neuron': <neuron.Neuron object at 0x7f4caa77c630>, 'high_degree_coordinates_time': 0.0018956661224365234, 'high_degree_coordinates_error_area': 0, 'high_degree_coordinates_error_length': 0}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 0.009518146514892578 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 0.029392242431640625\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [525738 590442 596787]\n",
      "nuclei_within_radius = [156347]\n",
      "nuclei_within_radius_distance = [10277.34523114]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 156347\n",
      "winning_nuclei_distance = 10277.345231138244\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = []\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 156347\n",
      "winning_nuclei_distance = 10277.345231138244\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 0\n",
      "nucleus_info = {'nuclei_id': 156347, 'nuclei_distance': 10277.35, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 0}\n",
      "winning_nucleus_id = 156347\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135651861970_1_proofread.pbz2\n",
      "File size is 0.010146 MB\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For presyn: # valid synapses = 0, # error synapses  = 0\n",
      "For postsyn: # valid synapses = 0, # error synapses  = 0\n",
      "Computing the overall stats\n",
      "n_presyn_error_syn = 0, n_postsyn_error_syn = 0\n",
      "total_presyns = 0, total_postsyns = 0\n",
      "perc_error_presyn = None, perc_error_postsyn = None\n",
      "total_error_synapses = 0, total_synapses = 0\n",
      "overall_percent_error= None\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135651861970 = 22.057820796966553 ------ ***\n",
      "Populate Done\n",
      "Total time for AutoProofreadNeuron populate = 47.03739047050476\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "import neuron_searching as ns\n",
    "ns = reload(ns)\n",
    "clu = reload(clu)\n",
    "import skeleton_utils as sk\n",
    "import networkx_utils as xu\n",
    "sk = reload(sk)\n",
    "xu = reload(xu)\n",
    "import random\n",
    "import datajoint_utils as du\n",
    "du = reload(du)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    AutoProofreadNeurons.populate(reserve_jobs=True, suppress_errors=False, order=\"random\")\n",
    "else:\n",
    "    AutoProofreadNeurons.populate(reserve_jobs=True, suppress_errors=False, order=\"random\")\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for AutoProofreadNeuron populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/notebooks/Auto_Proofreading/Preprocessing_Pipeline/pandas/_libs/hashtable_class_helper.pxi\u001b[0m(1627)\u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/notebooks/Auto_Proofreading/Preprocessing_Pipeline/pandas/_libs/hashtable_class_helper.pxi\u001b[0m(1619)\u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/notebooks/Auto_Proofreading/Preprocessing_Pipeline/pandas/_libs/index.pyx\u001b[0m(138)\u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/notebooks/Auto_Proofreading/Preprocessing_Pipeline/pandas/_libs/index.pyx\u001b[0m(111)\u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> uu\n",
      "*** NameError: name 'uu' is not defined\n",
      "ipdb> u\n",
      "> \u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m(2648)\u001b[0;36mget_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2646 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2647 \u001b[0;31m            \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2648 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2649 \u001b[0;31m        \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2650 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m(2800)\u001b[0;36m__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2798 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2799 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2800 \u001b[0;31m            \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2801 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2802 \u001b[0;31m                \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/meshAfterParty/neuron_utils.py\u001b[0m(3977)\u001b[0;36mneuron_spine_density\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   3975 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3976 \u001b[0;31m    \u001b[0;31m# ---- 1/24: Calculating the skeletal length of the viable branches --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 3977 \u001b[0;31m    \u001b[0mtotal_skeletal_length_in_search_radius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_branches_in_search_radius\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skeletal_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3978 \u001b[0;31m    \u001b[0mprocessed_skeletal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_limb_branch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skeletal_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3979 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> total_branches_in_search_radius\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
