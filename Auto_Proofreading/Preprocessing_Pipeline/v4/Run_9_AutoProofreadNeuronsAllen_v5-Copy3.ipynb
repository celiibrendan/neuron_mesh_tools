{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To decompose the multi-somas for splitting\\nusing the new decomposition method\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To decompose the multi-somas for splitting\n",
    "using the new decomposition method\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 16:39:46,169 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 16:39:46,171 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 16:39:46,172 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 16:39:46,175 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-06-02 16:39:46,177 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 16:39:46,192 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 16:39:46,797 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 16:39:46,801 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 16:39:46,802 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 16:39:46,804 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 16:39:46,805 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 16:39:46,806 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 16:39:46,807 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 16:39:46,810 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 16:39:47,478 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the contains method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 16:39:47,711 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 16:39:47,712 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 16:39:47,718 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 16:39:47,723 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 16:39:47,727 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 16:39:47,730 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 16:39:47,734 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 121 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 16:39:49,928 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import neuron_utils as nru\n",
    "\n",
    "import neuron\n",
    "\n",
    "import neuron_visualizations as nviz\n",
    "\n",
    "import time\n",
    "\n",
    "import datajoint_utils as du\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import preprocessing_vp2 as pre\n",
    "\n",
    "# -- For the axon classification --\n",
    "\n",
    "import neuron_searching as ns\n",
    "\n",
    "import skeleton_utils as sk\n",
    "\n",
    "import numpy_utils as nu\n",
    "\n",
    "import networkx_utils as xu\n",
    "\n",
    "import system_utils as su\n",
    "\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "import trimesh_utils as tu\n",
    "import proofreading_utils as pru\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 4682\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minnie,schema = du.configure_minnie_vm()\n",
    "# minnie.AutoProofreadNeurons5.drop()\n",
    "# minnie.AutoProofreadStats5.drop()\n",
    "# minnie.AutoProofreadSynapse5.drop()\n",
    "# minnie.AutoProofreadSynapseErrors5.drop()\n",
    "# minnie.schema.external['faces'].delete(delete_external_files=True)\n",
    "# minnie.schema.external['skeleton'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proofreading Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b></b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">proof_version</p>\n",
       "                                <span class=\"djtooltiptext\">key by which to lookup the decomposition process version</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">description</p>\n",
       "                                <span class=\"djtooltiptext\">new parts of the iteration of the decomposition process</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>0</td>\n",
       "<td>exc,inh rules</td></tr><tr><td>1</td>\n",
       "<td>eliminated presyns on dendrite</td></tr><tr><td>2</td>\n",
       "<td>high fidelity axons</td></tr><tr><td>3</td>\n",
       "<td>improved crossover</td></tr><tr><td>4</td>\n",
       "<td>better crossover and more axon rules</td></tr><tr><td>5</td>\n",
       "<td>fixed stitching on axon</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 6</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*proof_version description   \n",
       "+------------+ +------------+\n",
       "0              exc,inh rules \n",
       "1              eliminated pre\n",
       "2              high fidelity \n",
       "3              improved cross\n",
       "4              better crossov\n",
       "5              fixed stitchin\n",
       " (Total: 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@schema\n",
    "class AutoProofreadVersion(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    proof_version      : tinyint unsigned                   # key by which to lookup the decomposition process version\n",
    "    ---\n",
    "    description          : varchar(256)                 # new parts of the iteration of the decomposition process\n",
    "    \"\"\"\n",
    "versions=[[0,\"exc,inh rules\"],\n",
    "         [1,\"eliminated presyns on dendrite\"],\n",
    "         [2,\"high fidelity axons\"],\n",
    "         [3,\"improved crossover\"],\n",
    "         [4,\"better crossover and more axon rules\"],\n",
    "         [5,\"fixed stitching on axon\"]]\n",
    "\n",
    "\n",
    "dict_to_write = [dict(proof_version=k,description=v) for k,v in versions]\n",
    "AutoProofreadVersion.insert(dict_to_write,skip_duplicates=True)\n",
    "AutoProofreadVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Synapse Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class AutoProofreadSynapseAllen5(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    synapse_id           : bigint unsigned              # synapse index within the segmentation\n",
    "    synapse_type: enum('presyn','postsyn')\n",
    "    ver                  : decimal(6,2)                 # the version number of the materializaiton\n",
    "    ---\n",
    "    segment_id           : bigint unsigned              # segment_id of the cell. Equivalent to Allen 'pt_root_id\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'. \n",
    "    skeletal_distance_to_soma=NULL : double #the length (in um) of skeleton distance from synapse to soma (-1 if on the soma)\n",
    "    \"\"\"\n",
    "\n",
    "@schema\n",
    "class AutoProofreadSynapseErrorsAllen5(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    synapse_id           : bigint unsigned              # synapse index within the segmentation\n",
    "    synapse_type: enum('presyn','postsyn')\n",
    "    ver                  : decimal(6,2)                 # the version number of the materializaiton\n",
    "    ---\n",
    "    segment_id           : bigint unsigned              # segment_id of the cell. Equivalent to Allen 'pt_root_id\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'. \n",
    "    skeletal_distance_to_soma=NULL : double #the length (in um) of skeleton distance from synapse to soma (-1 if on the soma)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Proofreading Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis table will include the following information:\\n\\n1) Filtering Info\\n2) Synapse Stats for Individual Neuron\\n3) Synapse Stats for Segment\\n\\n\\n**** thing need to add:\\n1) Axon faces\\n2) Axon length/area\\n2) Neuron faces\\n3) n_presyn_error_syn_non_axon\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This table will include the following information:\n",
    "\n",
    "1) Filtering Info\n",
    "2) Synapse Stats for Individual Neuron\n",
    "3) Synapse Stats for Segment\n",
    "\n",
    "\n",
    "**** thing need to add:\n",
    "1) Axon faces\n",
    "2) Axon length/area\n",
    "2) Neuron faces\n",
    "3) n_presyn_error_syn_non_axon\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class AutoProofreadStatsAllen5(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    -> minnie.AutoProofreadVersion()   # the version of code used for this cell typing classification\n",
    "    ---\n",
    "    mesh_faces: <faces>                      # faces indices that were saved off as belonging to proofread neuron (external storage)\n",
    "    axon_faces: <faces>                      # faces indices that were saved off as belonging to proofread neuron's axon (external storage)\n",
    "    \n",
    "    axon_skeleton: <skeleton>      # the skeleton of the axon of the final proofread neuorn\n",
    "    dendrite_skeleton: <skeleton>  # the skeleton of the dendrite branches of the final proofread neuorn\n",
    "    neuron_skeleton: <skeleton>    # the skeleton of the entire neuron\n",
    "    \n",
    "    axon_on_dendrite_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    axon_on_dendrite_merges_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    low_branch_clusters_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    low_branch_clusters_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    dendrite_on_axon_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    dendrite_on_axon_merges_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    \n",
    "    crossovers_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    crossovers_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    high_degree_coordinates_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    high_degree_coordinates_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------- new filters for v4 Stats ------------\n",
    "    high_degree_branching_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    high_degree_branching_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    axon_webbing_t_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    axon_webbing_t_merges_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    thick_t_merge_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    thick_t_merge_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    double_back_and_width_change_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    double_back_and_width_change_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    axon_fork_divergence_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    axon_fork_divergence_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    # ---------- new filers for v5 Stats ----------\n",
    "    \n",
    "    width_jump_up_dendrite_error_area=NULL :double #the area (in um ^ 2) of the faces canceled out by filter FOR DENDRITES\n",
    "    width_jump_up_dendrite_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter FOR DENDRITES\n",
    "    \n",
    "    width_jump_up_axon_error_area=NULL :double # the area (in um ^ 2) of the faces canceled out by filter FOR AXONS\n",
    "    width_jump_up_axon_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter FOR AXONS\n",
    "    \n",
    "    double_back_dendrite_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter FOR DENDRITES\n",
    "    double_back_dendrite_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter FOR DENDRITES\n",
    "    \n",
    "    double_back_axon_thin_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter \n",
    "    double_back_axon_thin_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    double_back_axon_thick_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter \n",
    "    double_back_axon_thick_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    # ------------ For local valid synapses to that split_index\n",
    "    n_valid_syn_presyn_for_split: int unsigned\n",
    "    n_valid_syn_postsyn_for_split : int unsigned\n",
    "    n_presyn_error_syn_non_axon :int unsigned\n",
    "    \n",
    "    # ------------ For global stats belonging to the whole segment\n",
    "    # For the whole segment\n",
    "    n_presyn_error_syn: int unsigned\n",
    "    n_postsyn_error_syn: int unsigned\n",
    "    total_error_synapses: int unsigned\n",
    "    \n",
    "    total_presyns: int unsigned \n",
    "    total_postsyns: int unsigned \n",
    "    total_synapses:int unsigned\n",
    "    \n",
    "    perc_error_presyn=NULL: double\n",
    "    perc_error_postsyn=NULL: double\n",
    "    \n",
    "    overall_percent_error=NULL: double\n",
    "    \n",
    "    limb_branch_to_cancel: longblob # stores the limb information from \n",
    "    red_blue_suggestions: longblob\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Auto Proofread Neuron Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import classification_utils as clu\n",
    "\n",
    "axon_version = 5\n",
    "proof_version = 5\n",
    "\n",
    "verbose = True\n",
    "\n",
    "@schema\n",
    "class AutoProofreadNeuronsAllen5(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    -> minnie.AutoProofreadVersion()             # the version of code used for this cell typing classification\n",
    "    -> minnie.DecompositonAxonVersion()           # the version of the axon processing\n",
    "    ---\n",
    "    multiplicity  : tinyint unsigned   # the total number of neurons that came from the parent segment id\n",
    "    # -------- Important Excitatory Inhibitory Classfication ------- #\n",
    "    cell_type_predicted: enum('excitatory','inhibitory','other','unknown') # morphology predicted by classifier\n",
    "    spine_category: enum('no_spined','sparsely_spined','densely_spined')\n",
    "    \n",
    "    n_axons: tinyint unsigned             # Number of axon candidates identified\n",
    "    n_apicals: tinyint unsigned             # Number of apicals identified\n",
    "    \n",
    "    axon_length: double  # length (in um) of the classified axon skeleton\n",
    "    axon_area: double # # area (in um^2) of the classified axon\n",
    "    \n",
    "    # ----- Soma Information ----#\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'.\n",
    "    nuclei_distance      : double                    # the distance to the closest nuclei (even if no matching nuclei found)\n",
    "    n_nuclei_in_radius   : tinyint unsigned          # the number of nuclei within the search radius of 15000 belonging to that segment\n",
    "    n_nuclei_in_bbox     : tinyint unsigned          # the number of nuclei within the bounding box of that soma\n",
    "    \n",
    "    soma_x            : int unsigned                 # x coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    soma_y            : int unsigned                 # y coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    soma_z            : int unsigned                 # z coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    \n",
    "    max_soma_n_faces     : int unsigned                 # The largest number of faces of the somas\n",
    "    max_soma_volume      : int unsigned                 # The largest volume of the somas the (volume in billions (10*9 nm^3))\n",
    "    \n",
    "    # ---- Stores Neuron Mesh Faces (moved to AutoProofreadStats) --------\n",
    "    \n",
    "    \n",
    "    # ------------- The Regular Neuron Information ----------------- #\n",
    "    n_vertices           : int unsigned                 # number of vertices\n",
    "    n_faces              : int unsigned                 # number of faces\n",
    "    n_not_processed_soma_containing_meshes : int unsigned  #the number of meshes with somas that were not processed\n",
    "    n_error_limbs: int #the number of limbs that are touching multiple somas or 1 soma in multiple places\n",
    "    n_same_soma_multi_touching_limbs: int # number of limbs that touch the same soma multiple times\n",
    "    n_multi_soma_touching_limbs: int # number of limbs that touch multiple somas\n",
    "    n_somas: int #number of soma meshes detected\n",
    "    n_limbs: int\n",
    "    n_branches: int\n",
    "    max_limb_n_branches=NULL:int\n",
    "    \n",
    "    skeletal_length=NULL: double\n",
    "    max_limb_skeletal_length=NULL:double\n",
    "    median_branch_length=NULL:double #gives information on average skeletal length to next branch point\n",
    "    \n",
    "    \n",
    "    width_median=NULL: double #median width from mesh center without spines removed\n",
    "    width_no_spine_median=NULL: double #median width from mesh center with spines removed\n",
    "    width_90_perc=NULL: double # 90th percentile for width without spines removed\n",
    "    width_no_spine_90_perc=NULL: double  # 90th percentile for width with spines removed\n",
    "    \n",
    "    \n",
    "    n_spines: bigint\n",
    "    n_boutons: bigint\n",
    "\n",
    "    spine_density=NULL: double # n_spines/ skeletal_length\n",
    "    spines_per_branch=NULL: double\n",
    "    \n",
    "    skeletal_length_eligible=NULL: double # the skeletal length for all branches searched for spines\n",
    "    n_spine_eligible_branches=NULL: int # the number of branches that were checked for spines because passed width threshold\n",
    "    \n",
    "    spine_density_eligible=NULL:double # n_spines/skeletal_length_eligible\n",
    "    spines_per_branch_eligible=NULL:double # n_spines/n_spine_eligible_branches\n",
    "    \n",
    "    total_spine_volume=NULL: double # the sum of all spine volume\n",
    "    spine_volume_median=NULL: double # median of the spine volume for those spines with able to calculate volume\n",
    "    spine_volume_density=NULL: double #total_spine_volume/skeletal_length\n",
    "    spine_volume_density_eligible=NULL: double #total_spine_volume/skeletal_length_eligible\n",
    "    spine_volume_per_branch_eligible=NULL: double #total_spine_volume/n_spine_eligible_branches\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------ Information Used For Excitatory Inhibitory Classification -------- \n",
    "    axon_angle_maximum=NULL:double #the anlge of an identified axon\n",
    "    spine_density_classifier:double              # the number of spines divided by skeletal length for branches analyzed in classification\n",
    "    n_branches_processed: int unsigned                 # the number branches used for the spine density analysis\n",
    "    skeletal_length_processed: double                 # The total skeletal length of the viable branches used for the spine density analysis\n",
    "    n_branches_in_search_radius: int unsigned                 # the number branches existing in the search radius used for spine density\n",
    "    skeletal_length_in_search_radius : double         # The total skeletal length of the branches existing in the search radius used for spine density\n",
    "    \n",
    "    \n",
    "\n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #key_source = minnie.Decomposition() & minnie.NucleiSegmentsRun2()\n",
    "    #key_source = (minnie.Decomposition() & minnie.NucleiSegmentsRun2() \n",
    "    #              & minnie.DecompositionAxon().proj()) #& dict(segment_id=864691136361533410)\n",
    "    key_source = (minnie.Decomposition() & minnie.NucleiSegmentsRun4() \n",
    "                  & minnie.DecompositionAxon().proj() \n",
    "              & (minnie.AutoProofreadNeurons4() & \"spine_category = 'densely_spined'\").proj()\n",
    "             ) \n",
    "    \n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        1) Pull Down All of the Neurons\n",
    "        2) Get the nucleus centers and the original mesh\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1) Pull Down All of the Neurons\n",
    "        segment_id = key[\"segment_id\"]\n",
    "        \n",
    "        whole_pass_time = time.time()\n",
    "        \n",
    "\n",
    "        curr_output = pru.proofreading_table_processing(key,\n",
    "                                  proof_version=proof_version,\n",
    "                                  axon_version  = axon_version,\n",
    "                                  compute_synapse_to_soma_skeletal_distance=True,\n",
    "                                  perform_axon_classification = False,\n",
    "                                  high_fidelity_axon_on_excitatory = False,\n",
    "                                 verbose=True,)    \n",
    "        # ------ Writing the Data To the Tables ----- #\n",
    "            \n",
    "            \n",
    "        AutoProofreadSynapse_keys = curr_output[\"AutoProofreadSynapse_keys\"]\n",
    "        AutoProofreadSynapseErrors_keys = curr_output[\"AutoProofreadSynapseErrors_keys\"]\n",
    "        AutoProofreadNeurons_keys = curr_output[\"AutoProofreadNeurons_keys\"]\n",
    "        filtering_info_list = curr_output[\"filtering_info_list\"]\n",
    "        synapse_stats_list = curr_output[\"synapse_stats_list\"]\n",
    "        total_error_synapse_ids_list = curr_output[\"total_error_synapse_ids_list\"]\n",
    "        neuron_mesh_list = curr_output[\"neuron_mesh_list\"]\n",
    "        axon_mesh_list = curr_output[\"axon_mesh_list\"]\n",
    "        neuron_split_idxs = curr_output[\"neuron_split_idxs\"]\n",
    "        \n",
    "        axon_skeleton_list = curr_output[\"axon_skeleton_list\"]\n",
    "        dendrite_skeleton_list = curr_output[\"dendrite_skeleton_list\"]\n",
    "        neuron_skeleton_list = curr_output[\"neuron_skeleton_list\"]\n",
    "            \n",
    "        \n",
    "        # Once have inserted all the new neurons need to compute the stats\n",
    "        if verbose:\n",
    "            print(\"Computing the overall stats\")\n",
    "            \n",
    "        overall_syn_error_rates = pru.calculate_error_rate(total_error_synapse_ids_list,\n",
    "                        synapse_stats_list,\n",
    "                        verbose=True)\n",
    "        \n",
    "        \n",
    "        # Final Part: Create the stats table entries and insert\n",
    "        \n",
    "        proofread_stats_entries = []\n",
    "        \n",
    "        stats_to_make_sure_in_proofread_stats = [\n",
    "            \n",
    "         'axon_on_dendrite_merges_error_area',\n",
    "         'axon_on_dendrite_merges_error_length',\n",
    "         'low_branch_clusters_error_area',\n",
    "         'low_branch_clusters_error_length',\n",
    "         'dendrite_on_axon_merges_error_area',\n",
    "         'dendrite_on_axon_merges_error_length',\n",
    "         'double_back_and_width_change_error_area',\n",
    "         'double_back_and_width_change_error_length',\n",
    "         'crossovers_error_area',\n",
    "         'crossovers_error_length',\n",
    "         'high_degree_coordinates_error_area',\n",
    "         'high_degree_coordinates_error_length',\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        for sp_idx,split_index in enumerate(neuron_split_idxs):\n",
    "            \n",
    "            #write the AutoProofreadNeurons and AutoProofreadSynapse Tabel\n",
    "            keys_to_write = AutoProofreadSynapse_keys[sp_idx]\n",
    "            AutoProofreadSynapseAllen5.insert(keys_to_write,skip_duplicates=True)\n",
    "            \n",
    "            keys_to_write_errors = AutoProofreadSynapseErrors_keys[sp_idx]\n",
    "            AutoProofreadSynapseErrorsAllen5.insert(keys_to_write_errors,skip_duplicates=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            new_key = AutoProofreadNeurons_keys[sp_idx]\n",
    "            self.insert1(new_key,skip_duplicates=True,allow_direct_insert=True)\n",
    "            \n",
    "            synapse_stats = synapse_stats_list[sp_idx]\n",
    "            filtering_info = filtering_info_list[sp_idx]\n",
    "            limb_branch_to_cancel = pru.extract_from_filter_info(filtering_info,\n",
    "                            name_to_extract=\"limb_branch_dict_to_cancel\")\n",
    "                            \n",
    "            \n",
    "            red_blue_suggestions = pru.extract_from_filter_info(filtering_info,\n",
    "                            name_to_extract = \"red_blue_suggestions\")\n",
    "            \n",
    "            curr_key = dict(key,\n",
    "                           split_index = split_index,\n",
    "                           proof_version = proof_version,\n",
    "                           \n",
    "                             mesh_faces = neuron_mesh_list[sp_idx],\n",
    "                            axon_faces = axon_mesh_list[sp_idx],\n",
    "                            \n",
    "                            axon_skeleton = axon_skeleton_list[sp_idx],\n",
    "                            dendrite_skeleton = dendrite_skeleton_list[sp_idx],\n",
    "                            neuron_skeleton = neuron_skeleton_list[sp_idx],\n",
    "                         \n",
    "\n",
    "                            # ------------ For local valid synapses to that split_index\n",
    "                            n_valid_syn_presyn_for_split=synapse_stats[\"n_valid_syn_presyn\"],\n",
    "                            n_valid_syn_postsyn_for_split=synapse_stats[\"n_valid_syn_postsyn\"],\n",
    "                            n_presyn_error_syn_non_axon=synapse_stats[\"n_errored_syn_presyn_non_axon\"],\n",
    "                            \n",
    "                            limb_branch_to_cancel = limb_branch_to_cancel,\n",
    "                            red_blue_suggestions = red_blue_suggestions,\n",
    "                           \n",
    "                           \n",
    "                           )\n",
    "            \n",
    "            \n",
    "            for s in stats_to_make_sure_in_proofread_stats:\n",
    "                if s not in filtering_info.keys():\n",
    "                    curr_key[s] = None\n",
    "            \n",
    "            filter_key = {k:np.round(v,2) for k,v in filtering_info.items() if \"area\" in k or \"length\" in k}\n",
    "            curr_key.update(filter_key)\n",
    "            curr_key.update(overall_syn_error_rates)\n",
    "            \n",
    "            proofread_stats_entries.append(curr_key)\n",
    "            \n",
    "        \n",
    "        AutoProofreadStatsAllen5.insert(proofread_stats_entries,skip_duplicates=True)\n",
    "            \n",
    "#         for pse in proofread_stats_entries:\n",
    "#             AutoProofreadStats4.insert1(pse,skip_duplicates=True)\n",
    "            \n",
    "\n",
    "        print(f\"\\n\\n ***------ Total time for {key['segment_id']} = {time.time() - whole_pass_time} ------ ***\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>job reservation table for `microns_minnie65_02`</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">table_name</p>\n",
       "                                <span class=\"djtooltiptext\">className of the table</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">key_hash</p>\n",
       "                                <span class=\"djtooltiptext\">key hash</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">if tuple is missing, the job is available</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">key</p>\n",
       "                                <span class=\"djtooltiptext\">structure containing the key</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_message</p>\n",
       "                                <span class=\"djtooltiptext\">error message returned if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_stack</p>\n",
       "                                <span class=\"djtooltiptext\">error stack if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">user</p>\n",
       "                                <span class=\"djtooltiptext\">database user</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">host</p>\n",
       "                                <span class=\"djtooltiptext\">system hostname</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">pid</p>\n",
       "                                <span class=\"djtooltiptext\">system process id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">connection_id</p>\n",
       "                                <span class=\"djtooltiptext\">connection_id()</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">timestamp</p>\n",
       "                                <span class=\"djtooltiptext\">automatic timestamp</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>__auto_proofread_neurons_allen5</td>\n",
       "<td>44af3982e3e548529dfeaba4b801ede2</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.83</td>\n",
       "<td>at-compute004</td>\n",
       "<td>192204</td>\n",
       "<td>485047</td>\n",
       "<td>2021-06-02 11:38:12</td></tr><tr><td>__auto_proofread_neurons_allen5</td>\n",
       "<td>90bac4b4dc6c5c2bf9497debd27b0b41</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.83</td>\n",
       "<td>at-compute004</td>\n",
       "<td>192384</td>\n",
       "<td>485049</td>\n",
       "<td>2021-06-02 11:38:46</td></tr><tr><td>__auto_proofread_neurons_allen5</td>\n",
       "<td>f40ced8401f48880daf2026823bb093b</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.83</td>\n",
       "<td>at-compute004</td>\n",
       "<td>191620</td>\n",
       "<td>485018</td>\n",
       "<td>2021-06-02 11:33:18</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 3</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*table_name    *key_hash      status       key        error_message  error_stac user           host           pid        connection_id  timestamp     \n",
       "+------------+ +------------+ +----------+ +--------+ +------------+ +--------+ +------------+ +------------+ +--------+ +------------+ +------------+\n",
       "__auto_proofre 44af3982e3e548 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-compute004  192204     485047         2021-06-02 11:\n",
       "__auto_proofre 90bac4b4dc6c5c reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-compute004  192384     485049         2021-06-02 11:\n",
       "__auto_proofre f40ced8401f488 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-compute004  191620     485018         2021-06-02 11:\n",
       " (Total: 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__auto_proofread_neurons_allen5'\")\n",
    "(curr_table)#.delete()# & \"status='error'\")\n",
    "#curr_table.delete()\n",
    "#(curr_table & \"error_message = 'ValueError: need at least one array to concatenate'\").delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 16:39:50,675 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 16:39:50,680 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 16:39:50,683 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 16:39:50,688 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 16:39:50,693 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 16:39:50,697 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 16:39:50,706 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 16:39:52,783 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 16:39:59,376 - autopopulate - Found 48311 keys to populate\n",
      "INFO - 2021-06-02 16:39:59,417 - connection - Transaction started\n",
      "INFO - 2021-06-02 16:39:59,419 - autopopulate - Populating: {'segment_id': 864691136903001778, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': Decimal('30.00'), 'process_version': 3, 'index': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691136903001778  ----------\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 1\n",
      "Number of Neurons found =1\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [328471]\n",
      "nucleus_centers = [[845760 538368 888160]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [4514 4743]\n",
      "Skeleton paths distances = [24908.44425672 11554.19867595]\n",
      "Filtered indexes = [0]\n",
      "len(filtered_skeletons) = 1\n",
      "sk_angles = [167.61380978]\n",
      "local_axon_angles = [167.61380978]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Inhibitory Excitatory Classification = 16.515043258666992\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={1: {0: 167.61380978295747}}\n",
      "n_axons=1\n",
      "n_apicals=1\n",
      "neuron_spine_density=0.00042183896088298587\n",
      "n_branches_processed=24\n",
      "skeletal_length_processed=1790831.2543168603\n",
      "n_branches_in_search_radius=68\n",
      "skeletal_length_in_search_radius=2423390.195072479\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L5': [1, 0, 2, 3, 5, 6, 7]}\n",
      "total_sk_distance = 191.56341867886047, total_area = 219.31498249220314\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 0: [836799.57410903 742083.83985361 897214.73071707]--------\n",
      "For test node 18, sibling nodes were: [11]\n",
      "overlap = []\n",
      "With test node equal to the upstream node\n",
      "upstream = 18, downstream_nodes = [20 21 22]\n",
      "branches_at_coord = [18 20 21 22]\n",
      "widths_in_branches = [ 85.9164255  128.10674217  70.86912336 110.85595034]\n",
      "coordinate_branches = [18, 20, 21, 22]\n",
      "18 = red\n",
      "20 = aqua\n",
      "21 = purple\n",
      "22 = green\n",
      "Angle between 18 and 20 = 48.5 \n",
      "Angle between 18 and 21 = 28.61 \n",
      "Angle between 18 and 22 = 135.1 \n",
      "Angle between 20 and 21 = 149.91 \n",
      "Angle between 20 and 22 = 24.5 \n",
      "Angle between 21 and 22 = 16.47 \n",
      "Final Matches = [[18, 20], [18, 21], [20, 22], [21, 22]], Final Matches Angle = [48.5, 28.61, 24.5, 16.47]\n",
      "matched_edges = [[18, 20], [18, 21], [20, 22], [21, 22]]matched_edges_angles = [48.5, 28.61, 24.5, 16.47]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(18, 20), (18, 21), (20, 22), (21, 22)], Remaining Nodes = [18, 20, 21, 22]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(18, 20), (18, 21), (20, 22), (21, 22)], Remaining Nodes = [18, 20, 21, 22]\n",
      "--Working on edge [18 20]--\n",
      "--Working on edge [18 21]--\n",
      "--Working on edge [20 22]--\n",
      "--Working on edge [21 22]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(18, 20), (18, 21), (20, 22), (21, 22)], Remaining Nodes = [18, 20, 21, 22]\n",
      "upstream_subgraph = [18 20 21 22]\n",
      "Possible Connections = [20 21], angles = [48.5  28.61]\n",
      "Deleting the following nodes because above match threshold while 1 are: [(18, 20)]\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(18, 21), (20, 22), (21, 22)]\n",
      "Not doing kiss check because upstream_matches = [21]\n",
      "Using best match method\n",
      "for upstream node 18, winning_node = 21, error_branches = [20 22]\n",
      "winning_downstream = 21,error_downstream = [20 22] \n",
      "coordinate [836799.57410903 742083.83985361 897214.73071707] had error branches [20 22]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 1: [851500.66775257 839329.84695946 926706.98602134]--------\n",
      "For test node 7, sibling nodes were: [41 50]\n",
      "overlap = [41 50]\n",
      "With test node equal to the downstream node\n",
      "upstream = 51, downstream_nodes = [41 50  7]\n",
      "branches_at_coord = [ 7 41 50 51]\n",
      "widths_in_branches = [48.28655457 35.39774963 57.04383981 44.73611575]\n",
      "coordinate_branches = [7, 41, 50, 51]\n",
      "7 = red\n",
      "41 = aqua\n",
      "50 = purple\n",
      "51 = green\n",
      "Angle between 7 and 41 = 162.08 \n",
      "Angle between 7 and 50 = 44.66 \n",
      "Angle between 7 and 51 = 8.81 \n",
      "Angle between 41 and 50 = 28.28 \n",
      "Angle between 41 and 51 = 12.99 \n",
      "Angle between 50 and 51 = 138.73 \n",
      "Final Matches = [[7, 50], [7, 51], [41, 50], [41, 51]], Final Matches Angle = [44.66, 8.81, 28.28, 12.99]\n",
      "matched_edges = [[7, 50], [7, 51], [41, 50], [41, 51]]matched_edges_angles = [44.66, 8.81, 28.28, 12.99]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(7, 50), (7, 51), (41, 50), (41, 51)], Remaining Nodes = [7, 41, 50, 51]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(7, 50), (7, 51), (41, 50), (41, 51)], Remaining Nodes = [7, 41, 50, 51]\n",
      "--Working on edge [ 7 50]--\n",
      "--Working on edge [ 7 51]--\n",
      "--Working on edge [41 50]--\n",
      "--Working on edge [41 51]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(7, 50), (7, 51), (41, 50), (41, 51)], Remaining Nodes = [7, 41, 50, 51]\n",
      "upstream_subgraph = [41 50 51  7]\n",
      "Possible Connections = [ 7 41], angles = [ 8.81 12.99]\n",
      "Deleting the following nodes because above match threshold while 2 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(7, 50), (7, 51), (41, 50), (41, 51)]\n",
      "Working on Kissing check because possible upstream matches greater than 1: [7, 41]\n",
      "Step 5b: Removing kissing edges\n",
      "Remaining Edges = [(7, 50), (7, 51), (41, 50), (41, 51)]\n",
      "Using best match method\n",
      "for upstream node 51, winning_node = 7, error_branches = [41 50]\n",
      "winning_downstream = 7,error_downstream = [41 50] \n",
      "coordinate [851500.66775257 839329.84695946 926706.98602134] had error branches [41 50]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 2: [855428.74781997 597111.80768057 884618.54177124]--------\n",
      "For test node 57, sibling nodes were: [59 64]\n",
      "overlap = [59 64]\n",
      "With test node equal to the downstream node\n",
      "upstream = 63, downstream_nodes = [59 64 57]\n",
      "branches_at_coord = [57 59 63 64]\n",
      "widths_in_branches = [27.34929722 80.90940426 54.93184864 58.55477444]\n",
      "coordinate_branches = [57, 59, 63, 64]\n",
      "57 = red\n",
      "59 = aqua\n",
      "63 = purple\n",
      "64 = green\n",
      "Angle between 57 and 59 = 76.45 \n",
      "Angle between 57 and 63 = 108.81 \n",
      "Angle between 57 and 64 = 22.06 \n",
      "Angle between 59 and 63 = 5.28 \n",
      "Angle between 59 and 64 = 81.55 \n",
      "Angle between 63 and 64 = 93.21 \n",
      "Final Matches = [[57, 64], [59, 63]], Final Matches Angle = [22.06, 5.28]\n",
      "matched_edges = [[57, 64], [59, 63]]matched_edges_angles = [22.06, 5.28]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(57, 64), (59, 63)], Remaining Nodes = [57, 59, 63, 64]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(57, 64), (59, 63)], Remaining Nodes = [57, 59, 63, 64]\n",
      "--Working on edge [57 64]--\n",
      "Edge [57 64] is matches definite match threshold with: \n",
      "Edge Buffer of inf (angle_buffer = 15)\n",
      "Edge Angle of 22.06 (match_threshold = 45)\n",
      "--Working on edge [59 63]--\n",
      "Edge [59 63] is matches definite match threshold with: \n",
      "Edge Buffer of inf (angle_buffer = 15)\n",
      "Edge Angle of 5.28 (match_threshold = 45)\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(57, 64), (59, 63)], Remaining Nodes = [57, 59, 63, 64]\n",
      "upstream_subgraph = [59 63]\n",
      "Possible Connections = [59], angles = [5.28]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(57, 64), (59, 63)]\n",
      "Not doing kiss check because upstream_matches = [59]\n",
      "Using best match method\n",
      "for upstream node 63, winning_node = 59, error_branches = [64 57]\n",
      "winning_downstream = 59,error_downstream = [57 64] \n",
      "coordinate [855428.74781997 597111.80768057 884618.54177124] had error branches [57 64]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 3: [860621.13751278 588940.17427475 882567.56280707]--------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test node 44, sibling nodes were: [70 77 81]\n",
      "overlap = [70 77 81]\n",
      "With test node equal to the downstream node\n",
      "upstream = 74, downstream_nodes = [70 77 81 44]\n",
      "branches_at_coord = [44 70 74 77 81]\n",
      "widths_in_branches = [53.45882149 56.81677581 44.60323962 54.74301752 82.89592648]\n",
      "coordinate_branches = [44, 70, 74, 77, 81]\n",
      "44 = blue\n",
      "70 = green\n",
      "74 = red\n",
      "77 = cyan\n",
      "81 = magenta\n",
      "Angle between 44 and 70 = 29.68 \n",
      "Angle between 44 and 74 = 41.98 \n",
      "Angle between 44 and 77 = 133.85 \n",
      "Angle between 44 and 81 = 139.39 \n",
      "Angle between 70 and 74 = 167.68 \n",
      "Angle between 70 and 77 = 16.59 \n",
      "Angle between 70 and 81 = 11.08 \n",
      "Angle between 74 and 77 = 5.1 \n",
      "Angle between 74 and 81 = 3.05 \n",
      "Angle between 77 and 81 = 174.46 \n",
      "Final Matches = [[44, 70], [44, 74], [70, 77], [70, 81], [74, 77], [74, 81]], Final Matches Angle = [29.68, 41.98, 16.59, 11.08, 5.1, 3.05]\n",
      "matched_edges = [[44, 70], [44, 74], [70, 77], [70, 81], [74, 77], [74, 81]]matched_edges_angles = [29.68, 41.98, 16.59, 11.08, 5.1, 3.05]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(44, 70), (44, 74), (70, 77), (70, 81), (74, 77), (74, 81)], Remaining Nodes = [44, 70, 74, 77, 81]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(44, 70), (44, 74), (70, 77), (70, 81), (74, 77), (74, 81)], Remaining Nodes = [44, 70, 74, 77, 81]\n",
      "--Working on edge [44 70]--\n",
      "--Working on edge [44 74]--\n",
      "--Working on edge [70 77]--\n",
      "--Working on edge [70 81]--\n",
      "--Working on edge [74 77]--\n",
      "--Working on edge [74 81]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(44, 70), (44, 74), (70, 77), (70, 81), (74, 77), (74, 81)], Remaining Nodes = [44, 70, 74, 77, 81]\n",
      "upstream_subgraph = [70 74 44 77 81]\n",
      "Possible Connections = [44 77 81], angles = [41.98  5.1   3.05]\n",
      "Deleting the following nodes because above match threshold while 3 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(44, 70), (44, 74), (70, 77), (70, 81), (74, 77), (74, 81)]\n",
      "Working on Kissing check because possible upstream matches greater than 1: [44, 77, 81]\n",
      "Step 5b: Removing kissing edges\n",
      "Remaining Edges = [(44, 70), (44, 74), (70, 77), (70, 81), (74, 77), (74, 81)]\n",
      "Using best match method\n",
      "for upstream node 74, winning_node = 81, error_branches = [70 77 44]\n",
      "winning_downstream = 81,error_downstream = [44 70 77] \n",
      "coordinate [860621.13751278 588940.17427475 882567.56280707] had error branches [44 70 77]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 4: [862866.32268239 785205.35511803 908431.03693883]--------\n",
      "For test node 52, sibling nodes were: [76 86]\n",
      "overlap = [76 86]\n",
      "With test node equal to the downstream node\n",
      "upstream = 82, downstream_nodes = [76 86 52]\n",
      "branches_at_coord = [52 76 82 86]\n",
      "widths_in_branches = [ 66.86466193  55.31694243 109.25697247  67.61285491]\n",
      "coordinate_branches = [52, 76, 82, 86]\n",
      "52 = red\n",
      "76 = aqua\n",
      "82 = purple\n",
      "86 = green\n",
      "Angle between 52 and 76 = 156.52 \n",
      "Angle between 52 and 82 = 25.95 \n",
      "Angle between 52 and 86 = 16.92 \n",
      "Angle between 76 and 82 = 2.64 \n",
      "Angle between 76 and 86 = 37.91 \n",
      "Angle between 82 and 86 = 140.02 \n",
      "Final Matches = [[52, 82], [52, 86], [76, 82], [76, 86]], Final Matches Angle = [25.95, 16.92, 2.64, 37.91]\n",
      "matched_edges = [[52, 82], [52, 86], [76, 82], [76, 86]]matched_edges_angles = [25.95, 16.92, 2.64, 37.91]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(52, 82), (52, 86), (76, 82), (76, 86)], Remaining Nodes = [52, 76, 82, 86]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(52, 82), (52, 86), (76, 82), (76, 86)], Remaining Nodes = [52, 76, 82, 86]\n",
      "--Working on edge [52 82]--\n",
      "--Working on edge [52 86]--\n",
      "--Working on edge [76 82]--\n",
      "Edge [76 82] is matches definite match threshold with: \n",
      "Edge Buffer of 23.31 (angle_buffer = 15)\n",
      "Edge Angle of 2.64 (match_threshold = 45)\n",
      "--Working on edge [76 86]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(52, 86), (76, 82)], Remaining Nodes = [52, 76, 82, 86]\n",
      "upstream_subgraph = [82 76]\n",
      "Possible Connections = [76], angles = [2.64]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(52, 86), (76, 82)]\n",
      "Not doing kiss check because upstream_matches = [76]\n",
      "Using best match method\n",
      "for upstream node 82, winning_node = 76, error_branches = [86 52]\n",
      "winning_downstream = 76,error_downstream = [52 86] \n",
      "coordinate [862866.32268239 785205.35511803 908431.03693883] had error branches [52 86]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 5: [866831.22730981 722517.17475023 901951.79436284]--------\n",
      "For test node 88, sibling nodes were: [ 95 101]\n",
      "overlap = [ 95 101]\n",
      "With test node equal to the downstream node\n",
      "upstream = 92, downstream_nodes = [ 95 101  88]\n",
      "branches_at_coord = [ 88  92  95 101]\n",
      "widths_in_branches = [ 32.15119135 112.9247821   47.08639577 111.69524436]\n",
      "coordinate_branches = [88, 92, 95, 101]\n",
      "88 = red\n",
      "92 = aqua\n",
      "95 = purple\n",
      "101 = green\n",
      "Angle between 88 and 92 = 127.19 \n",
      "Angle between 88 and 95 = 29.28 \n",
      "Angle between 88 and 101 = 60.3 \n",
      "Angle between 92 and 95 = 39.13 \n",
      "Angle between 92 and 101 = 7.53 \n",
      "Angle between 95 and 101 = 134.26 \n",
      "Final Matches = [[88, 95], [88, 101], [92, 95], [92, 101]], Final Matches Angle = [29.28, 60.3, 39.13, 7.53]\n",
      "matched_edges = [[88, 95], [88, 101], [92, 95], [92, 101]]matched_edges_angles = [29.28, 60.3, 39.13, 7.53]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(88, 95), (88, 101), (92, 95), (92, 101)], Remaining Nodes = [88, 92, 95, 101]\n",
      "Removing edges (88, 101) because width difference 79.54405300373958\n",
      "edges_to_remove_by_width = [(88, 101)]\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(88, 95), (92, 95), (92, 101)], Remaining Nodes = [88, 92, 95, 101]\n",
      "--Working on edge [88 95]--\n",
      "--Working on edge [92 95]--\n",
      "--Working on edge [ 92 101]--\n",
      "Edge [ 92 101] is matches definite match threshold with: \n",
      "Edge Buffer of 31.6 (angle_buffer = 15)\n",
      "Edge Angle of 7.53 (match_threshold = 45)\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(88, 95), (92, 101)], Remaining Nodes = [88, 92, 95, 101]\n",
      "upstream_subgraph = [ 92 101]\n",
      "Possible Connections = [101], angles = [7.53]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(88, 95), (92, 101)]\n",
      "Not doing kiss check because upstream_matches = [101]\n",
      "Using best match method\n",
      "for upstream node 92, winning_node = 101, error_branches = [95 88]\n",
      "winning_downstream = 101,error_downstream = [88 95] \n",
      "coordinate [866831.22730981 722517.17475023 901951.79436284] had error branches [88 95]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 6: [867450.  830030.4 921801.1]--------\n",
      "For test node 47, sibling nodes were: [ 99 106]\n",
      "overlap = [ 99 106]\n",
      "With test node equal to the downstream node\n",
      "upstream = 97, downstream_nodes = [ 99 106  47]\n",
      "branches_at_coord = [ 47  97  99 106]\n",
      "widths_in_branches = [44.09166796 66.65005725 50.62205101 60.65701741]\n",
      "coordinate_branches = [47, 97, 99, 106]\n",
      "47 = red\n",
      "97 = aqua\n",
      "99 = purple\n",
      "106 = green\n",
      "Angle between 47 and 97 = 78.86 \n",
      "Angle between 47 and 99 = 79.06 \n",
      "Angle between 47 and 106 = 54.89 \n",
      "Angle between 97 and 99 = 75.12 \n",
      "Angle between 97 and 106 = 58.38 \n",
      "Angle between 99 and 106 = 80.53 \n",
      "Final Matches = [[47, 106], [97, 106]], Final Matches Angle = [54.89, 58.38]\n",
      "matched_edges = [[47, 106], [97, 106]]matched_edges_angles = [54.89, 58.38]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(47, 106), (97, 106)], Remaining Nodes = [47, 97, 99, 106]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(47, 106), (97, 106)], Remaining Nodes = [47, 97, 99, 106]\n",
      "--Working on edge [ 47 106]--\n",
      "--Working on edge [ 97 106]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(47, 106), (97, 106)], Remaining Nodes = [47, 97, 99, 106]\n",
      "upstream_subgraph = [ 97 106  47]\n",
      "Possible Connections = [106], angles = [58.38]\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(47, 106), (97, 106)]\n",
      "Not doing kiss check because upstream_matches = [106]\n",
      "Using best match method\n",
      "for upstream node 97, winning_node = 106, error_branches = [99 47]\n",
      "winning_downstream = 106,error_downstream = [47 99] \n",
      "coordinate [867450.  830030.4 921801.1] had error branches [47 99]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 7: [869669.96849919 838599.44021779 921636.89369984]--------\n",
      "For test node 89, sibling nodes were: [119 120]\n",
      "overlap = [119 120]\n",
      "With test node equal to the downstream node\n",
      "upstream = 113, downstream_nodes = [119 120  89]\n",
      "branches_at_coord = [ 89 113 119 120]\n",
      "widths_in_branches = [40.94461178 40.04088368 51.04102133 52.67531963]\n",
      "coordinate_branches = [89, 113, 119, 120]\n",
      "89 = red\n",
      "113 = aqua\n",
      "119 = purple\n",
      "120 = green\n",
      "Angle between 89 and 113 = 132.35 \n",
      "Angle between 89 and 119 = 81.36 \n",
      "Angle between 89 and 120 = 29.37 \n",
      "Angle between 113 and 119 = 35.52 \n",
      "Angle between 113 and 120 = 67.4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between 119 and 120 = 77.17 \n",
      "Final Matches = [[89, 120], [113, 119]], Final Matches Angle = [29.37, 35.52]\n",
      "matched_edges = [[89, 120], [113, 119]]matched_edges_angles = [29.37, 35.52]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(89, 120), (113, 119)], Remaining Nodes = [89, 113, 119, 120]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(89, 120), (113, 119)], Remaining Nodes = [89, 113, 119, 120]\n",
      "--Working on edge [ 89 120]--\n",
      "Edge [ 89 120] is matches definite match threshold with: \n",
      "Edge Buffer of inf (angle_buffer = 15)\n",
      "Edge Angle of 29.37 (match_threshold = 45)\n",
      "--Working on edge [113 119]--\n",
      "Edge [113 119] is matches definite match threshold with: \n",
      "Edge Buffer of inf (angle_buffer = 15)\n",
      "Edge Angle of 35.52 (match_threshold = 45)\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(89, 120), (113, 119)], Remaining Nodes = [89, 113, 119, 120]\n",
      "upstream_subgraph = [113 119]\n",
      "Possible Connections = [119], angles = [35.52]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(89, 120), (113, 119)]\n",
      "Not doing kiss check because upstream_matches = [119]\n",
      "Using best match method\n",
      "for upstream node 113, winning_node = 119, error_branches = [120  89]\n",
      "winning_downstream = 119,error_downstream = [ 89 120] \n",
      "coordinate [869669.96849919 838599.44021779 921636.89369984] had error branches [ 89 120]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 8: [875435.11241274 745744.96456118 897270.2401339 ]--------\n",
      "For test node 107, sibling nodes were: [102]\n",
      "overlap = []\n",
      "With test node equal to the upstream node\n",
      "upstream = 107, downstream_nodes = [117 124 129 130]\n",
      "branches_at_coord = [107 117 124 129 130]\n",
      "widths_in_branches = [55.41237783 75.5980009  42.18271241 71.67858605 64.78800108]\n",
      "coordinate_branches = [107, 117, 124, 129, 130]\n",
      "107 = blue\n",
      "117 = green\n",
      "124 = red\n",
      "129 = cyan\n",
      "130 = magenta\n",
      "Angle between 107 and 117 = 148.58 \n",
      "Angle between 107 and 124 = 133.92 \n",
      "Angle between 107 and 129 = 29.16 \n",
      "Angle between 107 and 130 = 53.79 \n",
      "Angle between 117 and 124 = 122.63 \n",
      "Angle between 117 and 129 = 20.3 \n",
      "Angle between 117 and 130 = 28.43 \n",
      "Angle between 124 and 129 = 70.01 \n",
      "Angle between 124 and 130 = 53.36 \n",
      "Angle between 129 and 130 = 131.77 \n",
      "Final Matches = [[107, 129], [107, 130], [117, 129], [117, 130], [124, 130]], Final Matches Angle = [29.16, 53.79, 20.3, 28.43, 53.36]\n",
      "matched_edges = [[107, 129], [107, 130], [117, 129], [117, 130], [124, 130]]matched_edges_angles = [29.16, 53.79, 20.3, 28.43, 53.36]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(107, 129), (107, 130), (117, 129), (117, 130), (124, 130)], Remaining Nodes = [107, 117, 124, 129, 130]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(107, 129), (107, 130), (117, 129), (117, 130), (124, 130)], Remaining Nodes = [107, 117, 124, 129, 130]\n",
      "--Working on edge [107 129]--\n",
      "--Working on edge [107 130]--\n",
      "--Working on edge [117 129]--\n",
      "--Working on edge [117 130]--\n",
      "--Working on edge [124 130]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(107, 129), (107, 130), (117, 129), (117, 130), (124, 130)], Remaining Nodes = [107, 117, 124, 129, 130]\n",
      "upstream_subgraph = [129 130 107 117 124]\n",
      "Possible Connections = [129 130], angles = [29.16 53.79]\n",
      "Deleting the following nodes because above match threshold while 1 are: [(107, 130)]\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(107, 129), (117, 129), (117, 130), (124, 130)]\n",
      "Not doing kiss check because upstream_matches = [129]\n",
      "Using best match method\n",
      "for upstream node 107, winning_node = 129, error_branches = [117 124 130]\n",
      "winning_downstream = 129,error_downstream = [117 124 130] \n",
      "coordinate [875435.11241274 745744.96456118 897270.2401339 ] had error branches [117 124 130]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 9: [876188.23454714 593247.65105784 884106.95333358]--------\n",
      "For test node 118, sibling nodes were: [115]\n",
      "overlap = []\n",
      "With test node equal to the upstream node\n",
      "upstream = 118, downstream_nodes = [128 131 133]\n",
      "branches_at_coord = [118 128 131 133]\n",
      "widths_in_branches = [67.89281638 86.59870201 66.76742941 38.13854089]\n",
      "coordinate_branches = [118, 128, 131, 133]\n",
      "118 = red\n",
      "128 = aqua\n",
      "131 = purple\n",
      "133 = green\n",
      "Angle between 118 and 128 = 148.74 \n",
      "Angle between 118 and 131 = 80.26 \n",
      "Angle between 118 and 133 = 22.63 \n",
      "Angle between 128 and 131 = 58.75 \n",
      "Angle between 128 and 133 = 49.63 \n",
      "Angle between 131 and 133 = 98.17 \n",
      "Final Matches = [[118, 133], [128, 131], [128, 133]], Final Matches Angle = [22.63, 58.75, 49.63]\n",
      "matched_edges = [[118, 133], [128, 131], [128, 133]]matched_edges_angles = [22.63, 58.75, 49.63]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(118, 133), (128, 131), (128, 133)], Remaining Nodes = [118, 128, 131, 133]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(118, 133), (128, 131), (128, 133)], Remaining Nodes = [118, 128, 131, 133]\n",
      "--Working on edge [118 133]--\n",
      "Edge [118 133] is matches definite match threshold with: \n",
      "Edge Buffer of 27.000000000000004 (angle_buffer = 15)\n",
      "Edge Angle of 22.63 (match_threshold = 45)\n",
      "--Working on edge [128 131]--\n",
      "--Working on edge [128 133]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(118, 133), (128, 131)], Remaining Nodes = [118, 128, 131, 133]\n",
      "upstream_subgraph = [133 118]\n",
      "Possible Connections = [133], angles = [22.63]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(118, 133), (128, 131)]\n",
      "Not doing kiss check because upstream_matches = [133]\n",
      "Using best match method\n",
      "for upstream node 118, winning_node = 133, error_branches = [128 131]\n",
      "winning_downstream = 133,error_downstream = [128 131] \n",
      "coordinate [876188.23454714 593247.65105784 884106.95333358] had error branches [128 131]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 10: [929506.10571956 786953.85100664 894211.67772456]--------\n",
      "For test node 154, sibling nodes were: [153]\n",
      "overlap = []\n",
      "With test node equal to the upstream node\n",
      "upstream = 154, downstream_nodes = [155 158 159]\n",
      "branches_at_coord = [154 155 158 159]\n",
      "widths_in_branches = [69.69243935 63.54671546 61.93567212 51.57302046]\n",
      "coordinate_branches = [154, 155, 158, 159]\n",
      "154 = red\n",
      "155 = aqua\n",
      "158 = purple\n",
      "159 = green\n",
      "Angle between 154 and 155 = 108.16 \n",
      "Angle between 154 and 158 = 70.26 \n",
      "Angle between 154 and 159 = 27.95 \n",
      "Angle between 155 and 158 = 18.35 \n",
      "Angle between 155 and 159 = 44.03 \n",
      "Angle between 158 and 159 = 134.47 \n",
      "Final Matches = [[154, 159], [155, 158], [155, 159]], Final Matches Angle = [27.95, 18.35, 44.03]\n",
      "matched_edges = [[154, 159], [155, 158], [155, 159]]matched_edges_angles = [27.95, 18.35, 44.03]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(154, 159), (155, 158), (155, 159)], Remaining Nodes = [154, 155, 158, 159]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(154, 159), (155, 158), (155, 159)], Remaining Nodes = [154, 155, 158, 159]\n",
      "--Working on edge [154 159]--\n",
      "Edge [154 159] is matches definite match threshold with: \n",
      "Edge Buffer of 16.080000000000002 (angle_buffer = 15)\n",
      "Edge Angle of 27.95 (match_threshold = 45)\n",
      "--Working on edge [155 158]--\n",
      "Edge [155 158] is matches definite match threshold with: \n",
      "Edge Buffer of 25.68 (angle_buffer = 15)\n",
      "Edge Angle of 18.35 (match_threshold = 45)\n",
      "--Working on edge [155 159]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(154, 159), (155, 158)], Remaining Nodes = [154, 155, 158, 159]\n",
      "upstream_subgraph = [154 159]\n",
      "Possible Connections = [159], angles = [27.95]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(154, 159), (155, 158)]\n",
      "Not doing kiss check because upstream_matches = [159]\n",
      "Using best match method\n",
      "for upstream node 154, winning_node = 159, error_branches = [155 158]\n",
      "winning_downstream = 159,error_downstream = [155 158] \n",
      "coordinate [929506.10571956 786953.85100664 894211.67772456] had error branches [155 158]--------\n",
      "limb_branch_dict_to_cancel = {'L1': array([ 20,  22,  41,  50,  57,  64,  44,  70,  77,  52,  86,  88,  95,\n",
      "        47,  99,  89, 120, 117, 124, 130, 128, 131, 155, 158])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [54, 56, 108, 118, 115, 133, 110, 0, 1, 2, 33, 4, 5, 10, 11, 14, 15, 16, 17, 18, 19, 21, 24, 26, 28, 29, 31, 116, 126, 134, 143, 145, 148, 149, 151, 152, 38, 43, 40, 53, 91, 114, 98, 100, 3, 7, 8, 9, 51, 84, 23, 87, 160, 161, 153, 162, 163, 122, 135, 136, 154, 121, 90, 159, 156, 157, 20, 22, 41, 50, 57, 64, 44, 70, 77, 52, 86, 88, 95, 47, 99, 89, 120, 117, 124, 130, 128, 131, 155, 158]}\n",
      "total_sk_distance = 1055.9886538134176, total_area = 677.6876899171631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {'L1': array([18, 25, 34, 48])}\n",
      "wide_angled_children= {'L1': array([34])}\n",
      "Web size = 109.40691217983323\n",
      "From limb L1, branch 34, Adding the downstream nodes [25, 44]  \n",
      "Final web t error limb branch dict = {'L1': [25, 44]}\n",
      "limb_branch_dict_to_cancel = {'L1': [25, 44]}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [2, 9, 11, 15, 16, 17, 18, 23, 24, 26, 45, 47, 48, 49, 50, 25, 44]}\n",
      "total_sk_distance = 194.17645046724698, total_area = 120.44229824733085\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {'L1': array([10, 33, 53])}\n",
      "wide_angled_children= {}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18,\n",
      "       19, 20, 21, 22]), 'L2': array([1, 3, 4]), 'L3': array([0, 2, 3]), 'L4': array([0, 1]), 'L6': array([0, 1])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L1': array([ 4,  8, 19, 21, 23, 24, 28, 30, 33, 35, 36, 38, 48, 49, 50, 51, 53,\n",
      "       55])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18,\n",
      "       19, 20, 21, 22]), 'L2': array([1, 3, 4]), 'L3': array([0, 2, 3]), 'L4': array([0, 1]), 'L6': array([0, 1])}\n",
      "limb_branch_dict_to_cancel = {'L3': array([3])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L3': [3]}\n",
      "total_sk_distance = 50.99776993332803, total_area = 119.74701324277143\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L1': array([ 0,  4,  8, 12, 18, 19, 21, 23, 24, 28, 30, 33, 35, 36, 38, 40, 44,\n",
      "       46, 48, 49, 50, 51, 53, 55])}\n",
      "limb_branch_dict_to_cancel = {'L1': array([46])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [45, 50, 46]}\n",
      "total_sk_distance = 46.68397607364975, total_area = 36.911725316764716\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L1': array([ 7, 11, 13, 16, 31, 34, 37, 42])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thick_axon_limb_branch = {'L1': array([ 8, 21, 24, 38, 39, 40, 41, 44, 47, 48, 49, 52, 53])}\n",
      "With divergence_threshold_mean = 165\n",
      "fork_div_limb_branch = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 271.4324994087219 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 289.5433135032654\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [845770 538702 887730]\n",
      "nuclei_within_radius = [328471]\n",
      "nuclei_within_radius_distance = [544.56955479]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 328471\n",
      "winning_nuclei_distance = 544.5695547861632\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [328471]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 328471\n",
      "winning_nuclei_distance = 544.5695547861632\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 328471, 'nuclei_distance': 544.57, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 328471\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 72, # error synapses  = 157, # error presyns = 7\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 187, # error synapses  = 0, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "Computing the overall stats\n",
      "n_presyn_error_syn = 157, n_postsyn_error_syn = 0\n",
      "total_presyns = 229, total_postsyns = 187\n",
      "perc_error_presyn = 0.6856, perc_error_postsyn = 0.0\n",
      "total_error_synapses = 157, total_synapses = 416\n",
      "overall_percent_error= 0.3774\n",
      "\n",
      "\n",
      " ***------ Total time for 864691136903001778 = 566.5524656772614 ------ ***\n",
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691136010916259  ----------\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 2\n",
      "Number of Neurons found =2\n",
      "Number of Corresponding Nuclei = 2\n",
      "nucleus_ids = [363898 468069]\n",
      "nucleus_centers = [[ 859136  603264  980640]\n",
      " [1062528  925760  840320]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [ 76 267]\n",
      "Skeleton paths distances = [ 2120.87581277 24937.35570255]\n",
      "Filtered indexes = [1]\n",
      "len(filtered_skeletons) = 1\n",
      "sk_angles = [141.41204371]\n",
      "local_axon_angles = [141.41204371]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Inhibitory Excitatory Classification = 6.6490747928619385\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={5: {0: 141.4120437057396}}\n",
      "n_axons=1\n",
      "n_apicals=0\n",
      "neuron_spine_density=0.00039691221417002977\n",
      "n_branches_processed=16\n",
      "skeletal_length_processed=1332533.9439005037\n",
      "n_branches_in_search_radius=28\n",
      "skeletal_length_in_search_radius=1519907.0461315268\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L0': [3, 11, 24]}\n",
      "total_sk_distance = 54.78568362366266, total_area = 47.77842669308081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "Final web t error limb branch dict = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 14, 18, 19, 20, 22,\n",
      "       24, 27, 28, 29]), 'L1': array([0, 1]), 'L2': array([1, 2]), 'L3': array([1, 2])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 14, 18, 19, 20, 22,\n",
      "       24, 27, 28, 29]), 'L1': array([0, 1]), 'L2': array([1, 2]), 'L3': array([1, 2])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thick_axon_limb_branch = {}\n",
      "With divergence_threshold_mean = 165\n",
      "fork_div_limb_branch = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 64.25512933731079 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 71.0288360118866\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [1062703  925597  840045]\n",
      "nuclei_within_radius = [468069]\n",
      "nuclei_within_radius_distance = [364.44341125]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 468069\n",
      "winning_nuclei_distance = 364.4434112451479\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [468069]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 468069\n",
      "winning_nuclei_distance = 364.4434112451479\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 468069, 'nuclei_distance': 364.44, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 468069\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 0, # error synapses  = 24, # error presyns = 6\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 150, # error synapses  = 455, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "\n",
      "-----Working on Neuron Split 1-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Inhibitory Excitatory Classification = 9.05306100845337\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={}\n",
      "n_axons=0\n",
      "n_apicals=2\n",
      "neuron_spine_density=0.0005728721268354254\n",
      "n_branches_processed=25\n",
      "skeletal_length_processed=2125131.564245944\n",
      "n_branches_in_search_radius=36\n",
      "skeletal_length_in_search_radius=2240419.131328756\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L0': [0, 2]}\n",
      "total_sk_distance = 32.58834558866719, total_area = 44.094835892739745\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "Final web t error limb branch dict = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12]), 'L1': array([0, 1, 2, 4, 5, 7]), 'L2': array([3, 4, 5, 6, 7, 8]), 'L3': array([0, 1, 2, 4])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12]), 'L1': array([0, 1, 2, 4, 5, 7]), 'L2': array([3, 4, 5, 6, 7, 8]), 'L3': array([0, 1, 2, 4])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 24.66089177131653 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 33.84797811508179\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [859389 603080 980687]\n",
      "nuclei_within_radius = [363898]\n",
      "nuclei_within_radius_distance = [316.34474865]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 363898\n",
      "winning_nuclei_distance = 316.3447486524788\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [363898]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 363898\n",
      "winning_nuclei_distance = 316.3447486524788\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 363898, 'nuclei_distance': 316.34, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 363898\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 0, # error synapses  = 24, # error presyns = 8\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 433, # error synapses  = 172, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "No skeletons to stack so returning empty list\n",
      "Computing the overall stats\n",
      "n_presyn_error_syn = 24, n_postsyn_error_syn = 22\n",
      "total_presyns = 24, total_postsyns = 605\n",
      "perc_error_presyn = 1.0, perc_error_postsyn = 0.0364\n",
      "total_error_synapses = 46, total_synapses = 629\n",
      "overall_percent_error= 0.0731\n",
      "\n",
      "\n",
      " ***------ Total time for 864691136010916259 = 422.9238176345825 ------ ***\n",
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135322963868  ----------\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 1\n",
      "Number of Neurons found =1\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [426790]\n",
      "nucleus_centers = [[1019584  629248 1044160]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [6321]\n",
      "Skeleton paths distances = [24931.04854801]\n",
      "Filtered indexes = [0]\n",
      "len(filtered_skeletons) = 1\n",
      "sk_angles = [167.88942977]\n",
      "local_axon_angles = [167.88942977]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Inhibitory Excitatory Classification = 16.12643837928772\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={1: {0: 167.88942976576973}}\n",
      "n_axons=1\n",
      "n_apicals=1\n",
      "neuron_spine_density=0.000495886586779079\n",
      "n_branches_processed=33\n",
      "skeletal_length_processed=2260345.370112992\n",
      "n_branches_in_search_radius=78\n",
      "skeletal_length_in_search_radius=2895693.0877307164\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L0': [24, 3, 7, 15, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], 'L1': [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118], 'L2': [3]}\n",
      "total_sk_distance = 935.5219564111698, total_area = 828.7611765220447\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 0: [ 964709.17344094  704286.32108915 1060405.77378187]--------\n",
      "For test node 11, sibling nodes were: [14 19]\n",
      "overlap = [14 19]\n",
      "With test node equal to the downstream node\n",
      "upstream = 20, downstream_nodes = [14 19 11]\n",
      "branches_at_coord = [11 14 19 20]\n",
      "widths_in_branches = [43.77283139 54.85570678 54.26309273 57.55909558]\n",
      "coordinate_branches = [11, 14, 19, 20]\n",
      "11 = red\n",
      "14 = aqua\n",
      "19 = purple\n",
      "20 = green\n",
      "Angle between 11 and 14 = 49.82 \n",
      "Angle between 11 and 19 = 40.09 \n",
      "Angle between 11 and 20 = 35.56 \n",
      "Angle between 14 and 19 = 93.39 \n",
      "Angle between 14 and 20 = 139.17 \n",
      "Angle between 19 and 20 = 126.85 \n",
      "Final Matches = [[11, 14], [11, 19], [11, 20]], Final Matches Angle = [49.82, 40.09, 35.56]\n",
      "matched_edges = [[11, 14], [11, 19], [11, 20]]matched_edges_angles = [49.82, 40.09, 35.56]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(11, 14), (11, 19), (11, 20)], Remaining Nodes = [11, 14, 19, 20]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(11, 14), (11, 19), (11, 20)], Remaining Nodes = [11, 14, 19, 20]\n",
      "--Working on edge [11 14]--\n",
      "--Working on edge [11 19]--\n",
      "--Working on edge [11 20]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(11, 14), (11, 19), (11, 20)], Remaining Nodes = [11, 14, 19, 20]\n",
      "upstream_subgraph = [19 11 20 14]\n",
      "Possible Connections = [11], angles = [35.56]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(11, 14), (11, 19), (11, 20)]\n",
      "Not doing kiss check because upstream_matches = [11]\n",
      "Using best match method\n",
      "for upstream node 20, winning_node = 11, error_branches = [14 19]\n",
      "winning_downstream = 11,error_downstream = [14 19] \n",
      "coordinate [ 964709.17344094  704286.32108915 1060405.77378187] had error branches [14 19]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 1: [ 964798.44782774  754800.28937102 1099620.76597402]--------\n",
      "For test node 4, sibling nodes were: [ 5  6  9 10 12 18 22 24]\n",
      "overlap = [ 5  6  9 10 12 18 22 24]\n",
      "With test node equal to the downstream node\n",
      "upstream = 23, downstream_nodes = [ 5  6  9 10 12 18 22 24  4]\n",
      "branches_at_coord = [ 4  5  6  9 10 12 18 22 23 24]\n",
      "Number of branches (9) was more than max_degree_to_resolve (6) so returning all downstream as error branches\n",
      "winning_downstream = None,error_downstream = [ 4  5  6 10 12 18 22 23 24] \n",
      "coordinate [ 964798.44782774  754800.28937102 1099620.76597402] had error branches [ 4  5  6 10 12 18 22 23 24]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 2: [ 967547.6531301   730460.2315542  1097771.04484553]--------\n",
      "For test node 7, sibling nodes were: [38]\n",
      "overlap = []\n",
      "With test node equal to the upstream node\n",
      "upstream = 7, downstream_nodes = [25 29 31 33 34]\n",
      "branches_at_coord = [ 7 25 29 31 33 34]\n",
      "widths_in_branches = [56.36914168 73.71042578 75.23585862 44.02833985 77.51917654 85.3078834 ]\n",
      "coordinate_branches = [7, 25, 29, 31, 33, 34]\n",
      "7 = blue\n",
      "25 = green\n",
      "29 = red\n",
      "31 = cyan\n",
      "33 = magenta\n",
      "34 = black\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between 7 and 25 = 122.78 \n",
      "Angle between 7 and 29 = 44.41 \n",
      "Angle between 7 and 31 = 11.21 \n",
      "Angle between 7 and 33 = 93.1 \n",
      "Angle between 7 and 34 = 20.25 \n",
      "Angle between 25 and 29 = 13.68 \n",
      "Angle between 25 and 31 = 50.26 \n",
      "Angle between 25 and 33 = 145.63 \n",
      "Angle between 25 and 34 = 68.59 \n",
      "Angle between 29 and 31 = 141.18 \n",
      "Angle between 29 and 33 = 47.68 \n",
      "Angle between 29 and 34 = 121.94 \n",
      "Angle between 31 and 33 = 77.23 \n",
      "Angle between 31 and 34 = 160.45 \n",
      "Angle between 33 and 34 = 90.85 \n",
      "Final Matches = [[7, 29], [7, 31], [7, 34], [25, 29], [25, 31], [29, 33]], Final Matches Angle = [44.41, 11.21, 20.25, 13.68, 50.26, 47.68]\n",
      "matched_edges = [[7, 29], [7, 31], [7, 34], [25, 29], [25, 31], [29, 33]]matched_edges_angles = [44.41, 11.21, 20.25, 13.68, 50.26, 47.68]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(7, 29), (7, 31), (7, 34), (25, 29), (25, 31), (29, 33)], Remaining Nodes = [7, 25, 29, 31, 33, 34]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(7, 29), (7, 31), (7, 34), (25, 29), (25, 31), (29, 33)], Remaining Nodes = [7, 25, 29, 31, 33, 34]\n",
      "--Working on edge [ 7 29]--\n",
      "--Working on edge [ 7 31]--\n",
      "--Working on edge [ 7 34]--\n",
      "--Working on edge [25 29]--\n",
      "Edge [25 29] is matches definite match threshold with: \n",
      "Edge Buffer of 30.729999999999997 (angle_buffer = 15)\n",
      "Edge Angle of 13.68 (match_threshold = 45)\n",
      "--Working on edge [25 31]--\n",
      "--Working on edge [29 33]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(7, 31), (7, 34), (25, 29)], Remaining Nodes = [7, 25, 29, 31, 33, 34]\n",
      "upstream_subgraph = [34 31  7]\n",
      "Possible Connections = [31 34], angles = [11.21 20.25]\n",
      "Deleting the following nodes because above match threshold while 2 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(7, 31), (7, 34), (25, 29)]\n",
      "Working on Kissing check because possible upstream matches greater than 1: [31, 34]\n",
      "Step 5b: Removing kissing edges\n",
      "Remaining Edges = [(7, 31), (7, 34), (25, 29)]\n",
      "Using best match method\n",
      "for upstream node 7, winning_node = 31, error_branches = [25 29 33 34]\n",
      "winning_downstream = 31,error_downstream = [25 29 33 34] \n",
      "coordinate [ 967547.6531301   730460.2315542  1097771.04484553] had error branches [25 29 33 34]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 3: [ 968817.6904561   744916.62141157 1093555.89233084]--------\n",
      "For test node 23, sibling nodes were: [36 43]\n",
      "overlap = [36 43]\n",
      "With test node equal to the downstream node\n",
      "upstream = 41, downstream_nodes = [36 43 23]\n",
      "branches_at_coord = [23 36 41 43]\n",
      "widths_in_branches = [62.97798798 60.02763112 84.43971813 70.87642328]\n",
      "coordinate_branches = [23, 36, 41, 43]\n",
      "23 = red\n",
      "36 = aqua\n",
      "41 = purple\n",
      "43 = green\n",
      "Angle between 23 and 36 = 161.83 \n",
      "Angle between 23 and 41 = 44.9 \n",
      "Angle between 23 and 43 = 74.45 \n",
      "Angle between 36 and 41 = 40.27 \n",
      "Angle between 36 and 43 = 91.93 \n",
      "Angle between 41 and 43 = 95.57 \n",
      "Final Matches = [[23, 41], [36, 41]], Final Matches Angle = [44.9, 40.27]\n",
      "matched_edges = [[23, 41], [36, 41]]matched_edges_angles = [44.9, 40.27]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(23, 41), (36, 41)], Remaining Nodes = [23, 36, 41, 43]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(23, 41), (36, 41)], Remaining Nodes = [23, 36, 41, 43]\n",
      "--Working on edge [23 41]--\n",
      "--Working on edge [36 41]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(23, 41), (36, 41)], Remaining Nodes = [23, 36, 41, 43]\n",
      "upstream_subgraph = [41 36 23]\n",
      "Possible Connections = [23 36], angles = [44.9  40.27]\n",
      "Deleting the following nodes because above match threshold while 2 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(23, 41), (36, 41)]\n",
      "Working on Kissing check because possible upstream matches greater than 1: [23, 36]\n",
      "Step 5b: Removing kissing edges\n",
      "Remaining Edges = [(23, 41), (36, 41)]\n",
      "Using best match method\n",
      "for upstream node 41, winning_node = 36, error_branches = [43 23]\n",
      "winning_downstream = 36,error_downstream = [23 43] \n",
      "coordinate [ 968817.6904561   744916.62141157 1093555.89233084] had error branches [23 43]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 4: [ 969203.71766363  750750.84486755 1096361.48394348]--------\n",
      "For test node 32, sibling nodes were: [35 44]\n",
      "overlap = [35 44]\n",
      "With test node equal to the downstream node\n",
      "upstream = 42, downstream_nodes = [35 44 32]\n",
      "branches_at_coord = [32 35 42 44]\n",
      "widths_in_branches = [55.57695656 72.1675457  96.91278297 57.96444925]\n",
      "coordinate_branches = [32, 35, 42, 44]\n",
      "32 = red\n",
      "35 = aqua\n",
      "42 = purple\n",
      "44 = green\n",
      "Angle between 32 and 35 = 153.71 \n",
      "Angle between 32 and 42 = 68.87 \n",
      "Angle between 32 and 44 = 14.71 \n",
      "Angle between 35 and 42 = 46.1 \n",
      "Angle between 35 and 44 = 32.89 \n",
      "Angle between 42 and 44 = 101.24 \n",
      "Final Matches = [[32, 44], [35, 42], [35, 44]], Final Matches Angle = [14.71, 46.1, 32.89]\n",
      "matched_edges = [[32, 44], [35, 42], [35, 44]]matched_edges_angles = [14.71, 46.1, 32.89]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(32, 44), (35, 42), (35, 44)], Remaining Nodes = [32, 35, 42, 44]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(32, 44), (35, 42), (35, 44)], Remaining Nodes = [32, 35, 42, 44]\n",
      "--Working on edge [32 44]--\n",
      "Edge [32 44] is matches definite match threshold with: \n",
      "Edge Buffer of 18.18 (angle_buffer = 15)\n",
      "Edge Angle of 14.71 (match_threshold = 45)\n",
      "--Working on edge [35 42]--\n",
      "--Working on edge [35 44]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(32, 44), (35, 42)], Remaining Nodes = [32, 35, 42, 44]\n",
      "upstream_subgraph = [42 35]\n",
      "Possible Connections = [35], angles = [46.1]\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(32, 44), (35, 42)]\n",
      "Not doing kiss check because upstream_matches = [35]\n",
      "Using best match method\n",
      "for upstream node 42, winning_node = 35, error_branches = [44 32]\n",
      "winning_downstream = 35,error_downstream = [32 44] \n",
      "coordinate [ 969203.71766363  750750.84486755 1096361.48394348] had error branches [32 44]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 5: [ 969399.7073728   741331.61656949 1092452.7910937 ]--------\n",
      "For test node 37, sibling nodes were: [40 41 47]\n",
      "overlap = [40 41 47]\n",
      "With test node equal to the downstream node\n",
      "upstream = 45, downstream_nodes = [40 41 47 37]\n",
      "branches_at_coord = [37 40 41 45 47]\n",
      "widths_in_branches = [ 90.66631735 122.56407255  84.43971813 179.35851036  76.37421937]\n",
      "coordinate_branches = [37, 40, 41, 45, 47]\n",
      "37 = blue\n",
      "40 = green\n",
      "41 = red\n",
      "45 = cyan\n",
      "47 = magenta\n",
      "Angle between 37 and 40 = 95.41 \n",
      "Angle between 37 and 41 = 113.08 \n",
      "Angle between 37 and 45 = 39.99 \n",
      "Angle between 37 and 47 = 74.26 \n",
      "Angle between 40 and 41 = 47.94 \n",
      "Angle between 40 and 45 = 103.19 \n",
      "Angle between 40 and 47 = 130.71 \n",
      "Angle between 41 and 45 = 32.16 \n",
      "Angle between 41 and 47 = 8.98 \n",
      "Angle between 45 and 47 = 143.07 \n",
      "Final Matches = [[37, 45], [40, 41], [41, 45], [41, 47]], Final Matches Angle = [39.99, 47.94, 32.16, 8.98]\n",
      "matched_edges = [[37, 45], [40, 41], [41, 45], [41, 47]]matched_edges_angles = [39.99, 47.94, 32.16, 8.98]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(37, 45), (40, 41), (41, 45), (41, 47)], Remaining Nodes = [37, 40, 41, 45, 47]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(37, 45), (40, 41), (41, 45), (41, 47)], Remaining Nodes = [37, 40, 41, 45, 47]\n",
      "--Working on edge [37 45]--\n",
      "--Working on edge [40 41]--\n",
      "--Working on edge [41 45]--\n",
      "--Working on edge [41 47]--\n",
      "Edge [41 47] is matches definite match threshold with: \n",
      "Edge Buffer of 23.179999999999996 (angle_buffer = 15)\n",
      "Edge Angle of 8.98 (match_threshold = 45)\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(37, 45), (41, 47)], Remaining Nodes = [37, 40, 41, 45, 47]\n",
      "upstream_subgraph = [45 37]\n",
      "Possible Connections = [37], angles = [39.99]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(37, 45), (41, 47)]\n",
      "Not doing kiss check because upstream_matches = [37]\n",
      "Using best match method\n",
      "for upstream node 45, winning_node = 37, error_branches = [40 41 47]\n",
      "winning_downstream = 37,error_downstream = [40 41 47] \n",
      "coordinate [ 969399.7073728   741331.61656949 1092452.7910937 ] had error branches [40 41 47]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 6: [ 971323.28806566  735122.62727727 1091413.68190866]--------\n",
      "For test node 46, sibling nodes were: [45]\n",
      "overlap = []\n",
      "With test node equal to the upstream node\n",
      "upstream = 46, downstream_nodes = [48 49 50 51]\n",
      "branches_at_coord = [46 48 49 50 51]\n",
      "widths_in_branches = [ 92.9123219   54.38101235  52.00814089 158.95867945  59.85280038]\n",
      "coordinate_branches = [46, 48, 49, 50, 51]\n",
      "46 = blue\n",
      "48 = green\n",
      "49 = red\n",
      "50 = cyan\n",
      "51 = magenta\n",
      "Angle between 46 and 48 = 21.12 \n",
      "Angle between 46 and 49 = 54.74 \n",
      "Angle between 46 and 50 = 136.9 \n",
      "Angle between 46 and 51 = 8.72 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between 48 and 49 = 139.82 \n",
      "Angle between 48 and 50 = 50.32 \n",
      "Angle between 48 and 51 = 166.55 \n",
      "Angle between 49 and 50 = 90.32 \n",
      "Angle between 49 and 51 = 133.53 \n",
      "Angle between 50 and 51 = 48.22 \n",
      "Final Matches = [[46, 48], [46, 49], [46, 51], [48, 50], [50, 51]], Final Matches Angle = [21.12, 54.74, 8.72, 50.32, 48.22]\n",
      "matched_edges = [[46, 48], [46, 49], [46, 51], [48, 50], [50, 51]]matched_edges_angles = [21.12, 54.74, 8.72, 50.32, 48.22]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(46, 48), (46, 49), (46, 51), (48, 50), (50, 51)], Remaining Nodes = [46, 48, 49, 50, 51]\n",
      "Removing edges (48, 50) because width difference 104.57766710280475\n",
      "Removing edges (50, 51) because width difference 99.10587906647703\n",
      "edges_to_remove_by_width = [(48, 50), (50, 51)]\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(46, 48), (46, 49), (46, 51)], Remaining Nodes = [46, 48, 49, 50, 51]\n",
      "--Working on edge [46 48]--\n",
      "--Working on edge [46 49]--\n",
      "--Working on edge [46 51]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(46, 48), (46, 49), (46, 51)], Remaining Nodes = [46, 48, 49, 50, 51]\n",
      "upstream_subgraph = [48 49 51 46]\n",
      "Possible Connections = [48 49 51], angles = [21.12 54.74  8.72]\n",
      "Deleting the following nodes because above match threshold while 2 are: [(46, 49)]\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(46, 48), (46, 51)]\n",
      "Working on Kissing check because possible upstream matches greater than 1: [48, 51]\n",
      "Step 5b: Removing kissing edges\n",
      "Remaining Edges = [(46, 48), (46, 51)]\n",
      "Using best match method\n",
      "for upstream node 46, winning_node = 51, error_branches = [48 49 50]\n",
      "winning_downstream = 51,error_downstream = [48 49 50] \n",
      "coordinate [ 971323.28806566  735122.62727727 1091413.68190866] had error branches [48 49 50]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 7: [1032592.55537542  730745.26939931 1052658.73108061]--------\n",
      "For test node 65, sibling nodes were: [70 74 79]\n",
      "overlap = [70 74 79]\n",
      "With test node equal to the downstream node\n",
      "upstream = 77, downstream_nodes = [70 74 79 65]\n",
      "branches_at_coord = [65 70 74 77 79]\n",
      "widths_in_branches = [ 53.98754967  95.77146221 152.6996336  134.63782555  63.64085845]\n",
      "coordinate_branches = [65, 70, 74, 77, 79]\n",
      "65 = blue\n",
      "70 = green\n",
      "74 = red\n",
      "77 = cyan\n",
      "79 = magenta\n",
      "Angle between 65 and 70 = 85.14 \n",
      "Angle between 65 and 74 = 125.06 \n",
      "Angle between 65 and 77 = 90.22 \n",
      "Angle between 65 and 79 = 7.18 \n",
      "Angle between 70 and 74 = 96.41 \n",
      "Angle between 70 and 77 = 71.93 \n",
      "Angle between 70 and 79 = 101.76 \n",
      "Angle between 74 and 77 = 35.84 \n",
      "Angle between 74 and 79 = 54.66 \n",
      "Angle between 77 and 79 = 89.53 \n",
      "Final Matches = [[65, 79], [74, 77], [74, 79]], Final Matches Angle = [7.18, 35.84, 54.66]\n",
      "matched_edges = [[65, 79], [74, 77], [74, 79]]matched_edges_angles = [7.18, 35.84, 54.66]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(65, 79), (74, 77), (74, 79)], Remaining Nodes = [65, 70, 74, 77, 79]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(65, 79), (74, 77), (74, 79)], Remaining Nodes = [65, 70, 74, 77, 79]\n",
      "--Working on edge [65 79]--\n",
      "Edge [65 79] is matches definite match threshold with: \n",
      "Edge Buffer of 47.48 (angle_buffer = 15)\n",
      "Edge Angle of 7.18 (match_threshold = 45)\n",
      "--Working on edge [74 77]--\n",
      "Edge [74 77] is matches definite match threshold with: \n",
      "Edge Buffer of 18.819999999999993 (angle_buffer = 15)\n",
      "Edge Angle of 35.84 (match_threshold = 45)\n",
      "--Working on edge [74 79]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(65, 79), (74, 77)], Remaining Nodes = [65, 70, 74, 77, 79]\n",
      "upstream_subgraph = [74 77]\n",
      "Possible Connections = [74], angles = [35.84]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(65, 79), (74, 77)]\n",
      "Not doing kiss check because upstream_matches = [74]\n",
      "Using best match method\n",
      "for upstream node 77, winning_node = 74, error_branches = [70 79 65]\n",
      "winning_downstream = 74,error_downstream = [65 70 79] \n",
      "coordinate [1032592.55537542  730745.26939931 1052658.73108061] had error branches [65 70 79]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 8: [1034898.07956071  657597.14185037 1098531.1148086 ]--------\n",
      "For test node 82, sibling nodes were: [83 88]\n",
      "overlap = [83 88]\n",
      "With test node equal to the downstream node\n",
      "upstream = 87, downstream_nodes = [83 88 82]\n",
      "branches_at_coord = [82 83 87 88]\n",
      "Number of branches (3, aka branches_at_coord = [83 87 88]) was less than min_degree_to_resolve (4) so returning no error branches\n",
      "winning_downstream = None,error_downstream = [] \n",
      "coordinate [1034898.07956071  657597.14185037 1098531.1148086 ] had error branches []--------\n",
      "limb_branch_dict_to_cancel = {'L1': array([14, 19,  4,  5,  6, 10, 12, 18, 22, 23, 24, 25, 29, 33, 34, 23, 43,\n",
      "       32, 44, 40, 41, 47, 48, 49, 50, 65, 70, 79])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [3, 26, 37, 45, 51, 46, 42, 35, 36, 39, 8, 13, 15, 17, 9, 27, 28, 14, 19, 4, 5, 6, 10, 12, 18, 22, 23, 24, 25, 29, 33, 34, 23, 43, 32, 44, 40, 41, 47, 48, 49, 50, 65, 70, 79]}\n",
      "total_sk_distance = 286.4025710424282, total_area = 190.2691211537844\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {'L1': array([ 4,  7,  8, 13, 19, 25, 32, 45])}\n",
      "wide_angled_children= {'L1': array([13, 45])}\n",
      "Web size = 179.8846458037545\n",
      "Web size = 215.4101145259488\n",
      "Final web t error limb branch dict = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {'L1': array([ 4,  8, 13, 16, 19, 25, 39, 45, 46])}\n",
      "wide_angled_children= {'L1': array([13, 45])}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  5,  6,  7, 11, 14, 15, 16]), 'L1': array([53, 54, 55, 56, 57, 58, 59, 60, 61]), 'L2': array([0, 1, 2, 3, 4, 6, 7]), 'L3': array([0, 1, 2, 3])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L1': array([ 0,  1,  2,  3,  5,  8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22,\n",
      "       23, 25, 32, 33, 39, 40, 41, 43, 46, 48])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3,  4,  5,  6,  7, 11, 14, 15, 16]), 'L1': array([53, 54, 55, 56, 57, 58, 59, 60, 61]), 'L2': array([0, 1, 2, 3, 4, 6, 7]), 'L3': array([0, 1, 2, 3])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L1': array([ 0,  1,  2,  3,  5,  8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22,\n",
      "       23, 25, 30, 32, 33, 39, 40, 41, 43, 44, 45, 46, 48])}\n",
      "limb_branch_dict_to_cancel = {'L1': array([20])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [20]}\n",
      "total_sk_distance = 60.42866631474034, total_area = 32.67412173708553\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L1': array([23, 25, 26, 27, 28, 30, 33, 34])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thick_axon_limb_branch = {'L1': array([ 0,  1,  2,  3,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17, 19,\n",
      "       29, 31, 41, 42, 44, 45, 47])}\n",
      "With divergence_threshold_mean = 165\n",
      "fork_div_limb_branch = {'L1': array([0, 2])}\n",
      "For L1 sib_groups= [[0, 2]]\n",
      "For sibling group [0, 2]: upstream node = 4\n",
      "Widths are [53.28710241 41.60652383], upstream_width = 43.77283139204671\n",
      "width_differences= [9.51427102 2.16630757]\n",
      "limb_branch_dict_to_cancel = {'L1': [0, 2]}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [0, 2]}\n",
      "total_sk_distance = 67.07482292554106, total_area = 32.42435362107874\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 159.1469645500183 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 175.80025339126587\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [1019509  629062 1044535]\n",
      "nuclei_within_radius = [426790]\n",
      "nuclei_within_radius_distance = [425.25992052]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 426790\n",
      "winning_nuclei_distance = 425.25992051920434\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [426790]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 426790\n",
      "winning_nuclei_distance = 425.25992051920434\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 426790, 'nuclei_distance': 425.26, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 426790\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 18, # error synapses  = 128, # error presyns = 4\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 324, # error synapses  = 0, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "Computing the overall stats\n",
      "n_presyn_error_syn = 128, n_postsyn_error_syn = 0\n",
      "total_presyns = 146, total_postsyns = 324\n",
      "perc_error_presyn = 0.8767, perc_error_postsyn = 0.0\n",
      "total_error_synapses = 128, total_synapses = 470\n",
      "overall_percent_error= 0.2723\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135322963868 = 374.66936445236206 ------ ***\n",
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135012566518  ----------\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 2\n",
      "Number of Neurons found =2\n",
      "Number of Corresponding Nuclei = 2\n",
      "nucleus_ids = [703907 707584]\n",
      "nucleus_centers = [[1566400  670016 1086040]\n",
      " [1572416  766848 1065160]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [ 714 1155 1499 1568 1587 1610]\n",
      "Skeleton paths distances = [24913.68073925 24963.78452637 13500.85321307 12278.03041735\n",
      " 12166.86109309 16211.43263358]\n",
      "Filtered indexes = [0 1]\n",
      "len(filtered_skeletons) = 2\n",
      "sk_angles = [100.87114375 148.87782652]\n",
      "local_axon_angles = [100.87114375 148.87782652]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Did not pass final filters to continuing\n",
      "Inhibitory Excitatory Classification = 6.774121999740601\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={3: {0: 100.87114374602791}}\n",
      "n_axons=1\n",
      "n_apicals=0\n",
      "neuron_spine_density=0.0006012727817822912\n",
      "n_branches_processed=19\n",
      "skeletal_length_processed=1162517.2283983012\n",
      "n_branches_in_search_radius=74\n",
      "skeletal_length_in_search_radius=1790891.3599320562\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L0': [12, 15, 17], 'L1': [5, 8, 10, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]}\n",
      "total_sk_distance = 610.8743114140433, total_area = 780.6930714426237\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 0: [1543287.36377108  830873.89427269 1086334.71518203]--------\n",
      "For test node 0, sibling nodes were: [1 3 4]\n",
      "overlap = [1 3 4]\n",
      "With test node equal to the downstream node\n",
      "upstream = 2, downstream_nodes = [1 3 4 0]\n",
      "branches_at_coord = [0 1 2 3 4]\n",
      "Changing max_degree_to_resolve = 8 because upstream width was 260.6138655599488 \n",
      "widths_in_branches = [ 74.2515123   59.08696567 260.61386556  62.36787569  94.8152822 ]\n",
      "coordinate_branches = [0, 1, 2, 3, 4]\n",
      "0 = blue\n",
      "1 = green\n",
      "2 = red\n",
      "3 = cyan\n",
      "4 = magenta\n",
      "Angle between 0 and 1 = 97.89 \n",
      "Angle between 0 and 2 = 88.29 \n",
      "Angle between 0 and 3 = 139.57 \n",
      "Angle between 0 and 4 = 111.24 \n",
      "Angle between 1 and 2 = 162.38 \n",
      "Angle between 1 and 3 = 137.91 \n",
      "Angle between 1 and 4 = 148.26 \n",
      "Angle between 2 and 3 = 128.27 \n",
      "Angle between 2 and 4 = 130.67 \n",
      "Angle between 3 and 4 = 139.41 \n",
      "Final Matches = [], Final Matches Angle = []\n",
      "matched_edges = []matched_edges_angles = []\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [], Remaining Nodes = [0, 1, 2, 3, 4]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [], Remaining Nodes = [0, 1, 2, 3, 4]\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [], Remaining Nodes = [0, 1, 2, 3, 4]\n",
      "upstream_subgraph = [2]\n",
      "Possible Connections = [], angles = []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = []\n",
      "Not doing kiss check because upstream_matches = []\n",
      "winning_downstream = None,error_downstream = [0 1 3 4] \n",
      "coordinate [1543287.36377108  830873.89427269 1086334.71518203] had error branches [0 1 3 4]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 1: [1566441.61594196  782201.94546601 1073038.08563707]--------\n",
      "For test node 10, sibling nodes were: [12 13]\n",
      "overlap = [12 13]\n",
      "With test node equal to the downstream node\n",
      "upstream = 14, downstream_nodes = [12 13 10]\n",
      "branches_at_coord = [10 12 13 14]\n",
      "Number of branches (2, aka branches_at_coord = [10 14]) was less than min_degree_to_resolve (4) so returning no error branches\n",
      "winning_downstream = None,error_downstream = [] \n",
      "coordinate [1566441.61594196  782201.94546601 1073038.08563707] had error branches []--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 2: [1567286.36501564  774817.97710011 1073132.08966758]--------\n",
      "For test node 6, sibling nodes were: [15 16]\n",
      "overlap = [15 16]\n",
      "With test node equal to the downstream node\n",
      "upstream = 17, downstream_nodes = [15 16  6]\n",
      "branches_at_coord = [ 6 15 16 17]\n",
      "Changing max_degree_to_resolve = 8 because upstream width was 348.2282403171282 \n",
      "widths_in_branches = [221.2532233  446.87052276 337.80606467 348.22824032]\n",
      "Returning No errors because widths are too thick for skeletons to be trusted\n",
      "winning_downstream = None,error_downstream = [] \n",
      "coordinate [1567286.36501564  774817.97710011 1073132.08966758] had error branches []--------\n",
      "limb_branch_dict_to_cancel = {'L3': array([0, 1, 3, 4])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L3': [5, 9, 0, 1, 3, 4]}\n",
      "total_sk_distance = 54.69651330439623, total_area = 37.4230040626391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "Final web t error limb branch dict = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 2,  3,  4,  5, 13, 14]), 'L1': array([0, 1, 2, 3, 4, 5, 7, 8]), 'L2': array([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 12])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 2,  3,  4,  5, 13, 14]), 'L1': array([0, 1, 2, 3, 4, 5, 7, 8]), 'L2': array([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 12])}\n",
      "limb_branch_dict_to_cancel = {'L1': array([7])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [7]}\n",
      "total_sk_distance = 7.043104942048451, total_area = 8.186306687578904\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L3': array([6])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L3': array([3])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thick_axon_limb_branch = {}\n",
      "With divergence_threshold_mean = 165\n",
      "fork_div_limb_branch = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 51.66031575202942 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 58.79200482368469\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [1572113  766135 1065912]\n",
      "nuclei_within_radius = [707584]\n",
      "nuclei_within_radius_distance = [1079.66754142]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 707584\n",
      "winning_nuclei_distance = 1079.6675414218953\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [707584]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 707584\n",
      "winning_nuclei_distance = 1079.6675414218953\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 707584, 'nuclei_distance': 1079.67, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 707584\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 0, # error synapses  = 22, # error presyns = 1\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 81, # error synapses  = 71, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "\n",
      "-----Working on Neuron Split 1-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [ 65 130]\n",
      "Skeleton paths distances = [11022.18774473 13646.4695284 ]\n",
      "Filtered indexes = []\n",
      "len(filtered_skeletons) = 2\n",
      "sk_angles = [144.1247831  121.99968767]\n",
      "local_axon_angles = [144.1247831  121.99968767]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = sparsely_spined\n",
      "n_apicals = 0\n",
      "n_axons = 1\n",
      "axon_angles = {4: {0: 144.12478309553754}}\n",
      "Inhibitory Excitatory Classification = 19.56418514251709\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=sparsely_spined\n",
      "axon_angles={4: {0: 144.12478309553754}}\n",
      "n_axons=1\n",
      "n_apicals=0\n",
      "neuron_spine_density=0.00025674765937254006\n",
      "n_branches_processed=23\n",
      "skeletal_length_processed=1240880.8637959876\n",
      "n_branches_in_search_radius=50\n",
      "skeletal_length_in_search_radius=1581392.5596901504\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L8': [3, 5, 6, 7, 8, 9, 10]}\n",
      "total_sk_distance = 148.3705805287109, total_area = 113.876729704138\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "Final web t error limb branch dict = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([3, 4, 5, 6]), 'L2': array([0, 1, 2, 3, 6]), 'L3': array([0, 1]), 'L4': array([5, 6]), 'L5': array([1, 2]), 'L8': array([0, 1, 3, 4, 5]), 'L9': array([0, 1, 4, 5, 6])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([3, 4, 5, 6]), 'L2': array([0, 1, 2, 3, 6]), 'L3': array([0, 1]), 'L4': array([5, 6]), 'L5': array([1, 2]), 'L8': array([0, 1, 3, 4, 5]), 'L9': array([0, 1, 4, 5, 6])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thick_axon_limb_branch = {}\n",
      "With divergence_threshold_mean = 165\n",
      "fork_div_limb_branch = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 27.034685373306274 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 46.71592688560486\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [1567759  670825 1085347]\n",
      "nuclei_within_radius = [703907]\n",
      "nuclei_within_radius_distance = [1726.73420074]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 703907\n",
      "winning_nuclei_distance = 1726.7342007384923\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [703907]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 703907\n",
      "winning_nuclei_distance = 1726.7342007384923\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 703907, 'nuclei_distance': 1726.73, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 703907\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 0, # error synapses  = 22, # error presyns = 4\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 67, # error synapses  = 85, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "Computing the overall stats\n",
      "n_presyn_error_syn = 22, n_postsyn_error_syn = 4\n",
      "total_presyns = 22, total_postsyns = 152\n",
      "perc_error_presyn = 1.0, perc_error_postsyn = 0.0263\n",
      "total_error_synapses = 26, total_synapses = 174\n",
      "overall_percent_error= 0.1494\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135012566518 = 294.6883752346039 ------ ***\n",
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135382976491  ----------\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 1\n",
      "Number of Neurons found =1\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [236977]\n",
      "nucleus_centers = [[641280 919040 995480]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [160 269]\n",
      "Skeleton paths distances = [ 8349.7588283  24929.01242866]\n",
      "Filtered indexes = [1]\n",
      "len(filtered_skeletons) = 1\n",
      "sk_angles = [152.4262881]\n",
      "local_axon_angles = [152.4262881]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Inhibitory Excitatory Classification = 14.114880800247192\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={5: {0: 152.4262880956695}}\n",
      "n_axons=1\n",
      "n_apicals=0\n",
      "neuron_spine_density=0.0004929723887887388\n",
      "n_branches_processed=15\n",
      "skeletal_length_processed=1083705.5218248407\n",
      "n_branches_in_search_radius=41\n",
      "skeletal_length_in_search_radius=1477850.1932922574\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L0': [9, 13], 'L1': [7]}\n",
      "total_sk_distance = 47.84363077829753, total_area = 33.81202673249811\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 0: [ 654667.14431942  954251.71617274 1021315.68260312]--------\n",
      "For test node 3, sibling nodes were: [5 8]\n",
      "overlap = [5 8]\n",
      "With test node equal to the downstream node\n",
      "upstream = 9, downstream_nodes = [5 8 3]\n",
      "branches_at_coord = [3 5 8 9]\n",
      "widths_in_branches = [58.45367676 47.41002452 45.9408248  56.67523345]\n",
      "coordinate_branches = [3, 5, 8, 9]\n",
      "3 = red\n",
      "5 = aqua\n",
      "8 = purple\n",
      "9 = green\n",
      "Angle between 3 and 5 = 46.15 \n",
      "Angle between 3 and 8 = 143.03 \n",
      "Angle between 3 and 9 = 20.26 \n",
      "Angle between 5 and 8 = 16.66 \n",
      "Angle between 5 and 9 = 120.7 \n",
      "Angle between 8 and 9 = 54.64 \n",
      "Final Matches = [[3, 5], [3, 9], [5, 8], [8, 9]], Final Matches Angle = [46.15, 20.26, 16.66, 54.64]\n",
      "matched_edges = [[3, 5], [3, 9], [5, 8], [8, 9]]matched_edges_angles = [46.15, 20.26, 16.66, 54.64]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(3, 5), (3, 9), (5, 8), (8, 9)], Remaining Nodes = [3, 5, 8, 9]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(3, 5), (3, 9), (5, 8), (8, 9)], Remaining Nodes = [3, 5, 8, 9]\n",
      "--Working on edge [3 5]--\n",
      "--Working on edge [3 9]--\n",
      "Edge [3 9] is matches definite match threshold with: \n",
      "Edge Buffer of 25.889999999999997 (angle_buffer = 15)\n",
      "Edge Angle of 20.26 (match_threshold = 45)\n",
      "--Working on edge [5 8]--\n",
      "Edge [5 8] is matches definite match threshold with: \n",
      "Edge Buffer of 29.49 (angle_buffer = 15)\n",
      "Edge Angle of 16.66 (match_threshold = 45)\n",
      "--Working on edge [8 9]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(3, 9), (5, 8)], Remaining Nodes = [3, 5, 8, 9]\n",
      "upstream_subgraph = [9 3]\n",
      "Possible Connections = [3], angles = [20.26]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(3, 9), (5, 8)]\n",
      "Not doing kiss check because upstream_matches = [3]\n",
      "Using best match method\n",
      "for upstream node 9, winning_node = 3, error_branches = [5 8]\n",
      "winning_downstream = 3,error_downstream = [5 8] \n",
      "coordinate [ 654667.14431942  954251.71617274 1021315.68260312] had error branches [5 8]--------\n",
      "limb_branch_dict_to_cancel = {'L5': array([5, 8])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L5': [5, 8]}\n",
      "total_sk_distance = 7.164162639297007, total_area = 3.307000281729044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "Final web t error limb branch dict = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {'L5': array([6])}\n",
      "wide_angled_children= {}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 2,  3,  4,  5,  6,  7, 10, 11, 13]), 'L1': array([0, 1, 3, 4, 5, 7]), 'L2': array([1, 2]), 'L3': array([0, 2])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L5': array([6])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 2,  3,  4,  5,  6,  7, 10, 11, 13]), 'L1': array([0, 1, 3, 4, 5, 7]), 'L2': array([1, 2]), 'L3': array([0, 2])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L5': array([ 3,  5,  6,  7, 10])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L5': array([ 1,  8,  9, 11, 12])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thick_axon_limb_branch = {'L5': array([5])}\n",
      "With divergence_threshold_mean = 165\n",
      "fork_div_limb_branch = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 35.656031131744385 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 49.98930239677429\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [642219 918733 996033]\n",
      "nuclei_within_radius = [236977]\n",
      "nuclei_within_radius_distance = [1132.15679126]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 236977\n",
      "winning_nuclei_distance = 1132.1567912617052\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [236977]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 236977\n",
      "winning_nuclei_distance = 1132.1567912617052\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 236977, 'nuclei_distance': 1132.16, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 236977\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 4, # error synapses  = 8, # error presyns = 7\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 232, # error synapses  = 0, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "Computing the overall stats\n",
      "n_presyn_error_syn = 8, n_postsyn_error_syn = 0\n",
      "total_presyns = 12, total_postsyns = 232\n",
      "perc_error_presyn = 0.6667, perc_error_postsyn = 0.0\n",
      "total_error_synapses = 8, total_synapses = 244\n",
      "overall_percent_error= 0.0328\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135382976491 = 210.09102773666382 ------ ***\n",
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135771647227  ----------\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 1\n",
      "Number of Neurons found =1\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [295479]\n",
      "nucleus_centers = [[747840 582336 623320]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [4404]\n",
      "Skeleton paths distances = [24920.00986401]\n",
      "Filtered indexes = [0]\n",
      "len(filtered_skeletons) = 1\n",
      "sk_angles = [166.17147145]\n",
      "local_axon_angles = [166.17147145]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Inhibitory Excitatory Classification = 21.759045600891113\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={2: {0: 166.17147145345803}}\n",
      "n_axons=1\n",
      "n_apicals=1\n",
      "neuron_spine_density=0.0006073830683989148\n",
      "n_branches_processed=30\n",
      "skeletal_length_processed=1810589.4265673521\n",
      "n_branches_in_search_radius=77\n",
      "skeletal_length_in_search_radius=2380113.877943593\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L1': [7], 'L4': [7], 'L6': [3, 4]}\n",
      "total_sk_distance = 62.890229110403084, total_area = 46.785228577891935\n",
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/meshAfterParty/neuron_utils.py\", line 719, in branches_to_concept_network\n",
      "    curr_branch_meshes_downsampled.append(sk.resize_skeleton_branch(b,n_segments=1))\n",
      "  File \"/meshAfterParty/meshAfterParty/skeleton_utils.py\", line 3822, in resize_skeleton_branch\n",
      "    skeleton_graph = sk.convert_skeleton_to_graph(curr_branch_skeleton)\n",
      "  File \"/meshAfterParty/meshAfterParty/skeleton_utils.py\", line 1673, in convert_skeleton_to_graph\n",
      "    UG = xu.remove_selfloops(UG)\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 300, in remove_selfloops\n",
      "    UG.remove_edges_from(self_edges)\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 723, in remove_edges_from\n",
      "    self.reorder_edges()\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 709, in reorder_edges\n",
      "    nx.set_edge_attributes(self,name=\"order\",values=dict([(tuple(k),v) for v,k in enumerate(ord_ed)]))\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 709, in <listcomp>\n",
      "    nx.set_edge_attributes(self,name=\"order\",values=dict([(tuple(k),v) for v,k in enumerate(ord_ed)]))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 3389, in apply_proofreading_filters_to_neuron\n",
      "    **filter_kwargs\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2664, in filter_away_axon_on_dendrite_merges\n",
      "    **kwargs\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2573, in filter_away_limb_branch_dict\n",
      "    add_split_to_description=False,\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2477, in delete_branches_from_neuron\n",
      "    verbose=verbose,\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2430, in delete_branches_from_limb\n",
      "    seperate_networks = seperate_networks\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 1164, in split_neuron_limb_by_seperated_network\n",
      "    verbose=verbose\n",
      "  File \"/meshAfterParty/meshAfterParty/preprocessing_vp2.py\", line 809, in calculate_limb_concept_networks\n",
      "    verbose=verbose)\n",
      "  File \"/meshAfterParty/meshAfterParty/neuron_utils.py\", line 723, in branches_to_concept_network\n",
      "    raise Exception(\"not downsampled branch\")\n",
      "Exception: not downsampled branch\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-439294792c1b>\", line 17, in <module>\n",
      "    AutoProofreadNeuronsAllen5.populate(reserve_jobs=True, suppress_errors=False, order=\"random\")\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/autopopulate.py\", line 159, in populate\n",
      "    make(dict(key))\n",
      "  File \"<ipython-input-15-fa9c35dc8200>\", line 133, in make\n",
      "    verbose=True,)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 4487, in proofreading_table_processing\n",
      "    verbose=True)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 3959, in proofread_neuron\n",
      "    plot_final_filtered_neuron = plot_final_filtered_neuron,)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 5001, in proofread_neuron_class_predetermined\n",
      "    return_limb_branch_dict_to_cancel=return_limb_branch_dict_to_cancel)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 3432, in apply_proofreading_filters_to_neuron\n",
      "    raise Exception(str(e))\n",
      "Exception: not downsampled branch\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Exception' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 81, in join\n",
      "    sep = _get_sep(a)\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 42, in _get_sep\n",
      "    if isinstance(path, bytes):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/meshAfterParty/neuron_utils.py\", line 719, in branches_to_concept_network\n",
      "    curr_branch_meshes_downsampled.append(sk.resize_skeleton_branch(b,n_segments=1))\n",
      "  File \"/meshAfterParty/meshAfterParty/skeleton_utils.py\", line 3822, in resize_skeleton_branch\n",
      "    skeleton_graph = sk.convert_skeleton_to_graph(curr_branch_skeleton)\n",
      "  File \"/meshAfterParty/meshAfterParty/skeleton_utils.py\", line 1673, in convert_skeleton_to_graph\n",
      "    UG = xu.remove_selfloops(UG)\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 300, in remove_selfloops\n",
      "    UG.remove_edges_from(self_edges)\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 723, in remove_edges_from\n",
      "    self.reorder_edges()\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 709, in reorder_edges\n",
      "    nx.set_edge_attributes(self,name=\"order\",values=dict([(tuple(k),v) for v,k in enumerate(ord_ed)]))\n",
      "  File \"/meshAfterParty/meshAfterParty/networkx_utils.py\", line 709, in <listcomp>\n",
      "    nx.set_edge_attributes(self,name=\"order\",values=dict([(tuple(k),v) for v,k in enumerate(ord_ed)]))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 3389, in apply_proofreading_filters_to_neuron\n",
      "    **filter_kwargs\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2664, in filter_away_axon_on_dendrite_merges\n",
      "    **kwargs\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2573, in filter_away_limb_branch_dict\n",
      "    add_split_to_description=False,\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2477, in delete_branches_from_neuron\n",
      "    verbose=verbose,\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 2430, in delete_branches_from_limb\n",
      "    seperate_networks = seperate_networks\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 1164, in split_neuron_limb_by_seperated_network\n",
      "    verbose=verbose\n",
      "  File \"/meshAfterParty/meshAfterParty/preprocessing_vp2.py\", line 809, in calculate_limb_concept_networks\n",
      "    verbose=verbose)\n",
      "  File \"/meshAfterParty/meshAfterParty/neuron_utils.py\", line 723, in branches_to_concept_network\n",
      "    raise Exception(\"not downsampled branch\")\n",
      "Exception: not downsampled branch\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-439294792c1b>\", line 17, in <module>\n",
      "    AutoProofreadNeuronsAllen5.populate(reserve_jobs=True, suppress_errors=False, order=\"random\")\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/autopopulate.py\", line 159, in populate\n",
      "    make(dict(key))\n",
      "  File \"<ipython-input-15-fa9c35dc8200>\", line 133, in make\n",
      "    verbose=True,)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 4487, in proofreading_table_processing\n",
      "    verbose=True)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 3959, in proofread_neuron\n",
      "    plot_final_filtered_neuron = plot_final_filtered_neuron,)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 5001, in proofread_neuron_class_predetermined\n",
      "    return_limb_branch_dict_to_cancel=return_limb_branch_dict_to_cancel)\n",
      "  File \"/meshAfterParty/meshAfterParty/proofreading_utils.py\", line 3432, in apply_proofreading_filters_to_neuron\n",
      "    raise Exception(str(e))\n",
      "Exception: not downsampled branch\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Exception' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/neuron_utils.py\u001b[0m in \u001b[0;36mbranches_to_concept_network\u001b[0;34m(curr_branch_skeletons, starting_coordinate, starting_edge, touching_soma_vertices, soma_group_idx, starting_soma, max_iterations, verbose)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0mcurr_branch_meshes_downsampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_skeleton_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mresize_skeleton_branch\u001b[0;34m(curr_branch_skeleton, segment_width, n_segments, print_flag)\u001b[0m\n\u001b[1;32m   3821\u001b[0m     \u001b[0;31m#(because skeleton can possibly be not ordered)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3822\u001b[0;31m     \u001b[0mskeleton_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_skeleton_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_branch_skeleton\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3823\u001b[0m     \u001b[0mskeleton_node_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ordered_branch_nodes_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskeleton_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mconvert_skeleton_to_graph\u001b[0;34m(staring_edges, stitch_print, combine_node_dist, node_matching_size_threshold)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;31m#UG.remove_edges_from(nx.selfloop_edges(UG))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m     \u001b[0mUG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_selfloops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m     \u001b[0;31m#print(f\"UG.__class__ = {UG.__class__}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/networkx_utils.py\u001b[0m in \u001b[0;36mremove_selfloops\u001b[0;34m(UG)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m#print(f\"self_edges = {self_edges}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mUG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mUG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/networkx_utils.py\u001b[0m in \u001b[0;36mremove_edges_from\u001b[0;34m(self, ebunch)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebunch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/networkx_utils.py\u001b[0m in \u001b[0;36mreorder_edges\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mord_ed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edge_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mord_ed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/networkx_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mord_ed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edge_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mord_ed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mapply_proofreading_filters_to_neuron\u001b[0;34m(input_neuron, filter_list, plot_limb_branch_filter_with_disconnect_effect, plot_limb_branch_filter_away, plot_final_neuron, return_error_info, verbose, verbose_outline, return_limb_branch_dict_to_cancel)\u001b[0m\n\u001b[1;32m   3388\u001b[0m                                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3389\u001b[0;31m                                                 \u001b[0;34m**\u001b[0m\u001b[0mfilter_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3390\u001b[0m                                                )\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mfilter_away_axon_on_dendrite_merges\u001b[0;34m(neuron_obj, perform_deepcopy, axon_merge_error_limb_branch_dict, perform_axon_classification, use_pre_existing_axon_labels, return_error_info, plot_limb_branch_filter_away, plot_limb_branch_filter_with_disconnect_effect, plot_final_neuron, verbose, return_limb_branch_dict_to_cancel, **kwargs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2664\u001b[0;31m                                                                            \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mfilter_away_limb_branch_dict\u001b[0;34m(neuron_obj, limb_branch_dict, limb_edge_dict, plot_limb_branch_filter_away, plot_limb_branch_filter_with_disconnect_effect, return_error_info, plot_final_neuron, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2572\u001b[0m                                     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2573\u001b[0;31m                                     \u001b[0madd_split_to_description\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2574\u001b[0m                                     )\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mdelete_branches_from_neuron\u001b[0;34m(neuron_obj, limb_branch_dict, plot_neuron_after_cancellation, plot_final_neuron, verbose, add_split_to_description, **kwargss)\u001b[0m\n\u001b[1;32m   2476\u001b[0m                               \u001b[0mlimb_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimb_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2478\u001b[0m                                 )\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mdelete_branches_from_limb\u001b[0;34m(neuron_obj, branches_to_delete, limb_idx, limb_name, verbose)\u001b[0m\n\u001b[1;32m   2429\u001b[0m                                                               \u001b[0;31m#seperate_networks = [list(concept_graph.nodes())]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2430\u001b[0;31m                                                               \u001b[0mseperate_networks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseperate_networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2431\u001b[0m                                                              )\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36msplit_neuron_limb_by_seperated_network\u001b[0;34m(neuron_obj, curr_limb_idx, seperate_networks, cut_concept_network, split_current_concept_network, error_on_multile_starting_nodes, delete_limb_if_empty, verbose)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                                                                                             \u001b[0mrun_concept_network_checks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m                                                                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m                                                                                            )   \n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/preprocessing_vp2.py\u001b[0m in \u001b[0;36mcalculate_limb_concept_networks\u001b[0;34m(limb_correspondence, network_starting_info, run_concept_network_checks, verbose)\u001b[0m\n\u001b[1;32m    808\u001b[0m                                                                        \u001b[0msoma_group_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoma_group_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                                                        verbose=verbose)\n\u001b[0m\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/neuron_utils.py\u001b[0m in \u001b[0;36mbranches_to_concept_network\u001b[0;34m(curr_branch_skeletons, starting_coordinate, starting_edge, touching_soma_vertices, soma_group_idx, starting_soma, max_iterations, verbose)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The following branch {i} could not be downsampled: {b}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not downsampled branch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: not downsampled branch",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-439294792c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mAutoProofreadNeuronsAllen5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreserve_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Populate Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datajoint/autopopulate.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, suppress_errors, return_exception_objects, reserve_jobs, order, limit, max_calls, display_progress, *restrictions)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                         \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-fa9c35dc8200>\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    132\u001b[0m                                   \u001b[0mhigh_fidelity_axon_on_excitatory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                                  verbose=True,)    \n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;31m# ------ Writing the Data To the Tables ----- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mproofreading_table_processing\u001b[0;34m(key, proof_version, axon_version, ver, compute_synapse_to_soma_skeletal_distance, return_errored_synapses_ids_non_axons, validation, soma_center_in_nm, perform_axon_classification, high_fidelity_axon_on_excitatory, verbose)\u001b[0m\n\u001b[1;32m   4486\u001b[0m                             \u001b[0mhigh_fidelity_axon_on_excitatory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhigh_fidelity_axon_on_excitatory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4487\u001b[0;31m                             verbose=True)\n\u001b[0m\u001b[1;32m   4488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mproofread_neuron\u001b[0;34m(input_neuron, attempt_to_split_neuron, plot_neuron_split_results, plot_neuron_before_filtering, plot_axon, plot_axon_like, plot_limb_branch_filter_with_disconnect_effect, plot_final_filtered_neuron, return_process_info, debug_time, verbose, verbose_outline, high_fidelity_axon_on_excitatory, inh_exc_class, perform_axon_classification)\u001b[0m\n\u001b[1;32m   3958\u001b[0m             \u001b[0mhigh_fidelity_axon_on_excitatory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhigh_fidelity_axon_on_excitatory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3959\u001b[0;31m             plot_final_filtered_neuron = plot_final_filtered_neuron,)\n\u001b[0m\u001b[1;32m   3960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mproofread_neuron_class_predetermined\u001b[0;34m(neuron_obj, inh_exc_class, perform_axon_classification, plot_limb_branch_filter_with_disconnect_effect, high_fidelity_axon_on_excitatory, plot_final_filtered_neuron, plot_new_axon_limb_correspondence, plot_new_limb_object, plot_final_revised_axon_branch, verbose, verbose_outline, return_limb_branch_dict_to_cancel, filter_list)\u001b[0m\n\u001b[1;32m   5000\u001b[0m                                         \u001b[0mverbose_outline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose_outline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5001\u001b[0;31m                                         return_limb_branch_dict_to_cancel=return_limb_branch_dict_to_cancel)\n\u001b[0m\u001b[1;32m   5002\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/proofreading_utils.py\u001b[0m in \u001b[0;36mapply_proofreading_filters_to_neuron\u001b[0;34m(input_neuron, filter_list, plot_limb_branch_filter_with_disconnect_effect, plot_limb_branch_filter_away, plot_final_neuron, return_error_info, verbose, verbose_outline, return_limb_branch_dict_to_cancel)\u001b[0m\n\u001b[1;32m   3431\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilter_catch_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3432\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: not downsampled branch",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Exception' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3262\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures)\u001b[0m\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3071\u001b[0m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0;32m-> 3072\u001b[0;31m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0m\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1211\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import time\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "import neuron_searching as ns\n",
    "ns = reload(ns)\n",
    "clu = reload(clu)\n",
    "du = reload(du)\n",
    "import random\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    AutoProofreadNeuronsAllen5.populate(reserve_jobs=True, suppress_errors=True, order=\"random\")\n",
    "else:\n",
    "    AutoProofreadNeuronsAllen5.populate(reserve_jobs=True, suppress_errors=False, order=\"random\")\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for AutoProofreadNeuron5 populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
