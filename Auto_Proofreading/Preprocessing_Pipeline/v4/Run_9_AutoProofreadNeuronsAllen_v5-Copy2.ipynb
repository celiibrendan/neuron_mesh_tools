{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To decompose the multi-somas for splitting\\nusing the new decomposition method\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To decompose the multi-somas for splitting\n",
    "using the new decomposition method\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 17:40:03,253 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 17:40:03,255 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 17:40:03,257 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 17:40:03,263 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-06-02 17:40:03,265 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 17:40:03,281 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 17:40:03,870 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 17:40:03,877 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 17:40:03,878 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 17:40:03,880 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 17:40:03,881 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 17:40:03,882 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 17:40:03,883 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 17:40:03,884 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 17:40:04,523 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the contains method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 17:40:04,652 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 17:40:04,653 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 17:40:04,654 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 17:40:04,656 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 17:40:04,657 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 17:40:04,657 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 17:40:04,661 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 163 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 17:40:05,445 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import neuron_utils as nru\n",
    "\n",
    "import neuron\n",
    "\n",
    "import neuron_visualizations as nviz\n",
    "\n",
    "import time\n",
    "\n",
    "import datajoint_utils as du\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import preprocessing_vp2 as pre\n",
    "\n",
    "# -- For the axon classification --\n",
    "\n",
    "import neuron_searching as ns\n",
    "\n",
    "import skeleton_utils as sk\n",
    "\n",
    "import numpy_utils as nu\n",
    "\n",
    "import networkx_utils as xu\n",
    "\n",
    "import system_utils as su\n",
    "\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "import trimesh_utils as tu\n",
    "import proofreading_utils as pru\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 483\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minnie,schema = du.configure_minnie_vm()\n",
    "# minnie.AutoProofreadNeurons5.drop()\n",
    "# minnie.AutoProofreadStats5.drop()\n",
    "# minnie.AutoProofreadSynapse5.drop()\n",
    "# minnie.AutoProofreadSynapseErrors5.drop()\n",
    "# minnie.schema.external['faces'].delete(delete_external_files=True)\n",
    "# minnie.schema.external['skeleton'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proofreading Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b></b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">proof_version</p>\n",
       "                                <span class=\"djtooltiptext\">key by which to lookup the decomposition process version</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">description</p>\n",
       "                                <span class=\"djtooltiptext\">new parts of the iteration of the decomposition process</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>0</td>\n",
       "<td>exc,inh rules</td></tr><tr><td>1</td>\n",
       "<td>eliminated presyns on dendrite</td></tr><tr><td>2</td>\n",
       "<td>high fidelity axons</td></tr><tr><td>3</td>\n",
       "<td>improved crossover</td></tr><tr><td>4</td>\n",
       "<td>better crossover and more axon rules</td></tr><tr><td>5</td>\n",
       "<td>fixed stitching on axon</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 6</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*proof_version description   \n",
       "+------------+ +------------+\n",
       "0              exc,inh rules \n",
       "1              eliminated pre\n",
       "2              high fidelity \n",
       "3              improved cross\n",
       "4              better crossov\n",
       "5              fixed stitchin\n",
       " (Total: 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@schema\n",
    "class AutoProofreadVersion(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    proof_version      : tinyint unsigned                   # key by which to lookup the decomposition process version\n",
    "    ---\n",
    "    description          : varchar(256)                 # new parts of the iteration of the decomposition process\n",
    "    \"\"\"\n",
    "versions=[[0,\"exc,inh rules\"],\n",
    "         [1,\"eliminated presyns on dendrite\"],\n",
    "         [2,\"high fidelity axons\"],\n",
    "         [3,\"improved crossover\"],\n",
    "         [4,\"better crossover and more axon rules\"],\n",
    "         [5,\"fixed stitching on axon\"]]\n",
    "\n",
    "\n",
    "dict_to_write = [dict(proof_version=k,description=v) for k,v in versions]\n",
    "AutoProofreadVersion.insert(dict_to_write,skip_duplicates=True)\n",
    "AutoProofreadVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Synapse Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class AutoProofreadSynapseAllen5(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    synapse_id           : bigint unsigned              # synapse index within the segmentation\n",
    "    synapse_type: enum('presyn','postsyn')\n",
    "    ver                  : decimal(6,2)                 # the version number of the materializaiton\n",
    "    ---\n",
    "    segment_id           : bigint unsigned              # segment_id of the cell. Equivalent to Allen 'pt_root_id\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'. \n",
    "    skeletal_distance_to_soma=NULL : double #the length (in um) of skeleton distance from synapse to soma (-1 if on the soma)\n",
    "    \"\"\"\n",
    "\n",
    "@schema\n",
    "class AutoProofreadSynapseErrorsAllen5(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    synapse_id           : bigint unsigned              # synapse index within the segmentation\n",
    "    synapse_type: enum('presyn','postsyn')\n",
    "    ver                  : decimal(6,2)                 # the version number of the materializaiton\n",
    "    ---\n",
    "    segment_id           : bigint unsigned              # segment_id of the cell. Equivalent to Allen 'pt_root_id\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'. \n",
    "    skeletal_distance_to_soma=NULL : double #the length (in um) of skeleton distance from synapse to soma (-1 if on the soma)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Proofreading Stats Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis table will include the following information:\\n\\n1) Filtering Info\\n2) Synapse Stats for Individual Neuron\\n3) Synapse Stats for Segment\\n\\n\\n**** thing need to add:\\n1) Axon faces\\n2) Axon length/area\\n2) Neuron faces\\n3) n_presyn_error_syn_non_axon\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This table will include the following information:\n",
    "\n",
    "1) Filtering Info\n",
    "2) Synapse Stats for Individual Neuron\n",
    "3) Synapse Stats for Segment\n",
    "\n",
    "\n",
    "**** thing need to add:\n",
    "1) Axon faces\n",
    "2) Axon length/area\n",
    "2) Neuron faces\n",
    "3) n_presyn_error_syn_non_axon\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class AutoProofreadStatsAllen5(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    -> minnie.AutoProofreadVersion()   # the version of code used for this cell typing classification\n",
    "    ---\n",
    "    mesh_faces: <faces>                      # faces indices that were saved off as belonging to proofread neuron (external storage)\n",
    "    axon_faces: <faces>                      # faces indices that were saved off as belonging to proofread neuron's axon (external storage)\n",
    "    \n",
    "    axon_skeleton: <skeleton>      # the skeleton of the axon of the final proofread neuorn\n",
    "    dendrite_skeleton: <skeleton>  # the skeleton of the dendrite branches of the final proofread neuorn\n",
    "    neuron_skeleton: <skeleton>    # the skeleton of the entire neuron\n",
    "    \n",
    "    axon_on_dendrite_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    axon_on_dendrite_merges_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    low_branch_clusters_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    low_branch_clusters_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    dendrite_on_axon_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    dendrite_on_axon_merges_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    \n",
    "    crossovers_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    crossovers_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    high_degree_coordinates_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    high_degree_coordinates_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------- new filters for v4 Stats ------------\n",
    "    high_degree_branching_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    high_degree_branching_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    axon_webbing_t_merges_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    axon_webbing_t_merges_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    thick_t_merge_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    thick_t_merge_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    double_back_and_width_change_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    double_back_and_width_change_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    axon_fork_divergence_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter\n",
    "    axon_fork_divergence_error_length=NULL : double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    # ---------- new filers for v5 Stats ----------\n",
    "    \n",
    "    width_jump_up_dendrite_error_area=NULL :double #the area (in um ^ 2) of the faces canceled out by filter FOR DENDRITES\n",
    "    width_jump_up_dendrite_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter FOR DENDRITES\n",
    "    \n",
    "    width_jump_up_axon_error_area=NULL :double # the area (in um ^ 2) of the faces canceled out by filter FOR AXONS\n",
    "    width_jump_up_axon_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter FOR AXONS\n",
    "    \n",
    "    double_back_dendrite_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter FOR DENDRITES\n",
    "    double_back_dendrite_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter FOR DENDRITES\n",
    "    \n",
    "    double_back_axon_thin_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter \n",
    "    double_back_axon_thin_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    double_back_axon_thick_error_area=NULL : double #the area (in um ^ 2) of the faces canceled out by filter \n",
    "    double_back_axon_thick_error_length =NULL: double #the length (in um) of skeleton distance canceled out by filter\n",
    "    \n",
    "    # ------------ For local valid synapses to that split_index\n",
    "    n_valid_syn_presyn_for_split: int unsigned\n",
    "    n_valid_syn_postsyn_for_split : int unsigned\n",
    "    n_presyn_error_syn_non_axon :int unsigned\n",
    "    \n",
    "    # ------------ For global stats belonging to the whole segment\n",
    "    # For the whole segment\n",
    "    n_presyn_error_syn: int unsigned\n",
    "    n_postsyn_error_syn: int unsigned\n",
    "    total_error_synapses: int unsigned\n",
    "    \n",
    "    total_presyns: int unsigned \n",
    "    total_postsyns: int unsigned \n",
    "    total_synapses:int unsigned\n",
    "    \n",
    "    perc_error_presyn=NULL: double\n",
    "    perc_error_postsyn=NULL: double\n",
    "    \n",
    "    overall_percent_error=NULL: double\n",
    "    \n",
    "    limb_branch_to_cancel: longblob # stores the limb information from \n",
    "    red_blue_suggestions: longblob\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Auto Proofread Neuron Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import classification_utils as clu\n",
    "\n",
    "axon_version = 5\n",
    "proof_version = 5\n",
    "\n",
    "verbose = True\n",
    "\n",
    "@schema\n",
    "class AutoProofreadNeuronsAllen5(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    -> minnie.AutoProofreadVersion()             # the version of code used for this cell typing classification\n",
    "    -> minnie.DecompositonAxonVersion()           # the version of the axon processing\n",
    "    ---\n",
    "    multiplicity  : tinyint unsigned   # the total number of neurons that came from the parent segment id\n",
    "    # -------- Important Excitatory Inhibitory Classfication ------- #\n",
    "    cell_type_predicted: enum('excitatory','inhibitory','other','unknown') # morphology predicted by classifier\n",
    "    spine_category: enum('no_spined','sparsely_spined','densely_spined')\n",
    "    \n",
    "    n_axons: tinyint unsigned             # Number of axon candidates identified\n",
    "    n_apicals: tinyint unsigned             # Number of apicals identified\n",
    "    \n",
    "    axon_length: double  # length (in um) of the classified axon skeleton\n",
    "    axon_area: double # # area (in um^2) of the classified axon\n",
    "    \n",
    "    # ----- Soma Information ----#\n",
    "    nucleus_id           : int unsigned                 # id of nucleus from the flat segmentation  Equivalent to Allen: 'id'.\n",
    "    nuclei_distance      : double                    # the distance to the closest nuclei (even if no matching nuclei found)\n",
    "    n_nuclei_in_radius   : tinyint unsigned          # the number of nuclei within the search radius of 15000 belonging to that segment\n",
    "    n_nuclei_in_bbox     : tinyint unsigned          # the number of nuclei within the bounding box of that soma\n",
    "    \n",
    "    soma_x            : int unsigned                 # x coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    soma_y            : int unsigned                 # y coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    soma_z            : int unsigned                 # z coordinate of nucleus centroid in EM voxels (x: 4nm, y: 4nm, z: 40nm)\n",
    "    \n",
    "    max_soma_n_faces     : int unsigned                 # The largest number of faces of the somas\n",
    "    max_soma_volume      : int unsigned                 # The largest volume of the somas the (volume in billions (10*9 nm^3))\n",
    "    \n",
    "    # ---- Stores Neuron Mesh Faces (moved to AutoProofreadStats) --------\n",
    "    \n",
    "    \n",
    "    # ------------- The Regular Neuron Information ----------------- #\n",
    "    n_vertices           : int unsigned                 # number of vertices\n",
    "    n_faces              : int unsigned                 # number of faces\n",
    "    n_not_processed_soma_containing_meshes : int unsigned  #the number of meshes with somas that were not processed\n",
    "    n_error_limbs: int #the number of limbs that are touching multiple somas or 1 soma in multiple places\n",
    "    n_same_soma_multi_touching_limbs: int # number of limbs that touch the same soma multiple times\n",
    "    n_multi_soma_touching_limbs: int # number of limbs that touch multiple somas\n",
    "    n_somas: int #number of soma meshes detected\n",
    "    n_limbs: int\n",
    "    n_branches: int\n",
    "    max_limb_n_branches=NULL:int\n",
    "    \n",
    "    skeletal_length=NULL: double\n",
    "    max_limb_skeletal_length=NULL:double\n",
    "    median_branch_length=NULL:double #gives information on average skeletal length to next branch point\n",
    "    \n",
    "    \n",
    "    width_median=NULL: double #median width from mesh center without spines removed\n",
    "    width_no_spine_median=NULL: double #median width from mesh center with spines removed\n",
    "    width_90_perc=NULL: double # 90th percentile for width without spines removed\n",
    "    width_no_spine_90_perc=NULL: double  # 90th percentile for width with spines removed\n",
    "    \n",
    "    \n",
    "    n_spines: bigint\n",
    "    n_boutons: bigint\n",
    "\n",
    "    spine_density=NULL: double # n_spines/ skeletal_length\n",
    "    spines_per_branch=NULL: double\n",
    "    \n",
    "    skeletal_length_eligible=NULL: double # the skeletal length for all branches searched for spines\n",
    "    n_spine_eligible_branches=NULL: int # the number of branches that were checked for spines because passed width threshold\n",
    "    \n",
    "    spine_density_eligible=NULL:double # n_spines/skeletal_length_eligible\n",
    "    spines_per_branch_eligible=NULL:double # n_spines/n_spine_eligible_branches\n",
    "    \n",
    "    total_spine_volume=NULL: double # the sum of all spine volume\n",
    "    spine_volume_median=NULL: double # median of the spine volume for those spines with able to calculate volume\n",
    "    spine_volume_density=NULL: double #total_spine_volume/skeletal_length\n",
    "    spine_volume_density_eligible=NULL: double #total_spine_volume/skeletal_length_eligible\n",
    "    spine_volume_per_branch_eligible=NULL: double #total_spine_volume/n_spine_eligible_branches\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------ Information Used For Excitatory Inhibitory Classification -------- \n",
    "    axon_angle_maximum=NULL:double #the anlge of an identified axon\n",
    "    spine_density_classifier:double              # the number of spines divided by skeletal length for branches analyzed in classification\n",
    "    n_branches_processed: int unsigned                 # the number branches used for the spine density analysis\n",
    "    skeletal_length_processed: double                 # The total skeletal length of the viable branches used for the spine density analysis\n",
    "    n_branches_in_search_radius: int unsigned                 # the number branches existing in the search radius used for spine density\n",
    "    skeletal_length_in_search_radius : double         # The total skeletal length of the branches existing in the search radius used for spine density\n",
    "    \n",
    "    \n",
    "\n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #key_source = minnie.Decomposition() & minnie.NucleiSegmentsRun2()\n",
    "    #key_source = (minnie.Decomposition() & minnie.NucleiSegmentsRun2() \n",
    "    #              & minnie.DecompositionAxon().proj()) #& dict(segment_id=864691136361533410)\n",
    "    key_source = (minnie.Decomposition() & minnie.NucleiSegmentsRun4() \n",
    "                  & minnie.DecompositionAxon().proj() \n",
    "              & (minnie.AutoProofreadNeurons4() & \"spine_category = 'densely_spined'\").proj()\n",
    "             ) & dict(segment_id=864691135777113533)\n",
    "    \n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        1) Pull Down All of the Neurons\n",
    "        2) Get the nucleus centers and the original mesh\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1) Pull Down All of the Neurons\n",
    "        segment_id = key[\"segment_id\"]\n",
    "        \n",
    "        whole_pass_time = time.time()\n",
    "        \n",
    "\n",
    "        curr_output = pru.proofreading_table_processing(key,\n",
    "                                  proof_version=proof_version,\n",
    "                                  axon_version  = axon_version,\n",
    "                                  compute_synapse_to_soma_skeletal_distance=True,\n",
    "                                  perform_axon_classification = False,\n",
    "                                  high_fidelity_axon_on_excitatory = False,\n",
    "                                 verbose=True,)    \n",
    "        # ------ Writing the Data To the Tables ----- #\n",
    "            \n",
    "            \n",
    "        AutoProofreadSynapse_keys = curr_output[\"AutoProofreadSynapse_keys\"]\n",
    "        AutoProofreadSynapseErrors_keys = curr_output[\"AutoProofreadSynapseErrors_keys\"]\n",
    "        AutoProofreadNeurons_keys = curr_output[\"AutoProofreadNeurons_keys\"]\n",
    "        filtering_info_list = curr_output[\"filtering_info_list\"]\n",
    "        synapse_stats_list = curr_output[\"synapse_stats_list\"]\n",
    "        total_error_synapse_ids_list = curr_output[\"total_error_synapse_ids_list\"]\n",
    "        neuron_mesh_list = curr_output[\"neuron_mesh_list\"]\n",
    "        axon_mesh_list = curr_output[\"axon_mesh_list\"]\n",
    "        neuron_split_idxs = curr_output[\"neuron_split_idxs\"]\n",
    "        \n",
    "        axon_skeleton_list = curr_output[\"axon_skeleton_list\"]\n",
    "        dendrite_skeleton_list = curr_output[\"dendrite_skeleton_list\"]\n",
    "        neuron_skeleton_list = curr_output[\"neuron_skeleton_list\"]\n",
    "            \n",
    "        \n",
    "        # Once have inserted all the new neurons need to compute the stats\n",
    "        if verbose:\n",
    "            print(\"Computing the overall stats\")\n",
    "            \n",
    "        overall_syn_error_rates = pru.calculate_error_rate(total_error_synapse_ids_list,\n",
    "                        synapse_stats_list,\n",
    "                        verbose=True)\n",
    "        \n",
    "        \n",
    "        # Final Part: Create the stats table entries and insert\n",
    "        \n",
    "        proofread_stats_entries = []\n",
    "        \n",
    "        stats_to_make_sure_in_proofread_stats = [\n",
    "            \n",
    "         'axon_on_dendrite_merges_error_area',\n",
    "         'axon_on_dendrite_merges_error_length',\n",
    "         'low_branch_clusters_error_area',\n",
    "         'low_branch_clusters_error_length',\n",
    "         'dendrite_on_axon_merges_error_area',\n",
    "         'dendrite_on_axon_merges_error_length',\n",
    "         'double_back_and_width_change_error_area',\n",
    "         'double_back_and_width_change_error_length',\n",
    "         'crossovers_error_area',\n",
    "         'crossovers_error_length',\n",
    "         'high_degree_coordinates_error_area',\n",
    "         'high_degree_coordinates_error_length',\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        for sp_idx,split_index in enumerate(neuron_split_idxs):\n",
    "            \n",
    "            #write the AutoProofreadNeurons and AutoProofreadSynapse Tabel\n",
    "            keys_to_write = AutoProofreadSynapse_keys[sp_idx]\n",
    "            AutoProofreadSynapseAllen5.insert(keys_to_write,skip_duplicates=True)\n",
    "            \n",
    "            keys_to_write_errors = AutoProofreadSynapseErrors_keys[sp_idx]\n",
    "            AutoProofreadSynapseErrorsAllen5.insert(keys_to_write_errors,skip_duplicates=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            new_key = AutoProofreadNeurons_keys[sp_idx]\n",
    "            self.insert1(new_key,skip_duplicates=True,allow_direct_insert=True)\n",
    "            \n",
    "            synapse_stats = synapse_stats_list[sp_idx]\n",
    "            filtering_info = filtering_info_list[sp_idx]\n",
    "            limb_branch_to_cancel = pru.extract_from_filter_info(filtering_info,\n",
    "                            name_to_extract=\"limb_branch_dict_to_cancel\")\n",
    "                            \n",
    "            \n",
    "            red_blue_suggestions = pru.extract_from_filter_info(filtering_info,\n",
    "                            name_to_extract = \"red_blue_suggestions\")\n",
    "            \n",
    "            curr_key = dict(key,\n",
    "                           split_index = split_index,\n",
    "                           proof_version = proof_version,\n",
    "                           \n",
    "                             mesh_faces = neuron_mesh_list[sp_idx],\n",
    "                            axon_faces = axon_mesh_list[sp_idx],\n",
    "                            \n",
    "                            axon_skeleton = axon_skeleton_list[sp_idx],\n",
    "                            dendrite_skeleton = dendrite_skeleton_list[sp_idx],\n",
    "                            neuron_skeleton = neuron_skeleton_list[sp_idx],\n",
    "                         \n",
    "\n",
    "                            # ------------ For local valid synapses to that split_index\n",
    "                            n_valid_syn_presyn_for_split=synapse_stats[\"n_valid_syn_presyn\"],\n",
    "                            n_valid_syn_postsyn_for_split=synapse_stats[\"n_valid_syn_postsyn\"],\n",
    "                            n_presyn_error_syn_non_axon=synapse_stats[\"n_errored_syn_presyn_non_axon\"],\n",
    "                            \n",
    "                            limb_branch_to_cancel = limb_branch_to_cancel,\n",
    "                            red_blue_suggestions = red_blue_suggestions,\n",
    "                           \n",
    "                           \n",
    "                           )\n",
    "            \n",
    "            \n",
    "            for s in stats_to_make_sure_in_proofread_stats:\n",
    "                if s not in filtering_info.keys():\n",
    "                    curr_key[s] = None\n",
    "            \n",
    "            filter_key = {k:np.round(v,2) for k,v in filtering_info.items() if \"area\" in k or \"length\" in k}\n",
    "            curr_key.update(filter_key)\n",
    "            curr_key.update(overall_syn_error_rates)\n",
    "            \n",
    "            proofread_stats_entries.append(curr_key)\n",
    "            \n",
    "        \n",
    "        AutoProofreadStatsAllen5.insert(proofread_stats_entries,skip_duplicates=True)\n",
    "            \n",
    "#         for pse in proofread_stats_entries:\n",
    "#             AutoProofreadStats4.insert1(pse,skip_duplicates=True)\n",
    "            \n",
    "\n",
    "        print(f\"\\n\\n ***------ Total time for {key['segment_id']} = {time.time() - whole_pass_time} ------ ***\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>job reservation table for `microns_minnie65_02`</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">table_name</p>\n",
       "                                <span class=\"djtooltiptext\">className of the table</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">key_hash</p>\n",
       "                                <span class=\"djtooltiptext\">key hash</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">if tuple is missing, the job is available</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">key</p>\n",
       "                                <span class=\"djtooltiptext\">structure containing the key</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_message</p>\n",
       "                                <span class=\"djtooltiptext\">error message returned if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_stack</p>\n",
       "                                <span class=\"djtooltiptext\">error stack if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">user</p>\n",
       "                                <span class=\"djtooltiptext\">database user</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">host</p>\n",
       "                                <span class=\"djtooltiptext\">system hostname</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">pid</p>\n",
       "                                <span class=\"djtooltiptext\">system process id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">connection_id</p>\n",
       "                                <span class=\"djtooltiptext\">connection_id()</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">timestamp</p>\n",
       "                                <span class=\"djtooltiptext\">automatic timestamp</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr>  </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 0</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*table_name    *key_hash    status     key        error_message  error_stac user     host     pid     connection_id  timestamp    \n",
       "+------------+ +----------+ +--------+ +--------+ +------------+ +--------+ +------+ +------+ +-----+ +------------+ +-----------+\n",
       "\n",
       " (Total: 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__auto_proofread_neurons_allen5'\")\n",
    "(curr_table)#.delete()# & \"status='error'\")\n",
    "#curr_table.delete()\n",
    "#(curr_table & \"error_message = 'ValueError: need at least one array to concatenate'\").delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-02 17:41:14,511 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 17:41:14,512 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 17:41:14,513 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 17:41:14,514 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-02 17:41:14,515 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-02 17:41:14,516 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-02 17:41:14,777 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 17:41:20,587 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-02 17:41:20,697 - autopopulate - Found 1 keys to populate\n",
      "INFO - 2021-06-02 17:41:20,712 - connection - Transaction started\n",
      "INFO - 2021-06-02 17:41:20,714 - autopopulate - Populating: {'segment_id': 864691135777113533, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': Decimal('30.00'), 'process_version': 1, 'index': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n",
      "\n",
      "\n",
      "------- AutoProofreadNeuron 864691135777113533  ----------\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 1\n",
      "Number of Neurons found =1\n",
      "Number of Corresponding Nuclei = 1\n",
      "nucleus_ids = [426280]\n",
      "nucleus_centers = [[1047360  632960  877120]]\n",
      "\n",
      "-----Working on Neuron Split 0-----\n",
      "\n",
      "   --> Part A: Proofreading the Neuron ----\n",
      "---- Part A: NOT Attempting to split neuron --------\n",
      "\n",
      "--- Working on Neuron 0 ---\n",
      "\n",
      "\n",
      " ------ Part B: Axon Classification ---- \n",
      "\n",
      "\n",
      "Skipping Axon Classification\n",
      "endnodes_to_test = [ 762  791 1220]\n",
      "Skeleton paths distances = [24896.65261353 12340.89741314 24951.45724723]\n",
      "Filtered indexes = [0 2]\n",
      "len(filtered_skeletons) = 2\n",
      "sk_angles = [161.69003729  81.74837333]\n",
      "local_axon_angles = [161.69003729  81.74837333]\n",
      "\n",
      "\n",
      " ------ Part C: Inhibitory Excitatory Classification ---- \n",
      "\n",
      "\n",
      "spine_category = densely_spined\n",
      "Inhibitory Excitatory Classification = 10.069108009338379\n",
      "\n",
      " -- Cell Type Classification Results --\n",
      "inh_exc_class=excitatory\n",
      "spine_category=densely_spined\n",
      "axon_angles={7: {0: 161.69003729146812}}\n",
      "n_axons=1\n",
      "n_apicals=1\n",
      "neuron_spine_density=0.0005571916297595733\n",
      "n_branches_processed=32\n",
      "skeletal_length_processed=2478861.4237679606\n",
      "n_branches_in_search_radius=66\n",
      "skeletal_length_in_search_radius=2904188.048869363\n",
      "\n",
      "\n",
      " ------ Part D: Neuron Filtering ---- \n",
      "\n",
      " \n",
      "\n",
      "*****Using v5 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "using pre-existing labels for axon-error detection\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L6': [0]}\n",
      "total_sk_distance = 164.11950680613145, total_area = 180.80394320014844\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_on_dendrite_merges Results --\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 0: [1047074.51636026  660832.3774445   880223.98358454]--------\n",
      "For test node 7, sibling nodes were: [ 9 11]\n",
      "overlap = [ 9 11]\n",
      "With test node equal to the downstream node\n",
      "upstream = 10, downstream_nodes = [ 9 11  7]\n",
      "branches_at_coord = [ 7  9 10 11]\n",
      "widths_in_branches = [ 42.75231697 164.85999111 164.70146797  96.92006611]\n",
      "coordinate_branches = [7, 9, 10, 11]\n",
      "7 = red\n",
      "9 = aqua\n",
      "10 = purple\n",
      "11 = green\n",
      "Angle between 7 and 9 = 40.31 \n",
      "Angle between 7 and 10 = 147.78 \n",
      "Angle between 7 and 11 = 137.47 \n",
      "Angle between 9 and 10 = 19.9 \n",
      "Angle between 9 and 11 = 20.19 \n",
      "Angle between 10 and 11 = 169.68 \n",
      "Final Matches = [[7, 9], [9, 10], [9, 11]], Final Matches Angle = [40.31, 19.9, 20.19]\n",
      "matched_edges = [[7, 9], [9, 10], [9, 11]]matched_edges_angles = [40.31, 19.9, 20.19]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(7, 9), (9, 10), (9, 11)], Remaining Nodes = [7, 9, 10, 11]\n",
      "Removing edges (7, 9) because width difference 122.10767414224492\n",
      "edges_to_remove_by_width = [(7, 9)]\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(9, 10), (9, 11)], Remaining Nodes = [7, 9, 10, 11]\n",
      "--Working on edge [ 9 10]--\n",
      "--Working on edge [ 9 11]--\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(9, 10), (9, 11)], Remaining Nodes = [7, 9, 10, 11]\n",
      "upstream_subgraph = [ 9 10 11]\n",
      "Possible Connections = [9], angles = [19.9]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(9, 10), (9, 11)]\n",
      "Not doing kiss check because upstream_matches = [9]\n",
      "Using best match method\n",
      "for upstream node 10, winning_node = 9, error_branches = [11  7]\n",
      "winning_downstream = 9,error_downstream = [ 7 11] \n",
      "coordinate [1047074.51636026  660832.3774445   880223.98358454] had error branches [ 7 11]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 1: [1049619.92715058  647428.75181389  882291.77097336]--------\n",
      "For test node 10, sibling nodes were: [12 14]\n",
      "overlap = [12 14]\n",
      "With test node equal to the downstream node\n",
      "upstream = 13, downstream_nodes = [12 14 10]\n",
      "branches_at_coord = [10 12 13 14]\n",
      "Changing max_degree_to_resolve = 8 because upstream width was 296.8808323897631 \n",
      "widths_in_branches = [164.70146797  64.63382646 296.88083239  53.42220103]\n",
      "coordinate_branches = [10, 12, 13, 14]\n",
      "10 = red\n",
      "12 = aqua\n",
      "13 = purple\n",
      "14 = green\n",
      "Angle between 10 and 12 = 121.68 \n",
      "Angle between 10 and 13 = 37.93 \n",
      "Angle between 10 and 14 = 39.52 \n",
      "Angle between 12 and 13 = 83.79 \n",
      "Angle between 12 and 14 = 21.35 \n",
      "Angle between 13 and 14 = 117.45 \n",
      "Final Matches = [[10, 13], [10, 14], [12, 14]], Final Matches Angle = [37.93, 39.52, 21.35]\n",
      "matched_edges = [[10, 13], [10, 14], [12, 14]]matched_edges_angles = [37.93, 39.52, 21.35]\n",
      "Step 2: Edges with worst case scenario matching = 65\n",
      "Remaining Edges = [(10, 13), (10, 14), (12, 14)], Remaining Nodes = [10, 12, 13, 14]\n",
      "edges_to_remove_by_width = []\n",
      "Step 2: Edges after widht mismatch\n",
      "Remaining Edges = [(10, 13), (10, 14), (12, 14)], Remaining Nodes = [10, 12, 13, 14]\n",
      "--Working on edge [10 13]--\n",
      "--Working on edge [10 14]--\n",
      "--Working on edge [12 14]--\n",
      "Edge [12 14] is matches definite match threshold with: \n",
      "Edge Buffer of 18.17 (angle_buffer = 15)\n",
      "Edge Angle of 21.35 (match_threshold = 45)\n",
      "Step 4: Definite Edges\n",
      "Remaining Edges = [(10, 13), (12, 14)], Remaining Nodes = [10, 12, 13, 14]\n",
      "upstream_subgraph = [10 13]\n",
      "Possible Connections = [10], angles = [37.93]\n",
      "Deleting the following nodes because above match threshold while 1 are: []\n",
      "Step 5: Removing worst case edges\n",
      "Remaining Edges = [(10, 13), (12, 14)]\n",
      "Not doing kiss check because upstream_matches = [10]\n",
      "Using best match method\n",
      "for upstream node 13, winning_node = 10, error_branches = [12 14]\n",
      "winning_downstream = 10,error_downstream = [12 14] \n",
      "coordinate [1049619.92715058  647428.75181389  882291.77097336] had error branches [12 14]--------\n",
      "limb_branch_dict_to_cancel = {'L6': array([ 7, 11, 12, 14])}\n",
      "After disconnecte effect, removed_limb_branch_dict = {'L6': [0, 1, 2, 3, 5, 8, 7, 11, 12, 14]}\n",
      "total_sk_distance = 62.05498998628452, total_area = 36.92641153315337\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter high_degree_branching Results --\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "Final web t error limb branch dict = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_webbing_t_merges Results --\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thin_axon_limb_branch = {}\n",
      "wide_angled_children= {}\n",
      "thick_t_crossing_limb_branch= {}\n",
      "t_error_limb_branch= {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter thick_t_merge Results --\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3, 11, 12, 13, 14]), 'L1': array([0, 1, 2, 3, 4, 6]), 'L2': array([1, 4, 5, 6, 7, 8]), 'L3': array([0, 1, 2, 3, 4, 5, 6]), 'L4': array([0, 1, 2, 3, 4, 5])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_dendrite Results --\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After skeletal restrictions, limb_branch_dict_restriction = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter width_jump_up_axon Results --\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L0': array([ 0,  1,  2,  3, 11, 12, 13, 14]), 'L1': array([0, 1, 2, 3, 4, 6]), 'L2': array([1, 4, 5, 6, 7, 8]), 'L3': array([0, 1, 2, 3, 4, 5, 6]), 'L4': array([0, 1, 2, 3, 4, 5])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_dendrite Results --\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L6': array([0])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thin Results --\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "After skeletal restrictions, limb_branch_dict_restriction = {'L6': array([1, 2, 3])}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter double_back_axon_thick Results --\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "----------------------- Running Filter ------------------\n",
      "two_downstream_thick_axon_limb_branch = {}\n",
      "With divergence_threshold_mean = 165\n",
      "fork_div_limb_branch = {}\n",
      "limb_branch_dict_to_cancel = {}\n",
      "limb_branch_dict was empty so returning original neuron\n",
      "----------------------- FINISHED Running Filter ------------------\n",
      "\n",
      "\n",
      "\n",
      " --Filter axon_fork_divergence Results --\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 31.832738399505615 -----\n",
      "\n",
      "\n",
      " ------ Part E: Save Neuron  ---- \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Total time for Neuron Proofreading: 42.09073209762573\n",
      "\n",
      "\n",
      "    --> Part B: Getting Soma Centers and Matching To Nuclei ----\n",
      "soma_center = [1046873  633258  877441]\n",
      "nuclei_within_radius = [426280]\n",
      "nuclei_within_radius_distance = [654.991603]\n",
      "\n",
      "There were 1 nuclei found within the radius of 15000 nm\n",
      "winning_nuclei = 426280\n",
      "winning_nuclei_distance = 654.991602999611\n",
      "\n",
      " For Bounding Box Search:\n",
      "inside_nuclei = [426280]\n",
      "\n",
      "\n",
      "At End: using return_id_0_if_no_matches = True\n",
      "winning_nuclei = 426280\n",
      "winning_nuclei_distance = 654.991602999611\n",
      "n_nuclei_in_radius = 1\n",
      "n_nuclei_in_bbox = 1\n",
      "nucleus_info = {'nuclei_id': 426280, 'nuclei_distance': 654.99, 'n_nuclei_in_radius': 1, 'n_nuclei_in_bbox': 1}\n",
      "winning_nucleus_id = 426280\n",
      "\n",
      "\n",
      "    --> Part C: Getting the Faces of the Original Mesh ----\n",
      "\n",
      "\n",
      "    --> Part D: Getting the Synapse Information ----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 0, # error synapses  = 32, # error presyns = 12\n",
      "Computing the distance to soma for the synapses\n",
      "For postsyn: # valid synapses = 353, # error synapses  = 0, # error presyns = 0\n",
      "Computing the distance to soma for the synapses\n",
      "Computing the overall stats\n",
      "n_presyn_error_syn = 32, n_postsyn_error_syn = 0\n",
      "total_presyns = 32, total_postsyns = 353\n",
      "perc_error_presyn = 1.0, perc_error_postsyn = 0.0\n",
      "total_error_synapses = 32, total_synapses = 385\n",
      "overall_percent_error= 0.0831\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135777113533 = 149.92508244514465 ------ ***\n",
      "Populate Done\n",
      "Total time for AutoProofreadNeuron5 populate = 150.01613879203796\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "import neuron_searching as ns\n",
    "ns = reload(ns)\n",
    "clu = reload(clu)\n",
    "du = reload(du)\n",
    "import random\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    AutoProofreadNeuronsAllen5.populate(reserve_jobs=True, suppress_errors=True, order=\"random\")\n",
    "else:\n",
    "    AutoProofreadNeuronsAllen5.populate(reserve_jobs=True, suppress_errors=False, order=\"random\")\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for AutoProofreadNeuron5 populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
