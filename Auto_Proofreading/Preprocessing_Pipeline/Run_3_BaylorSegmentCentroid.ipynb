{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: Run the Soma Finding\n",
    "Algorithm for all the cells\n",
    "in our final match\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_version = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:16:57,306 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-13 07:16:57,308 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-13 07:16:57,309 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-13 07:16:57,311 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-13 07:16:57,312 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-13 07:16:57,324 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:16:57,590 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:18:03,682 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-13 07:18:03,684 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-13 07:18:03,685 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-13 07:18:03,690 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 4 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:18:03,980 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()\n",
    "nucleus_table = du.configure_nucleus_table(current_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the list of neurons to decompose for the mutli soma testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# soma_soma_table = pd.read_csv(\"Minnie65 core proofreading - Soma-Soma.csv\")\n",
    "# no_header = soma_soma_table.iloc[1:]\n",
    "# multi_soma_ids_str = no_header[\"Dendrites\"].to_numpy()\n",
    "# multi_soma_ids = multi_soma_ids_str[~np.isnan(multi_soma_ids_str.astype(\"float\"))].astype(\"int\")\n",
    "\n",
    "# @schema\n",
    "# class MultiSomaProofread(dj.Manual):\n",
    "#     definition=\"\"\"\n",
    "#     segment_id : bigint unsigned  #segment id for those to be decimated\n",
    "#     \"\"\"\n",
    "    \n",
    "# dict_of_seg = [dict(segment_id=k) for k in multi_soma_ids]\n",
    "# minnie.MultiSomaProofread.insert(dict_of_seg,skip_duplicates=True)\n",
    "# MultiSomaProofread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 8810\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)\n",
    "temporary_folder = 'decimation_temp'\n",
    "meshlab_scripts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class NeuronGliaNuclei(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decimation.proj(decimation_version='version')\n",
    "    ver : decimal(6,2) #the version number of the materializaiton\n",
    "    ---\n",
    "    n_glia_faces              : int unsigned                 # The number of faces that were saved off as belonging to glia\n",
    "    glia_faces=NULL           : <faces>                      # faces indices that were saved off as belonging to glia (external storage)\n",
    "    n_nuclei_faces            : int unsigned                 # The number of faces that were saved off as belonging to nuclie\n",
    "    nuclei_faces=NULL         : <faces>                      # faces indices that were saved off as belonging to nuclei (external storage)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema.external['faces'].delete(delete_external_files=True)\n",
    "# schema.external['somas'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minnie.BaylorSegmentCentroid.delete()\n",
    "# minnie.NeuronGliaNuclei().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decimation_version = 0\n",
    "# decimation_ratio = 0.25\n",
    "# verts_min = 10000\n",
    "\n",
    "\n",
    "# key_source =  ((minnie.Decimation & f\"n_vertices > {verts_min}\").proj(decimation_version='version') & \n",
    "#                         \"decimation_version=\" + str(decimation_version) &\n",
    "#                    f\"decimation_ratio={decimation_ratio}\") & (dj.U(\"segment_id\") & (minnie.OldBaylorSegmentCentroid() & \"multiplicity<3\").proj()\n",
    "#                                                              & (dj.U(\"segment_id\") & nucleus_table))\n",
    "# key_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimation_version = 0\n",
    "decimation_ratio = 0.25\n",
    "verts_min = 10000\n",
    "current_version = 30\n",
    "\n",
    "\n",
    "import trimesh_utils as tu\n",
    "import soma_extraction_utils as sm\n",
    "@schema\n",
    "class BaylorSegmentCentroid(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decimation.proj(decimation_version='version')\n",
    "    soma_index : tinyint unsigned #index given to this soma to account for multiple somas in one base semgnet\n",
    "    ver : decimal(6,2) #the version number of the materializaiton\n",
    "    ---\n",
    "    centroid_x=NULL           : int unsigned                 # (EM voxels)\n",
    "    centroid_y=NULL           : int unsigned                 # (EM voxels)\n",
    "    centroid_z=NULL           : int unsigned                 # (EM voxels)\n",
    "    n_vertices=NULL           : bigint                 #number of vertices\n",
    "    n_faces=NULL            : bigint                  #number of faces\n",
    "    mesh: <somas>  #datajoint adapter to get the somas mesh objects\n",
    "    multiplicity=NULL         : tinyint unsigned             # the number of somas found for this base segment\n",
    "    sdf=NULL                  : double                       # sdf width value for the soma\n",
    "    volume=NULL               : double                       # the volume in billions (10*9 nm^3) of the convex hull\n",
    "    max_side_ratio=NULL       : double                       # the maximum of the side length ratios used for check if soma\n",
    "    bbox_volume_ratio=NULL    : double                       # ratio of bbox (axis aligned) volume to mesh volume to use for check if soma\n",
    "    max_hole_length=NULL      : double                    #euclidean distance of the maximum hole size\n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    key_source =  ((minnie.Decimation & f\"n_vertices > {verts_min}\").proj(decimation_version='version') & \n",
    "                            \"decimation_version=\" + str(decimation_version) &\n",
    "                       f\"decimation_ratio={decimation_ratio}\") & (dj.U(\"segment_id\") & (minnie.OldBaylorSegmentCentroid() & \"multiplicity<3\").proj()\n",
    "                                                                 & (dj.U(\"segment_id\") & nucleus_table))\n",
    "     \n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode: \n",
    "        1) Compute all of the\n",
    "        2) Save the mesh as an h5 py file\n",
    "        3) Store the saved path as the decomposition part of the dictionary and erase the vertices and faces\n",
    "        4) Insert\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #get the mesh data\n",
    "        print(f\"\\n\\n\\n---- Working on Neuron {key['segment_id']} ----\")\n",
    "        print(key)\n",
    "        new_mesh = (minnie.Decimation() & key).fetch1(\"mesh\")\n",
    "        current_mesh_verts,current_mesh_faces = new_mesh.vertices,new_mesh.faces\n",
    "\n",
    "        segment_id = key[\"segment_id\"]\n",
    "\n",
    "        (total_soma_list, \n",
    "         run_time, \n",
    "         total_soma_list_sdf,\n",
    "         glia_pieces,\n",
    "         nuclei_pieces) = sm.extract_soma_center(\n",
    "                            segment_id,\n",
    "                            current_mesh_verts,\n",
    "                            current_mesh_faces,\n",
    "            return_glia_nuclei_pieces=True,\n",
    "        )\n",
    "        \n",
    "        # -------- 1/9 Addition: Going to save off the glia and nuclei pieces ----------- #\n",
    "        \"\"\"\n",
    "        Psuedocode:\n",
    "        For both glia and nuclie pieces\n",
    "        1) If the length of array is greater than 0 --> combine the mesh and map the indices to original mesh\n",
    "        2) If not then just put None     \n",
    "        \"\"\"\n",
    "        orig_mesh = trimesh.Trimesh(vertices=current_mesh_verts,\n",
    "                                   faces=current_mesh_faces)\n",
    "        \n",
    "        if len(glia_pieces)>0:\n",
    "            glia_faces = tu.original_mesh_faces_map(orig_mesh,tu.combine_meshes(glia_pieces))\n",
    "            n_glia_faces = len(glia_faces)\n",
    "        else:\n",
    "            glia_faces = None\n",
    "            n_glia_faces = 0\n",
    "            \n",
    "        if len(nuclei_pieces)>0:\n",
    "            nuclei_faces = tu.original_mesh_faces_map(orig_mesh,tu.combine_meshes(nuclei_pieces))\n",
    "            n_nuclei_faces = len(nuclei_faces)\n",
    "        else:\n",
    "            nuclei_faces = None\n",
    "            n_nuclei_faces = 0\n",
    "            \n",
    "        # --------- saving the nuclei and glia saves\n",
    "        glia_path,nuclei_path = du.save_glia_nuclei_files(glia_faces=glia_faces,\n",
    "                                 nuclei_faces=nuclei_faces,\n",
    "                                 segment_id=segment_id)\n",
    "        \n",
    "        print(f\" glia_path = {glia_path} \\n nuclei_path = {nuclei_path}\")\n",
    "            \n",
    "        glia_nuclei_key = dict(key,\n",
    "                               ver=current_version,\n",
    "                               n_glia_faces=n_glia_faces,\n",
    "                               #glia_faces = glia_faces,\n",
    "                               glia_faces = glia_path,\n",
    "                               n_nuclei_faces = n_nuclei_faces,\n",
    "                               #nuclei_faces = nuclei_faces\n",
    "                               nuclei_faces = nuclei_path,\n",
    "                              )\n",
    "        \n",
    "        NeuronGliaNuclei.insert1(glia_nuclei_key,replace=True)\n",
    "        print(f\"Finished saving off glia and nuclei information : {glia_nuclei_key}\")\n",
    "        \n",
    "        # ---------------- End of 1/9 Addition --------------------------------- #\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"Run time was {run_time} \\n    total_soma_list = {total_soma_list}\"\n",
    "             f\"\\n    with sdf values = {total_soma_list_sdf}\")\n",
    "        \n",
    "        #check if soma list is empty and did not find soma\n",
    "        if len(total_soma_list) <= 0:\n",
    "            print(\"There were no somas found for this mesh so just writing empty data\")\n",
    "            \n",
    "\n",
    "            returned_file_path = tu.write_h5_file(\n",
    "                                                vertices=np.array([]),\n",
    "                                                  faces=np.array([]),\n",
    "                                                  segment_id=segment_id,\n",
    "                                                  filename = f'{segment_id}_0.h5',\n",
    "                                                    filepath=str(du.get_somas_path())\n",
    "                                                 )\n",
    "\n",
    "            \n",
    "            \n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=0,\n",
    "                               ver=current_version,\n",
    "                              centroid_x=None,\n",
    "                               centroid_y=None,\n",
    "                               centroid_z=None,\n",
    "                               #distance_from_prediction=None,\n",
    "                               #prediction_matching_index = None,\n",
    "                               n_vertices=0,\n",
    "                               n_faces=0,\n",
    "                               mesh=returned_file_path,\n",
    "                               multiplicity=0,\n",
    "                               sdf = None,\n",
    "                               volume = None,\n",
    "                               max_side_ratio = None,\n",
    "                               bbox_volume_ratio = None,\n",
    "                               max_hole_length=None,\n",
    "                               run_time=run_time\n",
    "                              )\n",
    "            \n",
    "            #raise Exception(\"to prevent writing because none were found\")\n",
    "            self.insert1(insert_dict,skip_duplicates=True)\n",
    "            return\n",
    "        \n",
    "        #if there is one or more soma found, get the volume and side length checks\n",
    "        max_side_ratio =  [np.max(sm.side_length_ratios(m)) for m in total_soma_list]\n",
    "        bbox_volume_ratio =  [sm.soma_volume_ratio(m) for m in total_soma_list]\n",
    "        dicts_to_insert = []\n",
    "\n",
    "\n",
    "        for i,(current_soma,soma_sdf,sz_ratio,vol_ratio) in enumerate(zip(total_soma_list,total_soma_list_sdf,max_side_ratio,bbox_volume_ratio)):\n",
    "            print(\"Trying to write off file\")\n",
    "            \"\"\" Currently don't need to export the meshes\n",
    "            current_soma.export(f\"{key['segment_id']}/{key['segment_id']}_soma_{i}.off\")\n",
    "            \"\"\"\n",
    "            auto_prediction_center = np.mean(current_soma.vertices,axis=0) / np.array([4,4,40])\n",
    "            auto_prediction_center = auto_prediction_center.astype(\"int\")\n",
    "            print(f\"Predicted Coordinates are {auto_prediction_center}\")\n",
    "            max_hole_length = tu.largest_hole_length(current_soma)\n",
    "            \n",
    "            returned_file_path = tu.write_h5_file(\n",
    "                                            vertices=current_soma.vertices,\n",
    "                                              faces=current_soma.faces,\n",
    "                                              segment_id=segment_id,\n",
    "                                              filename = f'{segment_id}_{i}.h5',\n",
    "                                                filepath=str(du.get_somas_path())\n",
    "                                             )\n",
    "\n",
    "\n",
    "\n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=i+1,\n",
    "                               ver=current_version,\n",
    "                              centroid_x=auto_prediction_center[0],\n",
    "                               centroid_y=auto_prediction_center[1],\n",
    "                               centroid_z=auto_prediction_center[2],\n",
    "                               n_vertices = len(current_soma.vertices),\n",
    "                               n_faces = len(current_soma.faces),\n",
    "                               mesh=returned_file_path,\n",
    "                               multiplicity=len(total_soma_list),\n",
    "                               sdf = np.round(soma_sdf,3),\n",
    "                               volume = current_soma.convex_hull.volume/1000000000,\n",
    "                               max_side_ratio = np.round(sz_ratio,3),\n",
    "                               bbox_volume_ratio = np.round(vol_ratio,3),\n",
    "                               max_hole_length = np.round(max_hole_length,3),\n",
    "                               run_time=np.round(run_time,4)\n",
    "                              )\n",
    "\n",
    "\n",
    "\n",
    "            dicts_to_insert.append(insert_dict)\n",
    "        self.insert(dicts_to_insert,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>job reservation table for `microns_minnie65_02`</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">table_name</p>\n",
       "                                <span class=\"djtooltiptext\">className of the table</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">key_hash</p>\n",
       "                                <span class=\"djtooltiptext\">key hash</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">if tuple is missing, the job is available</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">key</p>\n",
       "                                <span class=\"djtooltiptext\">structure containing the key</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_message</p>\n",
       "                                <span class=\"djtooltiptext\">error message returned if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_stack</p>\n",
       "                                <span class=\"djtooltiptext\">error stack if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">user</p>\n",
       "                                <span class=\"djtooltiptext\">database user</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">host</p>\n",
       "                                <span class=\"djtooltiptext\">system hostname</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">pid</p>\n",
       "                                <span class=\"djtooltiptext\">system process id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">connection_id</p>\n",
       "                                <span class=\"djtooltiptext\">connection_id()</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">timestamp</p>\n",
       "                                <span class=\"djtooltiptext\">automatic timestamp</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>__baylor_segment_centroid</td>\n",
       "<td>006d4a754852db78637a9730066c3558</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.147</td>\n",
       "<td>at-node20</td>\n",
       "<td>29</td>\n",
       "<td>34606</td>\n",
       "<td>2021-01-13 01:03:52</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>0de9544238e2741166282bce76c5b67b</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.26</td>\n",
       "<td>at-compute006</td>\n",
       "<td>29</td>\n",
       "<td>34582</td>\n",
       "<td>2021-01-13 01:05:15</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>0e0a23b50c00948d31c0e936b968e570</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.142</td>\n",
       "<td>at-node15</td>\n",
       "<td>29</td>\n",
       "<td>34616</td>\n",
       "<td>2021-01-13 01:03:46</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>1071bede410fb82537727d706a6779da</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.26</td>\n",
       "<td>at-compute006</td>\n",
       "<td>29</td>\n",
       "<td>34583</td>\n",
       "<td>2021-01-13 01:16:47</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>12dc98a8b9a21eadf99f39bdbf6efd06</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.164</td>\n",
       "<td>at-node37</td>\n",
       "<td>29</td>\n",
       "<td>34631</td>\n",
       "<td>2021-01-13 00:59:13</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>159fb5a371bd94dd452794c391f31487</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.165</td>\n",
       "<td>at-node38</td>\n",
       "<td>29</td>\n",
       "<td>34579</td>\n",
       "<td>2021-01-13 01:15:14</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>181b67c7b236e63d1bb947f25fb21690</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.132</td>\n",
       "<td>at-node5</td>\n",
       "<td>29</td>\n",
       "<td>34558</td>\n",
       "<td>2021-01-13 01:07:54</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>1bb2b246f4acc8687ff62021801e8c0f</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.172</td>\n",
       "<td>at-node45</td>\n",
       "<td>29</td>\n",
       "<td>34557</td>\n",
       "<td>2021-01-13 01:11:04</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>1dd6397125b48352b3a53e23b5447f81</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.135</td>\n",
       "<td>at-node8</td>\n",
       "<td>30</td>\n",
       "<td>34563</td>\n",
       "<td>2021-01-13 01:18:09</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>223292d754d01c10ec97cae17b086998</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.144</td>\n",
       "<td>at-node17</td>\n",
       "<td>29</td>\n",
       "<td>34601</td>\n",
       "<td>2021-01-13 01:02:05</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>2fce6f814c2680709bb844fc65ac2a5b</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.66.4.26</td>\n",
       "<td>at-compute006</td>\n",
       "<td>29</td>\n",
       "<td>34584</td>\n",
       "<td>2021-01-13 01:17:11</td></tr><tr><td>__baylor_segment_centroid</td>\n",
       "<td>392781f44ce7376cdcd349e7f64a994c</td>\n",
       "<td>reserved</td>\n",
       "<td>=BLOB=</td>\n",
       "<td></td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.166</td>\n",
       "<td>at-node39</td>\n",
       "<td>29</td>\n",
       "<td>34624</td>\n",
       "<td>2021-01-13 01:12:09</td> </tr> </tbody>\n",
       "            </table>\n",
       "            <p>...</p>\n",
       "            <p>Total: 80</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*table_name    *key_hash      status       key        error_message  error_stac user           host           pid     connection_id  timestamp     \n",
       "+------------+ +------------+ +----------+ +--------+ +------------+ +--------+ +------------+ +------------+ +-----+ +------------+ +------------+\n",
       "__baylor_segme 006d4a754852db reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node20      29      34606          2021-01-13 01:\n",
       "__baylor_segme 0de9544238e274 reserved     =BLOB=                    =BLOB=     celiib@10.66.4 at-compute006  29      34582          2021-01-13 01:\n",
       "__baylor_segme 0e0a23b50c0094 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node15      29      34616          2021-01-13 01:\n",
       "__baylor_segme 1071bede410fb8 reserved     =BLOB=                    =BLOB=     celiib@10.66.4 at-compute006  29      34583          2021-01-13 01:\n",
       "__baylor_segme 12dc98a8b9a21e reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node37      29      34631          2021-01-13 00:\n",
       "__baylor_segme 159fb5a371bd94 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node38      29      34579          2021-01-13 01:\n",
       "__baylor_segme 181b67c7b236e6 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node5       29      34558          2021-01-13 01:\n",
       "__baylor_segme 1bb2b246f4acc8 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node45      29      34557          2021-01-13 01:\n",
       "__baylor_segme 1dd6397125b483 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node8       30      34563          2021-01-13 01:\n",
       "__baylor_segme 223292d754d01c reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node17      29      34601          2021-01-13 01:\n",
       "__baylor_segme 2fce6f814c2680 reserved     =BLOB=                    =BLOB=     celiib@10.66.4 at-compute006  29      34584          2021-01-13 01:\n",
       "__baylor_segme 392781f44ce737 reserved     =BLOB=                    =BLOB=     celiib@10.28.0 at-node39      29      34624          2021-01-13 01:\n",
       "   ...\n",
       " (Total: 80)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__baylor_segment_centroid'\")\n",
    "curr_table#.delete()# & \"status='error'\"#.delete()\n",
    "#curr_table.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# key_hash,error_message = curr_table.fetch(\"key_hash\",\"error_message\")\n",
    "\n",
    "# df = pd.DataFrame.from_dict([dict(key_hash = k,error_message = m) for k,m in zip(key_hash,error_message)])\n",
    "# df\n",
    "# #df.columns = [\"error\",\"key_hash\"]\n",
    "# key_hashes_to_delete = df[df[\"error_message\"].str.contains(\"OSError\")][\"key_hash\"].to_numpy()\n",
    "\n",
    "# (curr_table & [dict(key_hash=k) for k in key_hashes_to_delete]).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:20:47,404 - autopopulate - Found 75752 keys to populate\n",
      "INFO - 2021-01-13 07:20:47,429 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:20:47,431 - autopopulate - Populating: {'segment_id': 864691136050815731, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136050815731 ----\n",
      "{'segment_id': 864691136050815731, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49109.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49109_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_800606.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49109.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49109_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_800606.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 4 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 4\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(53342, 3), faces.shape=(104640, 3))>, <trimesh.Trimesh(vertices.shape=(2493, 3), faces.shape=(3987, 3))>, <trimesh.Trimesh(vertices.shape=(1088, 3), faces.shape=(1749, 3))>, <trimesh.Trimesh(vertices.shape=(722, 3), faces.shape=(1163, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 190718, Final mesh size: 79179\n",
      "Total time = 12.517207145690918\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/neuron_864691136050815731.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/neuron_864691136050815731_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/decimation_meshlab_25725510.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(3810, 3), faces.shape=(4483, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34178.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34178_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_140305.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34178.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34178_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_140305.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 201\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/neuron_864691136050815731_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/neuron_864691136050815731_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/neuron_864691136050815731_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/poisson_256003.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(20760, 3), faces.shape=(41524, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(20760, 3), faces.shape=(41524, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/neuron_864691136050815731_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/neuron_864691136050815731_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136050815731/decimation_meshlab_25661506.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136050815731_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(5188, 3), faces.shape=(10380, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004436969757080078\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113605081573100_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.450702428817749\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.6366441249847412\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1, soma_sdf_value = 0.705742\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.003934383392333984\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.291534423828125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.008500814437866211\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.048883676528930664\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.705742\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 5, 2, 4, 0, 3, 6, 7]), array([0.705742  , 0.376277  , 0.280518  , 0.275424  , 0.1508785 ,\n",
      "       0.110212  , 0.0475757 , 0.02007585]))\n",
      "Sizes = [4277, 1121, 333, 3384, 1098, 84, 51, 32]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 5]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_618616.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_618616_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_579096.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_618616.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_618616_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_579096.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.623870744832023\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_381146.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_381146_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_868997.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_381146.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_381146_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_868997.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.2148497170009156\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 37.96501636505127\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40306.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40306_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_953961.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40306.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40306_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_953961.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_13342.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_13342_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_385337.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_13342.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_13342_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_385337.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3958, 3), faces.shape=(6025, 3))>, <trimesh.Trimesh(vertices.shape=(469, 3), faces.shape=(705, 3))>, <trimesh.Trimesh(vertices.shape=(392, 3), faces.shape=(625, 3))>, <trimesh.Trimesh(vertices.shape=(251, 3), faces.shape=(475, 3))>, <trimesh.Trimesh(vertices.shape=(247, 3), faces.shape=(358, 3))>, <trimesh.Trimesh(vertices.shape=(245, 3), faces.shape=(347, 3))>, <trimesh.Trimesh(vertices.shape=(232, 3), faces.shape=(374, 3))>, <trimesh.Trimesh(vertices.shape=(151, 3), faces.shape=(309, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_957439.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_957439_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_274728.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_957439.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_957439_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_274728.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.9498341430050752\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(53342, 3), faces.shape=(104640, 3))>, <trimesh.Trimesh(vertices.shape=(2493, 3), faces.shape=(3987, 3))>, <trimesh.Trimesh(vertices.shape=(1088, 3), faces.shape=(1749, 3))>, <trimesh.Trimesh(vertices.shape=(722, 3), faces.shape=(1163, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47042.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47042_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_331862.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47042.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47042_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_331862.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99625.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99625_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_714051.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99625.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99625_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_714051.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(451, 3), faces.shape=(722, 3))>, <trimesh.Trimesh(vertices.shape=(346, 3), faces.shape=(494, 3))>, <trimesh.Trimesh(vertices.shape=(281, 3), faces.shape=(439, 3))>, <trimesh.Trimesh(vertices.shape=(254, 3), faces.shape=(482, 3))>, <trimesh.Trimesh(vertices.shape=(234, 3), faces.shape=(331, 3))>]\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50209.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50209_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_888497.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50209.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50209_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_888497.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34363.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34363_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_705279.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34363.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34363_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_705279.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(743, 3), faces.shape=(1156, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8edd42689d4a1a86c93be31b664aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest hole before segmentation = 9909912.217917586, after = 2667806.044827589,\n",
      "ratio = 0.26920582000757487, difference = -7242106.173089997\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136050815731_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136050815731_nuclei.pbz2\n",
      "File size is 0.200273 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136050815731_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136050815731_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136050815731, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136050815731_glia.pbz2'), 'n_nuclei_faces': 118034, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136050815731_nuclei.pbz2')}\n",
      "Run time was 37.965012311935425 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(5150, 3), faces.shape=(8545, 3))>]\n",
      "    with sdf values = [0.705742]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_923801.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_923801_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_508508.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_923801.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_923801_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_508508.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 59821 106175  20062]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:21:53,787 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:21:53,792 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:21:53,794 - autopopulate - Populating: {'segment_id': 864691136521572241, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136521572241 ----\n",
      "{'segment_id': 864691136521572241, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54830.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54830_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_818650.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54830.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54830_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_818650.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 3 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 1\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "using precomputed glia pieces\n",
      "\n",
      " ---- Working on inside piece 0 ------\n",
      "For glia mesh 0 there were 20914 faces within 3000 distane\n",
      "New mesh size is <trimesh.Trimesh(vertices.shape=(10793, 3), faces.shape=(20914, 3))>\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(569, 3), faces.shape=(884, 3))>, <trimesh.Trimesh(vertices.shape=(508, 3), faces.shape=(829, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 437919, Final mesh size: 20897\n",
      "Total time = 26.807058572769165\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136521572241/neuron_864691136521572241.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136521572241/neuron_864691136521572241_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136521572241/decimation_meshlab_2531909.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 27.79727578163147\n",
      "Before Filtering the number of somas found = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:22:28,631 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:22:28,653 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:22:28,655 - autopopulate - Populating: {'segment_id': 864691135494586958, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136521572241_glia.pbz2\n",
      "File size is 0.211258 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136521572241_nuclei.pbz2\n",
      "File size is 0.000231 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136521572241_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136521572241_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136521572241, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 417005, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136521572241_glia.pbz2'), 'n_nuclei_faces': 17, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136521572241_nuclei.pbz2')}\n",
      "Run time was 27.79727339744568 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135494586958 ----\n",
      "{'segment_id': 864691135494586958, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44382.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44382_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_918132.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44382.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44382_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_918132.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3186, 3), faces.shape=(5947, 3))>, <trimesh.Trimesh(vertices.shape=(2958, 3), faces.shape=(5337, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 25838, Final mesh size: 14554\n",
      "Total time = 2.180716037750244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/neuron_864691135494586958.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/neuron_864691135494586958_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/decimation_meshlab_2551480.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(1740, 3), faces.shape=(2771, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9168.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9168_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_995052.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9168.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9168_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_995052.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 61\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/neuron_864691135494586958_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/neuron_864691135494586958_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/neuron_864691135494586958_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/poisson_378759.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(8287, 3), faces.shape=(16594, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(8287, 3), faces.shape=(16594, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/neuron_864691135494586958_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/neuron_864691135494586958_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135494586958/decimation_meshlab_25439036.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135494586958_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2064, 3), faces.shape=(4148, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0017762184143066406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113549458695800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.43244242668151855\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.5191733837127686\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0015621185302734375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.124641418457031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.003900289535522461\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.023008108139038086\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.765485, 0.69484 , 0.187797, 0.164855]))\n",
      "Sizes = [2232, 1120, 93, 703]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236721.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236721_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_403181.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236721.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236721_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_403181.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.161817346354821\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1131, 3), faces.shape=(2232, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/556_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac37a170ce0646478e89ee10dc43a944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_86612.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_86612_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_542855.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_86612.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_86612_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_542855.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.161817346354821\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1131, 3), faces.shape=(2232, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_17764.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_17764_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_105099.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_17764.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_17764_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_105099.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.170908379976625\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 27.202665328979492\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_21451.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_21451_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_757599.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_21451.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_21451_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_757599.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55142.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55142_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_120786.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:22:57,800 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:22:57,823 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:22:57,825 - autopopulate - Populating: {'segment_id': 864691136451074559, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55142.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55142_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_120786.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(1061, 3))>]\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135494586958_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135494586958_nuclei.pbz2\n",
      "File size is 0.015696 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135494586958_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135494586958_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135494586958, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135494586958_glia.pbz2'), 'n_nuclei_faces': 11284, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135494586958_nuclei.pbz2')}\n",
      "Run time was 27.202661991119385 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136451074559 ----\n",
      "{'segment_id': 864691136451074559, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_32056.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_32056_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_177131.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_32056.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_32056_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_177131.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 3 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 1\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "using precomputed glia pieces\n",
      "\n",
      " ---- Working on inside piece 0 ------\n",
      "For glia mesh 0 there were 12704 faces within 3000 distane\n",
      "New mesh size is <trimesh.Trimesh(vertices.shape=(6626, 3), faces.shape=(12704, 3))>\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(701, 3), faces.shape=(1091, 3))>, <trimesh.Trimesh(vertices.shape=(466, 3), faces.shape=(801, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 269822, Final mesh size: 12676\n",
      "Total time = 15.23640513420105\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136451074559/neuron_864691136451074559.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136451074559/neuron_864691136451074559_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136451074559/decimation_meshlab_25983698.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 15.982629299163818\n",
      "Before Filtering the number of somas found = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:23:17,239 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:23:17,261 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:23:17,263 - autopopulate - Populating: {'segment_id': 864691134684964653, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136451074559_glia.pbz2\n",
      "File size is 0.136287 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136451074559_nuclei.pbz2\n",
      "File size is 0.000251 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136451074559_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136451074559_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136451074559, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 257118, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136451074559_glia.pbz2'), 'n_nuclei_faces': 28, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136451074559_nuclei.pbz2')}\n",
      "Run time was 15.98262619972229 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691134684964653 ----\n",
      "{'segment_id': 864691134684964653, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23370.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23370_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_56470.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23370.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23370_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_56470.mls is being deleted....\n",
      "There were 3 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 3\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3323, 3), faces.shape=(6194, 3))>, <trimesh.Trimesh(vertices.shape=(2943, 3), faces.shape=(5469, 3))>, <trimesh.Trimesh(vertices.shape=(2446, 3), faces.shape=(4545, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 24831, Final mesh size: 8623\n",
      "Total time = 2.201982021331787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134684964653/neuron_864691134684964653.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134684964653/neuron_864691134684964653_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134684964653/decimation_meshlab_25235291.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:23:20,419 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:23:20,432 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:23:20,435 - autopopulate - Populating: {'segment_id': 864691134917390346, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 2.75921893119812\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134684964653_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134684964653_nuclei.pbz2\n",
      "File size is 0.020293 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134684964653_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134684964653_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691134684964653, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134684964653_glia.pbz2'), 'n_nuclei_faces': 16208, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134684964653_nuclei.pbz2')}\n",
      "Run time was 2.7592155933380127 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691134917390346 ----\n",
      "{'segment_id': 864691134917390346, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_11720.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_11720_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_439252.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_11720.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_11720_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_439252.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 5 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 1\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 4\n",
      "using precomputed glia pieces\n",
      "\n",
      " ---- Working on inside piece 0 ------\n",
      "For glia mesh 0 there were 33787 faces within 3000 distane\n",
      "New mesh size is <trimesh.Trimesh(vertices.shape=(17028, 3), faces.shape=(33787, 3))>\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5629, 3), faces.shape=(9034, 3))>, <trimesh.Trimesh(vertices.shape=(551, 3), faces.shape=(886, 3))>, <trimesh.Trimesh(vertices.shape=(524, 3), faces.shape=(819, 3))>, <trimesh.Trimesh(vertices.shape=(424, 3), faces.shape=(958, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 480641, Final mesh size: 25976\n",
      "Total time = 29.696861267089844\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/neuron_864691134917390346.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/neuron_864691134917390346_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/decimation_meshlab_2558795.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(2612, 3), faces.shape=(4073, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52051.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52051_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_815654.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52051.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52051_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_815654.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 24\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/neuron_864691134917390346_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/neuron_864691134917390346_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/neuron_864691134917390346_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/poisson_703092.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(9800, 3), faces.shape=(19636, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(9800, 3), faces.shape=(19636, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/neuron_864691134917390346_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/neuron_864691134917390346_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691134917390346/decimation_meshlab_25311135.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134917390346_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2436, 3), faces.shape=(4908, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008027553558349609\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113491739034600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6334872245788574\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.7510266304016113\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.4253315\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0018467903137207031\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.863739013671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0032815933227539062\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0229494571685791\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.4253315\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.4253315 , 0.08044985]))\n",
      "Sizes = [4786, 122]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_144900.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_144900_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_480841.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_144900.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_144900_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_480841.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 18.65722374146567\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(2379, 3), faces.shape=(4786, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/159_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a584dcfe5c44f3b03dda9b9eec9427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423933.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423933_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_85145.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423933.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423933_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_85145.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 16.539754170815357\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(2319, 3), faces.shape=(4662, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 51.224876403808594\n",
      "Before Filtering the number of somas found = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:24:17,747 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:24:17,758 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:24:17,759 - autopopulate - Populating: {'segment_id': 864691135777154237, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134917390346_glia.pbz2\n",
      "File size is 0.235666 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134917390346_nuclei.pbz2\n",
      "File size is 0.013222 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134917390346_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134917390346_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691134917390346, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 446854, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134917390346_glia.pbz2'), 'n_nuclei_faces': 7811, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691134917390346_nuclei.pbz2')}\n",
      "Run time was 51.224873065948486 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135777154237 ----\n",
      "{'segment_id': 864691135777154237, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17895.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17895_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_715409.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17895.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17895_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_715409.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 11 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 11\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(16564, 3), faces.shape=(38526, 3))>, <trimesh.Trimesh(vertices.shape=(1270, 3), faces.shape=(2328, 3))>, <trimesh.Trimesh(vertices.shape=(1172, 3), faces.shape=(2783, 3))>, <trimesh.Trimesh(vertices.shape=(644, 3), faces.shape=(1492, 3))>, <trimesh.Trimesh(vertices.shape=(608, 3), faces.shape=(1405, 3))>, <trimesh.Trimesh(vertices.shape=(580, 3), faces.shape=(1342, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(918, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 99172, Final mesh size: 50378\n",
      "Total time = 7.402454614639282\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/decimation_meshlab_25666500.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(2741, 3), faces.shape=(4961, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82002.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82002_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_939782.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82002.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82002_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_939782.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 594\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/poisson_441255.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(12592, 3), faces.shape=(25240, 3))>, <trimesh.Trimesh(vertices.shape=(2217, 3), faces.shape=(4434, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(12592, 3), faces.shape=(25240, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/decimation_meshlab_25591017.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135777154237_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3126, 3), faces.shape=(6308, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008184909820556641\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113577715423700_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.7497174739837646\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.8755366802215576\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.73901\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0025272369384765625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.267692565917969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004729270935058594\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.029229164123535156\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.73901\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.73901   , 0.4709425 , 0.110099  , 0.04852725]))\n",
      "Sizes = [3601, 888, 1771, 48]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_542283.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_542283_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_396916.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_542283.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_542283_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_396916.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.8933006756162638\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_700829.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_700829_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_340161.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_700829.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_700829_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_340161.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.19665026937196495\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2217, 3), faces.shape=(4434, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/neuron_864691135777154237_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135777154237/decimation_meshlab_25591017.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135777154237_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(553, 3), faces.shape=(1106, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002429485321044922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113577715423701_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08111906051635742\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10018682479858398\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004379749298095703\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.482269287109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010161399841308594\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0049893856048583984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.600673 , 0.0101688]))\n",
      "Sizes = [1081, 25]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_928168.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 52.77603022238921\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(543, 3), faces.shape=(1081, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/765_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ebe282142f423b9a89d6ba03bdc3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 31.704464197158813\n",
      "Before Filtering the number of somas found = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30187.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30187_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_668982.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30187.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30187_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_668982.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23974.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23974_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_501451.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23974.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23974_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_501451.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1156, 3), faces.shape=(2351, 3))>, <trimesh.Trimesh(vertices.shape=(617, 3), faces.shape=(921, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_613006.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_613006_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_796409.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_613006.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_613006_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_796409.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.409167360063313\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(16564, 3), faces.shape=(38526, 3))>, <trimesh.Trimesh(vertices.shape=(1270, 3), faces.shape=(2328, 3))>, <trimesh.Trimesh(vertices.shape=(1172, 3), faces.shape=(2783, 3))>, <trimesh.Trimesh(vertices.shape=(644, 3), faces.shape=(1492, 3))>, <trimesh.Trimesh(vertices.shape=(608, 3), faces.shape=(1405, 3))>, <trimesh.Trimesh(vertices.shape=(580, 3), faces.shape=(1342, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(918, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49808.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49808_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_179192.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49808.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49808_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_179192.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61728.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61728_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_574228.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61728.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61728_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_574228.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1193, 3), faces.shape=(2422, 3))>, <trimesh.Trimesh(vertices.shape=(610, 3), faces.shape=(910, 3))>, <trimesh.Trimesh(vertices.shape=(212, 3), faces.shape=(321, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22109.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22109_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_545191.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22109.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22109_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_545191.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7589.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7589_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_171439.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7589.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7589_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_171439.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 175\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5a172799af47568f1b32fef61905c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1626627.4282639355, after = 1530511.438855541,\n",
      "ratio = 0.940910876247195, difference = -96115.98940839455\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135777154237_glia.pbz2\n",
      "File size is 4.6e-05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135777154237_nuclei.pbz2\n",
      "File size is 0.075154 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135777154237_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135777154237_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135777154237, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135777154237_glia.pbz2'), 'n_nuclei_faces': 51541, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135777154237_nuclei.pbz2')}\n",
      "Run time was 31.704463481903076 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(8454, 3), faces.shape=(16211, 3))>]\n",
      "    with sdf values = [0.73901]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_756735.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_756735_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_852021.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_756735.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_756735_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_852021.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 60399 119863  20095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:25:17,194 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:25:17,200 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:25:17,203 - autopopulate - Populating: {'segment_id': 864691135269802405, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135269802405 ----\n",
      "{'segment_id': 864691135269802405, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15072.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15072_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_847916.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15072.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15072_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_847916.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 16 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 16\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(22061, 3), faces.shape=(56747, 3))>, <trimesh.Trimesh(vertices.shape=(7306, 3), faces.shape=(17243, 3))>, <trimesh.Trimesh(vertices.shape=(817, 3), faces.shape=(1828, 3))>, <trimesh.Trimesh(vertices.shape=(724, 3), faces.shape=(1720, 3))>, <trimesh.Trimesh(vertices.shape=(714, 3), faces.shape=(1620, 3))>, <trimesh.Trimesh(vertices.shape=(693, 3), faces.shape=(1628, 3))>, <trimesh.Trimesh(vertices.shape=(677, 3), faces.shape=(1532, 3))>, <trimesh.Trimesh(vertices.shape=(675, 3), faces.shape=(1508, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 184106, Final mesh size: 100279\n",
      "Total time = 13.060937404632568\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/neuron_864691135269802405.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/neuron_864691135269802405_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/decimation_meshlab_25841552.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(5369, 3), faces.shape=(9854, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(5369, 3), faces.shape=(9854, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_12208.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_12208_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_417201.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_12208.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_12208_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_417201.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 323\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/neuron_864691135269802405_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/neuron_864691135269802405_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/neuron_864691135269802405_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/poisson_120341.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(14946, 3), faces.shape=(29920, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(14946, 3), faces.shape=(29920, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/neuron_864691135269802405_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/neuron_864691135269802405_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135269802405/decimation_meshlab_25873837.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135269802405_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3725, 3), faces.shape=(7478, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008161067962646484\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113526980240500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.8044145107269287\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.9628064632415771\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 3, soma_sdf_value = 0.715289\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0030946731567382812\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.221366882324219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007682323455810547\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03849530220031738\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.715289\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 2, 4, 5, 1, 0]), array([0.715289 , 0.449426 , 0.382826 , 0.1230954, 0.120636 , 0.0898145]))\n",
      "Sizes = [3805, 1131, 308, 2, 1855, 377]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [3, 2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_508418.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_508418_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_765047.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_508418.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_508418_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_765047.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.8214706372448197\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_827700.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_827700_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_538020.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_827700.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_827700_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_538020.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.844539940804599\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 41.19895100593567\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56321.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56321_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_740712.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56321.off loaded has 26321 vn 49430 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56321_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_740712.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1224864\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1224864\n",
      "LOG: 2 Successfully removed 8162 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 8162 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1126920\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_740712.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71164.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71164_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_345474.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71164.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71164_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_345474.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(691, 3), faces.shape=(1368, 3))>, <trimesh.Trimesh(vertices.shape=(682, 3), faces.shape=(1694, 3))>, <trimesh.Trimesh(vertices.shape=(361, 3), faces.shape=(891, 3))>, <trimesh.Trimesh(vertices.shape=(298, 3), faces.shape=(536, 3))>, <trimesh.Trimesh(vertices.shape=(193, 3), faces.shape=(342, 3))>, <trimesh.Trimesh(vertices.shape=(156, 3), faces.shape=(335, 3))>, <trimesh.Trimesh(vertices.shape=(121, 3), faces.shape=(311, 3))>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_179048.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_179048_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_838043.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_179048.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_179048_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_838043.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.5716292376751047\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(22062, 3), faces.shape=(56748, 3))>, <trimesh.Trimesh(vertices.shape=(7306, 3), faces.shape=(17243, 3))>, <trimesh.Trimesh(vertices.shape=(817, 3), faces.shape=(1828, 3))>, <trimesh.Trimesh(vertices.shape=(724, 3), faces.shape=(1720, 3))>, <trimesh.Trimesh(vertices.shape=(714, 3), faces.shape=(1620, 3))>, <trimesh.Trimesh(vertices.shape=(693, 3), faces.shape=(1628, 3))>, <trimesh.Trimesh(vertices.shape=(677, 3), faces.shape=(1532, 3))>, <trimesh.Trimesh(vertices.shape=(675, 3), faces.shape=(1508, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77568.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77568_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_372801.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77568.off loaded has 20803 vn 38518 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77568_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_372801.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 961488\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 961488\n",
      "LOG: 2 Successfully removed 7650 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7650 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 869688\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_372801.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94421.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94421_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_461462.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94421.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94421_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_461462.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(691, 3), faces.shape=(1368, 3))>, <trimesh.Trimesh(vertices.shape=(682, 3), faces.shape=(1694, 3))>, <trimesh.Trimesh(vertices.shape=(370, 3), faces.shape=(912, 3))>, <trimesh.Trimesh(vertices.shape=(293, 3), faces.shape=(535, 3))>, <trimesh.Trimesh(vertices.shape=(197, 3), faces.shape=(349, 3))>, <trimesh.Trimesh(vertices.shape=(174, 3), faces.shape=(355, 3))>, <trimesh.Trimesh(vertices.shape=(123, 3), faces.shape=(320, 3))>, <trimesh.Trimesh(vertices.shape=(102, 3), faces.shape=(300, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4586.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4586_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_605112.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4586.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4586_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_605112.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89724.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89724_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_188144.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89724.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89724_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_188144.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 408\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab98080e0c704547bb95b99fe6e71cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest hole before segmentation = 2514674.533194572, after = 2786337.2747149365,\n",
      "ratio = 1.1080309749569268, difference = 271662.7415203643\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135269802405_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135269802405_nuclei.pbz2\n",
      "File size is 0.13865 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135269802405_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135269802405_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135269802405, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135269802405_glia.pbz2'), 'n_nuclei_faces': 89304, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135269802405_nuclei.pbz2')}\n",
      "Run time was 41.19894766807556 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(11439, 3), faces.shape=(21566, 3))>]\n",
      "    with sdf values = [0.715289]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_54862.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_54862_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_721448.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_54862.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_54862_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_721448.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 63290 125879  20086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:26:34,741 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:26:34,763 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:26:34,765 - autopopulate - Populating: {'segment_id': 864691135724233643, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135724233643 ----\n",
      "{'segment_id': 864691135724233643, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73690.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73690_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_510473.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73690.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73690_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_510473.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 31 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 31\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2153, 3), faces.shape=(5111, 3))>, <trimesh.Trimesh(vertices.shape=(1985, 3), faces.shape=(4714, 3))>, <trimesh.Trimesh(vertices.shape=(1970, 3), faces.shape=(4750, 3))>, <trimesh.Trimesh(vertices.shape=(1920, 3), faces.shape=(4507, 3))>, <trimesh.Trimesh(vertices.shape=(1731, 3), faces.shape=(4034, 3))>, <trimesh.Trimesh(vertices.shape=(1505, 3), faces.shape=(3597, 3))>, <trimesh.Trimesh(vertices.shape=(1408, 3), faces.shape=(3267, 3))>, <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3079, 3))>, <trimesh.Trimesh(vertices.shape=(1379, 3), faces.shape=(3189, 3))>, <trimesh.Trimesh(vertices.shape=(1090, 3), faces.shape=(2428, 3))>, <trimesh.Trimesh(vertices.shape=(998, 3), faces.shape=(2240, 3))>, <trimesh.Trimesh(vertices.shape=(990, 3), faces.shape=(2235, 3))>, <trimesh.Trimesh(vertices.shape=(776, 3), faces.shape=(1766, 3))>, <trimesh.Trimesh(vertices.shape=(735, 3), faces.shape=(1664, 3))>, <trimesh.Trimesh(vertices.shape=(717, 3), faces.shape=(1626, 3))>, <trimesh.Trimesh(vertices.shape=(638, 3), faces.shape=(1468, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(888, 3))>, <trimesh.Trimesh(vertices.shape=(321, 3), faces.shape=(722, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 138876, Final mesh size: 87591\n",
      "Total time = 10.576329708099365\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/decimation_meshlab_25336417.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(3819, 3), faces.shape=(7752, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(3819, 3), faces.shape=(7752, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_28692.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_28692_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_984503.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_28692.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_28692_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_984503.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 324\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/poisson_678280.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(5209, 3), faces.shape=(10418, 3))>, <trimesh.Trimesh(vertices.shape=(2971, 3), faces.shape=(5942, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(5209, 3), faces.shape=(10418, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/decimation_meshlab_25204857.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135724233643_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1302, 3), faces.shape=(2604, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00035190582275390625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113572423364300_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.2625093460083008\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.3052635192871094\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0009510517120361328\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.5299530029296875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0023627281188964844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.011922836303710938\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.737762, 0.203116]))\n",
      "Sizes = [2339, 265]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_337864.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_337864_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_988841.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_337864.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_337864_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_988841.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.257270793691852\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2971, 3), faces.shape=(5942, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/neuron_864691135724233643_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135724233643/decimation_meshlab_25204857.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135724233643_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(742, 3), faces.shape=(1484, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023221969604492188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113572423364301_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1046133041381836\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1387016773223877\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006396770477294922\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001761913299560547\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014929771423339844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007477760314941406\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.657835, 0.437885, 0.226419]))\n",
      "Sizes = [978, 459, 47]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_321058.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 185.74556778662802\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(492, 3), faces.shape=(978, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/774_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d6af2704d04d88b0e29da00dfc73aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_360421.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 186.3027794425688\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(488, 3), faces.shape=(968, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 30.984529972076416\n",
      "Before Filtering the number of somas found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98603.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98603_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_490276.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98603.off loaded has 23169 vn 47065 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98603_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_490276.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1120836\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1120836\n",
      "LOG: 2 Successfully removed 7081 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7081 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1035864\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_490276.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82345.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82345_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_803269.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82345.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82345_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_803269.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2667, 3), faces.shape=(7035, 3))>, <trimesh.Trimesh(vertices.shape=(811, 3), faces.shape=(2087, 3))>, <trimesh.Trimesh(vertices.shape=(367, 3), faces.shape=(1042, 3))>, <trimesh.Trimesh(vertices.shape=(268, 3), faces.shape=(557, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(406, 3))>, <trimesh.Trimesh(vertices.shape=(126, 3), faces.shape=(322, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_841505.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_841505_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_811546.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_841505.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_841505_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_811546.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.612401095796631\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(2153, 3), faces.shape=(5111, 3))>, <trimesh.Trimesh(vertices.shape=(1985, 3), faces.shape=(4714, 3))>, <trimesh.Trimesh(vertices.shape=(1970, 3), faces.shape=(4750, 3))>, <trimesh.Trimesh(vertices.shape=(1920, 3), faces.shape=(4507, 3))>, <trimesh.Trimesh(vertices.shape=(1731, 3), faces.shape=(4034, 3))>, <trimesh.Trimesh(vertices.shape=(1505, 3), faces.shape=(3597, 3))>, <trimesh.Trimesh(vertices.shape=(1408, 3), faces.shape=(3267, 3))>, <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3079, 3))>, <trimesh.Trimesh(vertices.shape=(1379, 3), faces.shape=(3189, 3))>, <trimesh.Trimesh(vertices.shape=(1090, 3), faces.shape=(2428, 3))>, <trimesh.Trimesh(vertices.shape=(998, 3), faces.shape=(2240, 3))>, <trimesh.Trimesh(vertices.shape=(990, 3), faces.shape=(2235, 3))>, <trimesh.Trimesh(vertices.shape=(776, 3), faces.shape=(1766, 3))>, <trimesh.Trimesh(vertices.shape=(735, 3), faces.shape=(1664, 3))>, <trimesh.Trimesh(vertices.shape=(717, 3), faces.shape=(1626, 3))>, <trimesh.Trimesh(vertices.shape=(638, 3), faces.shape=(1468, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(888, 3))>, <trimesh.Trimesh(vertices.shape=(321, 3), faces.shape=(722, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73223.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73223_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_779813.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73223.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73223_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_779813.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46692.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46692_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_819950.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46692.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46692_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_819950.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 396\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a60d2bbfa247c0aff010acb72a3df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 166402.1283455051, after = 580438.5483682404,\n",
      "ratio = 3.4881678145549952, difference = 414036.42002273526\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135724233643_glia.pbz2\n",
      "File size is 4.6e-05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135724233643_nuclei.pbz2\n",
      "File size is 0.084173 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135724233643_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135724233643_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135724233643, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135724233643_glia.pbz2'), 'n_nuclei_faces': 62734, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135724233643_nuclei.pbz2')}\n",
      "Run time was 30.984528303146362 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(11283, 3), faces.shape=(22300, 3))>]\n",
      "    with sdf values = [0.737762]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787912.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787912_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_205163.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787912.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787912_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_205163.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 64363 121865  20076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:27:35,482 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:27:35,488 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:27:35,490 - autopopulate - Populating: {'segment_id': 864691136436395166, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136436395166 ----\n",
      "{'segment_id': 864691136436395166, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67426.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67426_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_502573.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67426.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67426_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_502573.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 37 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 37\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2862, 3), faces.shape=(6729, 3))>, <trimesh.Trimesh(vertices.shape=(2118, 3), faces.shape=(4796, 3))>, <trimesh.Trimesh(vertices.shape=(1715, 3), faces.shape=(3967, 3))>, <trimesh.Trimesh(vertices.shape=(1344, 3), faces.shape=(3176, 3))>, <trimesh.Trimesh(vertices.shape=(1196, 3), faces.shape=(2800, 3))>, <trimesh.Trimesh(vertices.shape=(1187, 3), faces.shape=(2654, 3))>, <trimesh.Trimesh(vertices.shape=(929, 3), faces.shape=(2146, 3))>, <trimesh.Trimesh(vertices.shape=(837, 3), faces.shape=(1799, 3))>, <trimesh.Trimesh(vertices.shape=(833, 3), faces.shape=(1864, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1814, 3))>, <trimesh.Trimesh(vertices.shape=(742, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(728, 3), faces.shape=(1654, 3))>, <trimesh.Trimesh(vertices.shape=(721, 3), faces.shape=(1661, 3))>, <trimesh.Trimesh(vertices.shape=(718, 3), faces.shape=(1624, 3))>, <trimesh.Trimesh(vertices.shape=(703, 3), faces.shape=(1561, 3))>, <trimesh.Trimesh(vertices.shape=(690, 3), faces.shape=(1562, 3))>, <trimesh.Trimesh(vertices.shape=(689, 3), faces.shape=(1552, 3))>, <trimesh.Trimesh(vertices.shape=(665, 3), faces.shape=(1518, 3))>, <trimesh.Trimesh(vertices.shape=(658, 3), faces.shape=(1507, 3))>, <trimesh.Trimesh(vertices.shape=(638, 3), faces.shape=(1442, 3))>, <trimesh.Trimesh(vertices.shape=(627, 3), faces.shape=(1400, 3))>, <trimesh.Trimesh(vertices.shape=(529, 3), faces.shape=(1203, 3))>, <trimesh.Trimesh(vertices.shape=(477, 3), faces.shape=(1054, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 218722, Final mesh size: 167535\n",
      "Total time = 14.241865396499634\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/decimation_meshlab_25264825.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(11639, 3), faces.shape=(23324, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(11639, 3), faces.shape=(23324, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42330.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42330_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_96496.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42330.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42330_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_96496.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 171\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/poisson_512213.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(14830, 3), faces.shape=(29656, 3))>, <trimesh.Trimesh(vertices.shape=(3545, 3), faces.shape=(7086, 3))>, <trimesh.Trimesh(vertices.shape=(2391, 3), faces.shape=(4778, 3))>, <trimesh.Trimesh(vertices.shape=(1997, 3), faces.shape=(3990, 3))>, <trimesh.Trimesh(vertices.shape=(1835, 3), faces.shape=(3678, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(14830, 3), faces.shape=(29656, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/decimation_meshlab_25574253.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3709, 3), faces.shape=(7414, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005056858062744141\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.7134017944335938\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.8583154678344727\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 3, soma_sdf_value = 0.6804935000000001\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002862215042114258\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.698204040527344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006521940231323242\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03566122055053711\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.6804935000000001\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 5, 1, 4, 6, 0, 2]), array([0.6804935 , 0.110898  , 0.0924609 , 0.08946145, 0.0414556 ,\n",
      "       0.0334562 , 0.0303855 ]))\n",
      "Sizes = [3434, 249, 2699, 184, 105, 265, 478]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_629135.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_629135_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_799452.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_629135.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_629135_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_799452.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.043458446463479\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3545, 3), faces.shape=(7086, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/decimation_meshlab_25574253.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(887, 3), faces.shape=(1770, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022172927856445312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516601_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.12830424308776855\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.15916728973388672\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008599758148193359\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.601478576660156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016672611236572266\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008101701736450195\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 3, 1, 0, 2, 7, 4, 6, 8]), array([0.789373 , 0.56246  , 0.5434075, 0.4321235, 0.415236 , 0.2698665,\n",
      "       0.266924 , 0.26167  , 0.153348 ]))\n",
      "Sizes = [80, 214, 578, 456, 192, 76, 119, 24, 31]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_563940.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 64.17557527558088\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(294, 3), faces.shape=(578, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/796_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34db51f3a21f445eb918a13b872be559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(2391, 3), faces.shape=(4778, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/decimation_meshlab_25574253.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(599, 3), faces.shape=(1194, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021076202392578125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516602_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06878542900085449\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09001421928405762\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005576610565185547\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.6253204345703125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010900497436523438\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005368471145629883\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([8, 1, 6, 2, 0, 5, 3, 7, 4]), array([0.655099 , 0.6284725, 0.610982 , 0.582902 , 0.4743465, 0.332744 ,\n",
      "       0.2035565, 0.193775 , 0.1868365]))\n",
      "Sizes = [191, 166, 97, 221, 278, 92, 28, 29, 92]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(142, 3), faces.shape=(278, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00017714500427246094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516602_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.01445770263671875\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.029141902923583984\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008499622344970703\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.000118255615234375\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008893013000488281\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004191398620605469\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 3, 1, 2]), array([0.813202, 0.618176, 0.394482, 0.162042]))\n",
      "Sizes = [59, 65, 141, 13]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(74, 3), faces.shape=(141, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001952648162841797\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516602_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.007908105850219727\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.013237237930297852\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00014281272888183594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.458427429199219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000171661376953125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0007474422454833984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.344255]))\n",
      "Sizes = [141]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(1997, 3), faces.shape=(3990, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/decimation_meshlab_25574253.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(500, 3), faces.shape=(996, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021457672119140625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516603_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06011533737182617\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07900047302246094\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006082057952880859\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.3882598876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010328292846679688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00499415397644043\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3]), array([0.705998, 0.527414, 0.401386, 0.107333]))\n",
      "Sizes = [326, 507, 142, 21]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(257, 3), faces.shape=(507, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00019669532775878906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516603_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.029077529907226562\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03896903991699219\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002613067626953125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00013208389282226562\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005271434783935547\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002577066421508789\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.608429]))\n",
      "Sizes = [507]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(257, 3), faces.shape=(507, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001938343048095703\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516603_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.029037952423095703\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.039475440979003906\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00026297569274902344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001308917999267578\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005414485931396484\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0027120113372802734\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.608429]))\n",
      "Sizes = [507]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(1835, 3), faces.shape=(3678, 3))>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136436395166/decimation_meshlab_25574253.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136436395166_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(455, 3), faces.shape=(918, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005807876586914062\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113643639516604_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.055600643157958984\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0792839527130127\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004425048828125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.459785461425781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009577274322509766\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004579782485961914\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.606827, 0.403565]))\n",
      "Sizes = [193, 725]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xy = 6.241588904575422 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_361273.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 286.50214780319425\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(359, 3), faces.shape=(725, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/445_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc814c9f02dd4ed3ba4eaf2a1a1a49f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xy = 6.241588904575422 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_618016.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 286.50214780319425\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(359, 3), faces.shape=(725, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 43.52822756767273\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88245.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88245_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_911163.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88245.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88245_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_911163.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5804.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5804_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_446001.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5804.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5804_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_446001.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1878, 3), faces.shape=(4084, 3))>, <trimesh.Trimesh(vertices.shape=(1198, 3), faces.shape=(2557, 3))>, <trimesh.Trimesh(vertices.shape=(827, 3), faces.shape=(1648, 3))>, <trimesh.Trimesh(vertices.shape=(681, 3), faces.shape=(1356, 3))>, <trimesh.Trimesh(vertices.shape=(523, 3), faces.shape=(1068, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(1027, 3))>, <trimesh.Trimesh(vertices.shape=(439, 3), faces.shape=(636, 3))>, <trimesh.Trimesh(vertices.shape=(277, 3), faces.shape=(601, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_237960.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_237960_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_505164.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_237960.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_237960_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_505164.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.952532634545039\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(2862, 3), faces.shape=(6729, 3))>, <trimesh.Trimesh(vertices.shape=(2118, 3), faces.shape=(4796, 3))>, <trimesh.Trimesh(vertices.shape=(1715, 3), faces.shape=(3967, 3))>, <trimesh.Trimesh(vertices.shape=(1344, 3), faces.shape=(3176, 3))>, <trimesh.Trimesh(vertices.shape=(1196, 3), faces.shape=(2800, 3))>, <trimesh.Trimesh(vertices.shape=(1187, 3), faces.shape=(2654, 3))>, <trimesh.Trimesh(vertices.shape=(929, 3), faces.shape=(2146, 3))>, <trimesh.Trimesh(vertices.shape=(837, 3), faces.shape=(1799, 3))>, <trimesh.Trimesh(vertices.shape=(833, 3), faces.shape=(1864, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1814, 3))>, <trimesh.Trimesh(vertices.shape=(742, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(728, 3), faces.shape=(1654, 3))>, <trimesh.Trimesh(vertices.shape=(721, 3), faces.shape=(1661, 3))>, <trimesh.Trimesh(vertices.shape=(718, 3), faces.shape=(1624, 3))>, <trimesh.Trimesh(vertices.shape=(703, 3), faces.shape=(1561, 3))>, <trimesh.Trimesh(vertices.shape=(690, 3), faces.shape=(1562, 3))>, <trimesh.Trimesh(vertices.shape=(689, 3), faces.shape=(1552, 3))>, <trimesh.Trimesh(vertices.shape=(665, 3), faces.shape=(1518, 3))>, <trimesh.Trimesh(vertices.shape=(658, 3), faces.shape=(1507, 3))>, <trimesh.Trimesh(vertices.shape=(638, 3), faces.shape=(1442, 3))>, <trimesh.Trimesh(vertices.shape=(627, 3), faces.shape=(1400, 3))>, <trimesh.Trimesh(vertices.shape=(529, 3), faces.shape=(1203, 3))>, <trimesh.Trimesh(vertices.shape=(477, 3), faces.shape=(1054, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_39008.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_39008_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_216077.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_39008.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_39008_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_216077.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67226.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67226_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_557150.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67226.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_67226_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_557150.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 155\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4000993356fc4908a69bf541cb19edc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 227640.10788980685, after = 314639.36741416005,\n",
      "ratio = 1.382178959282811, difference = 86999.2595243532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136436395166_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136436395166_nuclei.pbz2\n",
      "File size is 0.08619 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136436395166_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136436395166_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136436395166, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136436395166_glia.pbz2'), 'n_nuclei_faces': 63453, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136436395166_nuclei.pbz2')}\n",
      "Run time was 43.5282256603241 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(15144, 3), faces.shape=(29973, 3))>]\n",
      "    with sdf values = [0.6804935]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_486226.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_486226_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_83325.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_486226.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_486226_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_83325.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 65302 123407  20028]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:28:53,128 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:28:53,151 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:28:53,153 - autopopulate - Populating: {'segment_id': 864691136740437084, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136740437084 ----\n",
      "{'segment_id': 864691136740437084, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55933.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55933_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_186025.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55933.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55933_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_186025.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 3 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 3\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(32607, 3), faces.shape=(64275, 3))>, <trimesh.Trimesh(vertices.shape=(949, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(954, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 237733, Final mesh size: 170776\n",
      "Total time = 12.238066911697388\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/decimation_meshlab_25116437.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(10448, 3), faces.shape=(20314, 3))>, <trimesh.Trimesh(vertices.shape=(10784, 3), faces.shape=(18964, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(10448, 3), faces.shape=(20314, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86145.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86145_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_962879.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86145.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86145_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_962879.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 207\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/poisson_129923.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(24937, 3), faces.shape=(49878, 3))>, <trimesh.Trimesh(vertices.shape=(2465, 3), faces.shape=(4926, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(24937, 3), faces.shape=(49878, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/decimation_meshlab_25123597.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(6232, 3), faces.shape=(12468, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004649162292480469\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113674043708400_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.272782802581787\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.4894752502441406\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.8093925\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0045011043548583984\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.673004150390625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.010935783386230469\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0589144229888916\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.8093925\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 6, 3, 4, 2, 7, 8, 1, 5]), array([0.8093925, 0.188598 , 0.1838695, 0.168775 , 0.0998522, 0.0843287,\n",
      "       0.0638338, 0.0545384, 0.0313457]))\n",
      "Sizes = [4088, 383, 1412, 281, 363, 787, 620, 4517, 17]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_528808.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_528808_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_696999.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_528808.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_528808_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_696999.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.6966815407580937\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2465, 3), faces.shape=(4926, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/decimation_meshlab_25123597.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(617, 3), faces.shape=(1230, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021791458129882812\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113674043708401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07632279396057129\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09705686569213867\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006482601165771484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.413459777832031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011165142059326172\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00563502311706543\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.5760185, 0.122898 , 0.0548797]))\n",
      "Sizes = [1196, 25, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_224776.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 184.17659201423447\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(601, 3), faces.shape=(1196, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/795_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc3f96a30f846ffbb0ece7e0f1e0479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_664283.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 60.564129857956495\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(303, 3), faces.shape=(599, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(10784, 3), faces.shape=(18964, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_59631.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_59631_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_904880.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_59631.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_59631_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_904880.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 125\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/poisson_129923.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(31732, 3), faces.shape=(63468, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(31732, 3), faces.shape=(63468, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136740437084/decimation_meshlab_25123597.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136740437084_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(7929, 3), faces.shape=(15862, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00034928321838378906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113674043708410_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.843956470489502\n",
      "2) Finished: Generating CGAL segmentation for neuron: 2.100782632827759\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 3, soma_sdf_value = 0.7863644999999999\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.005895137786865234\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.458427429199219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.012501239776611328\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.07471585273742676\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.7863644999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 3,  2,  9,  8, 11,  4, 10,  0,  6,  7,  1,  5]), array([0.7863645 , 0.31047   , 0.273704  , 0.1744555 , 0.173749  ,\n",
      "       0.1393555 , 0.136198  , 0.084938  , 0.0626365 , 0.06139615,\n",
      "       0.0577188 , 0.0481363 ]))\n",
      "Sizes = [8008, 774, 314, 2302, 187, 576, 107, 535, 682, 162, 1165, 1050]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_820114.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_820114_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_789997.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_820114.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_820114_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_789997.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.868350406252538\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 57.90110206604004\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82638.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82638_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_169829.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82638.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82638_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_169829.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5748.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5748_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_78263.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5748.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5748_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_78263.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2112, 3), faces.shape=(3194, 3))>, <trimesh.Trimesh(vertices.shape=(977, 3), faces.shape=(1644, 3))>, <trimesh.Trimesh(vertices.shape=(533, 3), faces.shape=(978, 3))>, <trimesh.Trimesh(vertices.shape=(382, 3), faces.shape=(531, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_294011.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_294011_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_825127.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_294011.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_294011_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_825127.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -1.693588863295965\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_84663.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_84663_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_516023.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_84663.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_84663_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_516023.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.43043203262884067\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(32607, 3), faces.shape=(64275, 3))>, <trimesh.Trimesh(vertices.shape=(949, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(954, 3))>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99984.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99984_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_108644.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99984.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_99984_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_108644.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97235.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97235_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_457569.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97235.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97235_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_457569.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2622, 3), faces.shape=(3886, 3))>, <trimesh.Trimesh(vertices.shape=(1010, 3), faces.shape=(1742, 3))>, <trimesh.Trimesh(vertices.shape=(539, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(634, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_200593.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_200593_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_867014.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_200593.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_200593_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_867014.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.0109237490589402\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_983688.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_983688_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_287384.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_983688.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_983688_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_287384.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.181355763210512\n",
      "Trying backtrack segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7f0ab05b094dc89525a056a03788bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--->This soma mesh was not added because it did not pass the sphere validation EVEN AFTER SEGMENTATION:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(5802, 3), faces.shape=(10414, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(32607, 3), faces.shape=(64275, 3))>, <trimesh.Trimesh(vertices.shape=(949, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(954, 3))>, <trimesh.Trimesh(vertices.shape=(1914, 3), faces.shape=(2274, 3))>, <trimesh.Trimesh(vertices.shape=(961, 3), faces.shape=(1453, 3))>, <trimesh.Trimesh(vertices.shape=(533, 3), faces.shape=(606, 3))>, <trimesh.Trimesh(vertices.shape=(319, 3), faces.shape=(371, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48966.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48966_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_550267.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48966.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48966_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_550267.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91932.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91932_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_553016.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91932.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91932_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_553016.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 70\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed907842f2494c839d4bbdb9747e2ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2374651.795355562, after = 2395445.1594902705,\n",
      "ratio = 1.0087563844835596, difference = 20793.36413470842\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8693.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8693_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_255552.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8693.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8693_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_255552.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_90909.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_90909_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_434966.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_90909.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_90909_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_434966.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 137\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec04beef939f4529b9bd9d968e57e8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2708258.2251141923, after = 1544579.1222333412,\n",
      "ratio = 0.5703219537598616, difference = -1163679.1028808511\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6848.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6848_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_72618.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6848.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6848_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_72618.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56128.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56128_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_684448.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56128.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56128_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_684448.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 141\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40efd99891da4188b24fedd76fa55c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 3136293.6638096008, after = 1853041.2463877657,\n",
      "ratio = 0.590837926872227, difference = -1283252.417421835\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136740437084_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136740437084_nuclei.pbz2\n",
      "File size is 0.118948 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136740437084_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136740437084_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136740437084, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136740437084_glia.pbz2'), 'n_nuclei_faces': 73657, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136740437084_nuclei.pbz2')}\n",
      "Run time was 57.90109658241272 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(8223, 3), faces.shape=(15874, 3))>, <trimesh.Trimesh(vertices.shape=(8812, 3), faces.shape=(25333, 3))>]\n",
      "    with sdf values = [0.8093925 0.7978785]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_387572.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_387572_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_551773.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_387572.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_387572_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_551773.mls is being deleted....\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236425.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236425_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_316253.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236425.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_236425_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_316253.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 61402 121156  20648]\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 62079 120220  20850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:31:07,299 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:31:07,322 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:31:07,325 - autopopulate - Populating: {'segment_id': 864691135462260637, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135462260637 ----\n",
      "{'segment_id': 864691135462260637, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86208.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86208_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_252661.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86208.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86208_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_252661.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 11 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 11\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(20283, 3), faces.shape=(53892, 3))>, <trimesh.Trimesh(vertices.shape=(1807, 3), faces.shape=(4366, 3))>, <trimesh.Trimesh(vertices.shape=(1481, 3), faces.shape=(3547, 3))>, <trimesh.Trimesh(vertices.shape=(786, 3), faces.shape=(1834, 3))>, <trimesh.Trimesh(vertices.shape=(685, 3), faces.shape=(1576, 3))>, <trimesh.Trimesh(vertices.shape=(617, 3), faces.shape=(1402, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 135428, Final mesh size: 68811\n",
      "Total time = 11.454320907592773\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135462260637/neuron_864691135462260637.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135462260637/neuron_864691135462260637_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135462260637/decimation_meshlab_25993468.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 16.79992651939392\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462260637_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462260637_nuclei.pbz2\n",
      "File size is 0.098804 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462260637_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462260637_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135462260637, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462260637_glia.pbz2'), 'n_nuclei_faces': 66617, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462260637_nuclei.pbz2')}\n",
      "Run time was 16.799924850463867 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:31:25,747 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:31:25,760 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:31:25,762 - autopopulate - Populating: {'segment_id': 864691135776658528, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135776658528 ----\n",
      "{'segment_id': 864691135776658528, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_93153.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_93153_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_71208.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_93153.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_93153_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_71208.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 34 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 34\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2395, 3), faces.shape=(5904, 3))>, <trimesh.Trimesh(vertices.shape=(2084, 3), faces.shape=(4920, 3))>, <trimesh.Trimesh(vertices.shape=(2021, 3), faces.shape=(4823, 3))>, <trimesh.Trimesh(vertices.shape=(1895, 3), faces.shape=(4530, 3))>, <trimesh.Trimesh(vertices.shape=(1720, 3), faces.shape=(4007, 3))>, <trimesh.Trimesh(vertices.shape=(1336, 3), faces.shape=(3115, 3))>, <trimesh.Trimesh(vertices.shape=(1169, 3), faces.shape=(2750, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(2142, 3))>, <trimesh.Trimesh(vertices.shape=(898, 3), faces.shape=(2062, 3))>, <trimesh.Trimesh(vertices.shape=(838, 3), faces.shape=(1943, 3))>, <trimesh.Trimesh(vertices.shape=(808, 3), faces.shape=(1830, 3))>, <trimesh.Trimesh(vertices.shape=(800, 3), faces.shape=(1859, 3))>, <trimesh.Trimesh(vertices.shape=(780, 3), faces.shape=(1800, 3))>, <trimesh.Trimesh(vertices.shape=(780, 3), faces.shape=(1801, 3))>, <trimesh.Trimesh(vertices.shape=(761, 3), faces.shape=(1767, 3))>, <trimesh.Trimesh(vertices.shape=(754, 3), faces.shape=(1726, 3))>, <trimesh.Trimesh(vertices.shape=(732, 3), faces.shape=(1673, 3))>, <trimesh.Trimesh(vertices.shape=(707, 3), faces.shape=(1552, 3))>, <trimesh.Trimesh(vertices.shape=(702, 3), faces.shape=(1601, 3))>, <trimesh.Trimesh(vertices.shape=(679, 3), faces.shape=(1539, 3))>, <trimesh.Trimesh(vertices.shape=(566, 3), faces.shape=(1279, 3))>, <trimesh.Trimesh(vertices.shape=(509, 3), faces.shape=(1102, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 156029, Final mesh size: 100304\n",
      "Total time = 11.453530550003052\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/neuron_864691135776658528.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/neuron_864691135776658528_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/decimation_meshlab_25856786.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(6270, 3), faces.shape=(12446, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(6270, 3), faces.shape=(12446, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87397.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87397_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_419165.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87397.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87397_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_419165.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 104\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/neuron_864691135776658528_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/neuron_864691135776658528_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/neuron_864691135776658528_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/poisson_826770.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(13820, 3), faces.shape=(27636, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(13820, 3), faces.shape=(27636, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/neuron_864691135776658528_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/neuron_864691135776658528_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135776658528/decimation_meshlab_25640203.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135776658528_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3455, 3), faces.shape=(6906, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008325576782226562\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113577665852800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6836261749267578\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.823310136795044\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0026044845581054688\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.1961669921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006600379943847656\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03178858757019043\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1,  0,  9,  4,  6,  3, 10,  5,  2,  8,  7]), array([0.733744  , 0.3739725 , 0.2389125 , 0.11349   , 0.0981962 ,\n",
      "       0.0846934 , 0.0750235 , 0.0733224 , 0.061107  , 0.0602085 ,\n",
      "       0.01965445]))\n",
      "Sizes = [2849, 628, 174, 693, 293, 159, 169, 1007, 483, 307, 144]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_608324.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_608324_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_378143.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_608324.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_608324_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_378143.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.679930822104126\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_733418.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_733418_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_202188.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_733418.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_733418_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_202188.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1.6015815346804765\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 38.710564613342285\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58507.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58507_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_924877.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58507.off loaded has 26694 vn 51908 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58507_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_924877.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1263552\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1263552\n",
      "LOG: 2 Successfully removed 6777 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 6777 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1182228\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_924877.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_57083.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_57083_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_472791.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_57083.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_57083_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_472791.mls is being deleted....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(732, 3), faces.shape=(1906, 3))>, <trimesh.Trimesh(vertices.shape=(480, 3), faces.shape=(1252, 3))>, <trimesh.Trimesh(vertices.shape=(273, 3), faces.shape=(676, 3))>, <trimesh.Trimesh(vertices.shape=(228, 3), faces.shape=(635, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_753420.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_753420_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_120094.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_753420.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_753420_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_120094.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.979056991313806\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(2395, 3), faces.shape=(5904, 3))>, <trimesh.Trimesh(vertices.shape=(2084, 3), faces.shape=(4920, 3))>, <trimesh.Trimesh(vertices.shape=(2021, 3), faces.shape=(4823, 3))>, <trimesh.Trimesh(vertices.shape=(1895, 3), faces.shape=(4530, 3))>, <trimesh.Trimesh(vertices.shape=(1720, 3), faces.shape=(4007, 3))>, <trimesh.Trimesh(vertices.shape=(1336, 3), faces.shape=(3115, 3))>, <trimesh.Trimesh(vertices.shape=(1169, 3), faces.shape=(2750, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(2142, 3))>, <trimesh.Trimesh(vertices.shape=(898, 3), faces.shape=(2062, 3))>, <trimesh.Trimesh(vertices.shape=(838, 3), faces.shape=(1943, 3))>, <trimesh.Trimesh(vertices.shape=(808, 3), faces.shape=(1830, 3))>, <trimesh.Trimesh(vertices.shape=(800, 3), faces.shape=(1859, 3))>, <trimesh.Trimesh(vertices.shape=(780, 3), faces.shape=(1800, 3))>, <trimesh.Trimesh(vertices.shape=(780, 3), faces.shape=(1801, 3))>, <trimesh.Trimesh(vertices.shape=(761, 3), faces.shape=(1767, 3))>, <trimesh.Trimesh(vertices.shape=(754, 3), faces.shape=(1726, 3))>, <trimesh.Trimesh(vertices.shape=(732, 3), faces.shape=(1673, 3))>, <trimesh.Trimesh(vertices.shape=(707, 3), faces.shape=(1552, 3))>, <trimesh.Trimesh(vertices.shape=(702, 3), faces.shape=(1601, 3))>, <trimesh.Trimesh(vertices.shape=(679, 3), faces.shape=(1539, 3))>, <trimesh.Trimesh(vertices.shape=(566, 3), faces.shape=(1279, 3))>, <trimesh.Trimesh(vertices.shape=(509, 3), faces.shape=(1102, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55309.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55309_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_211657.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55309.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55309_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_211657.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15775.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15775_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_908984.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15775.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15775_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_908984.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(404, 3), faces.shape=(873, 3))>, <trimesh.Trimesh(vertices.shape=(242, 3), faces.shape=(487, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "Mesh was manifold\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22783.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22783_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_740859.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22783.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_22783_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_740859.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48531.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48531_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_87864.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48531.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48531_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_87864.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 213\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a3e023d02148828496ec1885452346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 309977.8189102519, after = 347448.88399159507,\n",
      "ratio = 1.1208830529006084, difference = 37471.06508134317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135776658528_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135776658528_nuclei.pbz2\n",
      "File size is 0.08071 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135776658528_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135776658528_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135776658528, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135776658528_glia.pbz2'), 'n_nuclei_faces': 60194, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135776658528_nuclei.pbz2')}\n",
      "Run time was 38.710559368133545 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(12639, 3), faces.shape=(25076, 3))>]\n",
      "    with sdf values = [0.733744]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_307254.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_307254_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_623982.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_307254.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_307254_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_623982.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 65412 126619  20633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:32:37,863 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:32:37,878 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:32:37,880 - autopopulate - Populating: {'segment_id': 864691135230127665, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135230127665 ----\n",
      "{'segment_id': 864691135230127665, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97423.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97423_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_684602.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97423.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97423_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_684602.mls is being deleted....\n",
      "There were 5 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 5\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3703, 3), faces.shape=(7018, 3))>, <trimesh.Trimesh(vertices.shape=(2035, 3), faces.shape=(3824, 3))>, <trimesh.Trimesh(vertices.shape=(1324, 3), faces.shape=(2480, 3))>, <trimesh.Trimesh(vertices.shape=(961, 3), faces.shape=(1803, 3))>, <trimesh.Trimesh(vertices.shape=(730, 3), faces.shape=(1343, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 24242, Final mesh size: 7774\n",
      "Total time = 2.1381547451019287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135230127665/neuron_864691135230127665.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135230127665/neuron_864691135230127665_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135230127665/decimation_meshlab_25734772.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:32:40,938 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:32:40,951 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:32:40,953 - autopopulate - Populating: {'segment_id': 864691135511469390, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 2.7204360961914062\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135230127665_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135230127665_nuclei.pbz2\n",
      "File size is 0.021373 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135230127665_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135230127665_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135230127665, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135230127665_glia.pbz2'), 'n_nuclei_faces': 16468, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135230127665_nuclei.pbz2')}\n",
      "Run time was 2.720433235168457 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135511469390 ----\n",
      "{'segment_id': 864691135511469390, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58053.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58053_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_662028.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58053.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_58053_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_662028.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "There were 0 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 0\n",
      "\n",
      "\n",
      "Original Mesh size: 20703, Final mesh size: 20703\n",
      "Total time = 1.4360072612762451\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/neuron_864691135511469390.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/neuron_864691135511469390_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/decimation_meshlab_25797117.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(2331, 3), faces.shape=(5170, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(2331, 3), faces.shape=(5170, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60672.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60672_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_125011.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60672.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60672_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_125011.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 19\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/neuron_864691135511469390_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/neuron_864691135511469390_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/neuron_864691135511469390_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/poisson_710247.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(10563, 3), faces.shape=(21282, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(10563, 3), faces.shape=(21282, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/neuron_864691135511469390_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/neuron_864691135511469390_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135511469390/decimation_meshlab_25183111.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135511469390_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2582, 3), faces.shape=(5320, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008051395416259766\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113551146939000_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.4193553924560547\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.5244045257568359\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.23621\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0018448829650878906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.696846008300781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0036466121673583984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02680683135986328\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.23621\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.455041, 0.23621 ]))\n",
      "Sizes = [785, 4535]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_926145.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_926145_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_189011.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_926145.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_926145_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_189011.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.539289315939198\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(785, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/878_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c017b7fd0491492c816b57246cc43c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "INFO - 2021-01-13 07:32:56,944 - connection - Transaction committed and closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 15.669247150421143\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135511469390_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135511469390_nuclei.pbz2\n",
      "File size is 4.6e-05 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135511469390_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135511469390_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135511469390, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135511469390_glia.pbz2'), 'n_nuclei_faces': 0, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135511469390_nuclei.pbz2')}\n",
      "Run time was 15.669246435165405 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:32:56,958 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:32:56,960 - autopopulate - Populating: {'segment_id': 864691135941166708, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135941166708 ----\n",
      "{'segment_id': 864691135941166708, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87787.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87787_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_606600.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87787.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87787_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_606600.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 26 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 26\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(7472, 3), faces.shape=(16934, 3))>, <trimesh.Trimesh(vertices.shape=(2822, 3), faces.shape=(6749, 3))>, <trimesh.Trimesh(vertices.shape=(2491, 3), faces.shape=(5844, 3))>, <trimesh.Trimesh(vertices.shape=(1671, 3), faces.shape=(3922, 3))>, <trimesh.Trimesh(vertices.shape=(1474, 3), faces.shape=(3482, 3))>, <trimesh.Trimesh(vertices.shape=(1378, 3), faces.shape=(3254, 3))>, <trimesh.Trimesh(vertices.shape=(1150, 3), faces.shape=(2700, 3))>, <trimesh.Trimesh(vertices.shape=(962, 3), faces.shape=(2236, 3))>, <trimesh.Trimesh(vertices.shape=(920, 3), faces.shape=(2123, 3))>, <trimesh.Trimesh(vertices.shape=(846, 3), faces.shape=(1975, 3))>, <trimesh.Trimesh(vertices.shape=(769, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1551, 3))>, <trimesh.Trimesh(vertices.shape=(653, 3), faces.shape=(1450, 3))>, <trimesh.Trimesh(vertices.shape=(640, 3), faces.shape=(1452, 3))>, <trimesh.Trimesh(vertices.shape=(621, 3), faces.shape=(1056, 3))>, <trimesh.Trimesh(vertices.shape=(540, 3), faces.shape=(1188, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 206104, Final mesh size: 148460\n",
      "Total time = 13.632514238357544\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/decimation_meshlab_25271433.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(12141, 3), faces.shape=(23565, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(12141, 3), faces.shape=(23565, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97131.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97131_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_820678.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97131.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97131_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_820678.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 306\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/poisson_372851.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(12895, 3), faces.shape=(25794, 3))>, <trimesh.Trimesh(vertices.shape=(3970, 3), faces.shape=(7944, 3))>, <trimesh.Trimesh(vertices.shape=(1789, 3), faces.shape=(3578, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(12895, 3), faces.shape=(25794, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/decimation_meshlab_25622974.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3222, 3), faces.shape=(6448, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.001068115234375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113594116670800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.7338757514953613\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.863701581954956\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0023353099822998047\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.220008850097656e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006003379821777344\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03020930290222168\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 3, 4, 5, 6, 2]), array([0.7078035 , 0.426746  , 0.132451  , 0.104048  , 0.081436  ,\n",
      "       0.05471405, 0.0370774 ]))\n",
      "Sizes = [2840, 1752, 943, 145, 183, 274, 311]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_736746.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_736746_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_727876.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_736746.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_736746_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_727876.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.8176540461869132\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_213838.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_213838_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_225755.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_213838.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_213838_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_225755.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.3831749394782387\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3970, 3), faces.shape=(7944, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/decimation_meshlab_25622974.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(990, 3), faces.shape=(1984, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00028324127197265625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113594116670801_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.12828469276428223\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1649637222290039\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007646083831787109\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.435943603515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0018067359924316406\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.009243488311767578\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2, 3]), array([0.6737405, 0.5108745, 0.502816 , 0.0955373]))\n",
      "Sizes = [172, 1496, 293, 23]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_795192.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 401.57666396143367\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(747, 3), faces.shape=(1496, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/197_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457fa32957d14ad99a5bf46f3c0f04b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_112689.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 230.3599106580241\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(569, 3), faces.shape=(1139, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(1789, 3), faces.shape=(3578, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135941166708/decimation_meshlab_25622974.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135941166708_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(447, 3), faces.shape=(894, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00043320655822753906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113594116670802_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05041217803955078\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06607437133789062\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003991127014160156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.125999450683594e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008885860443115234\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004032611846923828\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3]), array([0.735837 , 0.517145 , 0.471898 , 0.0632079]))\n",
      "Sizes = [103, 259, 519, 13]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(261, 3), faces.shape=(519, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001761913299560547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113594116670802_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.026595115661621094\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03587841987609863\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00023889541625976562\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.838539123535156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005171298980712891\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0023903846740722656\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.503667]))\n",
      "Sizes = [519]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(261, 3), faces.shape=(519, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001704692840576172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113594116670802_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.026088476181030273\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03580141067504883\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00023484230041503906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.790855407714844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004811286926269531\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00246429443359375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.503667]))\n",
      "Sizes = [519]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 46.69330072402954\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41307.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41307_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_381271.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41307.off loaded has 25911 vn 51396 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41307_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_381271.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1238616\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1238616\n",
      "LOG: 2 Successfully removed 7392 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7392 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1149912\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_381271.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10507.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10507_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_900818.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10507.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10507_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_900818.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(939, 3), faces.shape=(2048, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(1988, 3))>, <trimesh.Trimesh(vertices.shape=(769, 3), faces.shape=(1991, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1279, 3))>, <trimesh.Trimesh(vertices.shape=(588, 3), faces.shape=(1503, 3))>, <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(725, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_818889.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_818889_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_822155.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_818889.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_818889_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_822155.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.591302431616265\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(7472, 3), faces.shape=(16934, 3))>, <trimesh.Trimesh(vertices.shape=(2822, 3), faces.shape=(6749, 3))>, <trimesh.Trimesh(vertices.shape=(2491, 3), faces.shape=(5844, 3))>, <trimesh.Trimesh(vertices.shape=(1671, 3), faces.shape=(3922, 3))>, <trimesh.Trimesh(vertices.shape=(1474, 3), faces.shape=(3482, 3))>, <trimesh.Trimesh(vertices.shape=(1378, 3), faces.shape=(3254, 3))>, <trimesh.Trimesh(vertices.shape=(1150, 3), faces.shape=(2700, 3))>, <trimesh.Trimesh(vertices.shape=(962, 3), faces.shape=(2236, 3))>, <trimesh.Trimesh(vertices.shape=(920, 3), faces.shape=(2123, 3))>, <trimesh.Trimesh(vertices.shape=(846, 3), faces.shape=(1975, 3))>, <trimesh.Trimesh(vertices.shape=(769, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1551, 3))>, <trimesh.Trimesh(vertices.shape=(653, 3), faces.shape=(1450, 3))>, <trimesh.Trimesh(vertices.shape=(640, 3), faces.shape=(1452, 3))>, <trimesh.Trimesh(vertices.shape=(621, 3), faces.shape=(1056, 3))>, <trimesh.Trimesh(vertices.shape=(540, 3), faces.shape=(1188, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71490.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71490_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_195572.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71490.off loaded has 16852 vn 32763 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_71490_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_195572.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 797604\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 797604\n",
      "LOG: 2 Successfully removed 5093 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 5093 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 736488\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_195572.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49259.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49259_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_835244.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49259.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_49259_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_835244.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(943, 3), faces.shape=(2073, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(1988, 3))>, <trimesh.Trimesh(vertices.shape=(563, 3), faces.shape=(1109, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_173810.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_173810_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_784584.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_173810.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_173810_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_784584.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.9753184220411906\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(7472, 3), faces.shape=(16934, 3))>, <trimesh.Trimesh(vertices.shape=(2822, 3), faces.shape=(6749, 3))>, <trimesh.Trimesh(vertices.shape=(2491, 3), faces.shape=(5844, 3))>, <trimesh.Trimesh(vertices.shape=(1671, 3), faces.shape=(3922, 3))>, <trimesh.Trimesh(vertices.shape=(1474, 3), faces.shape=(3482, 3))>, <trimesh.Trimesh(vertices.shape=(1378, 3), faces.shape=(3254, 3))>, <trimesh.Trimesh(vertices.shape=(1150, 3), faces.shape=(2700, 3))>, <trimesh.Trimesh(vertices.shape=(962, 3), faces.shape=(2236, 3))>, <trimesh.Trimesh(vertices.shape=(920, 3), faces.shape=(2123, 3))>, <trimesh.Trimesh(vertices.shape=(846, 3), faces.shape=(1975, 3))>, <trimesh.Trimesh(vertices.shape=(769, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1551, 3))>, <trimesh.Trimesh(vertices.shape=(653, 3), faces.shape=(1450, 3))>, <trimesh.Trimesh(vertices.shape=(640, 3), faces.shape=(1452, 3))>, <trimesh.Trimesh(vertices.shape=(621, 3), faces.shape=(1056, 3))>, <trimesh.Trimesh(vertices.shape=(540, 3), faces.shape=(1188, 3))>, <trimesh.Trimesh(vertices.shape=(939, 3), faces.shape=(2048, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(1988, 3))>, <trimesh.Trimesh(vertices.shape=(769, 3), faces.shape=(1991, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1279, 3))>, <trimesh.Trimesh(vertices.shape=(588, 3), faces.shape=(1503, 3))>, <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(725, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9856.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9856_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_870383.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9856.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9856_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_870383.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34814.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34814_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_120116.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34814.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34814_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_120116.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 296\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d2be92660c4f6f8b533840379a1ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 3028393.4472960485, after = 2942770.4685972435,\n",
      "ratio = 0.9717266001961354, difference = -85622.97869880497\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75248.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75248_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_965567.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75248.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75248_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_965567.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64300.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64300_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_306987.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64300.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64300_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_306987.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 240\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b4d393e88c4e27a0282559357b3726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2396183.638819608, after = 2083106.1568110306,\n",
      "ratio = 0.8693432853239899, difference = -313077.4820085773\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135941166708_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135941166708_nuclei.pbz2\n",
      "File size is 0.094738 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135941166708_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135941166708_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135941166708, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135941166708_glia.pbz2'), 'n_nuclei_faces': 67207, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135941166708_nuclei.pbz2')}\n",
      "Run time was 46.69330024719238 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(15547, 3), faces.shape=(35738, 3))>]\n",
      "    with sdf values = [0.56727475]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336098.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336098_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_391926.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336098.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336098_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_391926.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 64280 130508  20098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:34:31,134 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:34:31,149 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:34:31,151 - autopopulate - Populating: {'segment_id': 864691136115294545, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136115294545 ----\n",
      "{'segment_id': 864691136115294545, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44128.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44128_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_233168.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44128.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44128_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_233168.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1566, 3), faces.shape=(2933, 3))>, <trimesh.Trimesh(vertices.shape=(1299, 3), faces.shape=(2390, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 64583, Final mesh size: 59260\n",
      "Total time = 3.6064393520355225\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/neuron_864691136115294545.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/neuron_864691136115294545_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/decimation_meshlab_25722255.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(7551, 3), faces.shape=(14680, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(7551, 3), faces.shape=(14680, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76730.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76730_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_252256.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76730.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76730_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_252256.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 433\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/neuron_864691136115294545_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/neuron_864691136115294545_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/neuron_864691136115294545_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/poisson_659808.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(14384, 3), faces.shape=(28764, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(14384, 3), faces.shape=(28764, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/neuron_864691136115294545_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/neuron_864691136115294545_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136115294545/decimation_meshlab_25106149.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136115294545_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3596, 3), faces.shape=(7188, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008075237274169922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113611529454500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6929116249084473\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.8333287239074707\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.834223\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0025157928466796875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.649162292480469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005837678909301758\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03346657752990723\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.834223\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 4, 2, 3]), array([0.834223  , 0.1421645 , 0.083674  , 0.06355985, 0.0602533 ]))\n",
      "Sizes = [3193, 3012, 73, 872, 38]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423873.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423873_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_647860.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423873.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_423873_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_647860.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.1228968377140847\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 21.52415680885315\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98157.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98157_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_124598.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98157.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98157_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_124598.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3163.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3163_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_76222.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3163.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3163_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_76222.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(452, 3), faces.shape=(783, 3))>, <trimesh.Trimesh(vertices.shape=(260, 3), faces.shape=(314, 3))>, <trimesh.Trimesh(vertices.shape=(209, 3), faces.shape=(320, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_404721.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_404721_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_646405.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_404721.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_404721_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_646405.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.998988079898042\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(1566, 3), faces.shape=(2933, 3))>, <trimesh.Trimesh(vertices.shape=(1299, 3), faces.shape=(2390, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52114.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52114_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_899102.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52114.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52114_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_899102.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61285.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61285_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_366075.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61285.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_61285_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_366075.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 140\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cb8476c01d4c37aed4a5e0e51974fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2016702.226181787, after = 2033421.9118655715,\n",
      "ratio = 1.0082906070448685, difference = 16719.68568378454\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136115294545_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136115294545_nuclei.pbz2\n",
      "File size is 0.008812 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136115294545_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136115294545_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136115294545, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136115294545_glia.pbz2'), 'n_nuclei_faces': 6561, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136115294545_nuclei.pbz2')}\n",
      "Run time was 21.524152040481567 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(10986, 3), faces.shape=(21163, 3))>]\n",
      "    with sdf values = [0.834223]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_358186.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_358186_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_552984.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_358186.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_358186_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_552984.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 62680 136442  20563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:35:17,397 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:35:17,411 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:35:17,413 - autopopulate - Populating: {'segment_id': 864691135864711644, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135864711644 ----\n",
      "{'segment_id': 864691135864711644, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23577.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23577_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_531382.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23577.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_23577_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_531382.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 6 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 6\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11958, 3), faces.shape=(26490, 3))>, <trimesh.Trimesh(vertices.shape=(8223, 3), faces.shape=(19507, 3))>, <trimesh.Trimesh(vertices.shape=(785, 3), faces.shape=(1828, 3))>, <trimesh.Trimesh(vertices.shape=(626, 3), faces.shape=(1401, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 126345, Final mesh size: 77117\n",
      "Total time = 8.95281195640564\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/decimation_meshlab_2590718.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(6179, 3), faces.shape=(11533, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(6179, 3), faces.shape=(11533, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85045.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85045_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_968901.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85045.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85045_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_968901.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 156\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/poisson_376135.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(11950, 3), faces.shape=(23912, 3))>, <trimesh.Trimesh(vertices.shape=(2078, 3), faces.shape=(4152, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(11950, 3), faces.shape=(23912, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/decimation_meshlab_2550650.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135864711644_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2982, 3), faces.shape=(5976, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007719993591308594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113586471164400_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6145641803741455\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.7358250617980957\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.7790539999999999\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002155780792236328\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00456690788269043\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.028111934661865234\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.7790539999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 4, 3, 5, 1]), array([0.779054  , 0.349198  , 0.0926149 , 0.076578  , 0.0649838 ,\n",
      "       0.05928875]))\n",
      "Sizes = [3434, 409, 621, 1342, 44, 126]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_578208.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_578208_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_441324.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_578208.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_578208_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_441324.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.6445097968906888\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2078, 3), faces.shape=(4152, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/neuron_864691135864711644_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135864711644/decimation_meshlab_2550650.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135864711644_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(521, 3), faces.shape=(1038, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002243518829345703\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113586471164401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06042170524597168\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07923603057861328\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004677772521972656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.3392181396484375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010652542114257812\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004858255386352539\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 1, 5, 2, 0, 4]), array([0.735482 , 0.597799 , 0.571616 , 0.2764545, 0.200346 , 0.158313 ]))\n",
      "Sizes = [431, 330, 183, 38, 47, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(219, 3), faces.shape=(431, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00017833709716796875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113586471164401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.026250123977661133\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.034273624420166016\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00021004676818847656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.00543212890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004215240478515625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0020706653594970703\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.696758]))\n",
      "Sizes = [431]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(219, 3), faces.shape=(431, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001773834228515625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113586471164401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.026055574417114258\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0343320369720459\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00020694732666015625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.552436828613281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004062652587890625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0021181106567382812\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.696758]))\n",
      "Sizes = [431]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 29.71613383293152\n",
      "Before Filtering the number of somas found = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_38555.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_38555_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_994598.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_38555.off loaded has 16293 vn 30592 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_38555_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_994598.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 758136\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 758136\n",
      "LOG: 2 Successfully removed 4458 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 4458 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 704640\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_994598.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6030.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6030_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_119209.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6030.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6030_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_119209.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(489, 3), faces.shape=(1035, 3))>, <trimesh.Trimesh(vertices.shape=(322, 3), faces.shape=(723, 3))>, <trimesh.Trimesh(vertices.shape=(264, 3), faces.shape=(648, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_115290.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_115290_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_320885.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_115290.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_115290_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_320885.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.831770024836777\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(11959, 3), faces.shape=(26491, 3))>, <trimesh.Trimesh(vertices.shape=(8224, 3), faces.shape=(19508, 3))>, <trimesh.Trimesh(vertices.shape=(785, 3), faces.shape=(1828, 3))>, <trimesh.Trimesh(vertices.shape=(626, 3), faces.shape=(1401, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95132.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95132_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_152132.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95132.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95132_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_152132.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87278.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87278_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_147960.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87278.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_87278_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_147960.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 397\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033c3f81c05a4f20bf7f8c6dd1948204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1472597.9880031226, after = 2658186.5517035574,\n",
      "ratio = 1.8050999480911425, difference = 1185588.5637004348\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135864711644_glia.pbz2\n",
      "File size is 4.6e-05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135864711644_nuclei.pbz2\n",
      "File size is 0.079099 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135864711644_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135864711644_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135864711644, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135864711644_glia.pbz2'), 'n_nuclei_faces': 51634, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135864711644_nuclei.pbz2')}\n",
      "Run time was 29.716132640838623 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(9702, 3), faces.shape=(18393, 3))>]\n",
      "    with sdf values = [0.779054]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434633.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434633_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_592925.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434633.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434633_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_592925.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 64361 138564  21502]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:36:13,355 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:36:13,369 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:36:13,371 - autopopulate - Populating: {'segment_id': 864691135144934608, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135144934608 ----\n",
      "{'segment_id': 864691135144934608, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34092.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34092_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_951088.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34092.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34092_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_951088.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(4386, 3), faces.shape=(8208, 3))>, <trimesh.Trimesh(vertices.shape=(1062, 3), faces.shape=(1929, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 21088, Final mesh size: 10951\n",
      "Total time = 1.9287774562835693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135144934608/neuron_864691135144934608.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135144934608/neuron_864691135144934608_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135144934608/decimation_meshlab_25255900.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:36:16,177 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:36:16,198 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:36:16,200 - autopopulate - Populating: {'segment_id': 864691135968908901, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 2.504643440246582\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135144934608_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135144934608_nuclei.pbz2\n",
      "File size is 0.012159 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135144934608_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135144934608_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135144934608, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135144934608_glia.pbz2'), 'n_nuclei_faces': 10137, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135144934608_nuclei.pbz2')}\n",
      "Run time was 2.504640579223633 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135968908901 ----\n",
      "{'segment_id': 864691135968908901, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97841.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97841_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_951442.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97841.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97841_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_951442.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 20 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 20\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(4428, 3), faces.shape=(9901, 3))>, <trimesh.Trimesh(vertices.shape=(3398, 3), faces.shape=(8275, 3))>, <trimesh.Trimesh(vertices.shape=(2941, 3), faces.shape=(6738, 3))>, <trimesh.Trimesh(vertices.shape=(2688, 3), faces.shape=(6355, 3))>, <trimesh.Trimesh(vertices.shape=(1723, 3), faces.shape=(4088, 3))>, <trimesh.Trimesh(vertices.shape=(1483, 3), faces.shape=(3519, 3))>, <trimesh.Trimesh(vertices.shape=(1399, 3), faces.shape=(3236, 3))>, <trimesh.Trimesh(vertices.shape=(943, 3), faces.shape=(2114, 3))>, <trimesh.Trimesh(vertices.shape=(739, 3), faces.shape=(1640, 3))>, <trimesh.Trimesh(vertices.shape=(682, 3), faces.shape=(1572, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1544, 3))>, <trimesh.Trimesh(vertices.shape=(598, 3), faces.shape=(1346, 3))>, <trimesh.Trimesh(vertices.shape=(551, 3), faces.shape=(1228, 3))>, <trimesh.Trimesh(vertices.shape=(544, 3), faces.shape=(1228, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 143774, Final mesh size: 90989\n",
      "Total time = 10.195495843887329\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/decimation_meshlab_2559148.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(6089, 3), faces.shape=(11905, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(6089, 3), faces.shape=(11905, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47800.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47800_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_538983.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47800.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47800_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_538983.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 183\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/poisson_471315.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(12110, 3), faces.shape=(24224, 3))>, <trimesh.Trimesh(vertices.shape=(1649, 3), faces.shape=(3294, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(12110, 3), faces.shape=(24224, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/decimation_meshlab_25169159.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135968908901_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3024, 3), faces.shape=(6052, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008499622344970703\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113596890890100_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6118876934051514\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.732708215713501\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002409696578979492\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.412101745605469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005637645721435547\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0279998779296875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 5, 6, 3, 2, 4]), array([0.718619 , 0.4687825, 0.156579 , 0.1221385, 0.1134895, 0.103008 ,\n",
      "       0.055579 ]))\n",
      "Sizes = [2187, 1040, 418, 74, 482, 1769, 82]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_271584.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_271584_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_561894.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_271584.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_271584_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_561894.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.9471011509900223\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_646776.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_646776_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_715457.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_646776.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_646776_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_715457.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.9791270142977835\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1649, 3), faces.shape=(3294, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/neuron_864691135968908901_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135968908901/decimation_meshlab_25169159.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135968908901_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(413, 3), faces.shape=(822, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022983551025390625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113596890890101_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05834221839904785\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07390189170837402\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004956722259521484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.054473876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008299350738525391\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003938436508178711\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.534214, 0.390191, 0.113854]))\n",
      "Sizes = [443, 367, 12]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(225, 3), faces.shape=(443, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00019288063049316406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113596890890101_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.02936244010925293\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03843069076538086\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002315044403076172\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.172325134277344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00045490264892578125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002237081527709961\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.420246]))\n",
      "Sizes = [443]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(225, 3), faces.shape=(443, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00018596649169921875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113596890890101_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.03355002403259277\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04168367385864258\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00023698806762695312\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.00543212890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00045013427734375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002228260040283203\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.420246]))\n",
      "Sizes = [443]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 36.93438744544983\n",
      "Before Filtering the number of somas found = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75905.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75905_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_313922.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75905.off loaded has 22149 vn 42975 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75905_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_313922.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1047276\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1047276\n",
      "LOG: 2 Successfully removed 5937 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 5937 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 976032\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_313922.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46383.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46383_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_886127.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46383.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_46383_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_886127.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(837, 3), faces.shape=(2258, 3))>, <trimesh.Trimesh(vertices.shape=(469, 3), faces.shape=(713, 3))>, <trimesh.Trimesh(vertices.shape=(415, 3), faces.shape=(727, 3))>, <trimesh.Trimesh(vertices.shape=(276, 3), faces.shape=(555, 3))>, <trimesh.Trimesh(vertices.shape=(237, 3), faces.shape=(633, 3))>, <trimesh.Trimesh(vertices.shape=(186, 3), faces.shape=(458, 3))>, <trimesh.Trimesh(vertices.shape=(147, 3), faces.shape=(358, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_699717.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_699717_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_696405.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_699717.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_699717_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_696405.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.32128606042798\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(4429, 3), faces.shape=(9902, 3))>, <trimesh.Trimesh(vertices.shape=(3398, 3), faces.shape=(8275, 3))>, <trimesh.Trimesh(vertices.shape=(2941, 3), faces.shape=(6738, 3))>, <trimesh.Trimesh(vertices.shape=(2688, 3), faces.shape=(6355, 3))>, <trimesh.Trimesh(vertices.shape=(1723, 3), faces.shape=(4088, 3))>, <trimesh.Trimesh(vertices.shape=(1483, 3), faces.shape=(3519, 3))>, <trimesh.Trimesh(vertices.shape=(1399, 3), faces.shape=(3236, 3))>, <trimesh.Trimesh(vertices.shape=(943, 3), faces.shape=(2114, 3))>, <trimesh.Trimesh(vertices.shape=(739, 3), faces.shape=(1640, 3))>, <trimesh.Trimesh(vertices.shape=(682, 3), faces.shape=(1572, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1544, 3))>, <trimesh.Trimesh(vertices.shape=(598, 3), faces.shape=(1346, 3))>, <trimesh.Trimesh(vertices.shape=(551, 3), faces.shape=(1228, 3))>, <trimesh.Trimesh(vertices.shape=(544, 3), faces.shape=(1228, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73495.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73495_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_586929.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73495.off loaded has 22293 vn 43367 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73495_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_586929.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1055436\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1055436\n",
      "LOG: 2 Successfully removed 5937 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 5937 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 984192\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_586929.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77306.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77306_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_164720.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77306.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77306_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_164720.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(837, 3), faces.shape=(2258, 3))>, <trimesh.Trimesh(vertices.shape=(490, 3), faces.shape=(741, 3))>, <trimesh.Trimesh(vertices.shape=(416, 3), faces.shape=(729, 3))>, <trimesh.Trimesh(vertices.shape=(275, 3), faces.shape=(550, 3))>, <trimesh.Trimesh(vertices.shape=(237, 3), faces.shape=(633, 3))>, <trimesh.Trimesh(vertices.shape=(186, 3), faces.shape=(458, 3))>, <trimesh.Trimesh(vertices.shape=(147, 3), faces.shape=(358, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_999643.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_999643_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_230370.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_999643.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_999643_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_230370.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.419147527671218\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(4429, 3), faces.shape=(9902, 3))>, <trimesh.Trimesh(vertices.shape=(3398, 3), faces.shape=(8275, 3))>, <trimesh.Trimesh(vertices.shape=(2941, 3), faces.shape=(6738, 3))>, <trimesh.Trimesh(vertices.shape=(2688, 3), faces.shape=(6355, 3))>, <trimesh.Trimesh(vertices.shape=(1723, 3), faces.shape=(4088, 3))>, <trimesh.Trimesh(vertices.shape=(1483, 3), faces.shape=(3519, 3))>, <trimesh.Trimesh(vertices.shape=(1399, 3), faces.shape=(3236, 3))>, <trimesh.Trimesh(vertices.shape=(943, 3), faces.shape=(2114, 3))>, <trimesh.Trimesh(vertices.shape=(739, 3), faces.shape=(1640, 3))>, <trimesh.Trimesh(vertices.shape=(682, 3), faces.shape=(1572, 3))>, <trimesh.Trimesh(vertices.shape=(678, 3), faces.shape=(1544, 3))>, <trimesh.Trimesh(vertices.shape=(598, 3), faces.shape=(1346, 3))>, <trimesh.Trimesh(vertices.shape=(551, 3), faces.shape=(1228, 3))>, <trimesh.Trimesh(vertices.shape=(544, 3), faces.shape=(1228, 3))>, <trimesh.Trimesh(vertices.shape=(837, 3), faces.shape=(2258, 3))>, <trimesh.Trimesh(vertices.shape=(469, 3), faces.shape=(713, 3))>, <trimesh.Trimesh(vertices.shape=(415, 3), faces.shape=(727, 3))>, <trimesh.Trimesh(vertices.shape=(276, 3), faces.shape=(555, 3))>, <trimesh.Trimesh(vertices.shape=(237, 3), faces.shape=(633, 3))>, <trimesh.Trimesh(vertices.shape=(186, 3), faces.shape=(458, 3))>, <trimesh.Trimesh(vertices.shape=(147, 3), faces.shape=(358, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "Mesh was manifold\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63910.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63910_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_342993.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63910.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63910_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_342993.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8197.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8197_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_396768.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8197.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8197_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_396768.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 274\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852f5c7e767745979b1a6678f6ed682c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2126384.037372238, after = 2111657.2541099377,\n",
      "ratio = 0.9930742598686456, difference = -14726.783262300305\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76200.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76200_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_428827.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76200.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76200_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_428827.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30834.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30834_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_400822.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30834.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_30834_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_400822.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 298\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9e576330ca4f279ae2f881c948b27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No split meshes were above the width threshold (0.32) and size threshold (2000) so continuing\n",
      "So just going with old somas\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135968908901_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135968908901_nuclei.pbz2\n",
      "File size is 0.08337 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135968908901_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135968908901_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135968908901, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135968908901_glia.pbz2'), 'n_nuclei_faces': 58526, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135968908901_nuclei.pbz2')}\n",
      "Run time was 36.93438673019409 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(12449, 3), faces.shape=(30323, 3))>]\n",
      "    with sdf values = [0.59370075]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_124735.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_124735_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_325595.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_124735.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_124735_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_325595.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 64692 152810  20097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:37:38,112 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:37:38,135 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:37:38,137 - autopopulate - Populating: {'segment_id': 864691135463509061, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135463509061 ----\n",
      "{'segment_id': 864691135463509061, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64888.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64888_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_840709.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64888.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64888_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_840709.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(15144, 3), faces.shape=(31555, 3))>, <trimesh.Trimesh(vertices.shape=(467, 3), faces.shape=(809, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 94769, Final mesh size: 62405\n",
      "Total time = 5.61373496055603\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/decimation_meshlab_25399082.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(5876, 3), faces.shape=(10164, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(5876, 3), faces.shape=(10164, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86087.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86087_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_553910.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86087.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_86087_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_553910.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 221\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/poisson_165433.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(13035, 3), faces.shape=(26070, 3))>, <trimesh.Trimesh(vertices.shape=(1916, 3), faces.shape=(3828, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(13035, 3), faces.shape=(26070, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/decimation_meshlab_25960503.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135463509061_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3258, 3), faces.shape=(6516, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008027553558349609\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113546350906100_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6667885780334473\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.7971124649047852\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.538992\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0024156570434570312\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.054473876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0044748783111572266\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03036975860595703\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.538992\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 3, 1, 2]), array([0.538992 , 0.158625 , 0.139123 , 0.0325065]))\n",
      "Sizes = [5520, 718, 245, 33]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_375102.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_375102_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_966449.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_375102.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_375102_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_966449.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.664326125992514\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1916, 3), faces.shape=(3828, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/neuron_864691135463509061_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135463509061/decimation_meshlab_25960503.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135463509061_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(480, 3), faces.shape=(956, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005958080291748047\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113546350906101_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05743241310119629\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08349108695983887\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004932880401611328\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.459785461425781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010759830474853516\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0047647953033447266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 6, 2, 3, 1, 4, 5]), array([0.649048 , 0.637123 , 0.473202 , 0.3987315, 0.2334435, 0.2282   ,\n",
      "       0.213294 ]))\n",
      "Sizes = [571, 51, 126, 46, 106, 17, 39]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_610388.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 87.1696559336953\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(290, 3), faces.shape=(571, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/613_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801cac533b11468eb371e6186b38ce8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_955419.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 87.1696559336953\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(290, 3), faces.shape=(571, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 24.44145703315735\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60553.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60553_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_74901.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60553.off loaded has 15052 vn 27929 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60553_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_74901.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 696396\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 696396\n",
      "LOG: 2 Successfully removed 2289 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 2289 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 668928\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_74901.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41669.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41669_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_582057.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41669.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41669_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_582057.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(873, 3), faces.shape=(1050, 3))>, <trimesh.Trimesh(vertices.shape=(737, 3), faces.shape=(1427, 3))>, <trimesh.Trimesh(vertices.shape=(636, 3), faces.shape=(1152, 3))>, <trimesh.Trimesh(vertices.shape=(363, 3), faces.shape=(420, 3))>, <trimesh.Trimesh(vertices.shape=(271, 3), faces.shape=(624, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_239857.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_239857_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_717074.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_239857.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_239857_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_717074.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 6.9971887764148635\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(15144, 3), faces.shape=(31555, 3))>, <trimesh.Trimesh(vertices.shape=(467, 3), faces.shape=(809, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33836.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33836_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_852990.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33836.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33836_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_852990.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9611.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9611_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_278843.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9611.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_9611_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_278843.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 418\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b638b37933b4d31aeba3a4892682b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 3330958.2935999, after = 2885933.5717488704,\n",
      "ratio = 0.8663973899925137, difference = -445024.72185102943\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135463509061_glia.pbz2\n",
      "File size is 4.6e-05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135463509061_nuclei.pbz2\n",
      "File size is 0.047642 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135463509061_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135463509061_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135463509061, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135463509061_glia.pbz2'), 'n_nuclei_faces': 37037, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135463509061_nuclei.pbz2')}\n",
      "Run time was 24.44145631790161 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(10117, 3), faces.shape=(18769, 3))>]\n",
      "    with sdf values = [0.538992]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787714.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787714_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_8879.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787714.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_787714_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_8879.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 65055 148562  19845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:38:27,683 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:38:27,705 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:38:27,707 - autopopulate - Populating: {'segment_id': 864691135948553351, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135948553351 ----\n",
      "{'segment_id': 864691135948553351, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10312.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10312_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_596629.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10312.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10312_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_596629.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(595, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(474, 3), faces.shape=(735, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 24953, Final mesh size: 23231\n",
      "Total time = 1.8296136856079102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/neuron_864691135948553351.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/neuron_864691135948553351_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/decimation_meshlab_25582525.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(2742, 3), faces.shape=(5762, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(2742, 3), faces.shape=(5762, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10279.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10279_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_29900.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10279.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10279_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_29900.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 50\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/neuron_864691135948553351_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/neuron_864691135948553351_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/neuron_864691135948553351_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/poisson_836402.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(12873, 3), faces.shape=(25866, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(12873, 3), faces.shape=(25866, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/neuron_864691135948553351_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/neuron_864691135948553351_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135948553351/decimation_meshlab_25324657.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135948553351_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3173, 3), faces.shape=(6466, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008182525634765625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113594855335100_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.5606174468994141\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6894826889038086\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0022783279418945312\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00015926361083984375\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006182193756103516\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02995467185974121\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 3, 2, 4, 1, 6, 5]), array([0.601187 , 0.529437 , 0.3617085, 0.327027 , 0.312523 , 0.0862136,\n",
      "       0.0703855]))\n",
      "Sizes = [2249, 225, 1404, 305, 2229, 23, 31]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 2]\n",
      "xz = 8.376814220500968 ratio was beyong 6 multiplier\n",
      "yz = 20.47078983900497 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_286249.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_286249_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_755530.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_286249.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_286249_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_755530.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 6.447835643099616\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1140, 3), faces.shape=(2249, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/418_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce276ae13c7947a39fd31dc54fea6efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 9.223629504344766 ratio was beyong 6 multiplier\n",
      "yz = 15.82842832161528 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_777480.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_777480_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_465561.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_777480.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_777480_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_465561.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.168411137787668\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(921, 3), faces.shape=(1812, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_507113.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_507113_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_306078.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_507113.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_507113_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_306078.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.465640981071155\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(703, 3), faces.shape=(1404, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/907_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7476c2340fd544d498c5cdc9718cf514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:38:55,817 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:38:55,839 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:38:55,841 - autopopulate - Populating: {'segment_id': 864691135898530280, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 27.75845170021057\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135948553351_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135948553351_nuclei.pbz2\n",
      "File size is 0.003065 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135948553351_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135948553351_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135948553351, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135948553351_glia.pbz2'), 'n_nuclei_faces': 1722, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135948553351_nuclei.pbz2')}\n",
      "Run time was 27.758450746536255 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135898530280 ----\n",
      "{'segment_id': 864691135898530280, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4641.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4641_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_144033.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4641.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4641_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_144033.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5721, 3), faces.shape=(10712, 3))>, <trimesh.Trimesh(vertices.shape=(2686, 3), faces.shape=(5044, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 47721, Final mesh size: 31965\n",
      "Total time = 2.8847246170043945\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/neuron_864691135898530280.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/neuron_864691135898530280_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/decimation_meshlab_25695139.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(3196, 3), faces.shape=(5669, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(3196, 3), faces.shape=(5669, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48475.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48475_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_698066.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48475.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48475_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_698066.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 43\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/neuron_864691135898530280_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/neuron_864691135898530280_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/neuron_864691135898530280_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/poisson_351184.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(7565, 3), faces.shape=(15126, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(7565, 3), faces.shape=(15126, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/neuron_864691135898530280_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/neuron_864691135898530280_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135898530280/decimation_meshlab_25410689.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135898530280_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1892, 3), faces.shape=(3780, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0020554065704345703\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113589853028000_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.3800802230834961\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.46221208572387695\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0013263225555419922\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.506111145019531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0034799575805664062\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.018110036849975586\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.779959 , 0.0461577]))\n",
      "Sizes = [2345, 1435]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_143007.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_143007_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_152286.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_143007.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_143007_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_152286.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.1227498293716316\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 17.90742063522339\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88574.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88574_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_665714.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88574.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_88574_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_665714.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73537.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73537_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_478778.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:39:16,521 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:39:16,534 - connection - Transaction started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73537.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73537_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_478778.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1209, 3), faces.shape=(1757, 3))>]\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135898530280_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135898530280_nuclei.pbz2\n",
      "File size is 0.020083 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135898530280_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135898530280_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135898530280, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135898530280_glia.pbz2'), 'n_nuclei_faces': 15756, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135898530280_nuclei.pbz2')}\n",
      "Run time was 17.907416343688965 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:39:16,537 - autopopulate - Populating: {'segment_id': 864691135959436423, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135959436423 ----\n",
      "{'segment_id': 864691135959436423, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77853.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77853_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_632537.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77853.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77853_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_632537.mls is being deleted....\n",
      "There were 4 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 4\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5223, 3), faces.shape=(9381, 3))>, <trimesh.Trimesh(vertices.shape=(3167, 3), faces.shape=(5622, 3))>, <trimesh.Trimesh(vertices.shape=(451, 3), faces.shape=(796, 3))>, <trimesh.Trimesh(vertices.shape=(429, 3), faces.shape=(1021, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 54680, Final mesh size: 37860\n",
      "Total time = 3.221177577972412\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/neuron_864691135959436423.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/neuron_864691135959436423_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/decimation_meshlab_2550326.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(5408, 3), faces.shape=(8831, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(5408, 3), faces.shape=(8831, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94005.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94005_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_347291.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94005.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_94005_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_347291.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 42\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/neuron_864691135959436423_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/neuron_864691135959436423_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/neuron_864691135959436423_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/poisson_93529.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(18790, 3), faces.shape=(37584, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(18790, 3), faces.shape=(37584, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/neuron_864691135959436423_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/neuron_864691135959436423_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135959436423/decimation_meshlab_25575776.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135959436423_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(4695, 3), faces.shape=(9394, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008120536804199219\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113595943642300_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.2164034843444824\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.4071452617645264\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1, soma_sdf_value = 0.5878095\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0034780502319335938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00019693374633789062\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.008481502532958984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.04504847526550293\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.5878095\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3]), array([0.5878095, 0.3018715, 0.288497 , 0.129806 ]))\n",
      "Sizes = [5606, 1300, 2053, 435]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_940273.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_940273_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_989016.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_940273.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_940273_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_989016.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.209198007119104\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 20.49184513092041\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48371.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48371_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_417666.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48371.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48371_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_417666.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97023.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97023_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_896252.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97023.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97023_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_896252.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1445, 3), faces.shape=(2806, 3))>, <trimesh.Trimesh(vertices.shape=(972, 3), faces.shape=(1645, 3))>, <trimesh.Trimesh(vertices.shape=(477, 3), faces.shape=(784, 3))>, <trimesh.Trimesh(vertices.shape=(457, 3), faces.shape=(604, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "xz = 6.61052518945903 ratio was beyong 6 multiplier\n",
      "yz = 6.616560616543953 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434284.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434284_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_488823.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434284.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_434284_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_488823.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.5632316836662814\n",
      "Trying backtrack segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108483aac01a41af9baa5abfccd04209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "INFO - 2021-01-13 07:39:50,305 - connection - Transaction committed and closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 6.61052518945903 ratio was beyong 6 multiplier\n",
      "yz = 6.616560616543953 ratio was beyong 6 multiplier\n",
      "--->This soma mesh was not added because it did not pass the sphere validation EVEN AFTER SEGMENTATION:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(6223, 3), faces.shape=(11978, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135959436423_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135959436423_nuclei.pbz2\n",
      "File size is 0.025778 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135959436423_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135959436423_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135959436423, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135959436423_glia.pbz2'), 'n_nuclei_faces': 16820, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135959436423_nuclei.pbz2')}\n",
      "Run time was 20.491841077804565 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:39:50,325 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:39:50,327 - autopopulate - Populating: {'segment_id': 864691135896080616, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135896080616 ----\n",
      "{'segment_id': 864691135896080616, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85663.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85663_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_66.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85663.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85663_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_66.mls is being deleted....\n",
      "There were 1 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 1\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(9027, 3), faces.shape=(16221, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 61438, Final mesh size: 45217\n",
      "Total time = 3.4915149211883545\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/decimation_meshlab_25798375.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(5196, 3), faces.shape=(9019, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(5196, 3), faces.shape=(9019, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60210.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60210_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_698625.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60210.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_60210_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_698625.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 82\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/poisson_468088.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(13637, 3), faces.shape=(27274, 3))>, <trimesh.Trimesh(vertices.shape=(3010, 3), faces.shape=(6020, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(13637, 3), faces.shape=(27274, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/decimation_meshlab_25476902.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135896080616_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3409, 3), faces.shape=(6818, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008206367492675781\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113589608061600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.7791666984558105\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.9130933284759521\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0025653839111328125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.220008850097656e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006414651870727539\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03112649917602539\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0, 3]), array([0.720544 , 0.33688  , 0.1849885, 0.184004 ]))\n",
      "Sizes = [1458, 1665, 1870, 1825]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_870881.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_870881_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_792831.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_870881.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_870881_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_792831.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.5887080896670716\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_838747.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_838747_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_793369.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_838747.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_838747_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_793369.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.6257558631559443\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3010, 3), faces.shape=(6020, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/neuron_864691135896080616_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135896080616/decimation_meshlab_25476902.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135896080616_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(752, 3), faces.shape=(1504, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003540515899658203\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113589608061601_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09279870986938477\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11879086494445801\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006265640258789062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00013303756713867188\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015592575073242188\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006807804107666016\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 5, 3, 4, 6]), array([0.666463 , 0.571803 , 0.555528 , 0.273135 , 0.248469 , 0.1997685,\n",
      "       0.0622948]))\n",
      "Sizes = [627, 596, 208, 31, 15, 14, 13]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "xz = 6.648527185896274 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_925827.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 54.41973978391205\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(317, 3), faces.shape=(627, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/133_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df82fc2995d4d3aa71c5a5b1e1a53ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_285997.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 182.60828403586095\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(299, 3), faces.shape=(596, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/176_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06abd10affe94860a20919cd0d3d8772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_33298.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 182.60828403586095\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(299, 3), faces.shape=(596, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 26.982807159423828\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42997.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42997_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_902460.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42997.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_42997_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_902460.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_19570.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_19570_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_859157.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_19570.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_19570_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_859157.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(669, 3))>, <trimesh.Trimesh(vertices.shape=(351, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(239, 3), faces.shape=(371, 3))>, <trimesh.Trimesh(vertices.shape=(212, 3), faces.shape=(420, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95040.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95040_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_325910.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95040.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95040_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_325910.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63794.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63794_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_333212.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:40:21,797 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:40:21,817 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:40:21,819 - autopopulate - Populating: {'segment_id': 864691135905885097, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63794.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_63794_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_333212.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(667, 3), faces.shape=(1098, 3))>, <trimesh.Trimesh(vertices.shape=(328, 3), faces.shape=(399, 3))>]\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135896080616_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135896080616_nuclei.pbz2\n",
      "File size is 0.024314 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135896080616_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135896080616_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135896080616, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135896080616_glia.pbz2'), 'n_nuclei_faces': 16221, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135896080616_nuclei.pbz2')}\n",
      "Run time was 26.98280644416809 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135905885097 ----\n",
      "{'segment_id': 864691135905885097, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95131.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95131_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_888903.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95131.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_95131_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_888903.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(976, 3), faces.shape=(1808, 3))>, <trimesh.Trimesh(vertices.shape=(819, 3), faces.shape=(1507, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 42565, Final mesh size: 39250\n",
      "Total time = 2.4988152980804443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/decimation_meshlab_25370467.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(4180, 3), faces.shape=(9799, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(4180, 3), faces.shape=(9799, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_80217.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_80217_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_478147.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_80217.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_80217_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_478147.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 80\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/poisson_523520.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(24314, 3), faces.shape=(49000, 3))>, <trimesh.Trimesh(vertices.shape=(3135, 3), faces.shape=(6274, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(24314, 3), faces.shape=(49000, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/decimation_meshlab_25231436.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135905885097_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(5939, 3), faces.shape=(12250, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004074573516845703\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113590588509700_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.31406569480896\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.5263187885284424\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1, soma_sdf_value = 0.254825\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.004611492156982422\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.38690185546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.010657072067260742\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.06017565727233887\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.254825\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 8,  9,  2,  0,  6,  1,  7,  5,  3,  4, 12, 10, 11]), array([0.802759 , 0.570453 , 0.513106 , 0.4692165, 0.327963 , 0.254825 ,\n",
      "       0.2069325, 0.183979 , 0.1572745, 0.1393985, 0.0412985, 0.0366801,\n",
      "       0.0326743]))\n",
      "Sizes = [369, 265, 217, 2208, 520, 5685, 1186, 1072, 206, 456, 18, 35, 13]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_758981.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.743504812021806\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1095, 3), faces.shape=(2208, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/579_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489e34b66f3044a79a9fc0f1ed05e321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_809456.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_809456_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_36814.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_809456.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_809456_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_36814.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.835041504610962\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3135, 3), faces.shape=(6274, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/neuron_864691135905885097_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135905885097/decimation_meshlab_25231436.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135905885097_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(782, 3), faces.shape=(1568, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020694732666015625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113590588509701_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.15162277221679688\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.17811179161071777\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.000637054443359375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.649162292480469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016317367553710938\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007705211639404297\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.6930895, 0.0402579]))\n",
      "Sizes = [1544, 24]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_580618.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1.841452526054964\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 21.71691131591797\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55186.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55186_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_849463.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55186.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_55186_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_849463.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4717.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4717_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_102396.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4717.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4717_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_102396.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 18\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48635.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48635_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_614822.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48635.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_48635_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_614822.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_70160.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_70160_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_301985.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:40:46,499 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:40:46,505 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:40:46,507 - autopopulate - Populating: {'segment_id': 864691135823398252, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_70160.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_70160_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_301985.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 224\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135905885097_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135905885097_nuclei.pbz2\n",
      "File size is 0.004685 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135905885097_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135905885097_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135905885097, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135905885097_glia.pbz2'), 'n_nuclei_faces': 3315, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135905885097_nuclei.pbz2')}\n",
      "Run time was 21.716909885406494 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135823398252 ----\n",
      "{'segment_id': 864691135823398252, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31849.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31849_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_228220.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31849.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31849_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_228220.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "There were 0 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 0\n",
      "\n",
      "\n",
      "Original Mesh size: 22245, Final mesh size: 22245\n",
      "Total time = 1.6220550537109375\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/decimation_meshlab_25491125.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(2426, 3), faces.shape=(5539, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(2426, 3), faces.shape=(5539, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98070.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98070_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_879931.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98070.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_98070_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_879931.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 38\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/poisson_471380.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(9740, 3), faces.shape=(19652, 3))>, <trimesh.Trimesh(vertices.shape=(4913, 3), faces.shape=(9890, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(9740, 3), faces.shape=(19652, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/decimation_meshlab_25488282.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135823398252_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2370, 3), faces.shape=(4912, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003097057342529297\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113582339825200_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.4936220645904541\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.5706019401550293\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1, soma_sdf_value = 0.3341765\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.001999378204345703\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.363059997558594e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0037920475006103516\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.024363279342651367\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.3341765\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 3, 1]), array([0.6798465, 0.61153  , 0.596472 , 0.3341765]))\n",
      "Sizes = [358, 472, 288, 3794]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "yz = 11.110183804248287 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_270859.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_270859_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_372109.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_270859.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_270859_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_372109.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.094893514301981\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1837, 3), faces.shape=(3794, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/718_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d5e468fed14d80b4629b770015e11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yz = 11.092060959064098 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_527549.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_527549_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_940053.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_527549.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_527549_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_940053.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.104750405330329\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1784, 3), faces.shape=(3679, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(4913, 3), faces.shape=(9890, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/neuron_864691135823398252_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135823398252/decimation_meshlab_25488282.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135823398252_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1204, 3), faces.shape=(2472, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003743171691894531\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113582339825201_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.22207856178283691\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.26208066940307617\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0013270378112792969\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.984306335449219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0029799938201904297\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.012012958526611328\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.659444, 0.314313, 0.061818]))\n",
      "Sizes = [368, 2095, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1021, 3), faces.shape=(2095, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020647048950195312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113582339825201_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.19121265411376953\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.2243039608001709\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007312297821044922\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.719329833984375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001870870590209961\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.009610891342163086\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.446489]))\n",
      "Sizes = [2095]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "yz = 6.044375066636931 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_282261.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.588401841209391\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1021, 3), faces.shape=(2095, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/509_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dfc1a6e105499db2d3348a0d8a6d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:41:10,615 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:41:10,636 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:41:10,638 - autopopulate - Populating: {'segment_id': 864691135574216898, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yz = 6.044375066636931 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_971274.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.588401841209391\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1021, 3), faces.shape=(2095, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 23.775301456451416\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135823398252_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135823398252_nuclei.pbz2\n",
      "File size is 4.6e-05 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135823398252_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135823398252_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135823398252, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135823398252_glia.pbz2'), 'n_nuclei_faces': 0, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135823398252_nuclei.pbz2')}\n",
      "Run time was 23.7753005027771 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135574216898 ----\n",
      "{'segment_id': 864691135574216898, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54048.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54048_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_847277.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54048.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54048_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_847277.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "There were 0 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 0\n",
      "\n",
      "\n",
      "Original Mesh size: 26164, Final mesh size: 26164\n",
      "Total time = 1.8931388854980469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/neuron_864691135574216898.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/neuron_864691135574216898_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/decimation_meshlab_25518917.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(2838, 3), faces.shape=(6500, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(2838, 3), faces.shape=(6500, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15123.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15123_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_442332.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15123.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_15123_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_442332.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 37\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/neuron_864691135574216898_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/neuron_864691135574216898_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/neuron_864691135574216898_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/poisson_466899.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(13164, 3), faces.shape=(26592, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(13164, 3), faces.shape=(26592, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/neuron_864691135574216898_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/neuron_864691135574216898_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135574216898/decimation_meshlab_25835353.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135574216898_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3192, 3), faces.shape=(6648, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0010738372802734375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113557421689800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.588780403137207\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.719994306564331\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.297472\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002557992935180664\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005391836166381836\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.030584096908569336\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.297472\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([11, 10,  8,  3,  5,  0,  2,  4,  7,  1,  9,  6]), array([0.6018305, 0.592145 , 0.552546 , 0.518862 , 0.332123 , 0.297472 ,\n",
      "       0.196015 , 0.167978 , 0.1083655, 0.0879105, 0.0558757, 0.0337078]))\n",
      "Sizes = [332, 65, 122, 167, 1685, 3101, 291, 772, 22, 31, 11, 49]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [5]\n",
      "xz = 8.185082396298574 ratio was beyong 6 multiplier\n",
      "yz = 7.305505847258743 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_138696.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_138696_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_316790.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_138696.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_138696_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_316790.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 15.678941975910979\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1685, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/524_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0826bc23de64ee59ccae76f5e305af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 8.185082396298574 ratio was beyong 6 multiplier\n",
      "yz = 7.305505847258743 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336903.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336903_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_679844.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:41:33,253 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:41:33,267 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:41:33,268 - autopopulate - Populating: {'segment_id': 864691135209990080, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336903.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_336903_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_679844.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 15.678941975910979\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1685, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 22.246479988098145\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135574216898_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135574216898_nuclei.pbz2\n",
      "File size is 4.6e-05 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135574216898_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135574216898_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135574216898, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135574216898_glia.pbz2'), 'n_nuclei_faces': 0, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135574216898_nuclei.pbz2')}\n",
      "Run time was 22.24647879600525 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135209990080 ----\n",
      "{'segment_id': 864691135209990080, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_36609.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_36609_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_213437.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_36609.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_36609_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_213437.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 8 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 8\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(13990, 3), faces.shape=(34754, 3))>, <trimesh.Trimesh(vertices.shape=(755, 3), faces.shape=(1525, 3))>, <trimesh.Trimesh(vertices.shape=(667, 3), faces.shape=(1562, 3))>, <trimesh.Trimesh(vertices.shape=(528, 3), faces.shape=(1238, 3))>, <trimesh.Trimesh(vertices.shape=(480, 3), faces.shape=(1126, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 67227, Final mesh size: 27022\n",
      "Total time = 6.887742519378662\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135209990080/neuron_864691135209990080.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135209990080/neuron_864691135209990080_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135209990080/decimation_meshlab_25325518.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:41:43,766 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:41:43,779 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:41:43,781 - autopopulate - Populating: {'segment_id': 864691135516120662, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 9.684255599975586\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135209990080_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135209990080_nuclei.pbz2\n",
      "File size is 0.058167 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135209990080_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135209990080_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135209990080, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135209990080_glia.pbz2'), 'n_nuclei_faces': 40205, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135209990080_nuclei.pbz2')}\n",
      "Run time was 9.684255123138428 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135516120662 ----\n",
      "{'segment_id': 864691135516120662, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73087.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73087_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_744726.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73087.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_73087_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_744726.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "There were 0 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 0\n",
      "\n",
      "\n",
      "Original Mesh size: 20623, Final mesh size: 20623\n",
      "Total time = 1.4401378631591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/decimation_meshlab_25777716.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(2285, 3), faces.shape=(5142, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(2285, 3), faces.shape=(5142, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_27217.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_27217_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_610444.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_27217.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_27217_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_610444.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 13\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/poisson_792260.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(9774, 3), faces.shape=(19700, 3))>, <trimesh.Trimesh(vertices.shape=(1954, 3), faces.shape=(3916, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(9774, 3), faces.shape=(19700, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/decimation_meshlab_25408126.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135516120662_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2386, 3), faces.shape=(4924, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007948875427246094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113551612066200_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.45102953910827637\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.5531599521636963\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0019335746765136719\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.459785461425781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004606723785400391\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02526068687438965\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([8, 3, 5, 7, 0, 1, 4, 2, 6]), array([0.606277 , 0.5697925, 0.5518755, 0.534771 , 0.397594 , 0.365225 ,\n",
      "       0.207578 , 0.146415 , 0.0849183]))\n",
      "Sizes = [53, 418, 276, 201, 2289, 765, 534, 370, 18]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "xz = 9.353161897131647 ratio was beyong 6 multiplier\n",
      "yz = 13.2561337421346 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_576470.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_576470_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_188256.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_576470.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_576470_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_188256.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.654099449938757\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1143, 3), faces.shape=(2289, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/671_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e9de4b29f8492cb8ba52a767682f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 13.145002463252947 ratio was beyong 6 multiplier\n",
      "yz = 18.57073548969317 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_255949.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_255949_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_571451.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_255949.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_255949_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_571451.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.251278491426458\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1085, 3), faces.shape=(2162, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "yz = 6.758478313606965 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_743130.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 12.706116716263054\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(765, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/627_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4f60722a5440dabcf520c27662f078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yz = 8.285416094437249 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_388953.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 13.902646046342458\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(332, 3), faces.shape=(656, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1954, 3), faces.shape=(3916, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/neuron_864691135516120662_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135516120662/decimation_meshlab_25408126.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135516120662_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(485, 3), faces.shape=(978, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00047278404235839844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113551612066201_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06511902809143066\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08420753479003906\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004048347473144531\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.482269287109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008974075317382812\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0045282840728759766\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 0, 1]), array([0.710175 , 0.445235 , 0.2034715]))\n",
      "Sizes = [109, 803, 66]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xz = 8.272789394721064 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_858382.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.920829472654684\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(400, 3), faces.shape=(803, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/569_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6456a3fe33e34a6a93bc2c0fd5c6ffd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:42:06,368 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:42:06,389 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:42:06,391 - autopopulate - Populating: {'segment_id': 864691136108760290, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 8.272789394721064 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_402508.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.920829472654684\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(400, 3), faces.shape=(803, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 22.32889676094055\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135516120662_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135516120662_nuclei.pbz2\n",
      "File size is 4.6e-05 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135516120662_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135516120662_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135516120662, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135516120662_glia.pbz2'), 'n_nuclei_faces': 0, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135516120662_nuclei.pbz2')}\n",
      "Run time was 22.328895330429077 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136108760290 ----\n",
      "{'segment_id': 864691136108760290, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34663.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34663_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_92458.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34663.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_34663_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_92458.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3193, 3), faces.shape=(5192, 3))>, <trimesh.Trimesh(vertices.shape=(1123, 3), faces.shape=(1807, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 38809, Final mesh size: 31810\n",
      "Total time = 2.5519964694976807\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/neuron_864691136108760290.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/neuron_864691136108760290_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/decimation_meshlab_25108324.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(4153, 3), faces.shape=(7374, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(4153, 3), faces.shape=(7374, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_92545.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_92545_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_257443.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_92545.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_92545_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_257443.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 41\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/neuron_864691136108760290_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/neuron_864691136108760290_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/neuron_864691136108760290_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/poisson_661408.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(15981, 3), faces.shape=(32046, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(15981, 3), faces.shape=(32046, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/neuron_864691136108760290_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/neuron_864691136108760290_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136108760290/decimation_meshlab_25610251.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136108760290_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3962, 3), faces.shape=(8008, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0020928382873535156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113610876029000_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.8475754261016846\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.0050745010375977\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.172516\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0029599666595458984\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.935264587402344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006422281265258789\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03764176368713379\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.172516\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 6, 1, 3, 5, 0, 4]), array([0.6041465, 0.316817 , 0.314314 , 0.265415 , 0.204933 , 0.172516 ,\n",
      "       0.165281 ]))\n",
      "Sizes = [1892, 497, 1039, 249, 263, 3969, 99]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_519004.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_519004_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_755890.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_519004.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_519004_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_755890.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.690061059011149\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 18.867575645446777\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79978.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79978_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_541533.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79978.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79978_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_541533.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17838.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17838_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_319246.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17838.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_17838_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_319246.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2022, 3), faces.shape=(3001, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:42:28,362 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:42:28,406 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:42:28,408 - autopopulate - Populating: {'segment_id': 864691135563379140, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136108760290_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136108760290_nuclei.pbz2\n",
      "File size is 0.011375 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136108760290_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136108760290_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136108760290, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136108760290_glia.pbz2'), 'n_nuclei_faces': 6999, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136108760290_nuclei.pbz2')}\n",
      "Run time was 18.867570400238037 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135563379140 ----\n",
      "{'segment_id': 864691135563379140, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56657.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56657_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_425057.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56657.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_56657_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_425057.mls is being deleted....\n",
      "There were 3 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 3\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3317, 3), faces.shape=(6121, 3))>, <trimesh.Trimesh(vertices.shape=(1348, 3), faces.shape=(2457, 3))>, <trimesh.Trimesh(vertices.shape=(933, 3), faces.shape=(1653, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 36907, Final mesh size: 26676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time = 2.4683969020843506\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/decimation_meshlab_25689999.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(3645, 3), faces.shape=(6641, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(3645, 3), faces.shape=(6641, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7976.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7976_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_387756.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7976.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_7976_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_387756.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 8\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/poisson_674768.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(10363, 3), faces.shape=(20758, 3))>, <trimesh.Trimesh(vertices.shape=(3021, 3), faces.shape=(6038, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(10363, 3), faces.shape=(20758, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/decimation_meshlab_25292425.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135563379140_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2578, 3), faces.shape=(5188, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008671283721923828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113556337914000_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.4136848449707031\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.5183999538421631\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.001840829849243164\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.1484832763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004804134368896484\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.024019956588745117\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 4, 3, 2, 1]), array([0.5709835, 0.549231 , 0.439183 , 0.418324 , 0.16038  ]))\n",
      "Sizes = [2118, 58, 626, 2363, 23]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [0, 3, 2]\n",
      "xz = 10.931723668570333 ratio was beyong 6 multiplier\n",
      "yz = 10.977200336534175 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_333966.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_333966_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_744181.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_333966.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_333966_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_744181.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.518659713368822\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1072, 3), faces.shape=(2118, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/43_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd0575c5a924c37af2301456dc2ef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 10.931723668570333 ratio was beyong 6 multiplier\n",
      "yz = 10.977200336534175 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_232573.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_232573_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_247900.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_232573.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_232573_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_247900.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.518659713368822\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1072, 3), faces.shape=(2118, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "yz = 6.075629319562221 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_711424.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 14.21008528824095\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(315, 3), faces.shape=(626, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/262_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a72adb55c2a4266ab98cc45682ff1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "xz = 6.19601535301262 ratio was beyong 6 multiplier\n",
      "yz = 6.523025246465705 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_202886.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_202886_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_336138.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_202886.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_202886_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_336138.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.04188748735094\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1181, 3), faces.shape=(2363, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/189_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36889ea9ce244dea8dc16ba14112ad63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 6.19601535301262 ratio was beyong 6 multiplier\n",
      "yz = 6.523025246465705 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_234700.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_234700_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_509146.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_234700.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_234700_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_509146.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.04188748735094\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1181, 3), faces.shape=(2363, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3021, 3), faces.shape=(6038, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/neuron_864691135563379140_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135563379140/decimation_meshlab_25292425.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135563379140_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(756, 3), faces.shape=(1508, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021839141845703125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113556337914001_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11820197105407715\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.152388334274292\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005655288696289062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.506111145019531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001377105712890625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00710606575012207\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.562101, 0.493534]))\n",
      "Sizes = [1113, 395]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "yz = 6.4231854296307676 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_572740.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_572740_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_171186.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_572740.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_572740_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_171186.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 7.3351117099175465\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(560, 3), faces.shape=(1113, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/97_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b77aa8f5114d0380e44dbb6fb79b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yz = 6.4231854296307676 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_361510.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_361510_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_740457.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:43:13,914 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:43:13,927 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:43:13,929 - autopopulate - Populating: {'segment_id': 864691136107882466, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_361510.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_361510_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_740457.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 7.3351117099175465\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(560, 3), faces.shape=(1113, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 45.006166219711304\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135563379140_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135563379140_nuclei.pbz2\n",
      "File size is 0.014946 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135563379140_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135563379140_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135563379140, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135563379140_glia.pbz2'), 'n_nuclei_faces': 10231, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135563379140_nuclei.pbz2')}\n",
      "Run time was 45.00616526603699 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136107882466 ----\n",
      "{'segment_id': 864691136107882466, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40323.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40323_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_88309.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40323.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_40323_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_88309.mls is being deleted....\n",
      "There were 1 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 1\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(13318, 3), faces.shape=(24835, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 45396, Final mesh size: 20561\n",
      "Total time = 3.0750648975372314\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/neuron_864691136107882466.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/neuron_864691136107882466_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/decimation_meshlab_25647093.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(1924, 3), faces.shape=(3124, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79943.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79943_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_51743.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79943.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_79943_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_51743.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 14\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/neuron_864691136107882466_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/neuron_864691136107882466_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/neuron_864691136107882466_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/poisson_502032.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(14772, 3), faces.shape=(29275, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(14772, 3), faces.shape=(29275, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/neuron_864691136107882466_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/neuron_864691136107882466_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136107882466/decimation_meshlab_25529213.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136107882466_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3793, 3), faces.shape=(7317, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007786750793457031\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113610788246600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.3555617332458496\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.49465203285217285\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002691507339477539\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002532005310058594\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006817817687988281\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03520464897155762\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.]))\n",
      "Sizes = [7317]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3793, 3), faces.shape=(7317, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001933574676513672\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113610788246600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.34063124656677246\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.44561314582824707\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002530336380004883\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.838539123535156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006799221038818359\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03431510925292969\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.]))\n",
      "Sizes = [7317]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3793, 3), faces.shape=(7317, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001780986785888672\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113610788246600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.3409442901611328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:43:27,689 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:43:27,709 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:43:27,710 - autopopulate - Populating: {'segment_id': 864691136237475388, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Finished: Generating CGAL segmentation for neuron: 0.44640636444091797\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002959728240966797\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.9577484130859375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0070378780364990234\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.035523176193237305\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.]))\n",
      "Sizes = [7317]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 13.133304834365845\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136107882466_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136107882466_nuclei.pbz2\n",
      "File size is 0.033457 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136107882466_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136107882466_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136107882466, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136107882466_glia.pbz2'), 'n_nuclei_faces': 24835, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136107882466_nuclei.pbz2')}\n",
      "Run time was 13.133304119110107 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136237475388 ----\n",
      "{'segment_id': 864691136237475388, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76916.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76916_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_868147.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76916.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_76916_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_868147.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 1\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 0\n",
      "using precomputed glia pieces\n",
      "\n",
      " ---- Working on inside piece 0 ------\n",
      "For glia mesh 0 there were 10339 faces within 3000 distane\n",
      "New mesh size is <trimesh.Trimesh(vertices.shape=(5345, 3), faces.shape=(10339, 3))>\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "\n",
      "\n",
      "Original Mesh size: 192763, Final mesh size: 10339\n",
      "Total time = 11.213069438934326\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136237475388/neuron_864691136237475388.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136237475388/neuron_864691136237475388_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136237475388/decimation_meshlab_25532698.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 11.869969606399536\n",
      "Before Filtering the number of somas found = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:43:42,142 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:43:42,156 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:43:42,157 - autopopulate - Populating: {'segment_id': 864691135635239593, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136237475388_glia.pbz2\n",
      "File size is 0.09349 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136237475388_nuclei.pbz2\n",
      "File size is 4.6e-05 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136237475388_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136237475388_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136237475388, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 182424, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136237475388_glia.pbz2'), 'n_nuclei_faces': 0, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136237475388_nuclei.pbz2')}\n",
      "Run time was 11.869966506958008 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135635239593 ----\n",
      "{'segment_id': 864691135635239593, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33605.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33605_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_897384.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33605.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_33605_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_897384.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(2784, 3), faces.shape=(5142, 3))>, <trimesh.Trimesh(vertices.shape=(559, 3), faces.shape=(895, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 132694, Final mesh size: 126657\n",
      "Total time = 6.299616098403931\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/decimation_meshlab_2567229.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(16547, 3), faces.shape=(30939, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(16547, 3), faces.shape=(30939, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_2025.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_2025_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_888154.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_2025.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_2025_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_888154.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 38\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/poisson_15448.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(16744, 3), faces.shape=(33508, 3))>, <trimesh.Trimesh(vertices.shape=(3027, 3), faces.shape=(6050, 3))>, <trimesh.Trimesh(vertices.shape=(1977, 3), faces.shape=(3950, 3))>, <trimesh.Trimesh(vertices.shape=(1629, 3), faces.shape=(3254, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(16744, 3), faces.shape=(33508, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/decimation_meshlab_25628654.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(4178, 3), faces.shape=(8376, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008475780487060547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113563523959300_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.9019424915313721\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.0584588050842285\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.8694120000000001\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0031325817108154297\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.649162292480469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006766080856323242\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.17096304893493652\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.8694120000000001\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 8, 2, 3, 6, 5, 7, 1, 4]), array([0.869412  , 0.588227  , 0.102919  , 0.0969741 , 0.0959525 ,\n",
      "       0.0857851 , 0.0653009 , 0.06218375, 0.0504762 ]))\n",
      "Sizes = [4650, 716, 662, 222, 161, 261, 79, 1324, 301]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 8]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_505974.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_505974_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_375516.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_505974.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_505974_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_375516.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.319676981955126\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291027.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291027_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_189673.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291027.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291027_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_189673.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.14483514776896103\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3027, 3), faces.shape=(6050, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/decimation_meshlab_25628654.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(758, 3), faces.shape=(1512, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002124309539794922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113563523959301_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09889340400695801\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12496256828308105\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006744861602783203\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001304149627685547\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015995502471923828\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007261514663696289\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 3, 1, 4, 2]), array([0.684722, 0.643545, 0.571041, 0.169118, 0.102799]))\n",
      "Sizes = [229, 307, 882, 26, 68]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_593938.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 294.4783177165292\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(444, 3), faces.shape=(882, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/453_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f193ac72b5418fb5365f572cc3b071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(1977, 3), faces.shape=(3950, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/decimation_meshlab_25628654.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(495, 3), faces.shape=(986, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021338462829589844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113563523959302_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0850989818572998\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10901665687561035\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005393028259277344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.198883056640625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015444755554199219\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0055103302001953125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.4723375]))\n",
      "Sizes = [986]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_769503.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 37.17423230752705\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(495, 3), faces.shape=(986, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/639_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a25aa5a65449a4b620be42110f9a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_243414.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 37.17423230752705\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(495, 3), faces.shape=(986, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(1629, 3), faces.shape=(3254, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135635239593/decimation_meshlab_25628654.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135635239593_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(408, 3), faces.shape=(812, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002429485321044922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113563523959303_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.060848236083984375\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07659125328063965\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00038123130798339844\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.601478576660156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007483959197998047\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003706216812133789\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3, 4]), array([0.682005, 0.6655  , 0.421982, 0.413691, 0.22322 ]))\n",
      "Sizes = [314, 259, 58, 158, 23]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(161, 3), faces.shape=(314, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00017833709716796875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113563523959303_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.020372629165649414\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.02721381187438965\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00021409988403320312\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.743171691894531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003333091735839844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0015952587127685547\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5905335]))\n",
      "Sizes = [314]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(161, 3), faces.shape=(314, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00030493736267089844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113563523959303_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.020586729049682617\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.02750682830810547\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00017213821411132812\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.552436828613281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003046989440917969\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0015149116516113281\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5905335]))\n",
      "Sizes = [314]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 37.320369720458984\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54024.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54024_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_761090.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54024.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_54024_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_761090.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91318.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91318_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_273712.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91318.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_91318_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_273712.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(619, 3), faces.shape=(982, 3))>, <trimesh.Trimesh(vertices.shape=(358, 3), faces.shape=(468, 3))>, <trimesh.Trimesh(vertices.shape=(292, 3), faces.shape=(596, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_522352.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_522352_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_611868.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_522352.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_522352_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_611868.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.6075629143141827\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(2784, 3), faces.shape=(5142, 3))>, <trimesh.Trimesh(vertices.shape=(559, 3), faces.shape=(895, 3))>]\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_16304.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_16304_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_256192.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_16304.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_16304_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_256192.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77217.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77217_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_70744.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77217.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_77217_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_70744.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 166\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8887.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8887_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_350786.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8887.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8887_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_350786.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41989.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41989_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_25786.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41989.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_41989_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_25786.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 362\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7202ca3176431d85ef2a8a70f94cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1455963.725147326, after = 1466674.5466314754,\n",
      "ratio = 1.0073565167175202, difference = 10710.821484149434\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135635239593_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135635239593_nuclei.pbz2\n",
      "File size is 0.012704 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135635239593_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135635239593_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135635239593, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135635239593_glia.pbz2'), 'n_nuclei_faces': 7746, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135635239593_nuclei.pbz2')}\n",
      "Run time was 37.32036900520325 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(14966, 3), faces.shape=(29046, 3))>]\n",
      "    with sdf values = [0.869412]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_216424.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_216424_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_394041.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_216424.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_216424_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_394041.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 80865 109327  15111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:44:50,798 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:44:50,813 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:44:50,815 - autopopulate - Populating: {'segment_id': 864691136041020246, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691136041020246 ----\n",
      "{'segment_id': 864691136041020246, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_29370.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_29370_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_909780.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_29370.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_29370_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_909780.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 16 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 16\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5782, 3), faces.shape=(16139, 3))>, <trimesh.Trimesh(vertices.shape=(1383, 3), faces.shape=(3567, 3))>, <trimesh.Trimesh(vertices.shape=(1296, 3), faces.shape=(3061, 3))>, <trimesh.Trimesh(vertices.shape=(1265, 3), faces.shape=(3300, 3))>, <trimesh.Trimesh(vertices.shape=(1141, 3), faces.shape=(2845, 3))>, <trimesh.Trimesh(vertices.shape=(899, 3), faces.shape=(2268, 3))>, <trimesh.Trimesh(vertices.shape=(807, 3), faces.shape=(1898, 3))>, <trimesh.Trimesh(vertices.shape=(789, 3), faces.shape=(2055, 3))>, <trimesh.Trimesh(vertices.shape=(788, 3), faces.shape=(1911, 3))>, <trimesh.Trimesh(vertices.shape=(652, 3), faces.shape=(1660, 3))>, <trimesh.Trimesh(vertices.shape=(643, 3), faces.shape=(1510, 3))>, <trimesh.Trimesh(vertices.shape=(576, 3), faces.shape=(1352, 3))>, <trimesh.Trimesh(vertices.shape=(543, 3), faces.shape=(1282, 3))>, <trimesh.Trimesh(vertices.shape=(522, 3), faces.shape=(1203, 3))>, <trimesh.Trimesh(vertices.shape=(509, 3), faces.shape=(1178, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 74509, Final mesh size: 29280\n",
      "Total time = 7.413200855255127\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/neuron_864691136041020246.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/neuron_864691136041020246_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/decimation_meshlab_25820929.mls\n",
      "Total found significant pieces before Poisson = []\n",
      "Using smaller large_mesh_threshold because no significant pieces found with 5000.0\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(1505, 3), faces.shape=(2748, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89918.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89918_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_762098.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89918.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_89918_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_762098.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 332\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/neuron_864691136041020246_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/neuron_864691136041020246_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/neuron_864691136041020246_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/poisson_506810.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(18996, 3), faces.shape=(37741, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(18996, 3), faces.shape=(37741, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/neuron_864691136041020246_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/neuron_864691136041020246_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691136041020246/decimation_meshlab_2579686.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136041020246_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(4841, 3), faces.shape=(9431, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008215904235839844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113604102024600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.8036503791809082\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.9760434627532959\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1, soma_sdf_value = 0.362616\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0035626888275146484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.6253204345703125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007410287857055664\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.044420480728149414\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.362616\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 3, 2]), array([0.362616 , 0.16633  , 0.0345094, 0.       ]))\n",
      "Sizes = [5174, 3427, 150, 680]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_91786.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_91786_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_896578.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_91786.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_91786_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_896578.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.1344510354851156\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 25.64103865623474\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3283.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3283_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_113301.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3283.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_3283_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_113301.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5893.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5893_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_231173.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:45:18,759 - connection - Transaction committed and closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5893.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_5893_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_231173.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(248, 3), faces.shape=(577, 3))>]\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136041020246_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136041020246_nuclei.pbz2\n",
      "File size is 0.064374 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136041020246_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136041020246_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691136041020246, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136041020246_glia.pbz2'), 'n_nuclei_faces': 45229, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691136041020246_nuclei.pbz2')}\n",
      "Run time was 25.641033172607422 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:45:18,772 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:45:18,773 - autopopulate - Populating: {'segment_id': 864691135618175635, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135618175635 ----\n",
      "{'segment_id': 864691135618175635, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82526.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82526_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_380619.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82526.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_82526_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_380619.mls is being deleted....\n",
      "There were 4 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 4\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(8607, 3), faces.shape=(16137, 3))>, <trimesh.Trimesh(vertices.shape=(8297, 3), faces.shape=(15657, 3))>, <trimesh.Trimesh(vertices.shape=(7272, 3), faces.shape=(13683, 3))>, <trimesh.Trimesh(vertices.shape=(1077, 3), faces.shape=(1998, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 92950, Final mesh size: 45475\n",
      "Total time = 5.427424669265747\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/decimation_meshlab_25917891.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(6373, 3), faces.shape=(10189, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(6373, 3), faces.shape=(10189, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_66773.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_66773_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_677289.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_66773.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_66773_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_677289.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 44\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/poisson_866458.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(15896, 3), faces.shape=(31788, 3))>, <trimesh.Trimesh(vertices.shape=(2999, 3), faces.shape=(5994, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(15896, 3), faces.shape=(31788, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/decimation_meshlab_25797160.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135618175635_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3973, 3), faces.shape=(7942, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008282661437988281\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113561817563500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.8683109283447266\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.1492998600006104\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.8567\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002885103225708008\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.00543212890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0054967403411865234\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.037039756774902344\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.8567\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 3, 1, 2, 5, 4, 6]), array([0.8567   , 0.313367 , 0.204363 , 0.100821 , 0.0768475, 0.0552528,\n",
      "       0.0250576]))\n",
      "Sizes = [6807, 151, 356, 275, 330, 16, 7]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_635006.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_635006_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_429578.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_635006.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_635006_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_429578.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.178909114362977\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2999, 3), faces.shape=(5994, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/neuron_864691135618175635_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135618175635/decimation_meshlab_25797160.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135618175635_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(751, 3), faces.shape=(1498, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021958351135253906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113561817563501_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10176730155944824\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12794923782348633\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006597042083740234\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.125999450683594e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015168190002441406\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006885051727294922\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 9,  8,  7,  3,  4, 10,  5,  0, 11,  1,  6, 12,  2]), array([0.752031 , 0.721484 , 0.6726835, 0.6437665, 0.6285575, 0.617277 ,\n",
      "       0.483973 , 0.4762655, 0.350704 , 0.292769 , 0.211165 , 0.198706 ,\n",
      "       0.145675 ]))\n",
      "Sizes = [98, 56, 52, 56, 336, 141, 160, 354, 66, 72, 64, 19, 24]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(180, 3), faces.shape=(354, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00017595291137695312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113561817563501_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.01679849624633789\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.024523019790649414\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00020742416381835938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.504753112792969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003502368927001953\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.001636505126953125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0]), array([0.732336 , 0.4451815, 0.426002 ]))\n",
      "Sizes = [128, 120, 106]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(67, 3), faces.shape=(128, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00017309188842773438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113561817563501_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.01595449447631836\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0251162052154541\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00012373924255371094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.790855407714844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00015354156494140625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0006551742553710938\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.6297545]))\n",
      "Sizes = [128]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 24.268142461776733\n",
      "Before Filtering the number of somas found = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_25837.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_25837_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_83806.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_25837.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_25837_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_83806.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_65578.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_65578_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_535445.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_65578.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_65578_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_535445.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(868, 3), faces.shape=(1193, 3))>, <trimesh.Trimesh(vertices.shape=(438, 3), faces.shape=(570, 3))>, <trimesh.Trimesh(vertices.shape=(227, 3), faces.shape=(313, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_948849.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_948849_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_229788.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_948849.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_948849_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_229788.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.9954286270409725\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(8607, 3), faces.shape=(16137, 3))>, <trimesh.Trimesh(vertices.shape=(8297, 3), faces.shape=(15657, 3))>, <trimesh.Trimesh(vertices.shape=(7272, 3), faces.shape=(13683, 3))>, <trimesh.Trimesh(vertices.shape=(1077, 3), faces.shape=(1998, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85630.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85630_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_481507.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85630.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_85630_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_481507.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47856.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47856_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_146558.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47856.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_47856_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_146558.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 422\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4623370959449fb61fb50e25bbe807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest hole before segmentation = 4749935.389847032, after = 7487279.564945215,\n",
      "ratio = 1.5762908230181922, difference = 2737344.1750981836\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135618175635_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135618175635_nuclei.pbz2\n",
      "File size is 0.069106 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135618175635_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135618175635_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135618175635, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135618175635_glia.pbz2'), 'n_nuclei_faces': 48745, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135618175635_nuclei.pbz2')}\n",
      "Run time was 24.268141269683838 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(10724, 3), faces.shape=(19032, 3))>]\n",
      "    with sdf values = [0.8567]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_902098.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_902098_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_264544.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_902098.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_902098_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_264544.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 74909 110021  16892]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:46:08,670 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:46:08,676 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:46:08,678 - autopopulate - Populating: {'segment_id': 864691135925481912, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135925481912 ----\n",
      "{'segment_id': 864691135925481912, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52745.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52745_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_263985.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52745.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_52745_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_263985.mls is being deleted....\n",
      "There were 2 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 2\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(14314, 3), faces.shape=(27920, 3))>, <trimesh.Trimesh(vertices.shape=(604, 3), faces.shape=(1301, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Mesh size: 74068, Final mesh size: 44847\n",
      "Total time = 4.343476295471191\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/neuron_864691135925481912.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/neuron_864691135925481912_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/decimation_meshlab_2553561.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(4653, 3), faces.shape=(8351, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(4653, 3), faces.shape=(8351, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6444.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6444_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_316031.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6444.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_6444_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_316031.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 112\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/neuron_864691135925481912_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/neuron_864691135925481912_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/neuron_864691135925481912_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/poisson_565673.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(15909, 3), faces.shape=(31834, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(15909, 3), faces.shape=(31834, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/neuron_864691135925481912_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/neuron_864691135925481912_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135925481912/decimation_meshlab_25833442.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135925481912_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3969, 3), faces.shape=(7954, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008084774017333984\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113592548191200_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.8016319274902344\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.9482674598693848\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.760398\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002922534942626953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.38690185546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006074666976928711\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.036824703216552734\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.760398\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 3, 2]), array([0.760398  , 0.2774725 , 0.257609  , 0.08793925]))\n",
      "Sizes = [5055, 210, 1405, 1284]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291873.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291873_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_32360.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291873.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_291873_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_32360.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 12.683471544968102\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(2555, 3), faces.shape=(5055, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/750_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0eb8bc5fc2b487ea9dd6c3ba982a979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_127099.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_127099_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_125326.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:46:37,456 - connection - Transaction committed and closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_127099.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_127099_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_125326.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 12.683471544968102\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(2555, 3), faces.shape=(5055, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 27.811645984649658\n",
      "Before Filtering the number of somas found = 0\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135925481912_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135925481912_nuclei.pbz2\n",
      "File size is 0.034608 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135925481912_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135925481912_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135925481912, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135925481912_glia.pbz2'), 'n_nuclei_faces': 29221, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135925481912_nuclei.pbz2')}\n",
      "Run time was 27.811645030975342 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 07:46:37,471 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:46:37,473 - autopopulate - Populating: {'segment_id': 864691135207734905, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135207734905 ----\n",
      "{'segment_id': 864691135207734905, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4786.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4786_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_421148.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4786.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_4786_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_421148.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 19 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 19\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(7942, 3), faces.shape=(19618, 3))>, <trimesh.Trimesh(vertices.shape=(2510, 3), faces.shape=(5884, 3))>, <trimesh.Trimesh(vertices.shape=(2207, 3), faces.shape=(5051, 3))>, <trimesh.Trimesh(vertices.shape=(1895, 3), faces.shape=(4355, 3))>, <trimesh.Trimesh(vertices.shape=(1864, 3), faces.shape=(4409, 3))>, <trimesh.Trimesh(vertices.shape=(1697, 3), faces.shape=(3954, 3))>, <trimesh.Trimesh(vertices.shape=(1034, 3), faces.shape=(2313, 3))>, <trimesh.Trimesh(vertices.shape=(831, 3), faces.shape=(1846, 3))>, <trimesh.Trimesh(vertices.shape=(777, 3), faces.shape=(1727, 3))>, <trimesh.Trimesh(vertices.shape=(675, 3), faces.shape=(1482, 3))>, <trimesh.Trimesh(vertices.shape=(632, 3), faces.shape=(1430, 3))>, <trimesh.Trimesh(vertices.shape=(464, 3), faces.shape=(1057, 3))>, <trimesh.Trimesh(vertices.shape=(408, 3), faces.shape=(918, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 180354, Final mesh size: 126310\n",
      "Total time = 13.01181435585022\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/neuron_864691135207734905.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/neuron_864691135207734905_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/decimation_meshlab_25942734.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(7914, 3), faces.shape=(15513, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(7914, 3), faces.shape=(15513, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31370.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31370_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_120285.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31370.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_31370_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_120285.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 17\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/neuron_864691135207734905_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/neuron_864691135207734905_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/neuron_864691135207734905_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/poisson_897850.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(8262, 3), faces.shape=(16520, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(8262, 3), faces.shape=(16520, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/neuron_864691135207734905_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/neuron_864691135207734905_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135207734905/decimation_meshlab_25491343.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135207734905_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2067, 3), faces.shape=(4130, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008287429809570312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113520773490500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.410048246383667\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.4981963634490967\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0017848014831542969\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.792213439941406e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004037618637084961\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.021046161651611328\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3, 4]), array([0.874817  , 0.0734312 , 0.0652248 , 0.0603526 , 0.05804275]))\n",
      "Sizes = [2471, 383, 619, 159, 498]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_631029.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_631029_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_59814.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_631029.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_631029_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_59814.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.717617471240454\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 37.22750163078308\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10501.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10501_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_392154.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10501.off loaded has 24806 vn 50665 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_10501_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_392154.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1203324\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1203324\n",
      "LOG: 2 Successfully removed 8214 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 8214 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1104756\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_392154.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64026.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64026_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_810517.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64026.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_64026_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_810517.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3112, 3), faces.shape=(8974, 3))>, <trimesh.Trimesh(vertices.shape=(424, 3), faces.shape=(1208, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_667047.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_667047_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_279533.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_667047.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_667047_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_279533.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.111012118030773\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(7942, 3), faces.shape=(19618, 3))>, <trimesh.Trimesh(vertices.shape=(2510, 3), faces.shape=(5884, 3))>, <trimesh.Trimesh(vertices.shape=(2207, 3), faces.shape=(5051, 3))>, <trimesh.Trimesh(vertices.shape=(1895, 3), faces.shape=(4355, 3))>, <trimesh.Trimesh(vertices.shape=(1864, 3), faces.shape=(4409, 3))>, <trimesh.Trimesh(vertices.shape=(1697, 3), faces.shape=(3954, 3))>, <trimesh.Trimesh(vertices.shape=(1034, 3), faces.shape=(2313, 3))>, <trimesh.Trimesh(vertices.shape=(831, 3), faces.shape=(1846, 3))>, <trimesh.Trimesh(vertices.shape=(777, 3), faces.shape=(1727, 3))>, <trimesh.Trimesh(vertices.shape=(675, 3), faces.shape=(1482, 3))>, <trimesh.Trimesh(vertices.shape=(632, 3), faces.shape=(1430, 3))>, <trimesh.Trimesh(vertices.shape=(464, 3), faces.shape=(1057, 3))>, <trimesh.Trimesh(vertices.shape=(408, 3), faces.shape=(918, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh was manifold\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97620.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97620_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_72623.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97620.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_97620_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_72623.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_14234.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_14234_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_97094.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_14234.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_14234_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_97094.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 49\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160c5249bb42445eb4f626cf3b55f199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 314600.13217373984, after = 300036.9417589541,\n",
      "ratio = 0.9537088865342779, difference = -14563.190414785757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135207734905_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135207734905_nuclei.pbz2\n",
      "File size is 0.08115 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135207734905_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135207734905_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135207734905, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135207734905_glia.pbz2'), 'n_nuclei_faces': 64226, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135207734905_nuclei.pbz2')}\n",
      "Run time was 37.22749733924866 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(12021, 3), faces.shape=(23784, 3))>]\n",
      "    with sdf values = [0.874817]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_749186.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_749186_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_65345.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_749186.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_749186_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_65345.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [ 80838 108411  16988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-13 07:47:46,708 - connection - Transaction committed and closed.\n",
      "INFO - 2021-01-13 07:47:46,723 - connection - Transaction started\n",
      "INFO - 2021-01-13 07:47:46,725 - autopopulate - Populating: {'segment_id': 864691135758479438, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135758479438 ----\n",
      "{'segment_id': 864691135758479438, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75577.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75577_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_615982.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75577.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_75577_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_615982.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 7 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 7\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1802, 3), faces.shape=(4202, 3))>, <trimesh.Trimesh(vertices.shape=(1768, 3), faces.shape=(4158, 3))>, <trimesh.Trimesh(vertices.shape=(1544, 3), faces.shape=(3580, 3))>, <trimesh.Trimesh(vertices.shape=(1014, 3), faces.shape=(2310, 3))>, <trimesh.Trimesh(vertices.shape=(916, 3), faces.shape=(2038, 3))>, <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(1006, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 91271, Final mesh size: 73977\n",
      "Total time = 5.844149589538574\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/neuron_864691135758479438.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/neuron_864691135758479438_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/decimation_meshlab_25283190.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(6851, 3), faces.shape=(13659, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(6851, 3), faces.shape=(13659, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_43005.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_43005_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_823893.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_43005.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_43005_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_823893.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 133\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/neuron_864691135758479438_decimated_largest_piece.off\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/neuron_864691135758479438_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/neuron_864691135758479438_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/poisson_569667.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(6773, 3), faces.shape=(13542, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(6773, 3), faces.shape=(13542, 3))>\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/neuron_864691135758479438_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/neuron_864691135758479438_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/864691135758479438/decimation_meshlab_25328866.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135758479438_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1693, 3), faces.shape=(3382, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007922649383544922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/86469113575847943800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.3784315586090088\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.4501190185546875\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.77148\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0014963150024414062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.935264587402344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0023615360260009766\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.16402649879455566\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.77148\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.77148 , 0.146183]))\n",
      "Sizes = [3167, 215]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_252431.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_252431_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_621870.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_252431.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_252431_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_621870.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.6445647918760717\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 25.49285364151001\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8674.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8674_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_553947.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8674.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_8674_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_553947.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50964.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50964_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_64577.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50964.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50964_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_64577.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(563, 3), faces.shape=(1247, 3))>, <trimesh.Trimesh(vertices.shape=(218, 3), faces.shape=(400, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_49617.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_49617_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_41491.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_49617.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_49617_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_41491.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.7350873929170842\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(1802, 3), faces.shape=(4202, 3))>, <trimesh.Trimesh(vertices.shape=(1768, 3), faces.shape=(4158, 3))>, <trimesh.Trimesh(vertices.shape=(1544, 3), faces.shape=(3580, 3))>, <trimesh.Trimesh(vertices.shape=(1014, 3), faces.shape=(2310, 3))>, <trimesh.Trimesh(vertices.shape=(916, 3), faces.shape=(2038, 3))>, <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(1006, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44522.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44522_fill_holes.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_57531.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44522.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_44522_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/fill_holes_57531.mls is being deleted....\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50997.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50997_remove_interior.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_133856.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50997.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/neuron_50997_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Preprocessing_Pipeline/temp/remove_interior_133856.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 253\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4f2ef940da46b38e736ca909635497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 31881.212945100524, after = 109132.35405044594,\n",
      "ratio = 3.423092911752509, difference = 77251.14110534542\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135758479438_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135758479438_nuclei.pbz2\n",
      "File size is 0.021275 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135758479438_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135758479438_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135758479438, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135758479438_glia.pbz2'), 'n_nuclei_faces': 18832, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135758479438_nuclei.pbz2')}\n",
      "Run time was 25.492849349975586 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(12611, 3), faces.shape=(25098, 3))>]\n",
      "    with sdf values = [0.77148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8810 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_791299.off -o /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/neuron_791299_poisson.off -s /notebooks/Auto_Proofreading/Preprocessing_Pipeline/Poisson_temp/poisson_908936.mls\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "sm = reload(sm)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    BaylorSegmentCentroid.populate(reserve_jobs=True, suppress_errors=True)\n",
    "else:\n",
    "    BaylorSegmentCentroid.populate(reserve_jobs=True, suppress_errors=False)\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for BaylorSegmentCentroid populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
