{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To decompose the multi-somas for splitting\n",
    "using the new decomposition method\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-04 00:05:01,540 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-02-04 00:05:01,542 - settings - Setting database.user to celiib\n",
      "INFO - 2021-02-04 00:05:01,542 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-02-04 00:05:01,547 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-02-04 00:05:01,547 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-02-04 00:05:01,559 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-04 00:05:01,832 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the contains method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-04 00:05:06,421 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-02-04 00:05:06,423 - settings - Setting database.user to celiib\n",
      "INFO - 2021-02-04 00:05:06,424 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-02-04 00:05:06,429 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 194 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-02-04 00:05:06,713 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 9491\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "verbose = True\n",
    "spine_version = 0\n",
    "\n",
    "up_to_date_spine_process = 3\n",
    "@schema\n",
    "class SpineRecalculation(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    ---    \n",
    "    spine_version          : tinyint unsigned             # the version of the spine algorithm\n",
    "    updated_spines          : bool          # whether or not the spines were updated (1 = yes, 0 = no)\n",
    "    n_spines_old: int unsigned                 # number of spines before recalculation\n",
    "    n_spines_new: int unsigned                 # number of spines after recalculation\n",
    "    spine_data=NULL : longblob     #stores the newly computes spines that were used for the classification\n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "    \"\"\"\n",
    "                             \n",
    "    key_source = minnie.Decomposition() & minnie.NucleiSegmentsRun2() & \"process_version<3\"\n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode: \n",
    "        0) Download the possible neurons from either Decomposition or DecompositionSplit (using datajoint function)\n",
    "        \n",
    "        For Each Neuron\n",
    "        1) Get the number of spines currently\n",
    "        3) Run the calculate spines function\n",
    "        4) get the new spines as a data structure\n",
    "        5) Calculate the new number of spines\n",
    "        6) Save in dictionary to write\n",
    "        \n",
    "        7) Write all keys\n",
    "        \"\"\"\n",
    "        \n",
    "        whole_pass_time = time.time()\n",
    "        \n",
    "        segment_id = key[\"segment_id\"]\n",
    "        \n",
    "        \n",
    "        #0) Download the possible neurons from either Decomposition or DecompositionSplit\n",
    "        \n",
    "\n",
    "        neuron_objs,split_indexes,table_name,process_version = du.decomposition_by_segment_id(segment_id,\n",
    "                                                                                              return_split_indexes=True,\n",
    "                                                                                              return_process_version=True,\n",
    "                                                                                              return_table_name=True,\n",
    "                                                                              verbose=verbose)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        new_keys = []\n",
    "        for neuron_obj,split_index in zip(neuron_objs,split_indexes):     \n",
    "        \n",
    "            print(f\"\\n\\n\\n---- Working on Neuron {neuron_obj.segment_id}_{neuron_obj.description} ----\")\n",
    "            \n",
    "            #1) Get the number of spines currently\n",
    "            n_spines_old = neuron_obj.n_spines\n",
    "            \n",
    "            #2) Run the calculate spines function\n",
    "            if process_version < up_to_date_spine_process:\n",
    "                neuron_obj.calculate_spines()\n",
    "                updated_spines = True\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Skipping re-calculation because process version {process_version} is equal or above the required version {up_to_date_spine_process}\")\n",
    "                updated_spines = False\n",
    "            \n",
    "            #3) Run the calculate spines function\n",
    "            n_spines_new = neuron_obj.n_spines\n",
    "            \n",
    "            #4) get the new spines as a data structure\n",
    "            spine_data = neuron_obj.get_computed_attribute_data(attributes=[\"spines\",\"spines_volume\"])\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            #7) Pass stats and file location to insert\n",
    "            new_key = dict(key,\n",
    "                           split_index = split_index,\n",
    "                           spine_version=spine_version,\n",
    "                           updated_spines=updated_spines,\n",
    "                           n_spines_old = n_spines_old,\n",
    "                           n_spines_new = n_spines_new,\n",
    "                           spine_data = spine_data,\n",
    "                           run_time=np.round(time.time() - whole_pass_time,4)\n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "            new_keys.append(new_key)\n",
    "\n",
    "        \n",
    "        self.insert(new_keys, allow_direct_insert=True, skip_duplicates=True)\n",
    "\n",
    "        print(f\"\\n\\n ------ Total time for {key['segment_id']} = {time.time() - whole_pass_time} ------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__spine_recalculation'\")\n",
    "(curr_table).delete()# & \"status='error'\")\n",
    "#curr_table.delete()\n",
    "#(curr_table & \"error_message = 'ValueError: need at least one array to concatenate'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import neuron\n",
    "neuron = reload(neuron)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    SpineRecalculation.populate(reserve_jobs=True, suppress_errors=True, order=\"random\")\n",
    "else:\n",
    "    SpineRecalculation.populate(reserve_jobs=True, suppress_errors=False)\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for SpineRecalculation populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
