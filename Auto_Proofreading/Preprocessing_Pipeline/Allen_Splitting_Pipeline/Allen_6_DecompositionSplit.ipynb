{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To decompose the multi-somas for splitting\n",
    "using the new decomposition method\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-04-15 16:30:23,805 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-04-15 16:30:23,807 - settings - Setting database.user to celiib\n",
      "INFO - 2021-04-15 16:30:23,808 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-04-15 16:30:23,811 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-04-15 16:30:23,812 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-04-15 16:30:23,823 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-04-15 16:30:24,244 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-04-15 16:30:24,247 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-04-15 16:30:24,248 - settings - Setting database.user to celiib\n",
      "INFO - 2021-04-15 16:30:24,248 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-04-15 16:30:24,249 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-04-15 16:30:24,250 - settings - Setting database.user to celiib\n",
      "INFO - 2021-04-15 16:30:24,250 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-04-15 16:30:24,252 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-04-15 16:30:24,644 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty/\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the contains method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-04-15 16:30:29,865 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-04-15 16:30:29,866 - settings - Setting database.user to celiib\n",
      "INFO - 2021-04-15 16:30:29,867 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-04-15 16:30:29,868 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-04-15 16:30:29,869 - settings - Setting database.user to celiib\n",
      "INFO - 2021-04-15 16:30:29,869 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-04-15 16:30:29,874 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 70 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-04-15 16:30:30,351 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 8710\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema.external['decomposition'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_source = minnie.Decomposition() & (minnie.AllenProofreading() & dict(month=3,day=18,year=2021)).proj()\n",
    "# key_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import proofreading_utils as pru\n",
    "\n",
    "split_version = 0\n",
    "split_version = 1 #fixed the problem with split from suggestions\n",
    "split_version = 2 #fixed the problem with split from suggestions\n",
    "\n",
    "verbose = True\n",
    "\n",
    "@schema\n",
    "class DecompositionSplit(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index: tinyint unsigned  #the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    split_version: tinyint unsigned  #the version of the splitting algorithm used\n",
    "    ---\n",
    "    multiplicity=null    : tinyint unsigned             # the number of somas found for this base segment\n",
    "    n_splits             : int unsigned                 # the number of cuts required to help split the neuron\n",
    "    split_success        : tinyint unsigned             # the successfulness of the splitting\n",
    "    \n",
    "    n_error_limbs_cancelled : tinyint unsigned     # number of limbs that couldn't be resolved and cancelled out        \n",
    "    n_same_soma_limbs_cancelled : tinyint unsigned     # number of same soma touching limbs that couldn't be resolved and cancelled out\n",
    "    n_multi_soma_limbs_cancelled : tinyint unsigned     # number of multi soma touching limbs that couldn't be resolved and cancelled out        \n",
    "    \n",
    "    error_imbs_cancelled_area=NULL : double            # the total area (in microns^2) of the limbs that was cancelled out because touching the same soma multiple times or multiple somas\n",
    "    error_imbs_cancelled_skeletal_length = NULL : double #the total skeletal length (in microns) of the limbs that were called out because could not be resolved\n",
    "    \n",
    "    split_results: longblob #will store the results of how to split the limbs of neuron objects from original neuron\n",
    "    decomposition: <decomposition>\n",
    "    \n",
    "    \n",
    "    n_vertices           : int unsigned                 # number of vertices\n",
    "    n_faces              : int unsigned                 # number of faces\n",
    "    n_not_processed_soma_containing_meshes : int unsigned  #the number of meshes with somas that were not processed\n",
    "    n_error_limbs: int #the number of limbs that are touching multiple somas or 1 soma in multiple places\n",
    "    n_same_soma_multi_touching_limbs: int # number of limbs that touch the same soma multiple times\n",
    "    n_multi_soma_touching_limbs: int # number of limbs that touch multiple somas\n",
    "    n_somas: int #number of soma meshes detected\n",
    "    max_soma_n_faces:  int unsigned                 # The largest number of faces of the somas\n",
    "    max_soma_volume:  int unsigned                 # The largest volume of the somas the (volume in billions (10*9 nm^3))\n",
    "    n_limbs: int\n",
    "    n_branches: int\n",
    "    max_limb_n_branches=NULL:int\n",
    "    \n",
    "    skeletal_length=NULL: double\n",
    "    max_limb_skeletal_length=NULL:double\n",
    "    median_branch_length=NULL:double #gives information on average skeletal length to next branch point\n",
    "    \n",
    "    \n",
    "    width_median=NULL: double #median width from mesh center without spines removed\n",
    "    width_no_spine_median=NULL: double #median width from mesh center with spines removed\n",
    "    width_90_perc=NULL: double # 90th percentile for width without spines removed\n",
    "    width_no_spine_90_perc=NULL: double  # 90th percentile for width with spines removed\n",
    "    \n",
    "    \n",
    "    n_spines: bigint\n",
    "\n",
    "    spine_density=NULL: double # n_spines/ skeletal_length\n",
    "    spines_per_branch=NULL: double\n",
    "    \n",
    "    skeletal_length_eligible=NULL: double # the skeletal length for all branches searched for spines\n",
    "    n_spine_eligible_branches=NULL: int # the number of branches that were checked for spines because passed width threshold\n",
    "    \n",
    "    spine_density_eligible=NULL:double # n_spines/skeletal_length_eligible\n",
    "    spines_per_branch_eligible=NULL:double # n_spines/n_spine_eligible_branches\n",
    "    \n",
    "    total_spine_volume=NULL: double # the sum of all spine volume\n",
    "    spine_volume_median=NULL: double # median of the spine volume for those spines with able to calculate volume\n",
    "    spine_volume_density=NULL: double #total_spine_volume/skeletal_length\n",
    "    spine_volume_density_eligible=NULL: double #total_spine_volume/skeletal_length_eligible\n",
    "    spine_volume_per_branch_eligible=NULL: double #total_spine_volume/n_spine_eligible_branches\n",
    "    \n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "                             \n",
    "    \n",
    "    ''' Old keysource used for inhibitory excitatory check\n",
    "    classified_table = (minnie.BaylorManualCellType() &\n",
    "                        'nucleus_version=3' & \n",
    "                        \"(cell_type = 'excitatory') or  (cell_type = 'inhibitory')\")\n",
    "    \n",
    "    key_source = ((minnie.Decomposition & \n",
    "                (minnie.NeuronSplitSuggestions.proj()) & \n",
    "                (classified_table.proj()) \n",
    "                & f\"n_somas<{max_n_somas}\" & \"n_error_limbs>0\"))'''\n",
    "    \n",
    "    # This keysource acounts that you could have more than 1 possible soma but not a significant limb connecting them (no error limbs)\n",
    "    key_source = minnie.Decomposition() & \"n_somas>1 OR n_error_limbs>0\" & (minnie.AllenProofreading() & dict(month=4,day=14,year=2021)).proj()\n",
    "    \n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode for process:\n",
    "\n",
    "        1) Get the segment id from the key\n",
    "        2) Get the decomposed neurong object from Decomposition table\n",
    "        3) Run the multi_soma split suggestions algorithm\n",
    "        4) Get the number of splits required for this neuron\n",
    "        5) Split the neuron into a list of neuron objects\n",
    "        6) For each neuron object in the list:\n",
    "        - get the number of errored limbs (to indicate the success type)\n",
    "        - Change the description to include the multiplicity\n",
    "        - Compute the information on the largest soma faces and volume\n",
    "        - Save the neuron object to the external\n",
    "        - Add the new write key to a list to commit \n",
    "        7) Write all of the keys \n",
    "        \"\"\"\n",
    "        \n",
    "        whole_pass_time = time.time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 1) Get the segment id from the key\n",
    "        segment_id = key[\"segment_id\"]\n",
    "        print(f\"\\n\\n\\n---- Working on Neuron {key['segment_id']} ----\")\n",
    "        \n",
    "        \n",
    "        # 2) Get the decomposed neuron object from Decomposition table and the split suggestions\n",
    "#         try:\n",
    "#             neuron_obj = (minnie.Decomposition & key).fetch1(\"decomposition\")\n",
    "#         except:\n",
    "#             neuron_obj = du.fetch_neuron_obj_manual(segment_id)\n",
    "            \n",
    "        neuron_obj = du.fetch_neuron_obj_manual(segment_id)\n",
    "        \n",
    "        \"\"\" Old way that downloaded from another table\n",
    "        # 3) Retrieve the multi soma suggestions\n",
    "        split_results = (minnie.NeuronSplitSuggestions & key).fetch1(\"split_results\")\n",
    "        \"\"\"\n",
    "        #3) Calculated the split results\n",
    "        split_results = pru.multi_soma_split_suggestions(neuron_obj,plot_intermediates=False)\n",
    "        \n",
    "        # 4) Get the number of splits required for this neuron\n",
    "        n_paths_cut = pru.get_n_paths_cut(split_results)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"n_paths_cut = {n_paths_cut}\")\n",
    "            \n",
    "            \n",
    "        # 5) Split the neuron into a list of neuron objects\n",
    "        (neuron_list,\n",
    "        neuron_list_errored_limbs_area,\n",
    "         neuron_list_errored_limbs_skeletal_length,\n",
    "        neuron_list_n_multi_soma_errors,\n",
    "        neuron_list_n_same_soma_errors) = pru.split_neuron(neuron_obj,\n",
    "                        limb_results=split_results,\n",
    "                                       verbose=verbose,\n",
    "                                        return_error_info=True\n",
    "                                            )\n",
    "        \n",
    "        print(f\"neuron_list = {neuron_list}\")\n",
    "        print(f\"neuron_list_errored_limbs_area = {neuron_list_errored_limbs_area}\")\n",
    "        print(f\"neuron_list_n_multi_soma_errors = {neuron_list_n_multi_soma_errors}\")\n",
    "        print(f\"neuron_list_n_same_soma_errors = {neuron_list_n_same_soma_errors}\")\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Number of neurons: {len(neuron_list)}\")\n",
    "        \n",
    "        neuron_entries = []\n",
    "        for neuron_idx in range(len(neuron_list)):\n",
    "            \n",
    "            \"\"\"\n",
    "            # 6) For each neuron object in the list:\n",
    "            # - get the number of errored limbs (to indicate the success type)\n",
    "            # - Compute the information on the largest soma faces and volume\n",
    "            # - Save the neuron object to the external\n",
    "            # - Add the new write key to a list to commit \n",
    "            \"\"\"\n",
    "            n = neuron_list[neuron_idx]\n",
    "            \n",
    "            error_imbs_cancelled_area = neuron_list_errored_limbs_area[neuron_idx]\n",
    "            error_imbs_cancelled_skeletal_length = neuron_list_errored_limbs_skeletal_length[neuron_idx]\n",
    "            n_multi_soma_limbs_cancelled = neuron_list_n_multi_soma_errors[neuron_idx]\n",
    "            n_same_soma_limbs_cancelled = neuron_list_n_same_soma_errors[neuron_idx]\n",
    "            \n",
    "            \n",
    "            #for n in neuron_list:\n",
    "            #     nviz.visualize_neuron(n,\n",
    "            #                          limb_branch_dict=\"all\")\n",
    "\n",
    "            # - get the number of errored limbs (to indicate the success type)\n",
    "            if n.n_error_limbs == 0:\n",
    "                split_success = 0\n",
    "            elif n.multi_soma_touching_limbs == 0:\n",
    "                split_successs = 1\n",
    "            elif n.same_soma_multi_touching_limbs == 0:\n",
    "                split_success = 2\n",
    "            else:\n",
    "                split_success = 3\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"split_success = {split_success}\")\n",
    "\n",
    "            # - Compute the information on the largest soma faces and volume\n",
    "            soma_volumes = [n[k].volume/1000000000 for k in n.get_soma_node_names()] \n",
    "            soma_n_faces = [len(n[k].mesh.faces) for k in n.get_soma_node_names()] \n",
    "\n",
    "            largest_n_faces = np.max(soma_n_faces)\n",
    "            largest_volume = np.max(soma_volumes)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"largest_n_faces = {largest_n_faces}\")\n",
    "                print(f\"largest_volume = {largest_volume}\")\n",
    "\n",
    "            if \"split\" not in n.description:\n",
    "                n.description += \"_soma_0_split\"\n",
    "                \n",
    "            #6) Save the file in a certain location\n",
    "            if True:\n",
    "                save_time = time.time()\n",
    "                ret_file_path = n.save_compressed_neuron(output_folder=str(du.get_decomposition_path()),\n",
    "                                                  return_file_path=True,\n",
    "                                                 export_mesh=False,\n",
    "                                                 suppress_output=True)\n",
    "\n",
    "                ret_file_path_str = str(ret_file_path.absolute()) + \".pbz2\"\n",
    "                print(f\"Save time = {time.time() - save_time}\")\n",
    "            else:\n",
    "                print(\"Storing a dummy value for neuron\")\n",
    "                ret_file_path_str = \"dummy\"\n",
    "\n",
    "\n",
    "\n",
    "            #7) Pass stats and file location to insert\n",
    "            new_key = dict(key,\n",
    "                           split_index = neuron_idx,\n",
    "                           split_version = split_version,\n",
    "                           \n",
    "                           multiplicity=len(neuron_list),\n",
    "\n",
    "                           n_splits = n_paths_cut,\n",
    "                           split_success = split_success,\n",
    "                           \n",
    "                           n_error_limbs_cancelled = len(error_imbs_cancelled_area),\n",
    "                           \n",
    "                           n_multi_soma_limbs_cancelled =n_multi_soma_limbs_cancelled,\n",
    "                           n_same_soma_limbs_cancelled = n_same_soma_limbs_cancelled,\n",
    "                           error_imbs_cancelled_area = np.round(np.sum(error_imbs_cancelled_area),4),\n",
    "                           error_imbs_cancelled_skeletal_length = np.round(np.sum(error_imbs_cancelled_skeletal_length)/1000,4),\n",
    "                           \n",
    "                           split_results=split_results,\n",
    "\n",
    "                           max_soma_n_faces = largest_n_faces,\n",
    "                           max_soma_volume = largest_volume,\n",
    "\n",
    "\n",
    "                           decomposition=ret_file_path_str,\n",
    "                           n_vertices=len(n.mesh.vertices),\n",
    "                           n_faces=len(n.mesh.faces),\n",
    "                           run_time=np.round(time.time() - whole_pass_time,4)\n",
    "                          )\n",
    "\n",
    "            stats_dict = n.neuron_stats()\n",
    "            new_key.update(stats_dict)\n",
    "            \n",
    "            keys_to_delete = [\"axon_length\",\n",
    "            \"axon_area\",\"n_boutons\"]\n",
    "\n",
    "            for k_to_delete in keys_to_delete:\n",
    "                if k_to_delete in new_key.keys():\n",
    "                    del new_key[k_to_delete]\n",
    "\n",
    "\n",
    "            neuron_entries.append(new_key)\n",
    "\n",
    "        \n",
    "        self.insert(neuron_entries, allow_direct_insert=True, skip_duplicates=True)\n",
    "        \n",
    "\n",
    "        print(f\"\\n\\n ------ Total time for {segment_id} = {time.time() - whole_pass_time} ------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>job reservation table for `microns_minnie65_02`</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">table_name</p>\n",
       "                                <span class=\"djtooltiptext\">className of the table</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">key_hash</p>\n",
       "                                <span class=\"djtooltiptext\">key hash</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">if tuple is missing, the job is available</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">key</p>\n",
       "                                <span class=\"djtooltiptext\">structure containing the key</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_message</p>\n",
       "                                <span class=\"djtooltiptext\">error message returned if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_stack</p>\n",
       "                                <span class=\"djtooltiptext\">error stack if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">user</p>\n",
       "                                <span class=\"djtooltiptext\">database user</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">host</p>\n",
       "                                <span class=\"djtooltiptext\">system hostname</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">pid</p>\n",
       "                                <span class=\"djtooltiptext\">system process id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">connection_id</p>\n",
       "                                <span class=\"djtooltiptext\">connection_id()</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">timestamp</p>\n",
       "                                <span class=\"djtooltiptext\">automatic timestamp</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>__decomposition_split</td>\n",
       "<td>048ecac9af11b0a1efe61115b5c1b6c1</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>Exception: not downsampled branch</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.83</td>\n",
       "<td>at-compute004</td>\n",
       "<td>402563</td>\n",
       "<td>324375</td>\n",
       "<td>2021-04-15 15:14:09</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 1</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*table_name    *key_hash      status     key        error_message  error_stac user           host           pid        connection_id  timestamp     \n",
       "+------------+ +------------+ +--------+ +--------+ +------------+ +--------+ +------------+ +------------+ +--------+ +------------+ +------------+\n",
       "__decompositio 048ecac9af11b0 error      =BLOB=     Exception: not =BLOB=     celiib@10.28.0 at-compute004  402563     324375         2021-04-15 15:\n",
       " (Total: 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__decomposition_split'\")\n",
    "(curr_table)#.delete()# & \"status='error'\")\n",
    "#curr_table.delete()\n",
    "#(curr_table & \"error_message = 'ValueError: need at least one array to concatenate'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135569218694 ----\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Skipping endnode 88 because skeletal distance was 557.2427090088826 and threshold was 2500\n",
      "Skipping endnode 80 because skeletal distance was 76.78848154999419 and threshold was 2500\n",
      "n_paths_cut = 4\n",
      "using precomputed split suggestions\n",
      "\n",
      "\n",
      "---Working on Splitting Limb 0 with 15 components----\n",
      "\n",
      "\n",
      "----Working on seperate_graph 0----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [ 655595.  715706. 1044920.]---------\n",
      "Starting_edge inside branches_to_conept = [[ 654031.  716158. 1055790.]\n",
      " [ 655595.  715706. 1044920.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [17]\n",
      "printing out current edge:\n",
      "[[ 655595.  715706. 1044920.]\n",
      " [ 654031.  716158. 1055790.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 64 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 30\n",
      "Total time for branches to concept conversion = 1.0143239498138428\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 1----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [ 669648.  708395. 1039530.]---------\n",
      "Starting_edge inside branches_to_conept = [[ 669648.  708395. 1039530.]\n",
      " [ 669786.  708016. 1039910.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [21]\n",
      "printing out current edge:\n",
      "[[ 669648.  708395. 1039530.]\n",
      " [ 669786.  708016. 1039910.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 34 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 25\n",
      "Total time for branches to concept conversion = 0.7753188610076904\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 2----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 631029.0544181   755973.02900648 1088425.45065057]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 631029.0544181   755973.02900648 1088425.45065057]---------\n",
      "Starting_edge inside branches_to_conept = [[ 631029.0544181   755973.02900648 1088425.45065057]\n",
      " [ 648485.46809567  762006.51620651 1076866.77124316]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 3----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [ 660488.24133715  721114.5245215  1042094.95476337]---------\n",
      "Starting_edge inside branches_to_conept = [[ 660488.24133715  721114.5245215  1042094.95476337]\n",
      " [ 672112.34488863  774335.3793756  1037461.08590787]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [4]\n",
      "printing out current edge:\n",
      "[[ 660488.24133715  721114.5245215  1042094.95476337]\n",
      " [ 672112.34488863  774335.3793756  1037461.08590787]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 44 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 17\n",
      "Total time for branches to concept conversion = 0.6276240348815918\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 4----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 772292.62211686  768076.56985153 1099435.21763956]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 772292.62211686  768076.56985153 1099435.21763956]---------\n",
      "Starting_edge inside branches_to_conept = [[ 772292.62211686  768076.56985153 1099435.21763956]\n",
      " [ 783056.28368688  767059.05502109 1100459.19211004]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 5----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 783056.28368688  767059.05502109 1100459.19211004]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 783056.28368688  767059.05502109 1100459.19211004]---------\n",
      "Starting_edge inside branches_to_conept = [[ 783056.28368688  767059.05502109 1100459.19211004]\n",
      " [ 783260.90496257  773188.67356367 1107845.65978713]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [1]\n",
      "printing out current edge:\n",
      "[[ 783056.28368688  767059.05502109 1100459.19211004]\n",
      " [ 783260.90496257  773188.67356367 1107845.65978713]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 13 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 0\n",
      "Total time for branches to concept conversion = 0.15540552139282227\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 6----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 781330.14542409  769074.50292811 1098750.37066741]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 781330.14542409  769074.50292811 1098750.37066741]---------\n",
      "Starting_edge inside branches_to_conept = [[ 781330.14542409  769074.50292811 1098750.37066741]\n",
      " [ 781803.06662381  783479.21696607 1098011.02248568]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [1]\n",
      "printing out current edge:\n",
      "[[ 781330.14542409  769074.50292811 1098750.37066741]\n",
      " [ 781803.06662381  783479.21696607 1098011.02248568]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 5 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 0\n",
      "Total time for branches to concept conversion = 0.050855159759521484\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 7----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [ 660366.  720902. 1043710.]---------\n",
      "Starting_edge inside branches_to_conept = [[ 660366.  720902. 1043710.]\n",
      " [ 664446.  723557. 1054210.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [4]\n",
      "printing out current edge:\n",
      "[[ 660366.  720902. 1043710.]\n",
      " [ 664446.  723557. 1054210.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 158 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 4\n",
      "Total time for branches to concept conversion = 2.172978639602661\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 8----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [ 667897.82444444  726179.78666667 1040658.91111111]---------\n",
      "Starting_edge inside branches_to_conept = [[ 667897.82444444  726179.78666667 1040658.91111111]\n",
      " [ 667964.          726178.         1040620.        ]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [7]\n",
      "printing out current edge:\n",
      "[[ 667897.82444444  726179.78666667 1040658.91111111]\n",
      " [ 667964.          726178.         1040620.        ]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 10 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 7\n",
      "Total time for branches to concept conversion = 0.18448495864868164\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 9----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 662151.84606742  723793.29831461 1057549.65168539]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 662151.84606742  723793.29831461 1057549.65168539]---------\n",
      "Starting_edge inside branches_to_conept = [[ 662151.84606742  723793.29831461 1057549.65168539]\n",
      " [ 662157.08056742  723798.53281461 1057554.88618539]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 10----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 665640.46363636  767542.81038961 1104972.83116883]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 665640.46363636  767542.81038961 1104972.83116883]---------\n",
      "Starting_edge inside branches_to_conept = [[ 665640.46363636  767542.81038961 1104972.83116883]\n",
      " [ 665645.69813636  767548.04488961 1104978.06566883]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 11----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 668822.73847758  766151.86465068 1108494.23357664]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 668822.73847758  766151.86465068 1108494.23357664]---------\n",
      "Starting_edge inside branches_to_conept = [[ 668822.73847758  766151.86465068 1108494.23357664]\n",
      " [ 668827.97297758  766157.09915068 1108499.46807664]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 12----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 671017.43360656  767329.36147541 1109169.28415301]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 671017.43360656  767329.36147541 1109169.28415301]---------\n",
      "Starting_edge inside branches_to_conept = [[ 671017.43360656  767329.36147541 1109169.28415301]\n",
      " [ 671022.66810656  767334.59597541 1109174.51865301]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 13----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 783768.956       767698.98342857 1100991.74285714]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 783768.956       767698.98342857 1100991.74285714]---------\n",
      "Starting_edge inside branches_to_conept = [[ 783768.956       767698.98342857 1100991.74285714]\n",
      " [ 783774.1905      767704.21792857 1100996.97735714]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 14----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 783536.43859649  767045.44210526 1100984.42105263]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 783536.43859649  767045.44210526 1100984.42105263]---------\n",
      "Starting_edge inside branches_to_conept = [[ 783536.43859649  767045.44210526 1100984.42105263]\n",
      " [ 783541.67309649  767050.67660526 1100989.65555263]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------ Working on Soma 0 -------\n",
      "limb_neighbors = [0, 1, 2, 3, 6, 8, 9, 12, 16]\n",
      "limb_neighbors BEFORE error limbs removed = [0, 1, 2, 3, 6, 8, 9, 12, 16]\n",
      "limb_neighbors AFTER error limbs removed = [ 0  1  2  3  6  8  9 12 16]\n",
      "curr_n_multi_soma_limbs_cancelled = 0\n",
      "curr_n_same_soma_limbs_cancelled = 0\n",
      "n_errored_lims = 0\n",
      "curr_error_limbs_cancelled_area = []\n",
      "local_floating_meshes = [<trimesh.Trimesh(vertices.shape=(12060, 3), faces.shape=(24109, 3))>, <trimesh.Trimesh(vertices.shape=(9838, 3), faces.shape=(19565, 3))>, <trimesh.Trimesh(vertices.shape=(524, 3), faces.shape=(1044, 3))>, <trimesh.Trimesh(vertices.shape=(216, 3), faces.shape=(428, 3))>, <trimesh.Trimesh(vertices.shape=(99, 3), faces.shape=(202, 3))>, <trimesh.Trimesh(vertices.shape=(78, 3), faces.shape=(152, 3))>, <trimesh.Trimesh(vertices.shape=(65, 3), faces.shape=(126, 3))>]\n",
      "Already have preprocessed data\n",
      "--- 1) Finished unpacking preprocessed materials: 9.822845458984375e-05\n",
      "total_edges = [['S0', 'L0'], ['S0', 'L1'], ['S0', 'L2'], ['S0', 'L3'], ['S0', 'L4'], ['S0', 'L5'], ['S0', 'L6'], ['S0', 'L7'], ['S0', 'L8']]\n",
      "--- 2) Finished creating neuron connectivity graph: 0.0001819133758544922\n",
      "Having to generate soma_meshes_face_idx because none in preprocessed data\n",
      "--- 3a) Finshed generating soma_meshes_face_idx: 0.17283391952514648\n",
      "Using precomputed volume ratio\n",
      "--- 3b) Finished soma creation: 0.0977780818939209\n",
      "--- 3) Finshed generating soma objects and adding them to concept graph: 3.409385681152344e-05\n",
      "Using already existing limb_mehses_face_idx in preprocessed data \n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9ff4bbe0>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9fed5518>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9ff4b898>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9fe73668>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9fed51d0>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9ff3fb38>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9fea55f8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9fe73320>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f9ff26b38>]}\n",
      "--- 4) Finshed generating Limb objects and adding them to concept graph: 5.69742488861084\n",
      "--- 5) SKIPPING Doing the adaptive mesh correspondence on the meshparty preprocessing ---\n",
      "--- 6) SKIPPING Using the computed_attribute_dict to populate neuron attributes ---\n",
      "self.n_limbs = 9\n",
      "7) Calculating the spines for the neuorn if do not already exist\n",
      "Total time for neuron instance creation = 12.060172080993652\n",
      "\n",
      "\n",
      "------ Working on Soma 1 -------\n",
      "limb_neighbors = [4, 5, 7, 10, 17]\n",
      "limb_neighbors BEFORE error limbs removed = [4, 5, 7, 10, 17]\n",
      "limb_neighbors AFTER error limbs removed = [ 4  5  7 10 17]\n",
      "curr_n_multi_soma_limbs_cancelled = 0\n",
      "curr_n_same_soma_limbs_cancelled = 0\n",
      "n_errored_lims = 0\n",
      "curr_error_limbs_cancelled_area = []\n",
      "local_floating_meshes = [<trimesh.Trimesh(vertices.shape=(151, 3), faces.shape=(298, 3))>, <trimesh.Trimesh(vertices.shape=(56, 3), faces.shape=(102, 3))>]\n",
      "Already have preprocessed data\n",
      "--- 1) Finished unpacking preprocessed materials: 0.0003476142883300781\n",
      "total_edges = [['S0', 'L0'], ['S0', 'L1'], ['S0', 'L2'], ['S0', 'L3'], ['S0', 'L4']]\n",
      "--- 2) Finished creating neuron connectivity graph: 0.0002446174621582031\n",
      "Having to generate soma_meshes_face_idx because none in preprocessed data\n",
      "--- 3a) Finshed generating soma_meshes_face_idx: 0.14884471893310547\n",
      "Using precomputed volume ratio\n",
      "--- 3b) Finished soma creation: 0.14932703971862793\n",
      "--- 3) Finshed generating soma objects and adding them to concept graph: 3.933906555175781e-05\n",
      "Using already existing limb_mehses_face_idx in preprocessed data \n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f82984208>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f82984ac8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f829842e8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f82984240>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f829841d0>]}\n",
      "--- 4) Finshed generating Limb objects and adding them to concept graph: 1.4765863418579102\n",
      "--- 5) SKIPPING Doing the adaptive mesh correspondence on the meshparty preprocessing ---\n",
      "--- 6) SKIPPING Using the computed_attribute_dict to populate neuron attributes ---\n",
      "self.n_limbs = 5\n",
      "7) Calculating the spines for the neuorn if do not already exist\n",
      "Total time for neuron instance creation = 3.227001667022705\n",
      "\n",
      "\n",
      "Number of seperate neuron objects = 2\n",
      "neuron_list = [<neuron.Neuron object at 0x7f8fa81cbda0>, <neuron.Neuron object at 0x7f8f829844e0>]\n",
      "neuron_list_errored_limbs_area = [[], []]\n",
      "neuron_list_n_multi_soma_errors = [0, 0]\n",
      "neuron_list_n_same_soma_errors = [0, 0]\n",
      "Number of neurons: 2\n",
      "split_success = 0\n",
      "largest_n_faces = 34496\n",
      "largest_volume = 766.8010650893808\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135569218694_0_25_soma_0_split\n",
      "Save time = 113.7709550857544\n",
      "split_success = 0\n",
      "largest_n_faces = 30270\n",
      "largest_volume = 705.7206690703676\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135569218694_0_25_soma_1_split\n",
      "Save time = 50.378124952316284\n",
      "\n",
      "\n",
      " ------ Total time for 864691135569218694 = 750.2318382263184 ------\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135639122747 ----\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Skipping endnode 26 because skeletal distance was 274.83092811053706 and threshold was 2500\n",
      "n_paths_cut = 1\n",
      "using precomputed split suggestions\n",
      "\n",
      "\n",
      "---Working on Splitting Limb 1 with 3 components----\n",
      "\n",
      "\n",
      "----Working on seperate_graph 0----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [521377.4862069  781261.61494253 662151.10344828]---------\n",
      "Starting_edge inside branches_to_conept = [[521347.         781531.         662106.        ]\n",
      " [521377.4862069  781261.61494253 662151.10344828]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [21]\n",
      "printing out current edge:\n",
      "[[521377.4862069  781261.61494253 662151.10344828]\n",
      " [521347.         781531.         662106.        ]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 39 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 26\n",
      "Total time for branches to concept conversion = 0.6293675899505615\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----Working on seperate_graph 1----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [534952. 777809. 655497.]---------\n",
      "Starting_edge inside branches_to_conept = [[534952. 777809. 655497.]\n",
      " [544088. 776929. 661000.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [0]\n",
      "printing out current edge:\n",
      "[[534952. 777809. 655497.]\n",
      " [544088. 776929. 661000.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 28 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 0\n",
      "Total time for branches to concept conversion = 0.2990903854370117\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 2----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [542007.04137931 788106.23103448 718287.61896552]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [542007.04137931 788106.23103448 718287.61896552]---------\n",
      "Starting_edge inside branches_to_conept = [[542007.04137931 788106.23103448 718287.61896552]\n",
      " [542012.27587931 788111.46553448 718292.85346552]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------ Working on Soma 0 -------\n",
      "limb_neighbors = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "limb_neighbors BEFORE error limbs removed = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "limb_neighbors AFTER error limbs removed = [0 1 2 3 4 5 6 7]\n",
      "curr_n_multi_soma_limbs_cancelled = 0\n",
      "curr_n_same_soma_limbs_cancelled = 0\n",
      "n_errored_lims = 0\n",
      "curr_error_limbs_cancelled_area = []\n",
      "local_floating_meshes = [<trimesh.Trimesh(vertices.shape=(152, 3), faces.shape=(300, 3))>, <trimesh.Trimesh(vertices.shape=(125, 3), faces.shape=(243, 3))>, <trimesh.Trimesh(vertices.shape=(120, 3), faces.shape=(238, 3))>, <trimesh.Trimesh(vertices.shape=(94, 3), faces.shape=(188, 3))>, <trimesh.Trimesh(vertices.shape=(85, 3), faces.shape=(164, 3))>, <trimesh.Trimesh(vertices.shape=(68, 3), faces.shape=(132, 3))>, <trimesh.Trimesh(vertices.shape=(65, 3), faces.shape=(126, 3))>, <trimesh.Trimesh(vertices.shape=(63, 3), faces.shape=(122, 3))>, <trimesh.Trimesh(vertices.shape=(61, 3), faces.shape=(118, 3))>, <trimesh.Trimesh(vertices.shape=(60, 3), faces.shape=(116, 3))>, <trimesh.Trimesh(vertices.shape=(58, 3), faces.shape=(110, 3))>, <trimesh.Trimesh(vertices.shape=(56, 3), faces.shape=(108, 3))>, <trimesh.Trimesh(vertices.shape=(55, 3), faces.shape=(106, 3))>, <trimesh.Trimesh(vertices.shape=(53, 3), faces.shape=(102, 3))>, <trimesh.Trimesh(vertices.shape=(53, 3), faces.shape=(102, 3))>, <trimesh.Trimesh(vertices.shape=(50, 3), faces.shape=(103, 3))>, <trimesh.Trimesh(vertices.shape=(49, 3), faces.shape=(102, 3))>]\n",
      "Already have preprocessed data\n",
      "--- 1) Finished unpacking preprocessed materials: 0.00010180473327636719\n",
      "total_edges = [['S0', 'L0'], ['S0', 'L1'], ['S0', 'L2'], ['S0', 'L3'], ['S0', 'L4'], ['S0', 'L5'], ['S0', 'L6'], ['S0', 'L7']]\n",
      "--- 2) Finished creating neuron connectivity graph: 0.000354766845703125\n",
      "Having to generate soma_meshes_face_idx because none in preprocessed data\n",
      "--- 3a) Finshed generating soma_meshes_face_idx: 0.3869352340698242\n",
      "Using precomputed volume ratio\n",
      "--- 3b) Finished soma creation: 0.11199831962585449\n",
      "--- 3) Finshed generating soma objects and adding them to concept graph: 5.3882598876953125e-05\n",
      "Using already existing limb_mehses_face_idx in preprocessed data \n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f11aaa9e8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f11ab3d30>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f16ab12e8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f82711860>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f82cff320>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f83eebba8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f8314e9e8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f832d8048>]}\n",
      "--- 4) Finshed generating Limb objects and adding them to concept graph: 3.01070237159729\n",
      "--- 5) SKIPPING Doing the adaptive mesh correspondence on the meshparty preprocessing ---\n",
      "--- 6) SKIPPING Using the computed_attribute_dict to populate neuron attributes ---\n",
      "self.n_limbs = 8\n",
      "7) Calculating the spines for the neuorn if do not already exist\n",
      "Total time for neuron instance creation = 6.253851652145386\n",
      "\n",
      "\n",
      "Number of seperate neuron objects = 1\n",
      "neuron_list = [<neuron.Neuron object at 0x7f8f85a07a58>]\n",
      "neuron_list_errored_limbs_area = [[]]\n",
      "neuron_list_n_multi_soma_errors = [0]\n",
      "neuron_list_n_same_soma_errors = [0]\n",
      "Number of neurons: 1\n",
      "split_success = 0\n",
      "largest_n_faces = 86707\n",
      "largest_volume = 2336.61182104059\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135639122747_0_25_soma_0_split\n",
      "Save time = 189.18932485580444\n",
      "\n",
      "\n",
      " ------ Total time for 864691135639122747 = 330.5577108860016 ------\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135777371837 ----\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Skipping endnode 2 because skeletal distance was 925.2207858173406 and threshold was 2500\n",
      "n_paths_cut = 3\n",
      "using precomputed split suggestions\n",
      "\n",
      "\n",
      "---Working on Splitting Limb 0 with 4 components----\n",
      "\n",
      "\n",
      "----Working on seperate_graph 0----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [978068. 726096. 894521.]---------\n",
      "Starting_edge inside branches_to_conept = [[977613. 728733. 899259.]\n",
      " [978068. 726096. 894521.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [13]\n",
      "printing out current edge:\n",
      "[[978068. 726096. 894521.]\n",
      " [977613. 728733. 899259.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 19 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 2\n",
      "Total time for branches to concept conversion = 0.3077049255371094\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 1----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [979712. 717451. 883338.]---------\n",
      "Starting_edge inside branches_to_conept = [[979712. 717451. 883338.]\n",
      " [980966. 713660. 882850.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [22]\n",
      "printing out current edge:\n",
      "[[979712. 717451. 883338.]\n",
      " [980966. 713660. 882850.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 55 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 37\n",
      "Total time for branches to concept conversion = 1.1769087314605713\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 2----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [ 962988.60487919  673348.28593548 1102728.49096525]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [ 962988.60487919  673348.28593548 1102728.49096525]---------\n",
      "Starting_edge inside branches_to_conept = [[ 962988.60487919  673348.28593548 1102728.49096525]\n",
      " [ 967043.9632016   687576.06449859 1074191.89607284]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [0]\n",
      "printing out current edge:\n",
      "[[ 962988.60487919  673348.28593548 1102728.49096525]\n",
      " [ 967043.9632016   687576.06449859 1074191.89607284]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 5 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 0\n",
      "Total time for branches to concept conversion = 0.12046098709106445\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 3----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [1002900.  733564.  919139.]---------\n",
      "Starting_edge inside branches_to_conept = [[1002900.  733564.  919139.]\n",
      " [1017570.  711934.  927160.]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [47]\n",
      "printing out current edge:\n",
      "[[1002900.  733564.  919139.]\n",
      " [1017570.  711934.  927160.]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 237 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 50\n",
      "Total time for branches to concept conversion = 4.338263988494873\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---Working on Splitting Limb 6 with 3 components----\n",
      "\n",
      "\n",
      "----Working on seperate_graph 0----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 0, soma_group_idx 0, endpt = [996512.7        736574.48181818 912405.73181818]---------\n",
      "Starting_edge inside branches_to_conept = [[995033.99547067 730888.00058246 907181.1629659 ]\n",
      " [996512.7        736574.48181818 912405.73181818]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 1----\n",
      "\n",
      "\n",
      "---------Working on soma_idx = 1, soma_group_idx 0, endpt = [978374.75  728515.025 892711.65 ]---------\n",
      "Starting_edge inside branches_to_conept = [[978374.75       728515.025      892711.65      ]\n",
      " [978705.83258964 729378.55005556 892738.89517885]]\n",
      "At the start, starting_node (in terms of the skeleton, that shouldn't match the starting edge) = [2]\n",
      "printing out current edge:\n",
      "[[978374.75       728515.025      892711.65      ]\n",
      " [978705.83258964 729378.55005556 892738.89517885]]\n",
      "edge_endpoints_to_process was empty so exiting loop after 9 iterations\n",
      "starting_node in concept map (that should match the starting edge) = 2\n",
      "Total time for branches to concept conversion = 0.36835718154907227\n",
      "\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----Working on seperate_graph 2----\n",
      "There was no starting information so doing to put dummy information and random starting endpoint = [995033.99547067 730888.00058246 907181.1629659 ]\n",
      "\n",
      "\n",
      "---------Working on soma_idx = -1, soma_group_idx -1, endpt = [995033.99547067 730888.00058246 907181.1629659 ]---------\n",
      "Starting_edge inside branches_to_conept = [[ 995033.99547067  730888.00058246  907181.1629659 ]\n",
      " [1017127.58098304  598197.88990245  972162.98427218]]\n",
      "Done generating concept network \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------ Working on Soma 0 -------\n",
      "limb_neighbors = [2, 3, 6, 7, 10, 11, 14]\n",
      "limb_neighbors BEFORE error limbs removed = [2, 3, 6, 7, 10, 11, 14]\n",
      "limb_neighbors AFTER error limbs removed = [ 2  3  6  7 10 11 14]\n",
      "curr_n_multi_soma_limbs_cancelled = 0\n",
      "curr_n_same_soma_limbs_cancelled = 0\n",
      "n_errored_lims = 0\n",
      "curr_error_limbs_cancelled_area = []\n",
      "local_floating_meshes = [<trimesh.Trimesh(vertices.shape=(1053, 3), faces.shape=(1926, 3))>, <trimesh.Trimesh(vertices.shape=(947, 3), faces.shape=(1749, 3))>, <trimesh.Trimesh(vertices.shape=(91, 3), faces.shape=(135, 3))>, <trimesh.Trimesh(vertices.shape=(69, 3), faces.shape=(134, 3))>, <trimesh.Trimesh(vertices.shape=(65, 3), faces.shape=(125, 3))>]\n",
      "Already have preprocessed data\n",
      "--- 1) Finished unpacking preprocessed materials: 0.00010466575622558594\n",
      "total_edges = [['S0', 'L0'], ['S0', 'L1'], ['S0', 'L2'], ['S0', 'L3'], ['S0', 'L4'], ['S0', 'L5'], ['S0', 'L6']]\n",
      "--- 2) Finished creating neuron connectivity graph: 0.0005955696105957031\n",
      "Having to generate soma_meshes_face_idx because none in preprocessed data\n",
      "--- 3a) Finshed generating soma_meshes_face_idx: 0.33624744415283203\n",
      "Using precomputed volume ratio\n",
      "--- 3b) Finished soma creation: 0.15110182762145996\n",
      "--- 3) Finshed generating soma objects and adding them to concept graph: 3.814697265625e-05\n",
      "Using already existing limb_mehses_face_idx in preprocessed data \n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f1758f668>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f127c8710>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f94e74e48>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f82e0b8d0>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f82e3b390>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f94e597b8>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f94e59d68>]}\n",
      "--- 4) Finshed generating Limb objects and adding them to concept graph: 7.287946701049805\n",
      "--- 5) SKIPPING Doing the adaptive mesh correspondence on the meshparty preprocessing ---\n",
      "--- 6) SKIPPING Using the computed_attribute_dict to populate neuron attributes ---\n",
      "self.n_limbs = 7\n",
      "7) Calculating the spines for the neuorn if do not already exist\n",
      "Total time for neuron instance creation = 14.913681268692017\n",
      "\n",
      "\n",
      "------ Working on Soma 1 -------\n",
      "limb_neighbors = [0, 1, 4, 5, 8, 9, 12, 15]\n",
      "limb_neighbors BEFORE error limbs removed = [0, 1, 4, 5, 8, 9, 12, 15]\n",
      "limb_neighbors AFTER error limbs removed = [ 0  1  4  5  8  9 12 15]\n",
      "curr_n_multi_soma_limbs_cancelled = 0\n",
      "curr_n_same_soma_limbs_cancelled = 0\n",
      "n_errored_lims = 0\n",
      "curr_error_limbs_cancelled_area = []\n",
      "local_floating_meshes = [<trimesh.Trimesh(vertices.shape=(127, 3), faces.shape=(249, 3))>, <trimesh.Trimesh(vertices.shape=(100, 3), faces.shape=(196, 3))>, <trimesh.Trimesh(vertices.shape=(96, 3), faces.shape=(188, 3))>, <trimesh.Trimesh(vertices.shape=(85, 3), faces.shape=(160, 3))>, <trimesh.Trimesh(vertices.shape=(73, 3), faces.shape=(154, 3))>, <trimesh.Trimesh(vertices.shape=(70, 3), faces.shape=(140, 3))>, <trimesh.Trimesh(vertices.shape=(68, 3), faces.shape=(132, 3))>, <trimesh.Trimesh(vertices.shape=(56, 3), faces.shape=(108, 3))>, <trimesh.Trimesh(vertices.shape=(55, 3), faces.shape=(108, 3))>]\n",
      "Already have preprocessed data\n",
      "--- 1) Finished unpacking preprocessed materials: 0.0003345012664794922\n",
      "total_edges = [['S0', 'L0'], ['S0', 'L1'], ['S0', 'L2'], ['S0', 'L3'], ['S0', 'L4'], ['S0', 'L5'], ['S0', 'L6'], ['S0', 'L7']]\n",
      "--- 2) Finished creating neuron connectivity graph: 0.00017189979553222656\n",
      "Having to generate soma_meshes_face_idx because none in preprocessed data\n",
      "--- 3a) Finshed generating soma_meshes_face_idx: 0.3200497627258301\n",
      "Using precomputed volume ratio\n",
      "--- 3b) Finished soma creation: 0.15226197242736816\n",
      "--- 3) Finshed generating soma objects and adding them to concept graph: 4.0531158447265625e-05\n",
      "Using already existing limb_mehses_face_idx in preprocessed data \n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f12a8fb70>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f12a8fb00>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f12a8f898>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f12a8ff98>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f12a8f518>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f12a8f668>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8f12a8f748>]}\n",
      "curr_limb_concept_networks= {0: [<networkx_utils.GraphOrderedEdges object at 0x7f8fa37e48d0>]}\n",
      "--- 4) Finshed generating Limb objects and adding them to concept graph: 4.826503038406372\n",
      "--- 5) SKIPPING Doing the adaptive mesh correspondence on the meshparty preprocessing ---\n",
      "--- 6) SKIPPING Using the computed_attribute_dict to populate neuron attributes ---\n",
      "self.n_limbs = 8\n",
      "7) Calculating the spines for the neuorn if do not already exist\n",
      "Total time for neuron instance creation = 10.37593412399292\n",
      "\n",
      "\n",
      "Number of seperate neuron objects = 2\n",
      "neuron_list = [<neuron.Neuron object at 0x7f8fa8cb2208>, <neuron.Neuron object at 0x7f8f9f29a9e8>]\n",
      "neuron_list_errored_limbs_area = [[], []]\n",
      "neuron_list_n_multi_soma_errors = [0, 0]\n",
      "neuron_list_n_same_soma_errors = [0, 0]\n",
      "Number of neurons: 2\n",
      "split_success = 0\n",
      "largest_n_faces = 39917\n",
      "largest_volume = 857.0822110987408\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135777371837_0_25_soma_0_split\n",
      "Save time = 95.32166719436646\n",
      "split_success = 0\n",
      "largest_n_faces = 35760\n",
      "largest_volume = 780.2255935457404\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135777371837_0_25_soma_1_split\n",
      "Save time = 134.41994428634644\n",
      "\n",
      "\n",
      " ------ Total time for 864691135777371837 = 588.3723087310791 ------\n",
      "Populate Done\n",
      "Total time for DecompositionSplit populate = 1669.3108599185944\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "import neuron\n",
    "neuron = reload(neuron)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    DecompositionSplit.populate(reserve_jobs=True, suppress_errors=True)\n",
    "else:\n",
    "    DecompositionSplit.populate(reserve_jobs=True, suppress_errors=False)\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for DecompositionSplit populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
