{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To decompose the multi-somas for splitting\n",
    "using the new decomposition method\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-22 14:42:55,913 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-05-22 14:42:55,915 - settings - Setting database.user to celiib\n",
      "INFO - 2021-05-22 14:42:55,915 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-05-22 14:42:55,964 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-05-22 14:42:55,965 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-05-22 14:42:55,979 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-22 14:42:56,464 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-05-22 14:42:56,504 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-05-22 14:42:56,505 - settings - Setting database.user to celiib\n",
      "INFO - 2021-05-22 14:42:56,506 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-05-22 14:42:56,507 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-05-22 14:42:56,508 - settings - Setting database.user to celiib\n",
      "INFO - 2021-05-22 14:42:56,509 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-05-22 14:42:56,512 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-05-22 14:42:57,036 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty/\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the contains method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-22 14:43:00,161 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-05-22 14:43:00,162 - settings - Setting database.user to celiib\n",
      "INFO - 2021-05-22 14:43:00,163 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-05-22 14:43:00,165 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-05-22 14:43:00,166 - settings - Setting database.user to celiib\n",
      "INFO - 2021-05-22 14:43:00,167 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-05-22 14:43:00,171 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 177 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-22 14:43:00,796 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 8478\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema.external['decomposition'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_source = minnie.Decomposition() & (minnie.AllenProofreading() & dict(month=3,day=18,year=2021)).proj()\n",
    "# key_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import proofreading_utils as pru\n",
    "\n",
    "split_version = 0\n",
    "split_version = 1 #fixed the problem with split from suggestions\n",
    "split_version = 2 # adding all of the non-soma touching pieces to all of the splits\n",
    "\n",
    "verbose = True\n",
    "\n",
    "@schema\n",
    "class DecompositionSplit(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decomposition()\n",
    "    split_index: tinyint unsigned  #the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    split_version: tinyint unsigned  #the version of the splitting algorithm used\n",
    "    ---\n",
    "    multiplicity=null    : tinyint unsigned             # the number of somas found for this base segment\n",
    "    n_splits             : int unsigned                 # the number of cuts required to help split the neuron\n",
    "    split_success        : tinyint unsigned             # the successfulness of the splitting\n",
    "    \n",
    "    n_error_limbs_cancelled : tinyint unsigned     # number of limbs that couldn't be resolved and cancelled out        \n",
    "    n_same_soma_limbs_cancelled : tinyint unsigned     # number of same soma touching limbs that couldn't be resolved and cancelled out\n",
    "    n_multi_soma_limbs_cancelled : tinyint unsigned     # number of multi soma touching limbs that couldn't be resolved and cancelled out        \n",
    "    \n",
    "    error_imbs_cancelled_area=NULL : double            # the total area (in microns^2) of the limbs that was cancelled out because touching the same soma multiple times or multiple somas\n",
    "    error_imbs_cancelled_skeletal_length = NULL : double #the total skeletal length (in microns) of the limbs that were called out because could not be resolved\n",
    "    \n",
    "    split_results: longblob #will store the results of how to split the limbs of neuron objects from original neuron\n",
    "    decomposition: <decomposition>\n",
    "    \n",
    "    \n",
    "    n_vertices           : int unsigned                 # number of vertices\n",
    "    n_faces              : int unsigned                 # number of faces\n",
    "    n_not_processed_soma_containing_meshes : int unsigned  #the number of meshes with somas that were not processed\n",
    "    n_error_limbs: int #the number of limbs that are touching multiple somas or 1 soma in multiple places\n",
    "    n_same_soma_multi_touching_limbs: int # number of limbs that touch the same soma multiple times\n",
    "    n_multi_soma_touching_limbs: int # number of limbs that touch multiple somas\n",
    "    n_somas: int #number of soma meshes detected\n",
    "    max_soma_n_faces:  int unsigned                 # The largest number of faces of the somas\n",
    "    max_soma_volume:  int unsigned                 # The largest volume of the somas the (volume in billions (10*9 nm^3))\n",
    "    n_limbs: int\n",
    "    n_branches: int\n",
    "    max_limb_n_branches=NULL:int\n",
    "    \n",
    "    skeletal_length=NULL: double\n",
    "    max_limb_skeletal_length=NULL:double\n",
    "    median_branch_length=NULL:double #gives information on average skeletal length to next branch point\n",
    "    \n",
    "    \n",
    "    width_median=NULL: double #median width from mesh center without spines removed\n",
    "    width_no_spine_median=NULL: double #median width from mesh center with spines removed\n",
    "    width_90_perc=NULL: double # 90th percentile for width without spines removed\n",
    "    width_no_spine_90_perc=NULL: double  # 90th percentile for width with spines removed\n",
    "    \n",
    "    \n",
    "    n_spines: bigint\n",
    "\n",
    "    spine_density=NULL: double # n_spines/ skeletal_length\n",
    "    spines_per_branch=NULL: double\n",
    "    \n",
    "    skeletal_length_eligible=NULL: double # the skeletal length for all branches searched for spines\n",
    "    n_spine_eligible_branches=NULL: int # the number of branches that were checked for spines because passed width threshold\n",
    "    \n",
    "    spine_density_eligible=NULL:double # n_spines/skeletal_length_eligible\n",
    "    spines_per_branch_eligible=NULL:double # n_spines/n_spine_eligible_branches\n",
    "    \n",
    "    total_spine_volume=NULL: double # the sum of all spine volume\n",
    "    spine_volume_median=NULL: double # median of the spine volume for those spines with able to calculate volume\n",
    "    spine_volume_density=NULL: double #total_spine_volume/skeletal_length\n",
    "    spine_volume_density_eligible=NULL: double #total_spine_volume/skeletal_length_eligible\n",
    "    spine_volume_per_branch_eligible=NULL: double #total_spine_volume/n_spine_eligible_branches\n",
    "    \n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \"\"\"\n",
    "                             \n",
    "    \n",
    "    ''' Old keysource used for inhibitory excitatory check\n",
    "    classified_table = (minnie.BaylorManualCellType() &\n",
    "                        'nucleus_version=3' & \n",
    "                        \"(cell_type = 'excitatory') or  (cell_type = 'inhibitory')\")\n",
    "    \n",
    "    key_source = ((minnie.Decomposition & \n",
    "                (minnie.NeuronSplitSuggestions.proj()) & \n",
    "                (classified_table.proj()) \n",
    "                & f\"n_somas<{max_n_somas}\" & \"n_error_limbs>0\"))'''\n",
    "    \n",
    "    # This keysource acounts that you could have more than 1 possible soma but not a significant limb connecting them (no error limbs)\n",
    "    key_source = minnie.Decomposition() & \"n_somas>1 OR n_error_limbs>0\" & (minnie.AllenProofreading() \n",
    "                                                                            & minnie.AllenProofreadingCurrentDate()).proj()\n",
    "    \n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode for process:\n",
    "\n",
    "        1) Get the segment id from the key\n",
    "        2) Get the decomposed neurong object from Decomposition table\n",
    "        3) Run the multi_soma split suggestions algorithm\n",
    "        4) Get the number of splits required for this neuron\n",
    "        5) Split the neuron into a list of neuron objects\n",
    "        6) For each neuron object in the list:\n",
    "        - get the number of errored limbs (to indicate the success type)\n",
    "        - Change the description to include the multiplicity\n",
    "        - Compute the information on the largest soma faces and volume\n",
    "        - Save the neuron object to the external\n",
    "        - Add the new write key to a list to commit \n",
    "        7) Write all of the keys \n",
    "        \"\"\"\n",
    "        \n",
    "        whole_pass_time = time.time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 1) Get the segment id from the key\n",
    "        segment_id = key[\"segment_id\"]\n",
    "        print(f\"\\n\\n\\n---- Working on Neuron {key['segment_id']} ----\")\n",
    "        \n",
    "        \n",
    "        # 2) Get the decomposed neuron object from Decomposition table and the split suggestions\n",
    "        neuron_obj_path = (minnie.Decomposition & key).fetch1(\"decomposition\")\n",
    "        neuron_obj = du.filepath_to_neuron_obj(neuron_obj_path)\n",
    "        \n",
    "        \"\"\" Old way that downloaded from another table\n",
    "        # 3) Retrieve the multi soma suggestions\n",
    "        split_results = (minnie.NeuronSplitSuggestions & key).fetch1(\"split_results\")\n",
    "        \"\"\"\n",
    "        #3) Calculated the split results\n",
    "        split_results = pru.multi_soma_split_suggestions(neuron_obj,plot_intermediates=False)\n",
    "        \n",
    "        # 4) Get the number of splits required for this neuron\n",
    "        n_paths_cut = pru.get_n_paths_cut(split_results)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"n_paths_cut = {n_paths_cut}\")\n",
    "            \n",
    "            \n",
    "        # 5) Split the neuron into a list of neuron objects\n",
    "        (neuron_list,\n",
    "        neuron_list_errored_limbs_area,\n",
    "         neuron_list_errored_limbs_skeletal_length,\n",
    "        neuron_list_n_multi_soma_errors,\n",
    "        neuron_list_n_same_soma_errors) = pru.split_neuron(neuron_obj,\n",
    "                        limb_results=split_results,\n",
    "                                       verbose=verbose,\n",
    "                                        return_error_info=True\n",
    "                                            )\n",
    "        \n",
    "        print(f\"neuron_list = {neuron_list}\")\n",
    "        print(f\"neuron_list_errored_limbs_area = {neuron_list_errored_limbs_area}\")\n",
    "        print(f\"neuron_list_n_multi_soma_errors = {neuron_list_n_multi_soma_errors}\")\n",
    "        print(f\"neuron_list_n_same_soma_errors = {neuron_list_n_same_soma_errors}\")\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Number of neurons: {len(neuron_list)}\")\n",
    "        \n",
    "        neuron_entries = []\n",
    "        for neuron_idx in range(len(neuron_list)):\n",
    "            \n",
    "            \"\"\"\n",
    "            # 6) For each neuron object in the list:\n",
    "            # - get the number of errored limbs (to indicate the success type)\n",
    "            # - Compute the information on the largest soma faces and volume\n",
    "            # - Save the neuron object to the external\n",
    "            # - Add the new write key to a list to commit \n",
    "            \"\"\"\n",
    "            n = neuron_list[neuron_idx]\n",
    "            \n",
    "            error_imbs_cancelled_area = neuron_list_errored_limbs_area[neuron_idx]\n",
    "            error_imbs_cancelled_skeletal_length = neuron_list_errored_limbs_skeletal_length[neuron_idx]\n",
    "            n_multi_soma_limbs_cancelled = neuron_list_n_multi_soma_errors[neuron_idx]\n",
    "            n_same_soma_limbs_cancelled = neuron_list_n_same_soma_errors[neuron_idx]\n",
    "            \n",
    "            \n",
    "            #for n in neuron_list:\n",
    "            #     nviz.visualize_neuron(n,\n",
    "            #                          limb_branch_dict=\"all\")\n",
    "\n",
    "            # - get the number of errored limbs (to indicate the success type)\n",
    "            if n.n_error_limbs == 0:\n",
    "                split_success = 0\n",
    "            elif n.multi_soma_touching_limbs == 0:\n",
    "                split_successs = 1\n",
    "            elif n.same_soma_multi_touching_limbs == 0:\n",
    "                split_success = 2\n",
    "            else:\n",
    "                split_success = 3\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"split_success = {split_success}\")\n",
    "\n",
    "            # - Compute the information on the largest soma faces and volume\n",
    "            soma_volumes = [n[k].volume/1000000000 for k in n.get_soma_node_names()] \n",
    "            soma_n_faces = [len(n[k].mesh.faces) for k in n.get_soma_node_names()] \n",
    "\n",
    "            largest_n_faces = np.max(soma_n_faces)\n",
    "            largest_volume = np.max(soma_volumes)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"largest_n_faces = {largest_n_faces}\")\n",
    "                print(f\"largest_volume = {largest_volume}\")\n",
    "\n",
    "            if \"split\" not in n.description:\n",
    "                n.description += \"_soma_0_split\"\n",
    "                \n",
    "            #6) Save the file in a certain location\n",
    "            if True:\n",
    "                save_time = time.time()\n",
    "                ret_file_path = n.save_compressed_neuron(output_folder=str(du.get_decomposition_path()),\n",
    "                                                  return_file_path=True,\n",
    "                                                 export_mesh=False,\n",
    "                                                 suppress_output=True)\n",
    "\n",
    "                ret_file_path_str = str(ret_file_path.absolute()) + \".pbz2\"\n",
    "                print(f\"Save time = {time.time() - save_time}\")\n",
    "            else:\n",
    "                print(\"Storing a dummy value for neuron\")\n",
    "                ret_file_path_str = \"dummy\"\n",
    "\n",
    "\n",
    "\n",
    "            #7) Pass stats and file location to insert\n",
    "            new_key = dict(key,\n",
    "                           split_index = neuron_idx,\n",
    "                           split_version = split_version,\n",
    "                           \n",
    "                           multiplicity=len(neuron_list),\n",
    "\n",
    "                           n_splits = n_paths_cut,\n",
    "                           split_success = split_success,\n",
    "                           \n",
    "                           n_error_limbs_cancelled = len(error_imbs_cancelled_area),\n",
    "                           \n",
    "                           n_multi_soma_limbs_cancelled =n_multi_soma_limbs_cancelled,\n",
    "                           n_same_soma_limbs_cancelled = n_same_soma_limbs_cancelled,\n",
    "                           error_imbs_cancelled_area = np.round(np.sum(error_imbs_cancelled_area),4),\n",
    "                           error_imbs_cancelled_skeletal_length = np.round(np.sum(error_imbs_cancelled_skeletal_length)/1000,4),\n",
    "                           \n",
    "                           split_results=split_results,\n",
    "\n",
    "                           max_soma_n_faces = largest_n_faces,\n",
    "                           max_soma_volume = largest_volume,\n",
    "\n",
    "\n",
    "                           decomposition=ret_file_path_str,\n",
    "                           n_vertices=len(n.mesh.vertices),\n",
    "                           n_faces=len(n.mesh.faces),\n",
    "                           run_time=np.round(time.time() - whole_pass_time,4)\n",
    "                          )\n",
    "\n",
    "            stats_dict = n.neuron_stats()\n",
    "            new_key.update(stats_dict)\n",
    "            \n",
    "            attributes_to_remove = [\"axon_length\",\"axon_area\",\"n_boutons\"]\n",
    "            \n",
    "            for k in attributes_to_remove:\n",
    "                del new_key[k]\n",
    "            \n",
    "            neuron_entries.append(new_key)\n",
    "\n",
    "        \n",
    "        self.insert(neuron_entries, allow_direct_insert=True, skip_duplicates=True)\n",
    "        \n",
    "        print(f\"\\n\\n ------ Total time for {segment_id} = {time.time() - whole_pass_time} ------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# du.restrict_jobs_table_by_error_substring(curr_table,\"KeyboardInterrupt\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>job reservation table for `microns_minnie65_02`</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">table_name</p>\n",
       "                                <span class=\"djtooltiptext\">className of the table</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">key_hash</p>\n",
       "                                <span class=\"djtooltiptext\">key hash</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">if tuple is missing, the job is available</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">key</p>\n",
       "                                <span class=\"djtooltiptext\">structure containing the key</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_message</p>\n",
       "                                <span class=\"djtooltiptext\">error message returned if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_stack</p>\n",
       "                                <span class=\"djtooltiptext\">error stack if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">user</p>\n",
       "                                <span class=\"djtooltiptext\">database user</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">host</p>\n",
       "                                <span class=\"djtooltiptext\">system hostname</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">pid</p>\n",
       "                                <span class=\"djtooltiptext\">system process id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">connection_id</p>\n",
       "                                <span class=\"djtooltiptext\">connection_id()</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">timestamp</p>\n",
       "                                <span class=\"djtooltiptext\">automatic timestamp</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>__decomposition_split</td>\n",
       "<td>5e8b61293856de161f7df946e85e2299</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>Exception: after loop in directed concept graph, not all nodes have incoming edges (except starter node)</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.145</td>\n",
       "<td>at-node18</td>\n",
       "<td>1</td>\n",
       "<td>444416</td>\n",
       "<td>2021-05-21 15:46:01</td></tr><tr><td>__decomposition_split</td>\n",
       "<td>66499ab7ce9027faac7458a2c3342b82</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>KeyboardInterrupt</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.83</td>\n",
       "<td>at-compute004</td>\n",
       "<td>167581</td>\n",
       "<td>446861</td>\n",
       "<td>2021-05-22 09:43:31</td></tr><tr><td>__decomposition_split</td>\n",
       "<td>9e882857c8997633d321de790e884319</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>IndexError: list index out of range</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.146</td>\n",
       "<td>at-node19</td>\n",
       "<td>1</td>\n",
       "<td>444398</td>\n",
       "<td>2021-05-21 15:10:47</td></tr><tr><td>__decomposition_split</td>\n",
       "<td>f90ef88483b19f9b693412c09804c250</td>\n",
       "<td>error</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>IndexError: list index out of range</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>celiib@10.28.0.165</td>\n",
       "<td>at-node38</td>\n",
       "<td>1</td>\n",
       "<td>444422</td>\n",
       "<td>2021-05-21 15:29:13</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 4</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*table_name    *key_hash      status     key        error_message  error_stac user           host           pid        connection_id  timestamp     \n",
       "+------------+ +------------+ +--------+ +--------+ +------------+ +--------+ +------------+ +------------+ +--------+ +------------+ +------------+\n",
       "__decompositio 5e8b61293856de error      =BLOB=     Exception: aft =BLOB=     celiib@10.28.0 at-node18      1          444416         2021-05-21 15:\n",
       "__decompositio 66499ab7ce9027 error      =BLOB=     KeyboardInterr =BLOB=     celiib@10.28.0 at-compute004  167581     446861         2021-05-22 09:\n",
       "__decompositio 9e882857c89976 error      =BLOB=     IndexError: li =BLOB=     celiib@10.28.0 at-node19      1          444398         2021-05-21 15:\n",
       "__decompositio f90ef88483b19f error      =BLOB=     IndexError: li =BLOB=     celiib@10.28.0 at-node38      1          444422         2021-05-21 15:\n",
       " (Total: 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 715\n"
     ]
    }
   ],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__decomposition_split'\")\n",
    "(curr_table)#.delete()# & \"status='error'\")\n",
    "#curr_table.delete()\n",
    "#(curr_table & \"error_message = 'ValueError: need at least one array to concatenate'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-22 14:43:12,445 - autopopulate - Found 4 keys to populate\n",
      "INFO - 2021-05-22 14:43:12,461 - connection - Transaction started\n",
      "INFO - 2021-05-22 14:43:12,463 - autopopulate - Populating: {'segment_id': 864691135866531094, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': Decimal('30.00'), 'process_version': 7, 'index': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135866531094 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-22 14:43:31,042 - connection - Transaction cancelled. Rolling back ...\n",
      "ERROR - 2021-05-22 14:43:31,336 - ultratb - Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO - 2021-05-22 14:43:31,344 - ultratb - \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n",
      "ERROR - 2021-05-22 14:43:31,447 - ultratb - Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO - 2021-05-22 14:43:31,458 - ultratb - \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-a82ef80a41f6>\", line 15, in <module>\n",
      "    DecompositionSplit.populate(reserve_jobs=True, suppress_errors=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/autopopulate.py\", line 159, in populate\n",
      "    make(dict(key))\n",
      "  File \"<ipython-input-10-60ac8e861627>\", line 122, in make\n",
      "    neuron_obj = du.filepath_to_neuron_obj(neuron_obj_path)\n",
      "  File \"/meshAfterParty/meshAfterParty/datajoint_utils.py\", line 1237, in filepath_to_neuron_obj\n",
      "    dec_mesh = fetch_segment_id_mesh(segment_id)\n",
      "  File \"/meshAfterParty/meshAfterParty/datajoint_utils.py\", line 750, in fetch_segment_id_mesh\n",
      "    new_mesh = (minnie.Decimation() & key).fetch1(\"mesh\")\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 245, in __call__\n",
      "    result = self._expression.proj(*attributes).fetch(squeeze=squeeze, download_path=download_path)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 203, in __call__\n",
      "    ret[name] = list(map(partial(get, heading[name]), ret[name]))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 54, in _get\n",
      "    return adapt(extern.download_filepath(uuid.UUID(bytes=data))[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/external.py\", line 264, in download_filepath\n",
      "    file_exists = Path(local_filepath).is_file() and uuid_from_file(local_filepath) == contents_hash\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/hash.py\", line 39, in uuid_from_file\n",
      "    return uuid_from_stream(Path(filepath).open(\"rb\"), init_string=init_string)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/hash.py\", line 29, in uuid_from_stream\n",
      "    chunk = stream.read(chunk_size)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-a82ef80a41f6>\", line 15, in <module>\n",
      "    DecompositionSplit.populate(reserve_jobs=True, suppress_errors=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/autopopulate.py\", line 159, in populate\n",
      "    make(dict(key))\n",
      "  File \"<ipython-input-10-60ac8e861627>\", line 122, in make\n",
      "    neuron_obj = du.filepath_to_neuron_obj(neuron_obj_path)\n",
      "  File \"/meshAfterParty/meshAfterParty/datajoint_utils.py\", line 1237, in filepath_to_neuron_obj\n",
      "    dec_mesh = fetch_segment_id_mesh(segment_id)\n",
      "  File \"/meshAfterParty/meshAfterParty/datajoint_utils.py\", line 750, in fetch_segment_id_mesh\n",
      "    new_mesh = (minnie.Decimation() & key).fetch1(\"mesh\")\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 245, in __call__\n",
      "    result = self._expression.proj(*attributes).fetch(squeeze=squeeze, download_path=download_path)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 203, in __call__\n",
      "    ret[name] = list(map(partial(get, heading[name]), ret[name]))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 54, in _get\n",
      "    return adapt(extern.download_filepath(uuid.UUID(bytes=data))[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/external.py\", line 264, in download_filepath\n",
      "    file_exists = Path(local_filepath).is_file() and uuid_from_file(local_filepath) == contents_hash\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/hash.py\", line 39, in uuid_from_file\n",
      "    return uuid_from_stream(Path(filepath).open(\"rb\"), init_string=init_string)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/hash.py\", line 29, in uuid_from_stream\n",
      "    chunk = stream.read(chunk_size)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - 2021-05-22 14:43:31,621 - ultratb - Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO - 2021-05-22 14:43:31,628 - ultratb - \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-a82ef80a41f6>\", line 15, in <module>\n",
      "    DecompositionSplit.populate(reserve_jobs=True, suppress_errors=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/autopopulate.py\", line 159, in populate\n",
      "    make(dict(key))\n",
      "  File \"<ipython-input-10-60ac8e861627>\", line 122, in make\n",
      "    neuron_obj = du.filepath_to_neuron_obj(neuron_obj_path)\n",
      "  File \"/meshAfterParty/meshAfterParty/datajoint_utils.py\", line 1237, in filepath_to_neuron_obj\n",
      "    dec_mesh = fetch_segment_id_mesh(segment_id)\n",
      "  File \"/meshAfterParty/meshAfterParty/datajoint_utils.py\", line 750, in fetch_segment_id_mesh\n",
      "    new_mesh = (minnie.Decimation() & key).fetch1(\"mesh\")\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 245, in __call__\n",
      "    result = self._expression.proj(*attributes).fetch(squeeze=squeeze, download_path=download_path)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 203, in __call__\n",
      "    ret[name] = list(map(partial(get, heading[name]), ret[name]))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/fetch.py\", line 54, in _get\n",
      "    return adapt(extern.download_filepath(uuid.UUID(bytes=data))[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/external.py\", line 264, in download_filepath\n",
      "    file_exists = Path(local_filepath).is_file() and uuid_from_file(local_filepath) == contents_hash\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/hash.py\", line 39, in uuid_from_file\n",
      "    return uuid_from_stream(Path(filepath).open(\"rb\"), init_string=init_string)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/datajoint/hash.py\", line 29, in uuid_from_stream\n",
      "    chunk = stream.read(chunk_size)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "import neuron\n",
    "neuron = reload(neuron)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    DecompositionSplit.populate(reserve_jobs=True, suppress_errors=True)\n",
    "else:\n",
    "    DecompositionSplit.populate(reserve_jobs=True, suppress_errors=False)\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for DecompositionSplit populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
