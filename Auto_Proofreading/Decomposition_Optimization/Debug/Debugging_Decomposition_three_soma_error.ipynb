{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To Debug the Decomposition\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:21:21,382 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-12 00:21:21,384 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-12 00:21:21,385 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-12 00:21:21,403 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-12 00:21:21,404 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-12 00:21:21,416 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:21:21,667 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:21:21,746 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-12 00:21:21,747 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-12 00:21:21,747 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-12 00:21:21,749 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 6 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:21:22,000 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 30)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "#time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 2596\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment That we are checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id=864691134947393276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Working on 864691134947393276-------\n",
      "somas = [[<trimesh.Trimesh(vertices.shape=(19028, 3), faces.shape=(37767, 3))>], array([545.9343]), array([0.818])]\n"
     ]
    }
   ],
   "source": [
    "#1) Get the segment id from the key\n",
    "description = \"0_25\"\n",
    "print(f\"\\n\\n----- Working on {segment_id}-------\")\n",
    "global_start = time.time()\n",
    "\n",
    "#2) Get the decimated mesh\n",
    "current_neuron_mesh = du.fetch_segment_id_mesh(segment_id)\n",
    "\n",
    "#3) Get the somas info *************************** Need to change this when actually run *******************\n",
    "somas = du.get_soma_mesh_list(segment_id) \n",
    "print(f\"somas = {somas}\")\n",
    "#4) Run the preprocessing\n",
    "\n",
    "\n",
    "total_neuron_process_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting the glia and nuclei faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glia_faces,nuclei_faces = du.get_segment_glia_nuclei_faces(segment_id,return_empty_list=True)\n",
    "meshes_to_subtract = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No nuclie meshes to plot\n"
     ]
    }
   ],
   "source": [
    "nuclei_mesh = current_neuron_mesh.submesh([nuclei_faces],append=True,repair=False)\n",
    "if type(nuclei_mesh) is type(trimesh.Trimesh):\n",
    "    nviz.plot_objects(nuclei_mesh)\n",
    "    meshes_to_subtract.append(nuclei_mesh)\n",
    "else:\n",
    "    print(\"No nuclie meshes to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcdbf8906494d04ad4f55802479350b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glia_mesh = current_neuron_mesh.submesh([glia_faces],append=True,repair=False)\n",
    "if tu.is_mesh(glia_mesh):\n",
    "    nviz.plot_objects(glia_mesh)\n",
    "    meshes_to_subtract.append(glia_mesh)\n",
    "else:\n",
    "    print(\"No glias meshes to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19a01afabd147e79ab36a22c092284e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(tu.subtract_mesh(current_neuron_mesh,meshes_to_subtract),\n",
    "                 meshes=somas[0],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking that somas are already mapped to original mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1565897 1939176 1939177 ... 1605344 1605412 1605820]\n"
     ]
    }
   ],
   "source": [
    "for sm in somas[0]:\n",
    "    ret_info = tu.original_mesh_faces_map(original_mesh=current_neuron_mesh,\n",
    "                              submesh=sm,\n",
    "                              exact_match = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the decomposition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing_vp2 as pre\n",
    "pre = reload(pre)\n",
    "import skeleton_utils as sk\n",
    "sk = reload(sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Beginning preprocessing of 864691134947393276---\n",
      "--- 0) Having to preprocess the Neuron becuase no preprocessed data\n",
      "Please wait this could take a while.....\n",
      "Skipping the hole filling\n",
      "use_meshafterparty = True\n",
      "Using pre-computed somas: soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(19028, 3), faces.shape=(37767, 3))>]\n",
      "Soma List = [<trimesh.Trimesh(vertices.shape=(19028, 3), faces.shape=(37767, 3))>]\n",
      "soma_mesh_list_centers = [array([604782.36627076, 817703.83371873, 923126.39603741])]\n",
      "Getting Glia and Nuclei Pieces Subtracted Away 0.5511465072631836\n",
      " Splitting mesh after soma cancellation 1.4626708030700684\n",
      "# of split_meshes = 19\n",
      " Containing Mesh Indices 0.0450594425201416\n",
      " non_soma_touching_meshes 2.193450927734375e-05\n",
      "There were 18 pieces found after size threshold\n",
      " Finding inside pieces and non_soma_touching meshes 1.3059144020080566\n",
      "\n",
      "-----Before filtering away multiple disconneted soma pieces-----\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "Number of not_processed_soma_containing_meshes = 0\n",
      "\n",
      "-----After filtering away multiple disconneted soma pieces-----\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      " Filtering Away Disconnected Soma Pieces 0.0005977153778076172\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "Total time for Subtract Soma and Original_mesh_faces_map for somas= 0.6426849365234375\n",
      "new_floating_pieces = []\n",
      "Total time for sig_non_soma_pieces= 5.782944917678833\n",
      "Total time for split= 9.5367431640625e-07\n",
      "Total time for mesh_pieces_connectivity= 12.014845848083496\n",
      "# of insignificant_limbs = 2 with trimesh : [<trimesh.Trimesh(vertices.shape=(212, 3), faces.shape=(395, 3))>, <trimesh.Trimesh(vertices.shape=(18, 3), faces.shape=(27, 3))>]\n",
      "# of not_processed_soma_containing_meshes = 0 with trimesh : []\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 0 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [603951.8 807448.8 923483.1]\n",
      "Time for preparing soma vertices and root: 0.00022459030151367188\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899e6948560843529002fc7ca33f741d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=295340.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 11.883023023605347\n",
      "connecting at the root\n",
      "branches_touching_root = [98]\n",
      "length of Graph = 36893\n",
      "Working on path [3129. 3161. 3184. 3208. 3226. 3246. 3264.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [36893.  3315.  3349.  3384.  3418.  3452.  3490.  3502.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [36894.  3517.  3536.  3565.  3593.  3634.  3645.  3650.]\n",
      "path_degrees = [5, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [24841. 24843. 24848. 24850. 24855. 24857.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [28920. 28946. 28972. 28999. 29027. 29029.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [30188. 30215. 30242. 30265. 30274.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [31389. 31403. 31417. 31432. 31446.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "After combining close endpoints max(kept_branches_idx) = 98, len(kept_branches_idx) = 92\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.005023365876131107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af85d338fa14128ba12cd23428d228b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748fe7cd270a4ccf9bc5c7c0be4cd16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=92.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 36.650211572647095\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [3653, 8014, 6019, 5215, 3501, 7144, 7687, 9329, 8784, 41183, 20058, 2435, 22813, 4223, 8352, 28363, 16279, 17717, 20936, 2616, 22928, 14406, 15790]\n",
      "mesh_large_connectivity: 1.1729693412780762\n",
      "Finding MAP candidates connected components: 0.0002548694610595703\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 1.0829370021820068\n",
      "Grouping MP Sublimbs by Graph: 0.1690843105316162\n",
      "Divinding into MP and MAP pieces: 1.1920928955078125e-06\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.020974397659301758\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_589689.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 25.804481029510498\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(73209, 3), faces.shape=(146422, 3))>, <trimesh.Trimesh(vertices.shape=(9720, 3), faces.shape=(19436, 3))>, <trimesh.Trimesh(vertices.shape=(3481, 3), faces.shape=(6958, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n",
      "min_edge_length = 75\n",
      "min_edge_length = 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab469a1dbda4fc181a6ef1e2027bf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0393bc1aa78d434580e9fbfdbd4df1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.22408676147460938\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 40.686333656311035\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 3.421139717102051\n",
      "sbv[0].reshape(-1,3) = [[603951.8 807448.8 923483.1]]\n",
      "closest_sk_pt_coord BEFORE = [602549. 806993. 924750.]\n",
      "current_skeleton.shape = (6330, 2, 3)\n",
      "node_for_stitch = 4980: [602549. 806993. 924750.]\n",
      "node_for_stitch AFTER = 4980: [602549. 806993. 924750.]\n",
      "possible_node_loc = [   0  143  181  219  232  289  312  333  394  429  433  493  626  708\n",
      "  730  739  752  898  918  962 1057 1065 1117 1225 1238 1242 1283 1390\n",
      " 1438 1439 1517 1555 1572 1592 1621 1641 1686 1693 1735 1784 1823 1828\n",
      " 2009 2139 2249 2401 2477 2488 2497 2584 2673 2678 2962 3025 3045 3115\n",
      " 3127 3214 3245 3382 3403 3425 3431 3506 3590 3823 3856 4147 4205 4295\n",
      " 4312 4449 4453 4463 4510 4592 4676 4683 4717 4823 4883 4886 4893 4980\n",
      " 4996 4998 5110 5195 5225 5230 5268 5292 5336 5390 5409 5454 5515 5564\n",
      " 5593 5605 5621 5651 5710 5744 5754 5788 5815 5829 5887 5902 5912 5931\n",
      " 5958 5964 6009 6039 6091 6110 6143 6150 6223 6256 6330]\n",
      "possible_node_loc AFTER = [   0  143  181  219  232  289  312  333  394  429  433  493  626  708\n",
      "  730  739  752  898  918  962 1057 1065 1117 1225 1238 1242 1283 1390\n",
      " 1438 1439 1517 1555 1572 1592 1621 1641 1686 1693 1735 1784 1823 1828\n",
      " 2009 2139 2249 2401 2477 2488 2497 2584 2673 2678 2962 3025 3045 3115\n",
      " 3127 3214 3245 3382 3403 3425 3431 3506 3590 3823 3856 4147 4205 4295\n",
      " 4312 4449 4453 4463 4510 4592 4676 4683 4717 4823 4883 4886 4893 4980\n",
      " 4996 4998 5110 5195 5225 5230 5268 5292 5336 5390 5409 5454 5515 5564\n",
      " 5593 5605 5621 5651 5710 5744 5754 5788 5815 5829 5887 5902 5912 5931\n",
      " 5958 5964 6009 6039 6091 6110 6143 6150 6223 6256 6330]\n",
      "curr_shortest_path = [4980]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [602549. 806993. 924750.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[602549., 806993., 924750.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 7.037015438079834\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_7268.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_7268_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_674717.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_7268.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_7268_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_674717.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 55\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[ 602549.  806993.  924750.]\n",
      " [ 565837.  808651. 1049280.]\n",
      " [ 595870.  683856.  897102.]\n",
      " [ 596465.  692491.  897630.]\n",
      " [ 600495.  738130.  874043.]\n",
      " [ 604508.  711815.  894301.]]\n",
      "Number of end_nodes BEFORE filtering = 123\n",
      "all_single_nodes_to_eliminate = [83, 28, 67, 70, 76, 88]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1006f9c3e26c4aa29a66629351730404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (5865, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 109.36477565765381\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_55590.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_55590_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_415092.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_55590.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_55590_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_415092.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63295dbe3034069a3705be8b43b725a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 49.864224672317505\n",
      "mesh_correspondence_first_pass: 49.864256620407104\n",
      "Limb decomposed into 23 branches\n",
      "divided_skeleton_graph_recovered = (5865, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (5865, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (22, 23)\n",
      "empty_indices % = 0.18900637092571737\n",
      " conflict_indices % = 0.02475079426448587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9994a7598b1c46fa8fb8dbecd9975bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=535.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18eb2ddb396847d7b84e49ebe5f433b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4198dd6a61494d6786f8f69f75aba0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 182.69436240196228\n",
      "correspondence_1_to_1: 23.44433093070984\n",
      "Total time for MAP sublimb processing 182.69450902938843\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.008188962936401367\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0017576217651367188\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0010857582092285156\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "---- Working on MP Decomposition #3 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.003316164016723633\n",
      "Do Not Need to Fix MP Decomposition 3 so just continuing\n",
      "---- Working on MP Decomposition #4 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0016160011291503906\n",
      "Do Not Need to Fix MP Decomposition 4 so just continuing\n",
      "---- Working on MP Decomposition #5 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0009133815765380859\n",
      "Do Not Need to Fix MP Decomposition 5 so just continuing\n",
      "---- Working on MP Decomposition #6 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001260995864868164\n",
      "Do Not Need to Fix MP Decomposition 6 so just continuing\n",
      "---- Working on MP Decomposition #7 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.004011631011962891\n",
      "Do Not Need to Fix MP Decomposition 7 so just continuing\n",
      "---- Working on MP Decomposition #8 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.002193450927734375\n",
      "Do Not Need to Fix MP Decomposition 8 so just continuing\n",
      "---- Working on MP Decomposition #9 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0012903213500976562\n",
      "Do Not Need to Fix MP Decomposition 9 so just continuing\n",
      "---- Working on MP Decomposition #10 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0006692409515380859\n",
      "Do Not Need to Fix MP Decomposition 10 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "sk_conn = [7]\n",
      "conn = [7]\n",
      "winning_vertex = [603135.74903851 742788.78554442 889730.81694418]\n",
      "MP_branches_with_stitch_point = [7]\n",
      "MAP_branches_with_stitch_point = [16]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418e167071b543d6883169cf6d701104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3668106287973062\n",
      " conflict_indices % = 0.004172461752433936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dc047c8d5a4c7fa62d327ede2f8085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74f131dafee47d98064ac41b42c70b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b711ba8fde4352a5bff81dee997354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.5597597597597598\n",
      " conflict_indices % = 0.0013167013167013166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6accdffa99461d8001814b51837d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f0fb3b746a470e9285978790c776be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [7]\n",
      "MP_branches_for_correspondence = [7]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [600681.60681221 705205.74853506 896089.19052625]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [13]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d3fa018b8e444fad9fa22f4636e4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.10519967837041008\n",
      " conflict_indices % = 0.006566604127579738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa6ab927f064bc880f1c186e920ed5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a52f047e48c432094095f5b172ff266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a6204cde2d495f91b06d6488bf8d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.16701040592481484\n",
      " conflict_indices % = 0.03074903909252836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889cce6289af45cea7a7294fb8dab7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d712eaa18aaf4975adec76f7e98ef056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [589888.46394605 379178.23861797 923119.35177624]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [5]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905f53b8a2f04ff2bf05efca3c73d3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.28636548636548637\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9878ab5aae44437d9d01405886653983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5b0d196fca453aa2d934dff2c4621f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (3, 0) connection-----\n",
      "sk_conn = [11]\n",
      "conn = [11]\n",
      "winning_vertex = [562654.31349009 798124.16269965 977558.71613419]\n",
      "MP_branches_with_stitch_point = [11]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a71ad757b0f4390a04d548bbf6d553b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.15494061157442507\n",
      " conflict_indices % = 0.0006317917614354309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbb29c956894ea29d24c44e5c4b0b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c711659b84440b83cc8cd892a81329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5de7677d9f41229281ce699f0637ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.16584662790119775\n",
      " conflict_indices % = 0.003702599274389941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a315761984284dc3a941d8735958a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e068ef16801e42acb0deb8fdae64d658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [11]\n",
      "MP_branches_for_correspondence = [11]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (3, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [590995.76259516 639171.24516773 897215.6642029 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [3]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba16d244d590451197e3350de601a624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.10124848140202135\n",
      " conflict_indices % = 0.0007625300488536201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49523e7d81e6498f8266598a3040f95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=154.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338ac7377faa40428a8bb0c310f586df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51439a8c1104f0793280f0bf80b5d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.09624717275302488\n",
      " conflict_indices % = 0.003952655965216627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeb1c918a654402bcef45624498125f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7696fd06e7a542d683091d72eaa282f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (5, 0) connection-----\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [ 695093.31338795  773675.12013922 1003698.53947622]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [18]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83292a1b04a437e9965ff6311ec2672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.2683295764622138\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a71fb0369246919c4b27640aa28243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574befb1528b4618977899b0b39c5775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (5, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (6, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [592319.23514513 647352.35401891 897835.9063362 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [26]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0c3076a2ef4d1ba0c6acd7d34c97c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.08501064153238067\n",
      " conflict_indices % = 0.0006080875646093037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb6b3ff4be34e91ae59acafb83adbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1616c88769494fa2ab8aa4fb0d828a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25f4f88430a43c2b0847a9e614f1c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.1834555721425326\n",
      " conflict_indices % = 0.00967092879859804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08446584cbbf4ca5b23e81d1d91e69b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=55.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d09d4c3b814333ad3bca491ac225e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (6, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (7, 0) connection-----\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [613683.46083696 720058.24290574 903402.95527664]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [22]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f4977067944296a705d5cd27ddf8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.1311177368918624\n",
      " conflict_indices % = 0.00872663806268635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb1039011b240b0ad4f5812b5ee86cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b803031437ce4a109ea264b14b0914de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (7, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (8, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [619100.61219487 795382.76395145 958418.0067642 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [18]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd509a7f63de4fee8ad6a65d2315818f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.26652850583119997\n",
      " conflict_indices % = 0.0014222438945101386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cff3549dc954707ade877f727372c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=55.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf0ad1f9c454d3884341a230d9fd739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914ef0f8d47e4ac489fd7835cd9707f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.2945866648749132\n",
      " conflict_indices % = 0.00947389639185648\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5020a79f026e481b983d54250a1d6247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38109a66bc04a0394f771591154fb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (8, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (9, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [592988.65290932 583162.35783225 893295.61381551]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [3]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d779df3d30a48849caa9230dab6938c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.10361994631090865\n",
      " conflict_indices % = 9.761652973236802e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e0d225344c4258b94212200f24fcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=107.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bae22c1d794608af1a5e69c979b271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32805483d40049928f3db1a5b9828b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.11344003214357463\n",
      " conflict_indices % = 0.0028393490926136742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8447afc789ee438a82449044e49eb21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2f55097eba42eaa27d6354ad48ae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (9, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (10, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [592322.49174089 401754.95694618 907327.98191384]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [5]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9affe12920401fa3971408916771a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.337439742903053\n",
      " conflict_indices % = 0.002907644043155559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019b24fab42a42fc9b5f42ec1e3b73eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72824469966346feb79648b020ddbb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b0c4cb13274aaba8e796d11cf57604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.25356288359513157\n",
      " conflict_indices % = 0.008114012275044212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcfb05413d64d09a77d62bc22b19d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e7b896fb984c489160bf975f4f799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (10, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 383.28663206100464\n",
      "Number of matching vertices = 69\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[602549. 806993. 924750.]]\n",
      "Number of end_nodes BEFORE filtering = 55\n",
      "all_single_nodes_to_eliminate = [21]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fed3275c5b94f89ab0de943f37df500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 3 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bc85fdc62e4466bc44268bded31c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "588320 588321\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039cec8c99174f48b6cbc7a6aa00e5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d19a8e00345427cbe489d27e1aa5afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=94.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 1 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [602385. 827085. 925890.]\n",
      "Time for preparing soma vertices and root: 0.0002994537353515625\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc052016d9294635aab29b69a43cd626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=90059.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 3.0380260944366455\n",
      "branches_touching_root = [8]\n",
      "length of Graph = 20408\n",
      "Working on path [7434. 7496. 7543. 7575.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "Working on path [7782. 7788. 7796. 7801. 7807.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [18655. 18656. 18659. 18661.]\n",
      "path_degrees = [3, 2, 2, 3]\n",
      "After combining close endpoints max(kept_branches_idx) = 51, len(kept_branches_idx) = 49\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.008098045991104969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8880963a277a46768a495223652da351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f8c60d2ace443699563dc966ba8e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 14.195438385009766\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [3867, 5467, 21837]\n",
      "mesh_large_connectivity: 0.011957645416259766\n",
      "Finding MAP candidates connected components: 0.00010466575622558594\n",
      "len(filtered_pieces) = 2\n",
      "skeleton_connectivity_MP : 0.840552568435669\n",
      "Grouping MP Sublimbs by Graph: 0.08460021018981934\n",
      "Divinding into MP and MAP pieces: 1.430511474609375e-06\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.0010304450988769531\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_963628.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 6.1986634731292725\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(11745, 3), faces.shape=(23486, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfdac3e4c8b49fe8f73f4b379b98f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25319f2ddd6c4cda9164029c40d85cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.03096151351928711\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 6.922080755233765\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.009883642196655273\n",
      "filter_end_node_length = 4000\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6def2a08ec5949b3aaadd8b3e6a8e4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (218, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 7.254727125167847\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_41503.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_41503_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_291483.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_41503.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_41503_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_291483.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b51975aae942039d0e03c5fb222bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 1.4105701446533203\n",
      "mesh_correspondence_first_pass: 1.4106051921844482\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (218, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (218, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.015774502198086373\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276170ee65ee46ac8e60a0430b0bf967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c3e365b33e4bc38fa52b75be51e26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 8.848016262054443\n",
      "correspondence_1_to_1: 0.18151211738586426\n",
      "--- Working on MAP piece 1---\n",
      "MAP Filtering Soma Pieces: 0.0032482147216796875\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_942750.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 12.364763259887695\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(37852, 3), faces.shape=(75700, 3))>, <trimesh.Trimesh(vertices.shape=(10614, 3), faces.shape=(21224, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n",
      "min_edge_length = 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cb1a196e3c420dbc8405676c091dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8bb09812a44d4bb22c5e511e5e8d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.07706475257873535\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 16.125004529953003\n",
      "Checking connected components after removing cycles\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.09066200256347656\n",
      "filter_end_node_length = 4000\n",
      "Using Distance measure skeletal_distance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e774cfbb3841bd891f7a769b528727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (1739, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "Inside MAP decomposition and curr_limb_endpoints_must_keep was None\n",
      "skeletonize_and_clean_connected_branch_CGAL: 19.33079743385315\n",
      "Working on limb correspondence for #1 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46293.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46293_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_543192.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46293.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46293_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_543192.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da81c8e3979042498cc6310d0425cdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 9.265956401824951\n",
      "mesh_correspondence_first_pass: 9.26602554321289\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (1739, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (1739, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.06636390272487548\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7412435ad347fca47edbe87894be32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfd6478f10946dbb08b4a8d3aa6523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #1 mesh processing = 29.687093257904053\n",
      "correspondence_1_to_1: 1.087022304534912\n",
      "Total time for MAP sublimb processing 38.53552007675171\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.009565114974975586\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0020792484283447266\n",
      "Fixing Possible Soma Extension Branch for Sublimb 1\n",
      "Total time for mesh KDTree = 0.09038066864013672\n",
      "sbv[0].reshape(-1,3) = [[602385. 827085. 925890.]]\n",
      "closest_sk_pt_coord BEFORE = [603361.1472319  827358.94085163 925854.33348441]\n",
      "current_skeleton.shape = (836, 2, 3)\n",
      "node_for_stitch = 0: [603361.1472319  827358.94085163 925854.33348441]\n",
      "node_for_stitch AFTER = 0: [603361.1472319  827358.94085163 925854.33348441]\n",
      "possible_node_loc = [  0 366]\n",
      "possible_node_loc AFTER = [  0 366]\n",
      "curr_shortest_path = [0]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [603361.1472319  827358.94085163 925854.33348441]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[603361.1472319 , 827358.94085163, 925854.33348441]])}\n",
      "match_sk_branches = [3]\n",
      "The new branch info was none so skipping \n",
      "\n",
      "No soma extending branch was added for this sublimb even though it had a soma border (means they already existed)\n",
      "MP (because soma touching verts) soma extension add: 0.20931315422058105\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0009253025054931641\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "sk_conn = [5, 24]\n",
      "conn = [5, 24]\n",
      "winning_vertex = [612627.84497421 931802.8000052  955446.55137758]\n",
      "MP_branches_with_stitch_point = [5, 24]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46697834fe5c45b487d30fc2b390b94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.19293439077144917\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758efbeab90745d8a7b08b1b5af3b984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419f0f8d53a448108c27aab34739e166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [5, 24]\n",
      "MP_branches_for_correspondence = [ 5 24]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (0, 1) connection-----\n",
      "sk_conn = [5]\n",
      "conn = [5]\n",
      "winning_vertex = [615038.58474086 939230.06096386 956737.61579404]\n",
      "MP_branches_with_stitch_point = [4, 5]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9b2c3912684d589f0b61c90cd54c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.08742118200277867\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bb04c1eeb4419d8a3a2889bd33f288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6253d0649946648bafa33e326a6949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [4, 5]\n",
      "MP_branches_for_correspondence = [5]\n",
      "MP_leftover = [4], MP_leftover_idx = [0]\n",
      " Finished with (0, 1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "sk_conn = [1, 3]\n",
      "conn = [1, 3]\n",
      "winning_vertex = [614304.10149557 905017.35661518 940679.75767636]\n",
      "MP_branches_with_stitch_point = [1, 3]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b887fbdc1a9541de99c554d1dcd89d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.07360992018996108\n",
      " conflict_indices % = 0.009168260668821317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4b37501aa54fdcb0d31ad2cc501c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a7c86ac20b4f66b5bb6aaa3384fcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [1, 3]\n",
      "MP_branches_for_correspondence = [1 3]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 1) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [634944.22262841 982016.32245096 977359.37688788]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db236bbf9054704ad3cdd2c48cedb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.0775013619030325\n",
      " conflict_indices % = 0.0004358089704013074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60403ce3b8942e8bf31c3b69b19c69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd78972e5760439c8b6aef751bf2ed54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c403bd12084407291b41e03e123e35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.09454140767080155\n",
      " conflict_indices % = 0.004994435547352135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00723db59a514d2a83e9e06d8c4a7fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dbc7af44b344cb926abdd6001a1773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 1) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 92.16211533546448\n",
      "Number of matching vertices = 22\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[603361.1472319  827358.94085163 925854.33348441]]\n",
      "Number of end_nodes BEFORE filtering = 28\n",
      "all_single_nodes_to_eliminate = [1]\n",
      "no small end nodes to get rid of so returning whole skeleton\n",
      "Removed 0 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b7ab4d6d234bdb8d19971967732e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "179434 179435\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b7f5f29639412badfa55ad52e4b42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a816a84ae2ce441aa1be436bb4afb935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 2 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [604044. 822738. 915012.]\n",
      "Time for preparing soma vertices and root: 0.0002770423889160156\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9320746a2c423e9dcb612f6a1fe1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45996.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 0.7273757457733154\n",
      "connecting at the root\n",
      "branches_touching_root = [10]\n",
      "length of Graph = 4866\n",
      "After combining close endpoints max(kept_branches_idx) = 10, len(kept_branches_idx) = 11\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0038832833378783745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f610af23be4c829ea5310a2b9553d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693aa2b901cf41a098613a7a86c92834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 3.896238088607788\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [9013, 15912, 18660, 15600, 16702]\n",
      "mesh_large_connectivity: 0.058090925216674805\n",
      "Finding MAP candidates connected components: 0.00012946128845214844\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.06170320510864258\n",
      "Grouping MP Sublimbs by Graph: 0.010106563568115234\n",
      "Divinding into MP and MAP pieces: 9.5367431640625e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.004763126373291016\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_948379.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 21.612388849258423\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(117265, 3), faces.shape=(234558, 3))>, <trimesh.Trimesh(vertices.shape=(4505, 3), faces.shape=(9006, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n",
      "min_edge_length = 75\n",
      "node_degrees = [3 2 3 2 2 2 3 4 2 2 2]\n",
      "node_degrees = [2 3 2 4]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9641567c666c4319b19261e4f0bac7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363914c9c9a54eb0aff2540285226f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.11452937126159668\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 33.696096658706665\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.42158079147338867\n",
      "sbv[0].reshape(-1,3) = [[604044. 822738. 915012.]]\n",
      "closest_sk_pt_coord BEFORE = [604028. 823319. 915110.]\n",
      "current_skeleton.shape = (2884, 2, 3)\n",
      "node_for_stitch = 759: [604028. 823319. 915110.]\n",
      "node_for_stitch AFTER = 759: [604028. 823319. 915110.]\n",
      "possible_node_loc = [  58   68   82  108  117  140  154  172  225  250  267  299  319  323\n",
      "  345  409  410  435  497  536  550  553  564  606  611  633  647  669\n",
      "  715  759  838  842  879  908 1033 1048 1049 1055 1113 1122 1300 1302\n",
      " 1320 1333 1359 1407 1411 1417 1420 1448 1482 1492 1500 1582 1600 1653\n",
      " 1668 1671 1705 1731 1737 1749 1783 1804 1815 1854 1855 1908 1930 1934\n",
      " 1951 1967 2039 2043 2084 2128 2131 2135 2149 2239 2251 2267 2315 2357\n",
      " 2376 2395 2451 2475 2478 2519 2533 2541 2550 2561 2565 2584 2604 2634\n",
      " 2644 2688 2761 2765 2791 2795 2825 2883]\n",
      "possible_node_loc AFTER = [  58   68   82  108  117  140  154  172  225  250  267  299  319  323\n",
      "  345  409  410  435  497  536  550  553  564  606  611  633  647  669\n",
      "  715  759  838  842  879  908 1033 1048 1049 1055 1113 1122 1300 1302\n",
      " 1320 1333 1359 1407 1411 1417 1420 1448 1482 1492 1500 1582 1600 1653\n",
      " 1668 1671 1705 1731 1737 1749 1783 1804 1815 1854 1855 1908 1930 1934\n",
      " 1951 1967 2039 2043 2084 2128 2131 2135 2149 2239 2251 2267 2315 2357\n",
      " 2376 2395 2451 2475 2478 2519 2533 2541 2550 2561 2565 2584 2604 2634\n",
      " 2644 2688 2761 2765 2791 2795 2825 2883]\n",
      "curr_shortest_path = [759]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [604028. 823319. 915110.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[604028., 823319., 915110.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 1.4094266891479492\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_31907.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_31907_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_322399.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_31907.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_31907_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_322399.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(67, 3), faces.shape=(118, 3))>]\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[604028. 823319. 915110.]\n",
      " [604028. 823319. 915110.]\n",
      " [614168. 846638. 872932.]\n",
      " [662486. 860723. 834719.]]\n",
      "Number of end_nodes BEFORE filtering = 106\n",
      "all_single_nodes_to_eliminate = [29, 29, 49, 103]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a6277366384cfc9cdf5e9588e2b42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (2425, 2, 3)\n",
      "high-degree endpoints were connected so just using that connection\n",
      "curr_branch = {1152.0, 1154.0, 1156.0, 1157.0, 1160.0, 1163.0, 1168.0, 1147, 1149.0}\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 56.15408277511597\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_50175.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_50175_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_684452.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_50175.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_50175_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_684452.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(67, 3), faces.shape=(118, 3))>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc2dd0f2f95461c92bacf2ef9d49123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 12.991838932037354\n",
      "mesh_correspondence_first_pass: 12.99186635017395\n",
      "Limb decomposed into 9 branches\n",
      "divided_skeleton_graph_recovered = (2415, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (2415, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (8, 9)\n",
      "empty_indices % = 0.1547037041917588\n",
      " conflict_indices % = 0.019107356991316035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9568f96b06b47e9b69c1dabea0e731f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=192.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38079c723d5432ea56bc5aeb726cc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1860942197401fbba56e6b63e2f735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 75.36735534667969\n",
      "correspondence_1_to_1: 6.2165913581848145\n",
      "Total time for MAP sublimb processing 75.36746716499329\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.005443572998046875\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "sk_conn = [1, 3]\n",
      "conn = [1, 3]\n",
      "winning_vertex = [627789.137349   865419.30230339 839837.81036106]\n",
      "MP_branches_with_stitch_point = [1, 3]\n",
      "MAP_branches_with_stitch_point = [7]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51a226f1c5345dab133d87b380efad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.1418301164335391\n",
      " conflict_indices % = 0.023130421192466985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abaf6432a07b4d60a74255fc5284a0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa6463353504b9682dac858f2b21a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [1, 3]\n",
      "MP_branches_for_correspondence = [1 3]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 83.01256060600281\n",
      "Number of matching vertices = 31\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[604028. 823319. 915110.]]\n",
      "Number of end_nodes BEFORE filtering = 9\n",
      "all_single_nodes_to_eliminate = [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0649bc52d4408c9ab2d1ffb57efd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 1 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810ffc3240bf4e58bdb2d10a559df148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "91674 91675\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331534355a5a4b898ef6c7ea59fddf50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae59ccf2ec8348ae9680e75cd8530971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 3 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [597672.9 821864.4 917234.5]\n",
      "Time for preparing soma vertices and root: 0.0003561973571777344\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7aad7fb6d34c6d8bdf43b8033fc308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34669.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 0.5663647651672363\n",
      "branches_touching_root = [3]\n",
      "length of Graph = 4482\n",
      "After combining close endpoints max(kept_branches_idx) = 8, len(kept_branches_idx) = 9\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.005272000463472568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44b3bf6a08c40eb8fef9d8ade7c2a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aff4a2f7b8447bbba641ee740b450b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 3.1983234882354736\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [9391, 5314, 23308, 3621]\n",
      "mesh_large_connectivity: 0.02334427833557129\n",
      "Finding MAP candidates connected components: 0.00010013580322265625\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.12615466117858887\n",
      "Grouping MP Sublimbs by Graph: 0.014144182205200195\n",
      "Divinding into MP and MAP pieces: 1.1920928955078125e-06\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.002709627151489258\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_354539.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 15.148468971252441\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(71377, 3), faces.shape=(142774, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n",
      "node_degrees = [2 2 2 2 2 2 2 3 2 2 2 2 2 2 3 2 2]\n",
      "node_degrees = [3 2 2 2 3 3]\n",
      "node_degrees = [2 2 4 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8e41ffc12849d98d133730142f999e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e043f69cd8ad44a5a93a1c3565388b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.07016515731811523\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 21.076530933380127\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.24315547943115234\n",
      "sbv[0].reshape(-1,3) = [[597672.9 821864.4 917234.5]]\n",
      "closest_sk_pt_coord BEFORE = [597391. 821855. 917520.]\n",
      "current_skeleton.shape = (1621, 2, 3)\n",
      "node_for_stitch = 1620: [597391. 821855. 917520.]\n",
      "node_for_stitch AFTER = 1620: [597391. 821855. 917520.]\n",
      "possible_node_loc = [   0    7   53  128  132  147  156  161  193  226  271  311  322  354\n",
      "  384  407  416  433  449  479  488  504  509  516  550  559  582  591\n",
      "  592  598  642  657  676  689  705  714  728  768  812  818  902  907\n",
      "  919  953  984 1020 1028 1034 1065 1093 1106 1112 1156 1163 1180 1225\n",
      " 1276 1342 1367 1380 1396 1426 1449 1469 1502 1620]\n",
      "possible_node_loc AFTER = [   0    7   53  128  132  147  156  161  193  226  271  311  322  354\n",
      "  384  407  416  433  449  479  488  504  509  516  550  559  582  591\n",
      "  592  598  642  657  676  689  705  714  728  768  812  818  902  907\n",
      "  919  953  984 1020 1028 1034 1065 1093 1106 1112 1156 1163 1180 1225\n",
      " 1276 1342 1367 1380 1396 1426 1449 1469 1502 1620]\n",
      "curr_shortest_path = [1620]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [597391. 821855. 917520.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[597391., 821855., 917520.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.6552724838256836\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_20514.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_20514_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_356835.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_20514.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_20514_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_356835.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(119, 3), faces.shape=(245, 3))>, <trimesh.Trimesh(vertices.shape=(57, 3), faces.shape=(108, 3))>]\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[597391. 821855. 917520.]]\n",
      "Number of end_nodes BEFORE filtering = 66\n",
      "all_single_nodes_to_eliminate = [65]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804218b7910f416ebedaaa08effdfe4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (1295, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 1 valid paths to replace\n",
      "valid_paths = [array([419., 420., 422., 426., 430.])]\n",
      "valid_path_lengths = [491.7736630600145]\n",
      "length of Graph = 1295\n",
      "Working on path [419. 420. 422. 426. 430.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "skeletonize_and_clean_connected_branch_CGAL: 30.051340341567993\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_99405.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_99405_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_602511.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_99405.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_99405_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_602511.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(119, 3), faces.shape=(245, 3))>, <trimesh.Trimesh(vertices.shape=(57, 3), faces.shape=(108, 3))>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291363c3e4fc4d6ab6e7454ad24b9b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 8.868576049804688\n",
      "mesh_correspondence_first_pass: 8.868610858917236\n",
      "Limb decomposed into 5 branches\n",
      "divided_skeleton_graph_recovered = (1290, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (1290, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (4, 5)\n",
      "empty_indices % = 0.10664360858913388\n",
      " conflict_indices % = 0.0117211894124994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcdec3e1ae6462680d0f9cd31b04686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=82.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0899004585a944d88c024785a9ff3e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76176c520a74cd286d11552cb3f59af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 41.19255542755127\n",
      "correspondence_1_to_1: 2.2698185443878174\n",
      "Total time for MAP sublimb processing 41.192665576934814\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0014128684997558594\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0008838176727294922\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "sk_conn = [1]\n",
      "conn = [1]\n",
      "winning_vertex = [561421.78341996 824546.98975696 858062.84628584]\n",
      "MP_branches_with_stitch_point = [1]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a6840a6cbf4bfcb353421c1f7be600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.12102689486552567\n",
      " conflict_indices % = 0.0023685819070904646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b22a6d357e4012aa619e2c55809e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a8a137c1064fb4acf60e8c704f7e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f81f4945ddf491798ee3acaf19f5ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.356368426385652\n",
      " conflict_indices % = 0.001080825480460702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4bbdf6c22049afa4a6bc78b58bb2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53819fa22f754918b80e0aa8787820fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [1]\n",
      "MP_branches_for_correspondence = [1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [554672.45529903 825332.96555584 841083.51359406]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152eb07fa4a0415495cade6ad1c4c7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.45107535708422264\n",
      " conflict_indices % = 0.009193892628468231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade04e6948c540e98f3e2ecc74055579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf4bb5a100c43f5a34ee1413ae85d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 69.01566314697266\n",
      "Number of matching vertices = 16\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[597391. 821855. 917520.]]\n",
      "Number of end_nodes BEFORE filtering = 7\n",
      "all_single_nodes_to_eliminate = [6]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2767264d0848458c713679a0238a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 1 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18130c5d43743b2bc35230971ced139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "69043 69044\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714a378b2dad48e6b213e4a2d6950f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66350b125bc14f29821c3f193e98a040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 4 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [596925. 823935. 921669.]\n",
      "Time for preparing soma vertices and root: 0.00025391578674316406\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46551515ba7f43b4831800b4ada401a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29220.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 0.4715383052825928\n",
      "branches_touching_root = [2]\n",
      "length of Graph = 2968\n",
      "After combining close endpoints max(kept_branches_idx) = 6, len(kept_branches_idx) = 7\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.003644490287089565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1606057cd24857b766400b6d5eae98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a361fb64ae904e5fbf0cae38a30075bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 2.345595598220825\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [7516, 4657, 18649, 5824]\n",
      "mesh_large_connectivity: 0.02104043960571289\n",
      "Finding MAP candidates connected components: 9.775161743164062e-05\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.05547690391540527\n",
      "Grouping MP Sublimbs by Graph: 0.010859966278076172\n",
      "Divinding into MP and MAP pieces: 9.5367431640625e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.006119251251220703\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_317325.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 12.012372970581055\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(60797, 3), faces.shape=(121598, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n",
      "node_degrees = [2 2 2 2 3 2 2 3 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9365f222044e1b91268f2dbff31193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3b06f78050487f9b484999d3831a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.06507229804992676\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 18.95091724395752\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.21677470207214355\n",
      "sbv[0].reshape(-1,3) = [[596925. 823935. 921669.]]\n",
      "closest_sk_pt_coord BEFORE = [596794. 823762. 921237.]\n",
      "current_skeleton.shape = (1443, 2, 3)\n",
      "node_for_stitch = 1443: [596794. 823762. 921237.]\n",
      "node_for_stitch AFTER = 1443: [596794. 823762. 921237.]\n",
      "possible_node_loc = [   0   21   40   51   59   72  121  141  155  174  213  236  315  351\n",
      "  374  380  389  391  458  473  492  554  568  579  580  615  621  648\n",
      "  670  677  690  724  737  763  778  788  805  822  835  880  912  955\n",
      "  988 1045 1068 1072 1100 1103 1126 1162 1177 1212 1256 1443]\n",
      "possible_node_loc AFTER = [   0   21   40   51   59   72  121  141  155  174  213  236  315  351\n",
      "  374  380  389  391  458  473  492  554  568  579  580  615  621  648\n",
      "  670  677  690  724  737  763  778  788  805  822  835  880  912  955\n",
      "  988 1045 1068 1072 1100 1103 1126 1162 1177 1212 1256 1443]\n",
      "curr_shortest_path = [1443]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [596794. 823762. 921237.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[596794., 823762., 921237.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.5748047828674316\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_49859.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_49859_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_535963.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_49859.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_49859_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_535963.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 85\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[596794. 823762. 921237.]\n",
      " [539451. 922623. 894722.]\n",
      " [544967. 923592. 895463.]\n",
      " [555196. 855949. 894486.]]\n",
      "Number of end_nodes BEFORE filtering = 54\n",
      "all_single_nodes_to_eliminate = [53, 0, 5, 15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057fb1629ea7496cb2de0bdaf911d9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (1146, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 28.551762104034424\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_64461.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_64461_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_147095.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_64461.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_64461_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_147095.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f0f891653d43ebb59c9a6c03fb2097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 6.522116422653198\n",
      "mesh_correspondence_first_pass: 6.5221498012542725\n",
      "Limb decomposed into 5 branches\n",
      "divided_skeleton_graph_recovered = (1146, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (1146, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (4, 5)\n",
      "empty_indices % = 0.1269988538994706\n",
      " conflict_indices % = 0.015335916607542433\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1a1a9223c9471abcdcbc4a45e39951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278b5f1b9e46443a9d440e469f5b148a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c71f7306b024a4a93576557dc12d6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 37.13739800453186\n",
      "correspondence_1_to_1: 2.057298183441162\n",
      "Total time for MAP sublimb processing 37.1374990940094\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001308441162109375\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0006558895111083984\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [555148.89384564 855974.12974319 893808.62756725]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [3]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a265b591bb446b9a27718e4fd2c11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.14807414335515687\n",
      " conflict_indices % = 0.00956551313663804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8847d4ce32948a9b302c2a9fa9d39f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddc3283317f41f6b87498d72c1ad3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [571727.30409185 861919.40488365 915911.47868893]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fa2eb040e447c2a872645abdc3ba40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.14614425186013505\n",
      " conflict_indices % = 0.0005591157369575502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501e4351db19457683440bbd1e063e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62233c0e1ef641a5ba6e9e246f8bde66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f7e5b55b024bac8250cd318b456746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.15041608876560333\n",
      " conflict_indices % = 0.013072122052704577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a34ceb90e54deebd5fc245c74766b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a478a15a8444763ace517bc64c54388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 52.935142278671265\n",
      "Number of matching vertices = 25\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[596794. 823762. 921237.]]\n",
      "Number of end_nodes BEFORE filtering = 6\n",
      "all_single_nodes_to_eliminate = [5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cecf335d3be45b6bd1e44d7d42d9067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 1 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d37747aee27467dbad01b19c826bf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "58169 58170\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f358a5dc96054e4793825b727b36ae3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dc49b3ceb8478abe8b9ad77368b371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 5 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [614772.1 818025.6 921764.9]\n",
      "Time for preparing soma vertices and root: 0.00030422210693359375\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247319207fa542bdae2bf1416a4f9596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28582.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 0.43233442306518555\n",
      "connecting at the root\n",
      "branches_touching_root = [2]\n",
      "length of Graph = 3180\n",
      "After combining close endpoints max(kept_branches_idx) = 2, len(kept_branches_idx) = 3\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0013855516775698475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be9985f55c04053bb9a395bda902638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cb73bfa78c423486691ba4183b16c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 4.525397062301636\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [23602, 25828]\n",
      "mesh_large_connectivity: 0.010205268859863281\n",
      "Finding MAP candidates connected components: 8.082389831542969e-05\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.03375720977783203\n",
      "Grouping MP Sublimbs by Graph: 0.00415492057800293\n",
      "Divinding into MP and MAP pieces: 9.5367431640625e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.003259420394897461\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_545137.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 13.936254739761353\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(78817, 3), faces.shape=(157658, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffc0098d8de494eaec302972ffc5096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff36c9c385744eb89bc08f6642d7f4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.08630204200744629\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 20.369696140289307\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 2.265145778656006\n",
      "sbv[0].reshape(-1,3) = [[614772.1 818025.6 921764.9]]\n",
      "closest_sk_pt_coord BEFORE = [615168. 818627. 921115.]\n",
      "current_skeleton.shape = (2119, 2, 3)\n",
      "node_for_stitch = 0: [615168. 818627. 921115.]\n",
      "node_for_stitch AFTER = 0: [615168. 818627. 921115.]\n",
      "possible_node_loc = [   0  227  229  268  269  344  358  364  395  407  455  466  474  605\n",
      "  671  695  711  728  817  859  870  911  918  919  927  941 1002 1077\n",
      " 1090 1141 1179 1183 1194 1211 1240 1252 1279 1305 1330 1388 1405 1414\n",
      " 1444 1488 1493 1530 1547 1560 1570 1590 1643 1669 1758 1784 1788 1789\n",
      " 1856 1876 1900 1907 1951 1953 2023 2027 2064 2088 2118]\n",
      "possible_node_loc AFTER = [   0  227  229  268  269  344  358  364  395  407  455  466  474  605\n",
      "  671  695  711  728  817  859  870  911  918  919  927  941 1002 1077\n",
      " 1090 1141 1179 1183 1194 1211 1240 1252 1279 1305 1330 1388 1405 1414\n",
      " 1444 1488 1493 1530 1547 1560 1570 1590 1643 1669 1758 1784 1788 1789\n",
      " 1856 1876 1900 1907 1951 1953 2023 2027 2064 2088 2118]\n",
      "curr_shortest_path = [0]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [615168. 818627. 921115.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[615168., 818627., 921115.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 2.847748041152954\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46823.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46823_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_303974.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46823.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_46823_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_303974.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 78\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[615168. 818627. 921115.]\n",
      " [615168. 818627. 921115.]\n",
      " [697180. 867441. 975335.]]\n",
      "Number of end_nodes BEFORE filtering = 67\n",
      "all_single_nodes_to_eliminate = [0, 0, 66]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdbd2f725b84a6599b83f44396b3fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (1786, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 33.8241982460022\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_76127.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_76127_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_706484.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_76127.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_76127_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_706484.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328f61dbc06a45c4ad2376e2b3bf14db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 11.364003419876099\n",
      "mesh_correspondence_first_pass: 11.36403775215149\n",
      "Limb decomposed into 3 branches\n",
      "divided_skeleton_graph_recovered = (1786, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (1786, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.1519724863443253\n",
      " conflict_indices % = 0.008335019219097715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48e2de7b1e64656be8c54f963af1abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4ee0cc14814488ac3417451006a3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94612fcb60f04e2cae10fd75bf0f1450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 47.9524245262146\n",
      "correspondence_1_to_1: 2.7608749866485596\n",
      "Total time for MAP sublimb processing 47.95253133773804\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0046842098236083984\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [617654.43277847 836958.21655021 910576.18479659]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [1]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a11b6e2d6dd4a91bde149bad3d2883b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.13689061712392886\n",
      " conflict_indices % = 0.0030604162166054582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c892ad3136f7448bb042d422faad25b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9ac763b8c3435b8124c30f5880dec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2992789b2dbc49438c533e5f45d874a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.16102485789429033\n",
      " conflict_indices % = 0.009388874749017279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eece7b1842e40a1804a145d5597a68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c24d941ebc453a86d18bf48f79c09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 65.41614294052124\n",
      "Number of matching vertices = 23\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[615168. 818627. 921115.]]\n",
      "Number of end_nodes BEFORE filtering = 4\n",
      "all_single_nodes_to_eliminate = [1]\n",
      "no small end nodes to get rid of so returning whole skeleton\n",
      "Removed 0 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0263ca4b59cf4195981f49c2c688c6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "57016 57017\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6403b04d6a29480db2510a0f7ee43678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2e1a5471e84c5fb7ef0e6b293c7c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 6 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [599319. 809277. 927507.]\n",
      "Time for preparing soma vertices and root: 0.0003540515899658203\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d214f6589c80478086b17951839e43ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23043.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 0.35646629333496094\n",
      "branches_touching_root = [1]\n",
      "length of Graph = 2413\n",
      "After combining close endpoints max(kept_branches_idx) = 2, len(kept_branches_idx) = 3\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0015226328497161378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f46a4143514407814360f14b07979f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ab99c58f1d4d21a3a22a8e2377b32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 1.8351619243621826\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [19122, 5579, 21272]\n",
      "mesh_large_connectivity: 0.01778864860534668\n",
      "Finding MAP candidates connected components: 9.655952453613281e-05\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.009891510009765625\n",
      "Grouping MP Sublimbs by Graph: 3.695487976074219e-05\n",
      "Divinding into MP and MAP pieces: 7.152557373046875e-07\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.0030984878540039062\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_286416.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 15.974063396453857\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(76934, 3), faces.shape=(153876, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced47661d9cf4db1b3bc386c31fe2f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8365b4236ec0494294003e1423e9a227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.07922220230102539\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 22.21839952468872\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.26646852493286133\n",
      "sbv[0].reshape(-1,3) = [[599319. 809277. 927507.]]\n",
      "closest_sk_pt_coord BEFORE = [599039. 809695. 927893.]\n",
      "current_skeleton.shape = (1981, 2, 3)\n",
      "node_for_stitch = 1981: [599039. 809695. 927893.]\n",
      "node_for_stitch AFTER = 1981: [599039. 809695. 927893.]\n",
      "possible_node_loc = [   0   55   71  104  115  122  169  232  242  286  323  334  348  389\n",
      "  413  423  444  463  502  503  528  538  550  571  579  604  611  643\n",
      "  653  692  742  766  793  811  820  827  835  864  889  933  934  979\n",
      "  996 1044 1107 1140 1184 1195 1202 1275 1279 1337 1368 1387 1389 1431\n",
      " 1466 1487 1509 1519 1530 1564 1613 1620 1656 1663 1667 1697 1702 1722\n",
      " 1742 1762 1783 1812 1863 1981]\n",
      "possible_node_loc AFTER = [   0   55   71  104  115  122  169  232  242  286  323  334  348  389\n",
      "  413  423  444  463  502  503  528  538  550  571  579  604  611  643\n",
      "  653  692  742  766  793  811  820  827  835  864  889  933  934  979\n",
      "  996 1044 1107 1140 1184 1195 1202 1275 1279 1337 1368 1387 1389 1431\n",
      " 1466 1487 1509 1519 1530 1564 1613 1620 1656 1663 1667 1697 1702 1722\n",
      " 1742 1762 1783 1812 1863 1981]\n",
      "curr_shortest_path = [1981]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [599039. 809695. 927893.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[599039., 809695., 927893.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.7859528064727783\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_71646.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_71646_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_608460.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_71646.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_71646_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_608460.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 81\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[599039. 809695. 927893.]]\n",
      "Number of end_nodes BEFORE filtering = 76\n",
      "all_single_nodes_to_eliminate = [75]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91eb4448854443f184282f4c6e6e5965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (1573, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 35.423141956329346\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_12559.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_12559_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_519358.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_12559.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_12559_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_519358.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880654fa54d54cd4824ef07d2862a9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 8.3248131275177\n",
      "mesh_correspondence_first_pass: 8.324975728988647\n",
      "Limb decomposed into 3 branches\n",
      "divided_skeleton_graph_recovered = (1573, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (1573, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.12822743784395188\n",
      " conflict_indices % = 0.006743088334457181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536f0a570a474e2bb39d38621b86655d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=136.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e4237105384005aa99da5624916fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a919e6c0804664ad2da98ef8efef26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 48.296730279922485\n",
      "correspondence_1_to_1: 4.54545521736145\n",
      "Total time for MAP sublimb processing 48.29683065414429\n",
      "There were not both MAP and MP pieces so skipping the stitch resolving phase\n",
      "Time for decomp of Limb = 50.58237648010254\n",
      "Number of matching vertices = 17\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[599039. 809695. 927893.]]\n",
      "Number of end_nodes BEFORE filtering = 3\n",
      "all_single_nodes_to_eliminate = [2]\n",
      "no small end nodes to get rid of so returning whole skeleton\n",
      "Removed 0 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3cb793ba424bddacbb670e8196d146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "45972 45973\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4678e21d068a479bb72a601159181b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa31966b90249f3a2d84389f0c32866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----- Working on Proper Limb # 7 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [613383.8 813834.7 923499.7]\n",
      "Time for preparing soma vertices and root: 0.0003075599670410156\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f37c239af54b0cbb29f45eab834ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20940.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 0.3472757339477539\n",
      "branches_touching_root = [1]\n",
      "length of Graph = 2153\n",
      "After combining close endpoints max(kept_branches_idx) = 2, len(kept_branches_idx) = 3\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.002549915804666827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ab812c512a43219643f6f889c5eed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3513c4ec62eb4938ba521012a961b1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 1.6646552085876465\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [8689, 21548]\n",
      "mesh_large_connectivity: 0.0065953731536865234\n",
      "Finding MAP candidates connected components: 8.440017700195312e-05\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 0.03520369529724121\n",
      "Grouping MP Sublimbs by Graph: 0.005617618560791016\n",
      "Divinding into MP and MAP pieces: 1.1920928955078125e-06\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.0018396377563476562\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_294173.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 13.091374158859253\n",
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(48640, 3), faces.shape=(97284, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e73076588d4ce08d166d19e173d14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4315e1192a2411d8a314672303e82f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.05759406089782715\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 16.871123552322388\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 0.18863272666931152\n",
      "sbv[0].reshape(-1,3) = [[613383.8 813834.7 923499.7]]\n",
      "closest_sk_pt_coord BEFORE = [613893. 814194. 923650.]\n",
      "current_skeleton.shape = (1264, 2, 3)\n",
      "node_for_stitch = 0: [613893. 814194. 923650.]\n",
      "node_for_stitch AFTER = 0: [613893. 814194. 923650.]\n",
      "possible_node_loc = [   0  120  147  201  206  236  255  265  289  320  340  354  376  390\n",
      "  395  419  427  445  484  503  554  562  578  632  649  663  675  692\n",
      "  701  739  743  784  796  827  843  860  868  880  888  893  897  930\n",
      "  960  978  983 1062 1068 1101 1118 1144 1187 1216 1241 1256 1264]\n",
      "possible_node_loc AFTER = [   0  120  147  201  206  236  255  265  289  320  340  354  376  390\n",
      "  395  419  427  445  484  503  554  562  578  632  649  663  675  692\n",
      "  701  739  743  784  796  827  843  860  868  880  888  893  897  930\n",
      "  960  978  983 1062 1068 1101 1118 1144 1187 1216 1241 1256 1264]\n",
      "curr_shortest_path = [0]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [613893. 814194. 923650.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[613893., 814194., 923650.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 0.484926700592041\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_86251.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_86251_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_979406.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_86251.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_86251_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_979406.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 40\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[613893. 814194. 923650.]]\n",
      "Number of end_nodes BEFORE filtering = 55\n",
      "all_single_nodes_to_eliminate = [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b473f4ce0a480eb8c903ce159610f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (967, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 23.440211057662964\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_79482.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_79482_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_713706.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_79482.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_79482_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_713706.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121c19a8f5e34646bcee970c55fa3afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 5.816383123397827\n",
      "mesh_correspondence_first_pass: 5.816410303115845\n",
      "Limb decomposed into 1 branches\n",
      "divided_skeleton_graph_recovered = (967, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (967, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (0, 1)\n",
      "empty_indices % = 0.13122995006118332\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e038e1aa834e3f915aed170ba2e263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b68f9e32bea45679f6ad579000370ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9f52db884f40c5955049f726ece69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 32.89993143081665\n",
      "correspondence_1_to_1: 3.64139723777771\n",
      "Total time for MAP sublimb processing 32.90001893043518\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0036797523498535156\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [647080.7203491  829597.36832279 947023.16170874]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [0]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8950d165d54f8daadc43c81afde397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.16496345536924958\n",
      " conflict_indices % = 0.0018851076495684095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21a68812b70404ea326c82ae2631ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa94dab09e154693ab3186613b59cf1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd50fa918cb40159e134abc63db6648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.15900890064950685\n",
      " conflict_indices % = 0.008756314649987973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877cd0fc33a74659b20e3d4ece3fc55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ca927e0f344e2eb14a8fb2e3fd3257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 46.67876625061035\n",
      "Number of matching vertices = 9\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[613893. 814194. 923650.]]\n",
      "Number of end_nodes BEFORE filtering = 3\n",
      "all_single_nodes_to_eliminate = [0]\n",
      "no small end nodes to get rid of so returning whole skeleton\n",
      "Removed 0 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3221faca773d427685c54d0a8a6ca179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "41569 41570\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d4fe7098b9442bb29ff5e048c2a86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cb1df90fc84918985f344faa1c1eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for Skeletonization and Mesh Correspondence = 911.2340590953827\n",
      "\n",
      "\n",
      " ----- Working on Stitching ----------\n",
      "Status of Main limb stitch point moved = False\n",
      "Status of Main limb stitch point moved = True\n",
      "The closest float distance was 19706.26786266571 which was greater than the maximum stitch distance 8000\n",
      " --> so ending the floating mesh stitch processs\n",
      "Total time for stitching floating pieces = 7.699995517730713\n",
      "Total time for Concept Networks = 8.472983360290527\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'glia_meshes' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-3f1a6b4752e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mwidths_to_calculate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"no_spine_median_mesh_center\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mglia_faces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglia_faces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnuclei_faces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnuclei_faces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         )\n",
      "\u001b[0;32m/meshAfterParty/neuron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mesh, segment_id, description, preprocessed_data, decomposition_type, mesh_correspondence, distance_by_mesh_center, meshparty_segment_size, meshparty_n_surface_downsampling, meshparty_adaptive_correspondence_after_creation, suppress_preprocessing_print, computed_attribute_dict, somas, branch_skeleton_data, combine_close_skeleton_nodes, combine_close_skeleton_nodes_threshold, ignore_warnings, suppress_output, calculate_spines, widths_to_calculate, fill_hole_size, preprocessing_version, limb_to_branch_objects, glia_faces, nuclei_faces)\u001b[0m\n\u001b[1;32m   1800\u001b[0m                                         \u001b[0muse_meshafterparty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_meshafterparty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m                                         \u001b[0mglia_faces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglia_faces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                                          nuclei_faces = nuclei_faces)\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/preprocessing_vp2.py\u001b[0m in \u001b[0;36mpreprocess_neuron\u001b[0;34m(mesh, mesh_file, segment_id, description, sig_th_initial_split, limb_threshold, filter_end_node_length, return_no_somas, decomposition_type, distance_by_mesh_center, meshparty_segment_size, meshparty_n_surface_downsampling, somas, combine_close_skeleton_nodes, combine_close_skeleton_nodes_threshold, use_meshafterparty, glia_faces, nuclei_faces)\u001b[0m\n\u001b[1;32m   3721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m     \u001b[0;31m#------ 1/11/ getting the glia faces --------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3723\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mglia_meshes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglia_meshes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3724\u001b[0m             \u001b[0mglia_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_mesh_faces_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_neuron\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_meshes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglia_pieces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3725\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'glia_meshes' referenced before assignment"
     ]
    }
   ],
   "source": [
    "total_neuron_process_time = time.time()\n",
    "\n",
    "print(f\"\\n--- Beginning preprocessing of {segment_id}---\")\n",
    "recovered_neuron = neuron.Neuron(\n",
    "mesh = current_neuron_mesh,\n",
    "somas = somas,\n",
    "segment_id=segment_id,\n",
    "description=description,\n",
    "suppress_preprocessing_print=False,\n",
    "suppress_output=False,\n",
    "calculate_spines=True,\n",
    "widths_to_calculate=[\"no_spine_median_mesh_center\"],\n",
    "glia_faces=glia_faces,\n",
    "nuclei_faces=nuclei_faces,\n",
    "\n",
    "        )\n",
    "\n",
    "print(f\"\\n\\n\\n---- Total preprocessing time = {time.time() - total_neuron_process_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of neuron failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/meshAfterParty/neuron.py\", line 2807\n",
      "    n_error_limbs=self.n_error_limbs,\n",
      "                ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/meshAfterParty/preprocessing_vp2.py\u001b[0m(3723)\u001b[0;36mpreprocess_neuron\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   3721 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3722 \u001b[0;31m    preprocessed_data= dict(\n",
      "\u001b[0m\u001b[0;32m-> 3723 \u001b[0;31m        \u001b[0msoma_meshes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_mesh_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"soma_meshes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3724 \u001b[0;31m        \u001b[0msoma_to_piece_connectivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_mesh_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"soma_to_piece_connectivity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3725 \u001b[0;31m        \u001b[0msoma_sdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_soma_list_sdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb>     preprocessed_data= dict(         soma_meshes = current_mesh_data[0][\"soma_meshes\"],         soma_to_piece_connectivity = current_mesh_data[0][\"soma_to_piece_connectivity\"],         soma_sdfs = total_soma_list_sdf,         insignificant_limbs=insignificant_limbs,         not_processed_soma_containing_meshes=not_processed_soma_containing_meshes,         glia_faces = glia_faces,         non_soma_touching_meshes=non_soma_touching_meshes,         inside_pieces=inside_pieces,         limb_correspondence=limb_correspondence_with_floating_pieces,         limb_concept_networks=limb_concept_networks,         limb_network_stating_info=limb_network_stating_info,         limb_labels=limb_labels,         limb_meshes=current_mesh_data[0][\"branch_meshes\"],         )\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Function to Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predefined arguments for the Neuron constructor\n",
    "\n",
    "decomposition_type=\"meshafterparty\"\n",
    "mesh_correspondence=\"meshparty\" #meshafterparty_adaptive\n",
    "distance_by_mesh_center=True #how the distance is calculated for mesh correspondence\n",
    "meshparty_segment_size = 100\n",
    "meshparty_n_surface_downsampling = 2\n",
    "meshparty_adaptive_correspondence_after_creation=False\n",
    "suppress_preprocessing_print=True\n",
    "computed_attribute_dict=None\n",
    "\n",
    "\n",
    "branch_skeleton_data=None\n",
    "combine_close_skeleton_nodes = True\n",
    "combine_close_skeleton_nodes_threshold=700\n",
    "\n",
    "ignore_warnings=True\n",
    "suppress_output=False\n",
    "calculate_spines=True\n",
    "widths_to_calculate=[\"no_spine_median_mesh_center\"]\n",
    "fill_hole_size=0# The old value for the parameter when performing 2000,\n",
    "\n",
    "preprocessing_version=2\n",
    "limb_to_branch_objects=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments for the preprocess neuron\n",
    "mesh = current_neuron_mesh\n",
    "segment_id=segment_id\n",
    "description=description\n",
    "\n",
    "sig_th_initial_split=100 #for significant splitting meshes in the intial mesh split\n",
    "limb_threshold = 2000 #the mesh faces threshold for a mesh to be qualified as a limb (otherwise too small)\n",
    "filter_end_node_length=4000 #used in cleaning the skeleton during skeletonizations\n",
    "return_no_somas = False\n",
    "\n",
    "decomposition_type=decomposition_type\n",
    "mesh_correspondence=mesh_correspondence\n",
    "distance_by_mesh_center=distance_by_mesh_center\n",
    "meshparty_segment_size =meshparty_segment_size\n",
    "meshparty_n_surface_downsampling = meshparty_n_surface_downsampling\n",
    "somas=somas\n",
    "branch_skeleton_data=branch_skeleton_data\n",
    "combine_close_skeleton_nodes = combine_close_skeleton_nodes\n",
    "combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold\n",
    "\n",
    "use_meshafterparty=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting of the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_vp2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_meshafterparty = True\n"
     ]
    }
   ],
   "source": [
    "pre_branch_connectivity = \"edges\"\n",
    "print(f\"use_meshafterparty = {use_meshafterparty}\")\n",
    "\n",
    "whole_processing_tiempo = time.time()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Purpose: To process the mesh into a format that can be loaded into the neuron class\n",
    "and used for higher order processing (how to visualize is included)\n",
    "\n",
    "This method includes the fusion\n",
    "\n",
    "\"\"\"\n",
    "if description is None:\n",
    "    description = \"no_description\"\n",
    "if segment_id is None:\n",
    "    #pick a random segment id\n",
    "    segment_id = np.random.randint(100000000)\n",
    "    print(f\"picking a random 7 digit segment id: {segment_id}\")\n",
    "    description += \"_random_id\"\n",
    "\n",
    "\n",
    "if mesh is None:\n",
    "    if mesh_file is None:\n",
    "        raise Exception(\"No mesh or mesh_file file were given\")\n",
    "    else:\n",
    "        current_neuron = tu.load_mesh_no_processing(mesh_file)\n",
    "else:\n",
    "    current_neuron = mesh\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-computed somas: soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(19028, 3), faces.shape=(37767, 3))>]\n",
      "Soma List = [<trimesh.Trimesh(vertices.shape=(19028, 3), faces.shape=(37767, 3))>]\n",
      "soma_mesh_list_centers = [array([604782.36627076, 817703.83371873, 923126.39603741])]\n"
     ]
    }
   ],
   "source": [
    "# -------- Phase 1: Doing Soma Detection (if Not already done) ---------- #\n",
    "if somas is None:\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                             current_neuron.vertices,\n",
    "                                             current_neuron.faces)\n",
    "else:\n",
    "    soma_mesh_list,run_time,total_soma_list_sdf = somas\n",
    "    print(f\"Using pre-computed somas: soma_mesh_list = {soma_mesh_list}\")\n",
    "\n",
    "# geting the soma centers\n",
    "if len(soma_mesh_list) <= 0:\n",
    "    print(f\"**** No Somas Found for Mesh {segment_id} so just one mesh\")\n",
    "    soma_mesh_list_centers = []\n",
    "    if return_no_somas:\n",
    "        return_value= soma_mesh_list_centers\n",
    "    raise Exception(\"Processing of No Somas is not yet implemented yet\")\n",
    "else:\n",
    "    #compute the soma centers\n",
    "    print(f\"Soma List = {soma_mesh_list}\")\n",
    "\n",
    "    soma_mesh_list_centers = sm.find_soma_centroids(soma_mesh_list)\n",
    "    print(f\"soma_mesh_list_centers = {soma_mesh_list_centers}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Both the nuclie and the Glia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Glia and Nuclei Pieces Subtracted Away 0.7383794784545898\n",
      " Splitting mesh after soma cancellation 1.4465053081512451\n",
      "# of split_meshes = 19\n",
      " Containing Mesh Indices 0.04567575454711914\n"
     ]
    }
   ],
   "source": [
    "print_optimize = True\n",
    "#--- Phase 2: getting the soma submeshes that are connected to each soma and identifiying those that aren't \n",
    "# ------------------ (and eliminating any mesh pieces inside the soma) ------------------------\n",
    "\n",
    "# -------- 11/13 Addition: Will remove the inside nucleus --------- #\n",
    "\n",
    "optimize_time = time.time()\n",
    "\n",
    "glia_faces,nuclei_faces\n",
    "\n",
    "if glia_faces is None or nuclei_faces is None:\n",
    "    main_mesh_total,glia_meshes,nuclei_meshes = tu.remove_nuclei_and_glia_meshes(current_neuron,\n",
    "                                                                   verbose=True)\n",
    "    print(\"Using pre-computed glia and nuclei pieces\")\n",
    "    if len(glia_meshes) > 0 or len(nuclei_meshes) > 0:\n",
    "        main_mesh_total = tu.subtract_mesh(current_neuron,glia_meshes + nuclei_meshes)\n",
    "    else:\n",
    "        main_mesh_total = current_neuron\n",
    "else:\n",
    "    if len(nuclei_faces) > 0:\n",
    "        nuclei_meshes = current_neuron.submesh([nuclei_faces],append=True,repair=False)\n",
    "        nuclei_meshes = [nuclei_meshes]\n",
    "    else:\n",
    "        nuclei_meshes = []\n",
    "    \n",
    "    total_eliminated_faces = list(glia_faces) + list(nuclei_faces)\n",
    "    if len(total_eliminated_faces)>0:\n",
    "        faces_to_keep = np.delete(np.arange(len(current_neuron.faces)),total_eliminated_faces)\n",
    "        main_mesh_total = current_neuron.submesh([faces_to_keep],append=True,repair=False)\n",
    "    else:\n",
    "        main_mesh_total = current_neuron\n",
    "    \n",
    "    \n",
    "if print_optimize:\n",
    "    print(f\"Getting Glia and Nuclei Pieces Subtracted Away {time.time()-optimize_time}\")\n",
    "optimize_time = time.time()\n",
    "\n",
    "\n",
    "#finding the mesh pieces that contain the soma\n",
    "#splitting the current neuron into distinct pieces\n",
    "\n",
    "\n",
    "\n",
    "optimize_time = time.time()\n",
    "\n",
    "\n",
    "split_meshes,split_meshes_face_idx = tu.split_significant_pieces(\n",
    "                            main_mesh_total,\n",
    "                            significance_threshold=sig_th_initial_split,\n",
    "                            print_flag=False,\n",
    "                            return_face_indices=True,\n",
    "                            connectivity=pre_branch_connectivity)\n",
    "\n",
    "\n",
    "if print_optimize:\n",
    "    print(f\" Splitting mesh after soma cancellation {time.time()-optimize_time}\")\n",
    "optimize_time = time.time()\n",
    "\n",
    "print(f\"# of split_meshes = {len(split_meshes)}\")\n",
    "\n",
    "\"\"\"  Newer slower way of doing it    \n",
    "\n",
    "tu.two_mesh_list_connectivity(soma_mesh_list,split_meshes_face_idx,main_mesh_total)\n",
    "\"\"\"\n",
    "#returns the index of the split_meshes index that contains each soma    \n",
    "containing_mesh_indices = sm.find_soma_centroid_containing_meshes(soma_mesh_list,\n",
    "                                        split_meshes)\n",
    "\n",
    "if print_optimize:\n",
    "    print(f\" Containing Mesh Indices {time.time()-optimize_time}\")\n",
    "optimize_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containing_mesh_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " non_soma_touching_meshes 0.00012922286987304688\n",
      "There were 18 pieces found after size threshold\n",
      " Finding inside pieces and non_soma_touching meshes 1.3065917491912842\n",
      "\n",
      "-----Before filtering away multiple disconneted soma pieces-----\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "Number of not_processed_soma_containing_meshes = 0\n",
      "\n",
      "-----After filtering away multiple disconneted soma pieces-----\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      " Filtering Away Disconnected Soma Pieces 0.003236532211303711\n"
     ]
    }
   ],
   "source": [
    "optimize_time = time.time()\n",
    "\n",
    "# filtering away any of the inside floating pieces: \n",
    "non_soma_touching_meshes = [m for i,m in enumerate(split_meshes)\n",
    "                 if i not in set(list(containing_mesh_indices.values()))]\n",
    "\n",
    "if print_optimize:\n",
    "    print(f\" non_soma_touching_meshes {time.time()-optimize_time}\")\n",
    "optimize_time = time.time()\n",
    "\n",
    "#Adding the step that will filter away any pieces that are inside the soma\n",
    "if len(non_soma_touching_meshes) > 0 and len(soma_mesh_list) > 0:\n",
    "    \"\"\"\n",
    "    *** want to save these pieces that are inside of the soma***\n",
    "    \"\"\"\n",
    "\n",
    "    non_soma_touching_meshes,inside_pieces = sm.filter_away_inside_soma_pieces(soma_mesh_list,non_soma_touching_meshes,\n",
    "                                    significance_threshold=sig_th_initial_split,\n",
    "                                    return_inside_pieces = True)\n",
    "\n",
    "else:\n",
    "    non_soma_touching_meshes = []\n",
    "    inside_pieces=[]\n",
    "    \n",
    "if print_optimize:\n",
    "    print(f\" Finding inside pieces and non_soma_touching meshes {time.time()-optimize_time}\")\n",
    "optimize_time = time.time()\n",
    "\n",
    "# --------------------- 1/10 Change ---------------- #\n",
    "\n",
    "#adding in the nuclei center to the inside pieces\n",
    "inside_pieces += nuclei_meshes\n",
    "\n",
    "\n",
    "split_meshes # the meshes of the original mesh\n",
    "containing_mesh_indices #the mapping of each soma centroid to the correct split mesh\n",
    "soma_containing_meshes = sm.grouping_containing_mesh_indices(containing_mesh_indices)\n",
    "\n",
    "soma_touching_meshes = [split_meshes[k] for k in soma_containing_meshes.keys()]\n",
    "\n",
    "\n",
    "#     print(f\"# of non soma touching seperate meshes = {len(non_soma_touching_meshes)}\")\n",
    "#     print(f\"# of inside pieces = {len(inside_pieces)}\")\n",
    "print(f\"\\n-----Before filtering away multiple disconneted soma pieces-----\")\n",
    "print(f\"# of soma containing seperate meshes = {len(soma_touching_meshes)}\")\n",
    "print(f\"meshes with somas = {soma_containing_meshes}\")\n",
    "\n",
    "# ------ 11/15 Addition: Part 2.b \n",
    "\n",
    "\"\"\"\n",
    "Pseudocode: \n",
    "1) Get the largest of the meshes with a soma (largest in soma_touching_meshes)\n",
    "2) Save all other meshes not the largest in \n",
    "3) Overwrite the following variables:\n",
    "    soma_mesh_list\n",
    "    soma_containing_meshes\n",
    "    soma_touching_meshes\n",
    "    total_soma_list_sdf\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#1) Get the largest of the meshes with a soma (largest in soma_touching_meshes)\n",
    "soma_containing_meshes_keys = np.array(list(soma_containing_meshes.keys()))\n",
    "soma_touching_meshes = np.array([split_meshes[k] for k in soma_containing_meshes_keys])\n",
    "largest_soma_touching_mesh_idx = soma_containing_meshes_keys[np.argmax([len(kk.faces) for kk in soma_touching_meshes])]\n",
    "\n",
    "#2) Save all other meshes not the largest in \n",
    "not_processed_soma_containing_meshes_idx = np.setdiff1d(soma_containing_meshes_keys,[largest_soma_touching_mesh_idx])\n",
    "not_processed_soma_containing_meshes = [split_meshes[k] for k in not_processed_soma_containing_meshes_idx]\n",
    "print(f\"Number of not_processed_soma_containing_meshes = {len(not_processed_soma_containing_meshes)}\")\n",
    "\n",
    "\"\"\"\n",
    "3) Overwrite the following variables:\n",
    "    soma_mesh_list\n",
    "    soma_containing_meshes\n",
    "    soma_touching_meshes\n",
    "    total_soma_list_sdf\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "somas_idx_to_process = soma_containing_meshes[largest_soma_touching_mesh_idx]\n",
    "soma_mesh_list = [soma_mesh_list[k] for k in somas_idx_to_process]\n",
    "\n",
    "soma_containing_meshes = {largest_soma_touching_mesh_idx:list(np.arange(0,len(soma_mesh_list)))}\n",
    "\n",
    "soma_touching_meshes = [split_meshes[largest_soma_touching_mesh_idx]]\n",
    "\n",
    "total_soma_list_sdf = total_soma_list_sdf[somas_idx_to_process]\n",
    "\n",
    "print(f\"\\n-----After filtering away multiple disconneted soma pieces-----\")\n",
    "print(f\"# of soma containing seperate meshes = {len(soma_touching_meshes)}\")\n",
    "print(f\"meshes with somas = {soma_containing_meshes}\")\n",
    "\n",
    "\n",
    "if print_optimize:\n",
    "    print(f\" Filtering Away Disconnected Soma Pieces {time.time()-optimize_time}\")\n",
    "optimize_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Way to Get the Soma and Non-Soma Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_touching_mesh_data = dict()\n",
    "\n",
    "for z,(mesh_idx, soma_idxes) in enumerate(soma_containing_meshes.items()):\n",
    "    soma_touching_mesh_data[z] = dict()\n",
    "    print(f\"\\n\\n----Working on soma-containing mesh piece {z}----\")\n",
    "\n",
    "    #1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "    current_mesh = split_meshes[mesh_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(current_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_somas = tu.combine_meshes(soma_mesh_list)\n",
    "nviz.plot_objects(combined_somas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.original_mesh_faces_map(current_mesh,\n",
    "                          tu.combine_meshes(soma_mesh_list),\n",
    "                          exact_match=True,\n",
    "                          matching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.original_mesh_faces_map(current_mesh,\n",
    "                          tu.combine_meshes(soma_mesh_list),\n",
    "                          exact_match=True,\n",
    "                          matching=False)\n",
    "\n",
    "#     soma_mesh_list\n",
    "#     current_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1154523,  245834,  245833, ..., 1135397, 1135465, 1136982],\n",
       "      dtype=uint32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(seperated_somas_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperated_somas_idx = [tu.original_mesh_faces_map(original_mesh=current_mesh,\n",
    "                                  submesh=k,\n",
    "                                  exact_match = True,\n",
    "                                matching=True) for k in current_soma_mesh_list]\n",
    "seperated_somas_real = [current_mesh.submesh([k],append=True,repair=False) for k in seperated_somas_idx]\n",
    "\n",
    "other_meshes = current_mesh.submesh([np.delete(np.arange(len(current_mesh.faces)),np.concatenate(seperated_somas_idx))],append=True,repair=False)\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08070ee280304aea869f4ac0f6869bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(other_meshes,\n",
    "                  meshes=seperated_somas_real,\n",
    "                  meshes_colors=\"red\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_soma_stacked_mesh_face_idx = tu.original_mesh_faces_map(original_mesh=current_mesh,\n",
    "                                  submesh=tu.combine_meshes(current_soma_mesh_list),\n",
    "                                  exact_match = True,\n",
    "                                matching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "Total time for Subtract Soma and Original_mesh_faces_map for somas= 0.4018244743347168\n",
      "new_floating_pieces = []\n",
      "Total time for sig_non_soma_pieces= 4.9509968757629395\n",
      "Total time for split= 2.6226043701171875e-06\n",
      "Total time for mesh_pieces_connectivity= 13.859325885772705\n",
      "# of insignificant_limbs = 2 with trimesh : [<trimesh.Trimesh(vertices.shape=(212, 3), faces.shape=(395, 3))>, <trimesh.Trimesh(vertices.shape=(18, 3), faces.shape=(27, 3))>]\n",
      "# of not_processed_soma_containing_meshes = 0 with trimesh : []\n"
     ]
    }
   ],
   "source": [
    "#--- Phase 3:  Soma Extraction was great (but it wasn't the original soma faces), so now need to get the original soma faces and the original non-soma faces of original pieces\n",
    "\n",
    "\"\"\"\n",
    "for each soma touching mesh get the following:\n",
    "1) original soma meshes\n",
    "2) significant mesh pieces touching these somas\n",
    "3) The soma connectivity to each of the significant mesh pieces\n",
    "-- later will just translate the \n",
    "\n",
    "\n",
    "Process: \n",
    "\n",
    "1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "2) Subtact all soma faces from original mesh\n",
    "3) Find all significant mesh pieces\n",
    "4) Backtrack significant mesh pieces to orignal mesh and find connectivity of each to all\n",
    "   the available somas\n",
    "Conclusion: Will have connectivity map\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "soma_touching_mesh_data = dict()\n",
    "\n",
    "for z,(mesh_idx, soma_idxes) in enumerate(soma_containing_meshes.items()):\n",
    "    soma_touching_mesh_data[z] = dict()\n",
    "    print(f\"\\n\\n----Working on soma-containing mesh piece {z}----\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    #1) Final all soma faces (through soma extraction and then soma original faces function)\n",
    "    current_mesh = split_meshes[mesh_idx]\n",
    "    \n",
    "    current_soma_mesh_list = [soma_mesh_list[k] for k in soma_idxes]\n",
    "    \n",
    "\n",
    "    \n",
    "    current_time = time.time()\n",
    "    \n",
    "    '''    seperate_soma_meshes = current_soma_mesh_list\n",
    "\n",
    "        non_soma_stacked_mesh_face_idx = tu.original_mesh_faces_map(original_mesh=current_mesh,\n",
    "                                      submesh=tu.combine_meshes(current_soma_mesh_list),\n",
    "                                      exact_match = True,\n",
    "                                    matching=False)\n",
    "\n",
    "        non_soma_stacked_mesh = current_mesh.submesh([non_soma_stacked_mesh_face_idx],append=True,repair=False)'''\n",
    "\n",
    "\n",
    "    seperate_soma_meshes_idx = [tu.original_mesh_faces_map(original_mesh=current_mesh,\n",
    "                                  submesh=k,\n",
    "                                  exact_match = True,\n",
    "                                matching=True) for k in current_soma_mesh_list]\n",
    "    seperat_soma_meshs = [current_mesh.submesh([k],append=True,repair=False) for k in seperate_soma_meshes_idx]\n",
    "\n",
    "    non_soma_stacked_mesh = current_mesh.submesh([np.delete(np.arange(len(current_mesh.faces)),np.concatenate(seperate_soma_meshes_idx))],append=True,repair=False)\n",
    "\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_meshes\"] = seperate_soma_meshes\n",
    "    \n",
    "    print(f\"Total time for Subtract Soma and Original_mesh_faces_map for somas= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    # 3) Find all significant mesh pieces\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    a) Iterate through all of the somas and get the pieces that are connected\n",
    "    b) Concatenate all the results into one list and order\n",
    "    c) Filter away the mesh pieces that aren't touching and add to the floating pieces\n",
    "\n",
    "    \"\"\"\n",
    "    sig_non_soma_pieces,insignificant_limbs = tu.split_significant_pieces(non_soma_stacked_mesh,significance_threshold=limb_threshold,\n",
    "                                                     return_insignificant_pieces=True,\n",
    "                                                                         connectivity=pre_branch_connectivity)\n",
    "\n",
    "    # a) Filter these down to only those touching the somas\n",
    "    all_conneted_non_soma_pieces = []\n",
    "    for i,curr_soma in enumerate(seperate_soma_meshes):\n",
    "        (connected_mesh_pieces,\n",
    "         connected_mesh_pieces_vertices,\n",
    "         connected_mesh_pieces_vertices_idx) = tu.mesh_pieces_connectivity(\n",
    "                        main_mesh=current_mesh,\n",
    "                        central_piece=curr_soma,\n",
    "                        periphery_pieces = sig_non_soma_pieces,\n",
    "                        return_vertices = True,\n",
    "                        return_vertices_idx=True)\n",
    "        all_conneted_non_soma_pieces.append(connected_mesh_pieces)\n",
    "\n",
    "    #b) Iterate through all of the somas and get the pieces that are connected\n",
    "    t_non_soma_pieces = np.concatenate(all_conneted_non_soma_pieces)\n",
    "\n",
    "    #c) Filter away the mesh pieces that aren't touching and add to the floating pieces\n",
    "    sig_non_soma_pieces = [s_t for hh,s_t in enumerate(sig_non_soma_pieces) if hh in t_non_soma_pieces]\n",
    "    new_floating_pieces = [s_t for hh,s_t in enumerate(sig_non_soma_pieces) if hh not in t_non_soma_pieces]\n",
    "\n",
    "    print(f\"new_floating_pieces = {new_floating_pieces}\")\n",
    "\n",
    "    non_soma_touching_meshes += new_floating_pieces\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Total time for sig_non_soma_pieces= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "    soma_touching_mesh_data[z][\"branch_meshes\"] = sig_non_soma_pieces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Total time for split= {time.time() - current_time}\")\n",
    "    current_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    soma_to_piece_connectivity = dict()\n",
    "    soma_to_piece_touching_vertices = dict()\n",
    "    soma_to_piece_touching_vertices_idx = dict()\n",
    "    limb_root_nodes = dict()\n",
    "\n",
    "    m_vert_graph = tu.mesh_vertex_graph(current_mesh)\n",
    "\n",
    "    for i,curr_soma in enumerate(seperate_soma_meshes):\n",
    "        (connected_mesh_pieces,\n",
    "         connected_mesh_pieces_vertices,\n",
    "         connected_mesh_pieces_vertices_idx) = tu.mesh_pieces_connectivity(\n",
    "                        main_mesh=current_mesh,\n",
    "                        central_piece=curr_soma,\n",
    "                        periphery_pieces = sig_non_soma_pieces,\n",
    "                        return_vertices = True,\n",
    "                        return_vertices_idx=True)\n",
    "        #print(f\"soma {i}: connected_mesh_pieces = {connected_mesh_pieces}\")\n",
    "        soma_to_piece_connectivity[i] = connected_mesh_pieces\n",
    "\n",
    "        soma_to_piece_touching_vertices[i] = dict()\n",
    "        for piece_index,piece_idx in enumerate(connected_mesh_pieces):\n",
    "            limb_root_nodes[piece_idx] = connected_mesh_pieces_vertices[piece_index][0]\n",
    "\n",
    "            \"\"\" Old way of finding vertex connected components on a mesh without trimesh function\n",
    "            #find the number of touching groups and save those \n",
    "            soma_touching_graph = m_vert_graph.subgraph(connected_mesh_pieces_vertices_idx[piece_index])\n",
    "            soma_con_comp = [current_mesh.vertices[np.array(list(k)).astype(\"int\")] for k in list(nx.connected_components(soma_touching_graph))]\n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = soma_con_comp\n",
    "            \"\"\"\n",
    "\n",
    "            soma_to_piece_touching_vertices[i][piece_idx] = tu.split_vertex_list_into_connected_components(\n",
    "                                                vertex_indices_list=connected_mesh_pieces_vertices_idx[piece_index],\n",
    "                                                mesh=current_mesh, \n",
    "                                                vertex_graph=m_vert_graph, \n",
    "                                                return_coordinates=True\n",
    "                                               )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         border_debug = False\n",
    "#         if border_debug:\n",
    "#             print(f\"soma_to_piece_connectivity = {soma_to_piece_connectivity}\")\n",
    "#             print(f\"soma_to_piece_touching_vertices = {soma_to_piece_touching_vertices}\")\n",
    "\n",
    "\n",
    "    print(f\"Total time for mesh_pieces_connectivity= {time.time() - current_time}\")\n",
    "\n",
    "    soma_touching_mesh_data[z][\"soma_to_piece_connectivity\"] = soma_to_piece_connectivity\n",
    "\n",
    "print(f\"# of insignificant_limbs = {len(insignificant_limbs)} with trimesh : {insignificant_limbs}\")\n",
    "print(f\"# of not_processed_soma_containing_meshes = {len(not_processed_soma_containing_meshes)} with trimesh : {not_processed_soma_containing_meshes}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lets have an alert if there was more than one soma disconnected meshes\n",
    "if len(soma_touching_mesh_data.keys()) > 1:\n",
    "    raise Exception(\"More than 1 disconnected meshes that contain somas\")\n",
    "\n",
    "current_mesh_data = soma_touching_mesh_data\n",
    "soma_containing_idx = 0\n",
    "\n",
    "#doing inversion of the connectivity and touching vertices\n",
    "piece_to_soma_touching_vertices = gu.flip_key_orders_for_dict(soma_to_piece_touching_vertices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the Actual Limb Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = reload(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Working on Proper Limb # 0 ---------\n",
      "meshparty_segment_size = 100\n",
      "root_curr = [603951.8 807448.8 923483.1]\n",
      "Time for preparing soma vertices and root: 0.0003056526184082031\n",
      "invalidation_d = 12000\n",
      "cc_vertex_thresh = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f82359f314f47e69c9223424e4d5ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=295340.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meshparty_segment_size = 100\n",
      "Time for 1st pass MP skeletonization: 11.865105628967285\n",
      "connecting at the root\n",
      "branches_touching_root = [98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:903: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:941: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_segment_branches = np.array([sk_meshparty_obj.vertices[np.vstack([k[:-1],k[1:]]).T] for k in new_segments])\n",
      "/meshAfterParty/meshparty_skeletonize.py:973: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches = np.array(new_segment_branches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Graph = 36893\n",
      "Working on path [3129. 3161. 3184. 3208. 3226. 3246. 3264.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [36893.  3315.  3349.  3384.  3418.  3452.  3490.  3502.]\n",
      "path_degrees = [4, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [36894.  3517.  3536.  3565.  3593.  3634.  3645.  3650.]\n",
      "path_degrees = [5, 2, 2, 2, 2, 2, 2, 3]\n",
      "Working on path [24841. 24843. 24848. 24850. 24855. 24857.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [28920. 28946. 28972. 28999. 29027. 29029.]\n",
      "path_degrees = [3, 2, 2, 2, 2, 3]\n",
      "Working on path [30188. 30215. 30242. 30265. 30274.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n",
      "Working on path [31389. 31403. 31417. 31432. 31446.]\n",
      "path_degrees = [3, 2, 2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/meshparty_skeletonize.py:1002: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  segment_branches_filtered = np.array(segment_branches_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After combining close endpoints max(kept_branches_idx) = 98, len(kept_branches_idx) = 92\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.005023365876131107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cf8088ba984d81a317beedf66ffad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435c9858ce574de8b46ea5e591c7fe0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=92.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposing first pass: 34.6277756690979\n",
      "Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\n",
      "Another print\n",
      "Found len(mesh_large_idx) MAP candidates: [3646, 8022, 6024, 5208, 3500, 7146, 7685, 9334, 8788, 41184, 20056, 2440, 22806, 4221, 8344, 28366, 16273, 17720, 20925, 2622, 22934, 14405, 15785]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_large_connectivity: 1.1682426929473877\n",
      "Finding MAP candidates connected components: 0.00024890899658203125\n",
      "len(filtered_pieces) = 1\n",
      "skeleton_connectivity_MP : 2.791050434112549\n",
      "Grouping MP Sublimbs by Graph: 0.17036795616149902\n",
      "Divinding into MP and MAP pieces: 1.1920928955078125e-06\n",
      "--- Working on MAP piece 0---\n",
      "MAP Filtering Soma Pieces: 0.01847100257873535\n",
      "inside skeletonize_connected_branch and use_surface_after_CGAL=False, surface_reconstruction_size=1000\n",
      "     Starting Screened Poisson\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/poisson_585373.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/None_poisson.off\n",
      "Using the close holes feature\n",
      "Mesh was manifold\n",
      "No holes needed to fill and mesh was manifold so returning original mesh\n",
      "-----Time for Screened Poisson= 24.709524631500244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_pieces = [<trimesh.Trimesh(vertices.shape=(73274, 3), faces.shape=(146552, 3))>, <trimesh.Trimesh(vertices.shape=(9717, 3), faces.shape=(19430, 3))>, <trimesh.Trimesh(vertices.shape=(3485, 3), faces.shape=(6966, 3))>]\n",
      "     Starting Calcification (Changed back where stitches large poissons)\n",
      "min_edge_length = 75\n",
      "min_edge_length = 75\n",
      "min_edge_length = 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7075316e4dfd416485e04fc47244004e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No skeletons to stack so returning empty list\n",
      "len_subgraphs AT BEGINNING of the loop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057a2d6990964555b244b90802d4edc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all graph is one component!\n",
      "\n",
      "Total time for skeleton stitching = 0.22481060028076172\n",
      "The process was using a temp folder\n",
      "Checking connected components after skeletonize_connected_branch\n",
      "    Total time for skeletonizing branch: 39.56597423553467\n",
      "Checking connected components after removing cycles\n",
      "Total time for mesh KDTree = 2.764122724533081\n",
      "sbv[0].reshape(-1,3) = [[603951.8 807448.8 923483.1]]\n",
      "closest_sk_pt_coord BEFORE = [602607. 807152. 924772.]\n",
      "current_skeleton.shape = (6321, 2, 3)\n",
      "node_for_stitch = 5007: [602607. 807152. 924772.]\n",
      "node_for_stitch AFTER = 5007: [602607. 807152. 924772.]\n",
      "possible_node_loc = [   0  147  186  219  226  285  305  324  379  419  421  485  613  659\n",
      "  701  719  728  741  877  907  952 1051 1065 1117 1227 1243 1244 1336\n",
      " 1391 1437 1439 1514 1554 1572 1592 1593 1627 1641 1685 1691 1782 1825\n",
      " 1829 1994 2102 2120 2147 2243 2456 2468 2484 2585 2593 2670 2696 2964\n",
      " 3033 3034 3120 3122 3218 3239 3381 3407 3416 3423 3503 3598 3839 4159\n",
      " 4209 4245 4298 4308 4448 4464 4518 4602 4699 4706 4715 4749 4840 4906\n",
      " 4912 5007 5119 5235 5244 5281 5302 5354 5392 5417 5456 5516 5553 5594\n",
      " 5604 5621 5651 5711 5744 5755 5791 5823 5837 5894 5909 5923 5943 5966\n",
      " 5971 6038 6106 6142 6150 6218 6247 6321]\n",
      "possible_node_loc AFTER = [   0  147  186  219  226  285  305  324  379  419  421  485  613  659\n",
      "  701  719  728  741  877  907  952 1051 1065 1117 1227 1243 1244 1336\n",
      " 1391 1437 1439 1514 1554 1572 1592 1593 1627 1641 1685 1691 1782 1825\n",
      " 1829 1994 2102 2120 2147 2243 2456 2468 2484 2585 2593 2670 2696 2964\n",
      " 3033 3034 3120 3122 3218 3239 3381 3407 3416 3423 3503 3598 3839 4159\n",
      " 4209 4245 4298 4308 4448 4464 4518 4602 4699 4706 4715 4749 4840 4906\n",
      " 4912 5007 5119 5235 5244 5281 5302 5354 5392 5417 5456 5516 5553 5594\n",
      " 5604 5621 5651 5711 5744 5755 5791 5823 5837 5894 5909 5923 5943 5966\n",
      " 5971 6038 6106 6142 6150 6218 6247 6321]\n",
      "curr_shortest_path = [5007]\n",
      "Current stitch point was a branch or endpoint\n",
      "change_status for create soma extending pieces = False\n",
      "closest_sk_pt_coord AFTER = [602607. 807152. 924772.]\n",
      "skipping soma 0 because closest skeleton node was already end node\n",
      "endpoints_must_keep = {0: array([[602607., 807152., 924772.]])}\n",
      "    Total time for Fixing Skeleton Soma Endpoint Extension : 6.404739618301392\n",
      "filter_end_node_length = 4000\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_5631.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_5631_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_680796.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_5631.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_5631_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_680796.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 55\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[ 602607.  807152.  924772.]\n",
      " [ 565837.  808650. 1049280.]\n",
      " [ 596458.  692477.  897623.]\n",
      " [ 600572.  738150.  873959.]]\n",
      "Number of end_nodes BEFORE filtering = 120\n",
      "all_single_nodes_to_eliminate = [85, 29, 73, 79]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de4bf1c8b974662a23c67e0629413f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=111.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking connected components after clean_skeleton\n",
      "after DISTANCE cleaning limb size of skeleton = (5834, 2, 3)\n",
      "********COMBINING CLOSE SKELETON NODES WITHIN 700 DISTANCE**********\n",
      "Found 0 valid paths to replace\n",
      "valid_paths = []\n",
      "valid_path_lengths = []\n",
      "No valid paths found so just returning the original\n",
      "skeletonize_and_clean_connected_branch_CGAL: 106.07403302192688\n",
      "Working on limb correspondence for #0 MAP piece\n",
      "xvfb-run -n 2596 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_94278.off -o /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_94278_remove_interior.off -s /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_934398.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_94278.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/neuron_94278_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Decomposition_Optimization/Debug/temp/remove_interior_934398.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (100) interior meshes present\n",
      "largest is 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f125647c134b64a8277da86d0ec4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for decomposition = 51.399197816848755\n",
      "mesh_correspondence_first_pass: 51.39922642707825\n",
      "Limb decomposed into 19 branches\n",
      "divided_skeleton_graph_recovered = (5834, 2, 3) and \n",
      "current_mesh_data[0]['branch_skeletons_cleaned'].shape = (5834, 2, 3)\n",
      "\n",
      "Number of connected components in deocmposed recovered graph = 1\n",
      "Number of connected components in cleaned skeleton graph= 1\n",
      "The downsampled branches number of connected components = 1\n",
      "Empty submeshes = []\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (18, 19)\n",
      "empty_indices % = 0.18567816725727387\n",
      " conflict_indices % = 0.02087521937639947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239f852efb7d493c891da74d0a62b249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=546.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n",
      "Took 0 iterations to expand the label back\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245206f2a36e425a93c0a6bcb3fdce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6459e0a4e6a45dd912daa96940ece17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time for MAP sublimb #0 mesh processing = 180.0378773212433\n",
      "correspondence_1_to_1: 22.54611039161682\n",
      "Total time for MAP sublimb processing 180.03800582885742\n",
      "---- Working on MP Decomposition #0 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0074574947357177734\n",
      "Do Not Need to Fix MP Decomposition 0 so just continuing\n",
      "---- Working on MP Decomposition #1 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0015857219696044922\n",
      "Do Not Need to Fix MP Decomposition 1 so just continuing\n",
      "---- Working on MP Decomposition #2 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.001073598861694336\n",
      "Do Not Need to Fix MP Decomposition 2 so just continuing\n",
      "---- Working on MP Decomposition #3 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.003250598907470703\n",
      "Do Not Need to Fix MP Decomposition 3 so just continuing\n",
      "---- Working on MP Decomposition #4 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0016472339630126953\n",
      "Do Not Need to Fix MP Decomposition 4 so just continuing\n",
      "---- Working on MP Decomposition #5 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0009162425994873047\n",
      "Do Not Need to Fix MP Decomposition 5 so just continuing\n",
      "---- Working on MP Decomposition #6 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0012443065643310547\n",
      "Do Not Need to Fix MP Decomposition 6 so just continuing\n",
      "---- Working on MP Decomposition #7 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0041043758392333984\n",
      "Do Not Need to Fix MP Decomposition 7 so just continuing\n",
      "---- Working on MP Decomposition #8 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0018353462219238281\n",
      "Do Not Need to Fix MP Decomposition 8 so just continuing\n",
      "---- Working on MP Decomposition #9 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0012664794921875\n",
      "Do Not Need to Fix MP Decomposition 9 so just continuing\n",
      "---- Working on MP Decomposition #10 ----\n",
      "Computing the current soma touching verts dict manually\n",
      "MP filtering soma verts: 0.0006492137908935547\n",
      "Do Not Need to Fix MP Decomposition 10 so just continuing\n",
      "Successful mesh connectivity with type edges\n",
      "\n",
      "---- Working on (0, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 4619: [602411. 742605. 889757.]\n",
      "node_for_stitch AFTER = 4619: [602411. 742605. 889757.]\n",
      "possible_node_loc = [4367 4652]\n",
      "possible_node_loc AFTER = [4367 4652]\n",
      "curr_shortest_path = [4619, 4626.0, 4636.0, 4643.0, 4642.0, 4640.0, 4638.0, 4635.0, 4629.0, 4622.0, 4611.0, 4597.0, 4573.0, 4547.0, 4549.0, 4551.0, 4552.0, 4553.0, 4548.0, 4543.0, 4535.0, 4527.0, 4520.0, 4513.0, 4496.0, 4500.0, 4515.0, 4528.0, 4539.0, 4555.0, 4564.0, 4571.0, 4581.0, 4602.0, 4618.0, 4632.0, 4641.0, 4648.0, 4650.0, 4654.0, 4658.0, 4665.0, 4669.0, 4674.0, 4679.0, 4682.0, 4686.0, 4694.0, 4697.0, 4700.0, 4699.0, 4698.0, 4696.0, 4695.0, 4693.0, 4691.0, 4690.0, 4689.0, 4687.0, 4685.0, 4683.0, 4680.0, 4673.0, 4671.0, 4664.0, 4652.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 13267.173181625327\n",
      "sk_conn = [7]\n",
      "conn = [7]\n",
      "winning_vertex = [603135.74903851 742788.78554442 889730.81694418]\n",
      "MP_branches_with_stitch_point = [7]\n",
      "MAP_branches_with_stitch_point = [14]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a39cde48af7420480af7de00f97855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3489171788118232\n",
      " conflict_indices % = 0.0029997073456248173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f6bd09249b403a9186a3bb008d908b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b180c26fe534437bdd35f0148fa3621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef521c2f3af24e9497f27e1253d05d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/numpy_utils.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(conn_comps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.5506560103483322\n",
      " conflict_indices % = 0.0009470571930148757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c881b5703ce84fe396bf1d73247d2871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06937af139964e70b2d566dea4f83657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [7]\n",
      "MP_branches_for_correspondence = [7]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (0, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (1, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 4432: [601219. 705427. 895581.]\n",
      "node_for_stitch AFTER = 4432: [601219. 705427. 895581.]\n",
      "possible_node_loc = [4189 4903]\n",
      "possible_node_loc AFTER = [4189 4903]\n",
      "curr_shortest_path = [4432, 4428.0, 4425.0, 4418.0, 4415.0, 4412.0, 4411.0, 4407.0, 4403.0, 4402.0, 4399.0, 4397.0, 4393.0, 4390.0, 4389.0, 4386.0, 4385.0, 4384.0, 4381.0, 4379.0, 4380.0, 4383.0, 4388.0, 4392.0, 4400.0, 4405.0, 4395.0, 4387.0, 4377.0, 4372.0, 4365.0, 4357.0, 4352.0, 4339.0, 4331.0, 4323.0, 4320.0, 4318.0, 4314.0, 4310.0, 4303.0, 4296.0, 4295.0, 4292.0, 4288.0, 4284.0, 4281.0, 4277.0, 4274.0, 4269.0, 4265.0, 4262.0, 4260.0, 4252.0, 4233.0, 4241.0, 4242.0, 4244.0, 4246.0, 4248.0, 4253.0, 4251.0, 4249.0, 4247.0, 4243.0, 4239.0, 4238.0, 4236.0, 4232.0, 4230.0, 4229.0, 4226.0, 4224.0, 4221.0, 4220.0, 4218.0, 4216.0, 4215.0, 4211.0, 4210.0, 4207.0, 4204.0, 4202.0, 4198.0, 4195.0, 4189.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 15289.504996452022\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [600681.60681221 705205.74853506 896089.19052625]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [11]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec87a31ec65747cc9a4f01a600412b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.1309779276517474\n",
      " conflict_indices % = 0.002605763335377069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e7d3027dfd44a99af44e32e2172b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c11147c7f924808b80c5e04e888c577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb952193a9af41959ecb22ac390186cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.16844333840953832\n",
      " conflict_indices % = 0.022360063885896817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504e1e117c164290bfccb418fe7587e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe5e1ad054947a3baab5b2669afbada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (1, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (2, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 2880: [591879. 400238. 908602.]\n",
      "node_for_stitch AFTER = 2880: [591879. 400238. 908602.]\n",
      "possible_node_loc = [2251 2880]\n",
      "possible_node_loc AFTER = [2251 2880]\n",
      "curr_shortest_path = [2880]\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [589888.46394605 379178.23861797 923119.35177624]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [5]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc59a916f09475d8410721ee065415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n",
      "/meshAfterParty/numpy_utils.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(conn_comps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.26042515067600586\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2356b3677ad34991b0adcdc7e57db557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0801756e48d04228874ef53a17ec0d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (2, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (3, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 1085: [562573. 798788. 977576.]\n",
      "node_for_stitch AFTER = 1085: [562573. 798788. 977576.]\n",
      "possible_node_loc = [1307 4095]\n",
      "possible_node_loc AFTER = [1307 4095]\n",
      "curr_shortest_path = [1085, 1082.0, 1079.0, 1077.0, 1072.0, 1067.0, 1063.0, 1053.0, 1049.0, 1038.0, 1032.0, 1022.0, 1011.0, 1002.0, 980.0, 973.0, 969.0, 967.0, 957.0, 950.0, 945.0, 938.0, 934.0, 930.0, 924.0, 908.0, 903.0, 897.0, 891.0, 887.0, 883.0, 880.0, 881.0, 884.0, 886.0, 889.0, 893.0, 895.0, 902.0, 916.0, 929.0, 936.0, 947.0, 954.0, 958.0, 962.0, 977.0, 976.0, 983.0, 991.0, 1008.0, 1013.0, 1025.0, 1036.0, 1045.0, 1060.0, 1070.0, 1080.0, 1093.0, 1102.0, 1110.0, 1114.0, 1117.0, 1120.0, 1125.0, 1128.0, 1131.0, 1134.0, 1135.0, 1138.0, 1145.0, 1152.0, 1160.0, 1169.0, 1178.0, 1186.0, 1194.0, 1211.0, 1219.0, 1220.0, 1224.0, 1229.0, 1234.0, 1239.0, 1243.0, 1248.0, 1256.0, 1268.0, 1273.0, 1278.0, 1285.0, 1291.0, 1301.0, 1305.0, 1306.0, 1308.0, 1309.0, 1312.0, 1313.0, 1315.0, 1318.0, 1320.0, 1322.0, 1325.0, 1327.0, 1330.0, 1331.0, 1335.0, 1337.0, 1338.0, 1341.0, 1344.0, 1347.0, 1350.0, 1351.0, 1354.0, 1357.0, 1360.0, 1362.0, 1366.0, 1371.0, 1374.0, 1376.0, 1379.0, 1382.0, 1385.0, 1388.0, 1390.0, 1393.0, 1395.0, 1397.0, 1399.0, 1401.0, 1404.0, 1407.0, 1411.0, 1412.0, 1416.0, 1419.0, 1421.0, 1425.0, 1428.0, 1431.0, 1436.0, 1437.0, 1439.0, 1442.0, 1445.0, 1446.0, 1449.0, 1451.0, 1453.0, 1455.0, 1458.0, 1462.0, 1465.0, 1468.0, 1471.0, 1472.0, 1475.0, 1477.0, 1478.0, 1480.0, 1482.0, 1484.0, 1486.0, 1488.0, 1490.0, 1491.0, 1494.0, 1496.0, 1497.0, 1500.0, 1501.0, 1503.0, 1505.0, 1507.0, 1509.0, 1510.0, 1513.0, 1514.0, 1516.0, 1517.0, 1520.0, 1521.0, 1523.0, 1525.0, 1526.0, 1530.0, 1531.0, 1532.0, 1535.0, 1528.0, 1538.0, 1542.0, 1547.0, 1552.0, 1558.0, 1560.0, 1562.0, 1565.0, 1567.0, 1572.0, 1573.0, 1574.0, 1578.0, 1581.0, 1584.0, 1586.0, 1589.0, 1591.0, 1593.0, 1594.0, 1596.0, 1599.0, 1602.0, 1605.0, 1607.0, 1609.0, 1612.0, 1614.0, 1617.0, 1618.0, 1621.0, 1622.0, 1624.0, 1627.0, 1629.0, 1631.0, 1634.0, 1635.0, 1636.0, 1638.0, 1639.0, 1642.0, 1641.0, 1644.0, 1649.0, 1652.0, 1655.0, 1658.0, 1659.0, 1662.0, 1665.0, 1666.0, 1669.0, 1667.0, 1673.0, 1675.0, 1681.0, 1684.0, 1689.0, 1691.0, 1694.0, 1696.0, 1697.0, 1701.0, 1704.0, 1706.0, 1709.0, 1711.0, 1713.0, 1715.0, 1717.0, 1720.0, 1721.0, 1724.0, 1726.0, 1730.0, 1732.0, 1734.0, 1736.0, 1737.0, 1740.0, 1742.0, 1745.0, 1748.0, 1749.0, 1751.0, 1754.0, 1755.0, 1757.0, 1759.0, 1760.0, 1762.0, 1764.0, 1766.0, 1769.0, 1771.0, 1774.0, 1776.0, 1778.0, 1781.0, 1784.0, 1787.0, 1789.0, 1792.0, 1794.0, 1797.0, 1800.0, 1802.0, 1806.0, 1809.0, 1812.0, 1815.0, 1819.0, 1822.0, 1825.0, 1826.0, 1828.0, 1830.0, 1832.0, 1833.0, 1865.0, 1880.0, 1887.0, 1891.0, 1884.0, 1909.0, 1919.0, 1926.0, 1949.0, 1956.0, 1965.0, 1968.0, 1973.0, 1991.0, 2004.0, 2020.0, 2041.0, 2065.0, 2083.0, 2094.0, 2105.0, 2112.0, 2126.0, 2141.0, 2155.0, 2166.0, 2175.0, 2183.0, 2202.0, 2223.0, 2239.0, 2266.0, 2297.0, 2327.0, 2358.0, 2390.0, 2409.0, 2426.0, 2487.0, 2532.0, 2571.0, 2609.0, 2621.0, 2645.0, 2670.0, 2690.0, 2738.0, 2777.0, 2796.0, 2810.0, 2845.0, 2899.0, 2914.0, 2938.0, 2970.0, 2986.0, 3011.0, 3093.0, 3125.0, 3161.0, 3171.0, 3210.0, 3230.0, 3290.0, 3308.0, 3343.0, 3394.0, 3399.0, 3436.0, 3471.0, 3489.0, 3505.0, 3512.0, 3524.0, 3535.0, 3546.0, 3568.0, 3588.0, 3596.0, 3605.0, 3619.0, 3626.0, 3633.0, 3643.0, 3656.0, 3664.0, 3680.0, 3705.0, 3725.0, 3752.0, 3768.0, 3783.0, 3803.0, 3841.0, 3853.0, 3867.0, 3896.0, 3930.0, 3968.0, 3999.0, 4026.0, 4051.0, 4095.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 72424.00309427954\n",
      "sk_conn = [11]\n",
      "conn = [11]\n",
      "winning_vertex = [562654.31349009 798124.16269965 977558.71613419]\n",
      "MP_branches_with_stitch_point = [11]\n",
      "MAP_branches_with_stitch_point = [2]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132c576267184bcb91a0dcf95eea3a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.15672000202219358\n",
      " conflict_indices % = 0.0005055483936199793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6e9a2fc54949008a70ca69e4359fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=91.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8364e843f702452c838ba4b5319f2fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ecc20419aa4ff1a240319c43d3b18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.16760290316166235\n",
      " conflict_indices % = 0.0035295287333465897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e6780fe88349b0b35cca4bbb171337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc3276243da4b2b8a197e1c9238d540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [11]\n",
      "MP_branches_for_correspondence = [11]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (3, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (4, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 2589: [590897. 639844. 897287.]\n",
      "node_for_stitch AFTER = 2589: [590897. 639844. 897287.]\n",
      "possible_node_loc = [2251 4189]\n",
      "possible_node_loc AFTER = [2251 4189]\n",
      "curr_shortest_path = [2589, 2623.0, 2640.0, 2696.0, 2642.0, 2632.0, 2620.0, 2606.0, 2577.0, 2576.0, 2586.0, 2593.0, 2600.0, 2612.0, 2619.0, 2624.0, 2639.0, 2657.0, 2676.0, 2685.0, 2694.0, 2707.0, 2732.0, 2764.0, 2791.0, 2797.0, 2798.0, 2805.0, 2806.0, 2812.0, 2813.0, 2817.0, 2824.0, 2827.0, 2832.0, 2834.0, 2837.0, 2840.0, 2844.0, 2847.0, 2852.0, 2854.0, 2860.0, 2866.0, 2869.0, 2872.0, 2873.0, 2870.0, 2867.0, 2864.0, 2858.0, 2855.0, 2856.0, 2857.0, 2859.0, 2861.0, 2865.0, 2868.0, 2871.0, 2874.0, 2878.0, 2883.0, 2881.0, 2887.0, 2893.0, 2901.0, 2908.0, 2923.0, 2933.0, 2946.0, 2962.0, 2976.0, 2993.0, 2999.0, 3009.0, 3013.0, 3034.0, 3064.0, 3094.0, 3107.0, 3122.0, 3140.0, 3156.0, 3180.0, 3202.0, 3215.0, 3234.0, 3282.0, 3292.0, 3310.0, 3325.0, 3347.0, 3355.0, 3361.0, 3377.0, 3407.0, 3419.0, 3433.0, 3441.0, 3449.0, 3455.0, 3463.0, 3473.0, 3479.0, 3483.0, 3487.0, 3491.0, 3498.0, 3504.0, 3508.0, 3518.0, 3522.0, 3527.0, 3534.0, 3539.0, 3547.0, 3553.0, 3558.0, 3563.0, 3571.0, 3573.0, 3579.0, 3582.0, 3591.0, 3598.0, 3600.0, 3607.0, 3611.0, 3615.0, 3620.0, 3625.0, 3631.0, 3634.0, 3636.0, 3640.0, 3649.0, 3654.0, 3660.0, 3667.0, 3673.0, 3678.0, 3681.0, 3692.0, 3696.0, 3701.0, 3706.0, 3713.0, 3730.0, 3741.0, 3753.0, 3755.0, 3757.0, 3760.0, 3761.0, 3762.0, 3766.0, 3767.0, 3774.0, 3776.0, 3778.0, 3782.0, 3787.0, 3790.0, 3801.0, 3804.0, 3827.0, 3838.0, 3849.0, 3855.0, 3863.0, 3875.0, 3884.0, 3893.0, 3903.0, 3910.0, 3913.0, 3918.0, 3924.0, 3935.0, 3947.0, 3948.0, 3950.0, 3952.0, 3953.0, 3954.0, 3949.0, 3957.0, 3960.0, 3965.0, 3970.0, 3976.0, 3986.0, 3994.0, 4003.0, 4008.0, 4014.0, 4021.0, 4023.0, 4027.0, 4029.0, 4032.0, 4038.0, 4044.0, 4049.0, 4053.0, 4055.0, 4058.0, 4059.0, 4061.0, 4064.0, 4067.0, 4068.0, 4066.0, 4065.0, 4063.0, 4050.0, 4045.0, 4041.0, 4030.0, 4010.0, 3987.0, 3971.0, 3966.0, 3958.0, 3945.0, 3936.0, 3927.0, 3919.0, 3914.0, 3908.0, 3902.0, 3894.0, 3885.0, 3881.0, 3891.0, 3900.0, 3906.0, 3920.0, 3928.0, 3941.0, 3963.0, 3972.0, 3995.0, 4019.0, 4028.0, 4042.0, 4056.0, 4069.0, 4078.0, 4092.0, 4107.0, 4112.0, 4119.0, 4125.0, 4129.0, 4135.0, 4132.0, 4127.0, 4126.0, 4121.0, 4117.0, 4111.0, 4102.0, 4115.0, 4122.0, 4123.0, 4120.0, 4116.0, 4114.0, 4106.0, 4097.0, 4091.0, 4085.0, 4082.0, 4079.0, 4075.0, 4072.0, 4073.0, 4076.0, 4080.0, 4084.0, 4086.0, 4105.0, 4118.0, 4124.0, 4128.0, 4134.0, 4138.0, 4141.0, 4142.0, 4145.0, 4148.0, 4150.0, 4154.0, 4157.0, 4158.0, 4162.0, 4164.0, 4166.0, 4153.0, 4168.0, 4173.0, 4176.0, 4179.0, 4182.0, 4186.0, 4188.0, 4190.0, 4189.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 55064.63772542521\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [590995.76259516 639171.24516773 897215.6642029 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [3]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523fe45f9faa4d02bdd7fdd98317f2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.08395346529741529\n",
      " conflict_indices % = 0.0014635114352334177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e74c16767343e68566ecf185eafd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392d6614cd0941f19d5a3045974f908f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda19a54bd0d46698ddc74db007d22a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.08991169954524736\n",
      " conflict_indices % = 0.0046111281893636644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e47fdd0869640969cc1297fec2e2dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a659bc328cec405c8e9ad8997a5821b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (4, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (5, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 5834: [673835. 776410. 988110.]\n",
      "node_for_stitch AFTER = 5834: [673835. 776410. 988110.]\n",
      "possible_node_loc = [4644 5834]\n",
      "possible_node_loc AFTER = [4644 5834]\n",
      "curr_shortest_path = [5834]\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [ 695093.31338795  773675.12013922 1003698.53947622]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [17]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb08b7f98cc4a5b95ef87b185563c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n",
      "/meshAfterParty/numpy_utils.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(conn_comps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.2597514057413436\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a01bd6471a4249969ae7641e9ded17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbef76baa50a45e99fe0d25169ac38ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (5, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (6, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 2854: [591824. 647374. 897425.]\n",
      "node_for_stitch AFTER = 2854: [591824. 647374. 897425.]\n",
      "possible_node_loc = [2589 4189]\n",
      "possible_node_loc AFTER = [2589 4189]\n",
      "curr_shortest_path = [2854, 2852.0, 2847.0, 2844.0, 2840.0, 2837.0, 2834.0, 2832.0, 2827.0, 2824.0, 2817.0, 2813.0, 2812.0, 2806.0, 2805.0, 2798.0, 2797.0, 2791.0, 2764.0, 2732.0, 2707.0, 2694.0, 2685.0, 2676.0, 2657.0, 2639.0, 2624.0, 2619.0, 2612.0, 2600.0, 2593.0, 2586.0, 2576.0, 2577.0, 2606.0, 2620.0, 2632.0, 2642.0, 2696.0, 2640.0, 2623.0, 2589.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 8016.226550216117\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [592319.23514513 647352.35401891 897835.9063362 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [22]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f0b1453c684aa281fe1ed4bbe6cc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.08605537211074422\n",
      " conflict_indices % = 0.000762001524003048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109602168ac4801a5635b8dcd4870af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5d7e9b6ce74b1fa1a47b93d83042b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd46b824f00e43faa78059939f9471f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.1747518646854995\n",
      " conflict_indices % = 0.00872144241498796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bf3d87b19f4390afe0588e366cccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=55.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cac6482ee774c5085244df86e9768be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (6, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (7, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 5118: [613352. 719915. 903222.]\n",
      "node_for_stitch AFTER = 5118: [613352. 719915. 903222.]\n",
      "possible_node_loc = [4903 5118]\n",
      "possible_node_loc AFTER = [4903 5118]\n",
      "curr_shortest_path = [5118]\n",
      "Current stitch point was a branch or endpoint\n",
      "sk_conn = [0, 1]\n",
      "conn = [0, 1]\n",
      "winning_vertex = [613683.46083696 720058.24290574 903402.95527664]\n",
      "MP_branches_with_stitch_point = [0, 1]\n",
      "MAP_branches_with_stitch_point = [18]\n",
      "MAP_stitch_point_on_end_or_branch = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc4ea6a0ebe4bac95f1ccc77748ef08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.13232617400800872\n",
      " conflict_indices % = 0.007826720058245359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf18b5983494da89ccb1ca3f7030b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=76.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf41fe0bc4c4e26ad9ee8b3dee3284a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP_branches_with_stitch_point= [0, 1]\n",
      "MP_branches_for_correspondence = [0 1]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (7, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (8, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 5248: [618457. 795266. 958504.]\n",
      "node_for_stitch AFTER = 5248: [618457. 795266. 958504.]\n",
      "possible_node_loc = [4644 5834]\n",
      "possible_node_loc AFTER = [4644 5834]\n",
      "curr_shortest_path = [5248, 5246.0, 5244.0, 5242.0, 5240.0, 5237.0, 5231.0, 5228.0, 5230.0, 5235.0, 5234.0, 5232.0, 5229.0, 5226.0, 5225.0, 5224.0, 5222.0, 5221.0, 5220.0, 5218.0, 5216.0, 5214.0, 5213.0, 5212.0, 5210.0, 5209.0, 5208.0, 5206.0, 5205.0, 5203.0, 5202.0, 5200.0, 5198.0, 5197.0, 5194.0, 5193.0, 5192.0, 5190.0, 5189.0, 5187.0, 5186.0, 5184.0, 5183.0, 5182.0, 5181.0, 5179.0, 5178.0, 5176.0, 5175.0, 5174.0, 5173.0, 5172.0, 5170.0, 5169.0, 5167.0, 5162.0, 5160.0, 5154.0, 5152.0, 5149.0, 5146.0, 5145.0, 5143.0, 5147.0, 5155.0, 5168.0, 5177.0, 5171.0, 5164.0, 5156.0, 5153.0, 5157.0, 5159.0, 5163.0, 5165.0, 5161.0, 5158.0, 5151.0, 5150.0, 5148.0, 5144.0, 5141.0, 5139.0, 5138.0, 5136.0, 5135.0, 5133.0, 5132.0, 5130.0, 5128.0, 5127.0, 5124.0, 5123.0, 5121.0, 5119.0, 5117.0, 5115.0, 5112.0, 5110.0, 5109.0, 5105.0, 5102.0, 5100.0, 5098.0, 5096.0, 5093.0, 5091.0, 5088.0, 5086.0, 5083.0, 5082.0, 5080.0, 5077.0, 5076.0, 5074.0, 5072.0, 5070.0, 5068.0, 5066.0, 5064.0, 5061.0, 5059.0, 5058.0, 5053.0, 5051.0, 5049.0, 5044.0, 5043.0, 5040.0, 5038.0, 5036.0, 5033.0, 5030.0, 5028.0, 5027.0, 5024.0, 5023.0, 5021.0, 5018.0, 5015.0, 5012.0, 5010.0, 5009.0, 5006.0, 5005.0, 5002.0, 4999.0, 4996.0, 4993.0, 4991.0, 4990.0, 4987.0, 4985.0, 4982.0, 4979.0, 4977.0, 4973.0, 4971.0, 4969.0, 4968.0, 4966.0, 4964.0, 4963.0, 4962.0, 4961.0, 4960.0, 4959.0, 4957.0, 4956.0, 4955.0, 4953.0, 4952.0, 4950.0, 4949.0, 4947.0, 4945.0, 4944.0, 4942.0, 4941.0, 4940.0, 4938.0, 4936.0, 4935.0, 4934.0, 4933.0, 4930.0, 4929.0, 4927.0, 4926.0, 4923.0, 4922.0, 4921.0, 4919.0, 4918.0, 4916.0, 4914.0, 4912.0, 4910.0, 4908.0, 4906.0, 4905.0, 4902.0, 4897.0, 4891.0, 4885.0, 4881.0, 4875.0, 4868.0, 4865.0, 4859.0, 4850.0, 4820.0, 4806.0, 4777.0, 4767.0, 4764.0, 4752.0, 4741.0, 4735.0, 4716.0, 4678.0, 4661.0, 4644.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 39956.734286383966\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [619100.61219487 795382.76395145 958418.0067642 ]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [17]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4315dd952cf94c3ab4b1de75acee215c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.2516406060115045\n",
      " conflict_indices % = 0.0015393340354857004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f13e1f64de441e96ae3995d806829e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3f235e911f4e10ae6cc6552024b11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bef578d8c64cabacdf26f508bebd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/numpy_utils.py:418: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(conn_comps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.2776697292826325\n",
      " conflict_indices % = 0.009344331924977087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36cd4feb4dc4f7297d448b2b99b7e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588bb212012d4471b7593f86968a6a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (8, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (9, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 3397: [593477. 583254. 893325.]\n",
      "node_for_stitch AFTER = 3397: [593477. 583254. 893325.]\n",
      "possible_node_loc = [2251 2589]\n",
      "possible_node_loc AFTER = [2251 2589]\n",
      "curr_shortest_path = [3397, 3395.0, 3389.0, 3385.0, 3386.0, 3390.0, 3393.0, 3396.0, 3398.0, 3402.0, 3405.0, 3409.0, 3416.0, 3423.0, 3427.0, 3442.0, 3445.0, 3453.0, 3457.0, 3466.0, 3472.0, 3485.0, 3493.0, 3500.0, 3507.0, 3517.0, 3521.0, 3529.0, 3538.0, 3549.0, 3557.0, 3564.0, 3576.0, 3583.0, 3592.0, 3601.0, 3614.0, 3630.0, 3638.0, 3648.0, 3658.0, 3671.0, 3698.0, 3714.0, 3739.0, 3751.0, 3771.0, 3789.0, 3799.0, 3813.0, 3820.0, 3834.0, 3828.0, 3806.0, 3800.0, 3793.0, 3780.0, 3749.0, 3722.0, 3709.0, 3688.0, 3672.0, 3663.0, 3644.0, 3635.0, 3624.0, 3617.0, 3608.0, 3594.0, 3585.0, 3581.0, 3577.0, 3569.0, 3562.0, 3559.0, 3556.0, 3554.0, 3552.0, 3551.0, 3548.0, 3545.0, 3544.0, 3543.0, 3537.0, 3536.0, 3530.0, 3528.0, 3525.0, 3519.0, 3513.0, 3510.0, 3506.0, 3502.0, 3495.0, 3490.0, 3486.0, 3480.0, 3474.0, 3464.0, 3458.0, 3451.0, 3444.0, 3432.0, 3411.0, 3403.0, 3383.0, 3371.0, 3358.0, 3328.0, 3313.0, 3304.0, 3297.0, 3284.0, 3247.0, 3218.0, 3147.0, 3152.0, 3170.0, 3185.0, 3193.0, 3197.0, 3207.0, 3208.0, 3205.0, 3195.0, 3181.0, 3166.0, 3155.0, 3146.0, 3138.0, 3129.0, 3116.0, 3109.0, 3095.0, 3067.0, 3052.0, 3025.0, 3007.0, 3001.0, 2991.0, 2984.0, 2977.0, 2973.0, 2972.0, 2969.0, 2966.0, 2965.0, 2963.0, 2958.0, 2953.0, 2948.0, 2941.0, 2937.0, 2931.0, 2929.0, 2924.0, 2921.0, 2918.0, 2917.0, 2906.0, 2892.0, 2882.0, 2862.0, 2846.0, 2833.0, 2816.0, 2807.0, 2803.0, 2804.0, 2809.0, 2815.0, 2825.0, 2835.0, 2843.0, 2853.0, 2879.0, 2885.0, 2896.0, 2903.0, 2909.0, 2915.0, 2922.0, 2950.0, 2959.0, 2961.0, 2967.0, 2979.0, 2992.0, 2995.0, 3005.0, 3012.0, 3019.0, 3026.0, 3035.0, 3046.0, 3051.0, 3048.0, 3044.0, 3040.0, 3039.0, 3028.0, 2996.0, 2980.0, 2955.0, 2927.0, 2913.0, 2907.0, 2894.0, 2863.0, 2841.0, 2828.0, 2821.0, 2808.0, 2795.0, 2775.0, 2730.0, 2704.0, 2686.0, 2662.0, 2633.0, 2611.0, 2599.0, 2584.0, 2559.0, 2533.0, 2502.0, 2483.0, 2457.0, 2440.0, 2429.0, 2425.0, 2423.0, 2420.0, 2417.0, 2414.0, 2415.0, 2431.0, 2450.0, 2474.0, 2509.0, 2542.0, 2554.0, 2564.0, 2567.0, 2538.0, 2587.0, 2598.0, 2613.0, 2625.0, 2637.0, 2650.0, 2671.0, 2682.0, 2687.0, 2695.0, 2709.0, 2710.0, 2715.0, 2720.0, 2722.0, 2716.0, 2712.0, 2711.0, 2708.0, 2705.0, 2703.0, 2699.0, 2693.0, 2677.0, 2651.0, 2638.0, 2627.0, 2615.0, 2605.0, 2601.0, 2604.0, 2592.0, 2585.0, 2579.0, 2574.0, 2566.0, 2548.0, 2535.0, 2525.0, 2511.0, 2489.0, 2510.0, 2562.0, 2546.0, 2505.0, 2467.0, 2444.0, 2436.0, 2433.0, 2441.0, 2451.0, 2460.0, 2486.0, 2496.0, 2514.0, 2523.0, 2530.0, 2531.0, 2534.0, 2527.0, 2522.0, 2512.0, 2501.0, 2490.0, 2473.0, 2461.0, 2453.0, 2445.0, 2439.0, 2437.0, 2443.0, 2447.0, 2458.0, 2480.0, 2495.0, 2513.0, 2526.0, 2549.0, 2552.0, 2558.0, 2560.0, 2555.0, 2561.0, 2565.0, 2568.0, 2589.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 60698.803090432164\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [592988.65290932 583162.35783225 893295.61381551]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [3]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937f14ba0c424525b05e0b54f86ed361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.09953809121072149\n",
      " conflict_indices % = 0.0001789083338754798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf2083d331a4ba7826b1b77af40eed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=126.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcead4c253f4084ab6c83bf13b44890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3effd4f0782b44e2920b1b7005b1c54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.11011422526346801\n",
      " conflict_indices % = 0.0030263668867254977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8f49b3643249d58b74974d7e6fb6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff15ef5ecb2c44fa9645345f2cc0d76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (9, 0) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---- Working on (10, 0) connection-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/preprocessing_vp2.py:1851: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  for k in o_keys])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_for_stitch = 3124: [592679. 401751. 907019.]\n",
      "node_for_stitch AFTER = 3124: [592679. 401751. 907019.]\n",
      "possible_node_loc = [2251 2880]\n",
      "possible_node_loc AFTER = [2251 2880]\n",
      "curr_shortest_path = [3124, 3115.0, 3108.0, 3100.0, 3088.0, 3059.0, 3047.0, 3010.0, 2997.0, 2982.0, 2945.0, 2912.0, 2900.0, 2880.0]\n",
      "Current stitch point was not a branch or endpoint, shortest_path_length to one = 2343.159727665759\n",
      "sk_conn = [0]\n",
      "conn = [0]\n",
      "winning_vertex = [592322.49174089 401754.95694618 907327.98191384]\n",
      "MP_branches_with_stitch_point = [0]\n",
      "MAP_branches_with_stitch_point = [5]\n",
      "MAP_stitch_point_on_end_or_branch = False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e510c1c5064144b4ba8d65db164b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (1, 2)\n",
      "empty_indices % = 0.3376484105706626\n",
      " conflict_indices % = 0.0007659900421294523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054b7c4125c742e6b2fb98ca9c876e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc509a9a262149a3afb9f32e6f98b563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18420e5b448b417ea07b8bbf42254154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--- Working on 1-to-1 correspondence-----\n",
      "max(original_labels),len(original_labels) = (2, 3)\n",
      "empty_indices % = 0.25719190552983406\n",
      " conflict_indices % = 0.005670290797482182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09363eba61b34db1a7793afb4279b05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae3520b13c6470aa0fd0c14afd3db63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting branches from dictionary\n",
      "MP_branches_with_stitch_point= [0]\n",
      "MP_branches_for_correspondence = [0]\n",
      "MP_leftover = [], MP_leftover_idx = []\n",
      " Finished with (10, 0) \n",
      "\n",
      "\n",
      "\n",
      "Time for decomp of Limb = 381.812180519104\n",
      "Number of matching vertices = 69\n",
      "Only one endpoint after filtering away the endpoints that are not on the skeleton\n",
      "Using Distance measure skeletal_distance\n",
      "endpoints_must_keep = [[602607. 807152. 924772.]]\n",
      "Number of end_nodes BEFORE filtering = 53\n",
      "all_single_nodes_to_eliminate = [20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97e7dae83d944029ff6f45242dd1e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 1 skeletal branches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2504d24457ea4129bb23c2b39c92f774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=96.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "588320 588321\n",
      "For marked faces: None\n",
      "empty_indices % = 0.0\n",
      " conflict_indices % = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bb215d137d41db805d8de1d0994a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER face_lookup_resolved_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db43a68f0b4945e284e7ead82dbcda71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=94.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Finished",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-264b27191b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mlimb_network_stating_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_limb_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_starting_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total time for Skeletonization and Mesh Correspondence = {time.time() - skeleton_time}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Finished"
     ]
    }
   ],
   "source": [
    "# Phase 4: Skeletonization, Mesh Correspondence,  \n",
    "\n",
    "proper_time = time.time()\n",
    "\n",
    "#The containers that will hold the final data for the preprocessed neuron\n",
    "limb_correspondence=dict()\n",
    "limb_network_stating_info = dict()\n",
    "\n",
    "# ---------- Part A: skeletonization and mesh decomposition --------- #\n",
    "skeleton_time = time.time()\n",
    "\n",
    "for curr_limb_idx,limb_mesh_mparty in enumerate(current_mesh_data[0][\"branch_meshes\"]):\n",
    "\n",
    "    #Arguments to pass to the specific function (when working with a limb)\n",
    "    soma_touching_vertices_dict = piece_to_soma_touching_vertices[curr_limb_idx]\n",
    "\n",
    "    curr_limb_time = time.time()\n",
    "    print(f\"\\n\\n----- Working on Proper Limb # {curr_limb_idx} ---------\")\n",
    "    \n",
    "#     if curr_limb_idx != 1:\n",
    "#         continue\n",
    "#     else:\n",
    "#         raise Exception(\"\")\n",
    "\n",
    "    print(f\"meshparty_segment_size = {meshparty_segment_size}\")\n",
    "    limb_correspondence_individual,network_starting_info = pre.preprocess_limb(mesh=limb_mesh_mparty,\n",
    "                   soma_touching_vertices_dict = soma_touching_vertices_dict,\n",
    "                   return_concept_network = False, \n",
    "                   return_concept_network_starting_info=True,\n",
    "                   width_threshold_MAP=500,\n",
    "                   size_threshold_MAP=2000,\n",
    "                   surface_reconstruction_size=1000,  \n",
    "\n",
    "                   #arguments added from the big preprocessing step                                                            \n",
    "                   distance_by_mesh_center=distance_by_mesh_center,\n",
    "                   meshparty_segment_size=meshparty_segment_size,\n",
    "                   meshparty_n_surface_downsampling = meshparty_n_surface_downsampling,\n",
    "\n",
    "                    use_meshafterparty=use_meshafterparty,\n",
    "\n",
    "                   )\n",
    "    #Storing all of the data to be sent to \n",
    "\n",
    "    limb_correspondence[curr_limb_idx] = limb_correspondence_individual\n",
    "    limb_network_stating_info[curr_limb_idx] = network_starting_info\n",
    "    \n",
    "\n",
    "print(f\"Total time for Skeletonization and Mesh Correspondence = {time.time() - skeleton_time}\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Part B: Stitching on floating pieces --------- #\n",
    "print(\"\\n\\n ----- Working on Stitching ----------\")\n",
    "\n",
    "floating_stitching_time = time.time()\n",
    "\n",
    "if len(limb_correspondence) > 0:\n",
    "    non_soma_touching_meshes_to_stitch = tu.check_meshes_outside_multiple_mesh_bbox(seperate_soma_meshes,non_soma_touching_meshes,\n",
    "                             return_indices=False)\n",
    "\n",
    "    limb_correspondence_with_floating_pieces = pre.attach_floating_pieces_to_limb_correspondence(\n",
    "            limb_correspondence,\n",
    "            floating_meshes=non_soma_touching_meshes_to_stitch,\n",
    "            floating_piece_face_threshold = 600,\n",
    "            max_stitch_distance=8000,\n",
    "            distance_to_move_point_threshold = 4000,\n",
    "            verbose = False)\n",
    "else:\n",
    "    limb_correspondence_with_floating_pieces = limb_correspondence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total time for stitching floating pieces = {time.time() - floating_stitching_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Part C: Computing Concept Networks --------- #\n",
    "concept_network_time = time.time()\n",
    "\n",
    "limb_concept_networks=dict()\n",
    "limb_labels=dict()\n",
    "\n",
    "for curr_limb_idx,limb_mesh_mparty in enumerate(current_mesh_data[0][\"branch_meshes\"]):\n",
    "    limb_to_soma_concept_networks = pre.calculate_limb_concept_networks(limb_correspondence_with_floating_pieces[curr_limb_idx],\n",
    "                                                                    limb_network_stating_info[curr_limb_idx],\n",
    "                                                                    run_concept_network_checks=True,\n",
    "                                                                       )   \n",
    "\n",
    "\n",
    "\n",
    "    limb_concept_networks[curr_limb_idx] = limb_to_soma_concept_networks\n",
    "    limb_labels[curr_limb_idx]= \"Unlabeled\"\n",
    "\n",
    "print(f\"Total time for Concept Networks = {time.time() - concept_network_time}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the can't find endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Limb Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh=limb_mesh_mparty\n",
    "soma_touching_vertices_dict = soma_touching_vertices_dict\n",
    "return_concept_network = False\n",
    "return_concept_network_starting_info=True\n",
    "width_threshold_MAP=500\n",
    "size_threshold_MAP=2000\n",
    "surface_reconstruction_size=1000  \n",
    "\n",
    "#arguments added from the big preprocessing step                                                            \n",
    "distance_by_mesh_center=distance_by_mesh_center\n",
    "meshparty_segment_size=meshparty_segment_size\n",
    "meshparty_n_surface_downsampling = meshparty_n_surface_downsampling\n",
    "\n",
    "use_meshafterparty=use_meshafterparty\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combine_close_skeleton_nodes=True\n",
    "combine_close_skeleton_nodes_threshold=700\n",
    "filter_end_node_length=4000\n",
    "perform_cleaning_checks = True\n",
    "\n",
    "\n",
    "\n",
    "#parameters for MP skeletonization,\n",
    "\n",
    "#Parameters for setting how the MAP skeletonization takes place\n",
    "use_surface_after_CGAL=False\n",
    "\n",
    "#parametrers for stitching the MAP and MP pieces together\n",
    "move_MAP_stitch_to_end_or_branch = True\n",
    "distance_to_move_point_threshold=500\n",
    "\n",
    "#concept_network parameters\n",
    "run_concept_network_checks = True\n",
    "\n",
    "\n",
    "#printing controls\n",
    "verbose = True\n",
    "print_fusion_steps=True\n",
    "\n",
    "check_correspondence_branches = True\n",
    "filter_end_nodes_from_correspondence = True\n",
    "\n",
    "error_on_no_starting_coordinates=True,\n",
    "prevent_MP_starter_branch_stitches = False, #will control if a MP soma extending branch is able to be stitched to\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb_time = time.time()\n",
    "\n",
    "limb_mesh_mparty = mesh\n",
    "\n",
    "\n",
    "#will store a list of all the endpoints tha tmust be kept:\n",
    "limb_to_endpoints_must_keep_list = []\n",
    "limb_to_soma_touching_vertices_list = []\n",
    "\n",
    "# --------------- Part 1 and 2: Getting Border Vertices and Setting the Root------------- #\n",
    "fusion_time = time.time()\n",
    "#will eventually get the current root from soma_to_piece_touching_vertices[i]\n",
    "if not soma_touching_vertices_dict is None:\n",
    "    root_curr = soma_touching_vertices_dict[list(soma_touching_vertices_dict.keys())[0]][0][0]\n",
    "else:\n",
    "    root_curr = None\n",
    "\n",
    "print(f\"root_curr = {root_curr}\")\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Time for preparing soma vertices and root: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "# --------------- Part 3: Meshparty skeletonization and Decomposition ------------- #\n",
    "sk_meshparty_obj = m_sk.skeletonize_mesh_largest_component(limb_mesh_mparty,\n",
    "                                                        root=root_curr,\n",
    "                                                          filter_mesh=False)\n",
    "\n",
    "print(f\"meshparty_segment_size = {meshparty_segment_size}\")\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Time for 1st pass MP skeletonization: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "(segment_branches, #skeleton branches\n",
    "divided_submeshes, divided_submeshes_idx, #mesh correspondence (mesh and indices)\n",
    "segment_widths_median) = m_sk.skeleton_obj_to_branches(sk_meshparty_obj,\n",
    "                                                      mesh = limb_mesh_mparty,\n",
    "                                                      meshparty_segment_size=meshparty_segment_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Decomposing first pass: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "\n",
    "if use_meshafterparty:\n",
    "    print(\"Attempting to use MeshAfterParty Skeletonization and Mesh Correspondence\")\n",
    "    # --------------- Part 4: Find Individual Branches that could be MAP processed because of width ------------- #\n",
    "    #gettin the branches that should be passed through MAP skeletonization\n",
    "    pieces_above_threshold = np.where(segment_widths_median>width_threshold_MAP)[0]\n",
    "\n",
    "    #getting the correspondnece info for those MAP qualifying\n",
    "    width_large = segment_widths_median[pieces_above_threshold]\n",
    "    sk_large = [segment_branches[k] for k in pieces_above_threshold]\n",
    "    mesh_large_idx = [divided_submeshes_idx[k] for k in pieces_above_threshold]\n",
    "else:\n",
    "    print(\"Only Using MeshParty Skeletonization and Mesh Correspondence\")\n",
    "    mesh_large_idx = []\n",
    "    width_large = []\n",
    "    sk_large = []\n",
    "\n",
    "\n",
    "print(\"Another print\")\n",
    "mesh_pieces_for_MAP = []\n",
    "mesh_pieces_for_MAP_face_idx = []\n",
    "\n",
    "\n",
    "if len(mesh_large_idx) > 0: #will only continue processing if found MAP candidates\n",
    "\n",
    "    # --------------- Part 5: Find mesh connectivity and group MAP branch candidates into MAP sublimbs ------------- #\n",
    "    print(f\"Found len(mesh_large_idx) MAP candidates: {[len(k) for k in mesh_large_idx]}\")\n",
    "\n",
    "    #finds the connectivity edges of all the MAP candidates\n",
    "    mesh_large_connectivity = tu.mesh_list_connectivity(meshes = mesh_large_idx,\n",
    "                                                        connectivity=\"edges\",\n",
    "                            main_mesh = limb_mesh_mparty,\n",
    "                            print_flag = False)\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_large_connectivity: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    --------------- Grouping MAP candidates ----------------\n",
    "    Purpose: Will see what mesh pieces should be grouped together\n",
    "    to pass through CGAL skeletonization\n",
    "\n",
    "\n",
    "    Pseudocode: \n",
    "    1) build a networkx graph with all nodes for mesh_large_idx indexes\n",
    "    2) Add the edges\n",
    "    3) Find the connected components\n",
    "    4) Find sizes of connected components\n",
    "    5) For all those connected components that are of a large enough size, \n",
    "    add the mesh branches and skeletons to the final list\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(np.arange(len(mesh_large_idx)))\n",
    "    G.add_edges_from(mesh_large_connectivity)\n",
    "    conn_comp = list(nx.connected_components(G))\n",
    "    \n",
    "    print(\"**** Debugging big mesh connectivity ********\")\n",
    "    print(f\"mesh_large_connectivity = {mesh_large_connectivity}\")\n",
    "    print(f\"conn_comp = {conn_comp}\")\n",
    "\n",
    "    filtered_pieces = []\n",
    "\n",
    "    sk_large_size_filt = []\n",
    "    mesh_large_idx_size_filt = []\n",
    "    width_large_size_filt = []\n",
    "\n",
    "    for cc in conn_comp:\n",
    "        total_cc_size = np.sum([len(mesh_large_idx[k]) for k in cc])\n",
    "        if total_cc_size>size_threshold_MAP:\n",
    "            #print(f\"cc ({cc}) passed the size threshold because size was {total_cc_size}\")\n",
    "            filtered_pieces.append(pieces_above_threshold[list(cc)])\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"Finding MAP candidates connected components: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    #filtered_pieces: will have the indexes of all the branch candidates that should  be \n",
    "    #grouped together and passed through MAP skeletonization\n",
    "\n",
    "    if len(filtered_pieces) > 0:\n",
    "        # --------------- Part 6: If Found MAP sublimbs, Get the meshes and mesh_idxs of the sublimbs ------------- #\n",
    "        print(f\"len(filtered_pieces) = {len(filtered_pieces)}\")\n",
    "        #all the pieces that will require MAP mesh correspondence and skeletonization\n",
    "        #(already organized into their components)\n",
    "        mesh_pieces_for_MAP = [limb_mesh_mparty.submesh([np.concatenate(divided_submeshes_idx[k])],append=True,repair=False) for k in filtered_pieces]\n",
    "        mesh_pieces_for_MAP_face_idx = [np.concatenate(divided_submeshes_idx[k]) for k in filtered_pieces]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Old Way: Finding connectivity of pieces through\n",
    "        mesh_idx_MP = [divided_submeshes_idx[k] for k in pieces_idx_MP]\n",
    "\n",
    "        mesh_large_connectivity_MP = tu.mesh_list_connectivity(meshes = mesh_idx_MP,\n",
    "                                main_mesh = limb_mesh_mparty,\n",
    "                                print_flag = False)\n",
    "\n",
    "        New Way: going to use skeleton connectivity to determine\n",
    "        connectivity of pieces\n",
    "\n",
    "        Pseudocode: \n",
    "        1)\n",
    "\n",
    "        \"\"\"\n",
    "        # --------------- Part 7: If Found MAP sublimbs, Get the meshes and mesh_idxs of the sublimbs ------------- #\n",
    "        # ********* if there are no pieces leftover then will automatically make all the lists below just empty (don't need to if.. else.. the case)****\n",
    "        pieces_idx_MP = np.setdiff1d(np.arange(len(divided_submeshes_idx)),np.concatenate(filtered_pieces))\n",
    "\n",
    "        skeleton_MP = [segment_branches[k] for k in pieces_idx_MP]\n",
    "        skeleton_connectivity_MP = sk.skeleton_list_connectivity(\n",
    "                                        skeletons=skeleton_MP\n",
    "                                        )\n",
    "        if print_fusion_steps:\n",
    "            print(f\"skeleton_connectivity_MP : {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(np.arange(len(skeleton_MP)))\n",
    "        G.add_edges_from(skeleton_connectivity_MP)\n",
    "        sublimbs_MP = list(nx.connected_components(G))\n",
    "        sublimbs_MP_orig_idx = [pieces_idx_MP[list(k)] for k in sublimbs_MP]\n",
    "\n",
    "\n",
    "        #concatenate into sublimbs the skeletons and meshes\n",
    "        sublimb_mesh_idx_branches_MP = [divided_submeshes_idx[k] for k in sublimbs_MP_orig_idx]\n",
    "        sublimb_mesh_branches_MP = [[limb_mesh_mparty.submesh([ki],append=True,repair=False)\n",
    "                                    for ki in k] for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_meshes_MP = [limb_mesh_mparty.submesh([np.concatenate(k)],append=True,repair=False)\n",
    "                                                     for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_meshes_MP_face_idx = [np.concatenate(k)\n",
    "                                                     for k in sublimb_mesh_idx_branches_MP]\n",
    "        sublimb_skeleton_branches = [segment_branches[k] for k in sublimbs_MP_orig_idx]\n",
    "        widths_MP = [segment_widths_median[k] for k in sublimbs_MP_orig_idx]\n",
    "\n",
    "        if print_fusion_steps:\n",
    "            print(f\"Grouping MP Sublimbs by Graph: {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "\n",
    "# else: #if no pieces were determine to need MAP processing\n",
    "#     print(\"No MAP processing needed: just returning the Meshparty skeletonization and mesh correspondence\")\n",
    "#     raise Exception(\"Returning MP correspondence\")\n",
    "\n",
    "\n",
    "# nviz.plot_objects(main_mesh=tu.combine_meshes([limb_mesh_mparty,current_neuron[\"S0\"].mesh]),\n",
    "#                   main_mesh_color=\"green\",\n",
    "#     skeletons=sk_large_size_filt,\n",
    "#      meshes=[limb_mesh_mparty.submesh([k],append=True) for k in mesh_large_idx_size_filt],\n",
    "#       meshes_colors=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------- Part 8: If No MAP sublimbs found, set the MP sublimb lists to just the whole MP branch decomposition ------------- #\n",
    "\n",
    "#if no sublimbs need to be decomposed with MAP then just reassign all of the previous MP processing to the sublimb_MPs\n",
    "if len(mesh_pieces_for_MAP) == 0:\n",
    "    sublimb_meshes_MP = [limb_mesh_mparty] #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "    # -- the decomposition information ---\n",
    "    sublimb_mesh_branches_MP = [divided_submeshes] #the mesh branches for all the disconnected sublimbs\n",
    "    sublimb_mesh_idx_branches_MP = [divided_submeshes_idx] #The mesh branches idx that have already passed through MP skeletonization\n",
    "    sublimb_skeleton_branches = [segment_branches]#the skeleton bnraches for all the sublimbs\n",
    "    widths_MP = [segment_widths_median] #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "    MAP_flag = False\n",
    "else:\n",
    "    MAP_flag = True\n",
    "\n",
    "\n",
    "\n",
    "mesh_pieces_for_MAP #trimesh pieces that should go through CGAL skeletonization\n",
    "sublimb_meshes_MP #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "\n",
    "# -- the decomposition information ---\n",
    "sublimb_mesh_branches_MP #the mesh branches for all the disconnected sublimbs\n",
    "sublimb_mesh_idx_branches_MP #The mesh branches idx that have already passed through MP skeletonization\n",
    "sublimb_skeleton_branches #the skeleton bnraches for all the sublimbs\n",
    "widths_MP #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "if print_fusion_steps:\n",
    "    print(f\"Divinding into MP and MAP pieces: {time.time() - fusion_time }\")\n",
    "    fusion_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------- At this point have the correct division between MAP and MP ------------------------\n",
    "\n",
    "# -------------- Part 9: Doing the MAP decomposition ------------------ #\n",
    "global_start_time = time.time()\n",
    "endpoints_must_keep = dict()\n",
    "\n",
    "\n",
    "\n",
    "limb_correspondence_MAP = dict()\n",
    "\n",
    "for sublimb_idx,(mesh,mesh_idx) in enumerate(zip(mesh_pieces_for_MAP,mesh_pieces_for_MAP_face_idx)):\n",
    "    print(f\"--- Working on MAP piece {sublimb_idx}---\")\n",
    "    #print(f\"soma_touching_vertices_dict = {soma_touching_vertices_dict}\")\n",
    "    mesh_start_time = time.time()\n",
    "    curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "    mesh = mesh,\n",
    "    curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "    )\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MAP Filtering Soma Pieces: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 0) Generating the Clean skeletons  -------------------------------------------#\n",
    "    if not curr_soma_to_piece_touching_vertices is None:\n",
    "        curr_total_border_vertices = dict([(k,np.vstack(v)) for k,v in curr_soma_to_piece_touching_vertices.items()])\n",
    "    else:\n",
    "        curr_total_border_vertices = None\n",
    "\n",
    "\n",
    "    cleaned_branch,curr_limb_endpoints_must_keep = sk.skeletonize_and_clean_connected_branch_CGAL(\n",
    "        mesh=mesh,\n",
    "        curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices,\n",
    "        total_border_vertices=curr_total_border_vertices,\n",
    "        filter_end_node_length=filter_end_node_length,\n",
    "        perform_cleaning_checks=perform_cleaning_checks,\n",
    "        combine_close_skeleton_nodes = combine_close_skeleton_nodes,\n",
    "        combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold,\n",
    "    use_surface_after_CGAL=use_surface_after_CGAL,\n",
    "    surface_reconstruction_size=surface_reconstruction_size)\n",
    "\n",
    "    if not curr_limb_endpoints_must_keep is None:\n",
    "        limb_to_endpoints_must_keep_list.append(curr_limb_endpoints_must_keep)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices)\n",
    "    else:\n",
    "        print(\"Inside MAP decomposition and curr_limb_endpoints_must_keep was None\")\n",
    "\n",
    "    if len(cleaned_branch) == 0:\n",
    "        raise Exception(f\"Found a zero length skeleton for limb {z} of trmesh {branch}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"skeletonize_and_clean_connected_branch_CGAL: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 1) Generating Initial Mesh Correspondence -------------------------------------------#\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Working on limb correspondence for #{sublimb_idx} MAP piece\")\n",
    "    local_correspondence = mesh_correspondence_first_pass(mesh=mesh,\n",
    "                                                         skeleton=cleaned_branch,\n",
    "                                                         distance_by_mesh_center=distance_by_mesh_center,\n",
    "                                                         connectivity=\"edges\",\n",
    "                                                         remove_inside_pieces_threshold=100)\n",
    "\n",
    "\n",
    "    print(f\"Total time for decomposition = {time.time() - start_time}\")\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_correspondence_first_pass: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "\n",
    "    #------------- 2) Doing Some checks on the initial corespondence -------- #\n",
    "\n",
    "\n",
    "    if perform_cleaning_checks:\n",
    "        check_skeletonization_and_decomp(skeleton=cleaned_branch,\n",
    "                                        local_correspondence=local_correspondence)\n",
    "\n",
    "    # -------3) Finishing off the face correspondence so get 1-to-1 correspondence of mesh face to skeletal piece\n",
    "    local_correspondence_revised = correspondence_1_to_1(mesh=mesh,\n",
    "                                    local_correspondence=local_correspondence,\n",
    "                                    curr_limb_endpoints_must_keep=curr_limb_endpoints_must_keep,\n",
    "                                    curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices)\n",
    "\n",
    "    # -------3b) Fixing the mesh indices to correspond to the larger mesh as a whole\n",
    "    for k,v in local_correspondence_revised.items():\n",
    "        local_correspondence_revised[k][\"branch_face_idx\"] = mesh_idx[local_correspondence_revised[k][\"branch_face_idx\"]]\n",
    "\n",
    "    print(f\"Total time for MAP sublimb #{sublimb_idx} mesh processing = {time.time() - mesh_start_time}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"correspondence_1_to_1: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    limb_correspondence_MAP[sublimb_idx] = local_correspondence_revised\n",
    "\n",
    "print(f\"Total time for MAP sublimb processing {time.time() - global_start_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- Part 10: Doing the MP Decomposition ---------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sublimb_meshes_MP #trimesh pieces that have already been passed through MP skeletonization (may not need)\n",
    "# -- the decomposition information ---\n",
    "sublimb_mesh_branches_MP #the mesh branches for all the disconnected sublimbs\n",
    "sublimb_mesh_idx_branches_MP #The mesh branches idx that have already passed through MP skeletonization\n",
    "sublimb_skeleton_branches #the skeleton bnraches for all the sublimbs\n",
    "widths_MP #the mesh branches widths for all the disconnected groups\n",
    "\n",
    "limb_correspondence_MP = dict()\n",
    "\n",
    "for sublimb_idx,mesh in enumerate(sublimb_meshes_MP):\n",
    "    print(f\"---- Working on MP Decomposition #{sublimb_idx} ----\")\n",
    "    mesh_start_time = time.time()\n",
    "\n",
    "    if len(sublimb_meshes_MP) == 1 and MAP_flag == False:\n",
    "        print(\"Using Quicker soma_to_piece_touching_vertices because no MAP and only one sublimb_mesh piece \")\n",
    "        curr_soma_to_piece_touching_vertices = soma_touching_vertices_dict\n",
    "    else:\n",
    "        if not soma_touching_vertices_dict is None:\n",
    "            print(\"Computing the current soma touching verts dict manually\")\n",
    "            curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "                                                mesh = mesh,\n",
    "                                                curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "                                                )\n",
    "        else:\n",
    "            curr_soma_to_piece_touching_vertices = None\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MP filtering soma verts: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    #creating all of the sublimb groups\n",
    "    segment_branches = np.array(sublimb_skeleton_branches[sublimb_idx])\n",
    "    whole_sk_MP = sk.stack_skeletons(segment_branches)\n",
    "    branch = mesh\n",
    "    divided_submeshes = np.array(sublimb_mesh_branches_MP[sublimb_idx])\n",
    "    divided_submeshes_idx = sublimb_mesh_idx_branches_MP[sublimb_idx]\n",
    "    segment_widths_median = widths_MP[sublimb_idx]\n",
    "\n",
    "\n",
    "    if curr_soma_to_piece_touching_vertices is None:\n",
    "        print(f\"Do Not Need to Fix MP Decomposition {sublimb_idx} so just continuing\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        # ------- 11/9 addition: Fixing error where creating soma touching branch on mesh that doesn't touch border ------------------- #\n",
    "        print(f\"Fixing Possible Soma Extension Branch for Sublimb {sublimb_idx}\")\n",
    "        no_soma_extension_add = True \n",
    "\n",
    "        endpts_total = dict()\n",
    "        curr_soma_to_piece_touching_vertices_total = dict()\n",
    "        for sm_idx,sm_bord_verts_list in curr_soma_to_piece_touching_vertices.items():\n",
    "            #will be used for later\n",
    "            endpts_total[sm_idx] = []\n",
    "            curr_soma_to_piece_touching_vertices_total[sm_idx] = []\n",
    "\n",
    "            for sm_bord_verts in sm_bord_verts_list:\n",
    "                #1) Get the mesh pieces that are touching the border\n",
    "                matching_mesh_idx = tu.filter_meshes_by_containing_coordinates(mesh_list=divided_submeshes,\n",
    "                                           nullifying_points=sm_bord_verts,\n",
    "                                            filter_away=False,\n",
    "                                           distance_threshold=0,\n",
    "                                           return_indices=True)\n",
    "                #2) concatenate all meshes and skeletons that are touching\n",
    "                if len(matching_mesh_idx) <= 0:\n",
    "                    raise Exception(\"None of branches were touching the border vertices when fixing MP pieces\")\n",
    "\n",
    "                touch_mesh = tu.combine_meshes(divided_submeshes[matching_mesh_idx])\n",
    "                touch_sk = sk.stack_skeletons(segment_branches[matching_mesh_idx])\n",
    "\n",
    "                local_curr_soma_to_piece_touching_vertices = {sm_idx:[sm_bord_verts]}\n",
    "                new_sk,endpts,new_branch_info = sk.create_soma_extending_branches(current_skeleton=touch_sk,\n",
    "                                      skeleton_mesh=touch_mesh,\n",
    "                                      soma_to_piece_touching_vertices=local_curr_soma_to_piece_touching_vertices,\n",
    "                                      return_endpoints_must_keep=True,\n",
    "                                      return_created_branch_info=True,\n",
    "                                      check_connected_skeleton=False)\n",
    "                # ---- 12/30 Addition Check if the endpoint found is an endnode or not and if not then manually add branch ---\n",
    "                curr_endnode = endpts[sm_idx][0]\n",
    "                match_sk_branches = sk.find_branch_skeleton_with_specific_coordinate(segment_branches,\n",
    "                    current_coordinate=curr_endnode)\n",
    "                \n",
    "                if len(match_sk_branches) > 1:\n",
    "                    border_average_coordinate = np.mean(sm_bord_verts,axis=0)\n",
    "                    new_branch_sk = np.vstack([curr_endnode,border_average_coordinate]).reshape(-1,2,3)\n",
    "                    br_info = dict(new_branch = new_branch_sk,border_verts=sm_bord_verts)\n",
    "                    endpts_total[sm_idx].append(border_average_coordinate)\n",
    "                else:\n",
    "                    br_info = new_branch_info[sm_idx][0]\n",
    "                    endpts_total[sm_idx].append(endpts[sm_idx][0])\n",
    "                # -------------------- End of 12/30 Addition ------------------\n",
    "                \n",
    "\n",
    "                #3) Add the info to the new running lists\n",
    "                \n",
    "                curr_soma_to_piece_touching_vertices_total[sm_idx].append(sm_bord_verts)\n",
    "\n",
    "\n",
    "                #4) Skip if no new branch was added\n",
    "                \n",
    "                if br_info is None:\n",
    "                    print(\"The new branch info was none so skipping \\n\")\n",
    "                    continue\n",
    "\n",
    "                #4 If new branch was made then \n",
    "                no_soma_extension_add=False\n",
    "\n",
    "                #1) Get the newly added branch (and the original vertex which is the first row)\n",
    "                br_new,sm_bord_verts = br_info[\"new_branch\"],br_info[\"border_verts\"] #this will hold the new branch and the border vertices corresponding to it\n",
    "\n",
    "                curr_soma_to_piece_touching_vertices_MP = {sm_idx:[sm_bord_verts]}\n",
    "                endpoints_must_keep_MP = {sm_idx:[br_new[0][1]]}\n",
    "\n",
    "\n",
    "                orig_vertex = br_new[0][0]\n",
    "                print(f\"orig_vertex = {orig_vertex}\")\n",
    "\n",
    "                #2) Find the branches that have that coordinate (could be multiple)\n",
    "                match_sk_branches = sk.find_branch_skeleton_with_specific_coordinate(segment_branches,\n",
    "                    current_coordinate=orig_vertex)\n",
    "\n",
    "                print(f\"match_sk_branches = {match_sk_branches}\")\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\" ******************* THIS NEEDS TO BE FIXED WITH THE SAME METHOD OF STITCHING ********************  \"\"\"\n",
    "                \"\"\"\n",
    "                Pseudocode:\n",
    "                1) Find if branch point will require split or not\n",
    "                2) If does require split then split the skeleton\n",
    "                3) Gather mesh pieces for correspondence and the skeletons\n",
    "                4) Run the mesh correspondence\n",
    "                - this case calculate the new widths after run \n",
    "                5) Replace the old branch parts with the new ones\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                stitch_point_on_end_or_branch = find_if_stitch_point_on_end_or_branch(\n",
    "                                                        matched_branches_skeletons= segment_branches[match_sk_branches],\n",
    "                                                         stitch_coordinate=orig_vertex,\n",
    "                                                          verbose=False)\n",
    "\n",
    "\n",
    "                if not stitch_point_on_end_or_branch:\n",
    "                    matching_branch_sk = sk.cut_skeleton_at_coordinate(skeleton=segment_branches[match_sk_branches][0],\n",
    "                                                                      cut_coordinate = orig_vertex)\n",
    "                else:\n",
    "                    matching_branch_sk = segment_branches[match_sk_branches]\n",
    "\n",
    "\n",
    "                #3) Find the mesh and skeleton of the winning branch\n",
    "                matching_branch_meshes = np.array(divided_submeshes)[match_sk_branches]\n",
    "                matching_branch_mesh_idx = np.array(divided_submeshes_idx)[match_sk_branches]\n",
    "                extend_soma_mesh_idx = np.concatenate(matching_branch_mesh_idx)\n",
    "                extend_soma_mesh = limb_mesh_mparty.submesh([extend_soma_mesh_idx ],append=True,repair=False)\n",
    "\n",
    "                #4) Add newly created branch to skeleton and divide the skeleton into branches (could make 2 or 3)\n",
    "                #extended_skeleton_to_soma = sk.stack_skeletons([list(matching_branch_sk),br_new])\n",
    "\n",
    "                sk.check_skeleton_connected_component(sk.stack_skeletons(list(matching_branch_sk) + [br_new]))\n",
    "\n",
    "                #5) Run Adaptive mesh correspondnece using branches and mesh\n",
    "                local_correspondnece_MP = mesh_correspondence_first_pass(mesh=extend_soma_mesh,\n",
    "                                                                         skeleton_branches = list(matching_branch_sk) + [br_new]\n",
    "                                              #skeleton=extended_skeleton_to_soma\n",
    "                                                                        )\n",
    "\n",
    "                # GETTING MESHES THAT ARE NOT FULLY CONNECTED!!\n",
    "                local_correspondence_revised = correspondence_1_to_1(mesh=extend_soma_mesh,\n",
    "                                                            local_correspondence=local_correspondnece_MP,\n",
    "                                                            curr_limb_endpoints_must_keep=endpoints_must_keep_MP,\n",
    "                                                            curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices_MP)\n",
    "\n",
    "                # All the things that should be revised:\n",
    "            #     segment_branches, #skeleton branches\n",
    "            #     divided_submeshes, divided_submeshes_idx, #mesh correspondence (mesh and indices)\n",
    "            #     segment_widths_median\n",
    "\n",
    "\n",
    "                new_submeshes = [k[\"branch_mesh\"] for k in local_correspondence_revised.values()]\n",
    "                new_submeshes_idx = [extend_soma_mesh_idx[k[\"branch_face_idx\"]] for k in local_correspondence_revised.values()]\n",
    "                new_skeletal_branches = [k[\"branch_skeleton\"] for k in local_correspondence_revised.values()]\n",
    "\n",
    "                #calculate the new width\n",
    "                ray_inter = tu.ray_pyembree.RayMeshIntersector(limb_mesh_mparty)\n",
    "                new_widths = []\n",
    "                for new_s_idx in new_submeshes_idx:\n",
    "                    curr_ray_distance = tu.ray_trace_distance(mesh=limb_mesh_mparty, \n",
    "                                        face_inds=new_s_idx,\n",
    "                                       ray_inter=ray_inter)\n",
    "                    curr_width_median = np.median(curr_ray_distance[curr_ray_distance!=0])\n",
    "                    print(f\"curr_width_median = {curr_width_median}\")\n",
    "                    if (not np.isnan(curr_width_median)) and (curr_width_median > 0):\n",
    "                        new_widths.append(curr_width_median)\n",
    "                    else:\n",
    "                        print(f\"USING A DEFAULT WIDTH BECAUSE THE NEWLY COMPUTED ONE WAS {curr_width_median}: {segment_widths_median[match_sk_branches[0]]}\")\n",
    "                        new_widths.append(segment_widths_median[match_sk_branches[0]])\n",
    "\n",
    "\n",
    "                #6) Remove the original branch and mesh correspondence and replace with the multiples\n",
    "#                     print(f\"match_sk_branches BEFORE = {match_sk_branches}\")\n",
    "#                     print(f\"segment_branches BEFORE = {segment_branches}\")\n",
    "#                     print(f\"len(new_skeletal_branches) = {len(new_skeletal_branches)}\")\n",
    "#                     print(f\"new_skeletal_branches BEFORE= {new_skeletal_branches}\")\n",
    "\n",
    "\n",
    "                #segment_branches = np.delete(segment_branches,match_sk_branches,axis=0)\n",
    "                #segment_branches = np.append(segment_branches,new_skeletal_branches,axis=0)\n",
    "\n",
    "                segment_branches = np.array([k for i,k in enumerate(segment_branches) if i not in match_sk_branches] + new_skeletal_branches)\n",
    "\n",
    "\n",
    "                divided_submeshes = np.delete(divided_submeshes,match_sk_branches,axis=0)\n",
    "                divided_submeshes = np.append(divided_submeshes,new_submeshes,axis=0)\n",
    "\n",
    "\n",
    "                #divided_submeshes_idx = np.delete(divided_submeshes_idx,match_sk_branches,axis=0)\n",
    "                #divided_submeshes_idx = np.append(divided_submeshes_idx,new_submeshes_idx,axis=0)\n",
    "                divided_submeshes_idx = np.array([k for i,k in enumerate(divided_submeshes_idx) if i not in match_sk_branches] + new_submeshes_idx)\n",
    "\n",
    "                segment_widths_median = np.delete(segment_widths_median,match_sk_branches,axis=0)\n",
    "                segment_widths_median = np.append(segment_widths_median,new_widths,axis=0)\n",
    "\n",
    "                try:\n",
    "                    debug = False\n",
    "                    if debug:\n",
    "                        print(f\"segment_branches.shape = {segment_branches.shape}\")\n",
    "                        print(f\"segment_branches = {segment_branches}\")\n",
    "                        print(f\"new_skeletal_branches = {new_skeletal_branches}\")\n",
    "                    sk.check_skeleton_connected_component(sk.stack_skeletons(segment_branches))\n",
    "                except:\n",
    "                    su.compressed_pickle(local_correspondence_revised,\"local_correspondence_revised\")\n",
    "                print(\"checked segment branches after soma add on\")\n",
    "                return_find = sk.find_branch_skeleton_with_specific_coordinate(segment_branches,\n",
    "                                             orig_vertex)\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\" ******************* END OF HOW CAN DO STITCHING ********************  \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        limb_to_endpoints_must_keep_list.append(endpts_total)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices_total)\n",
    "\n",
    "        # ------------------- 11/9 addition ------------------- #\n",
    "\n",
    "        if no_soma_extension_add:\n",
    "            print(\"No soma extending branch was added for this sublimb even though it had a soma border (means they already existed)\")\n",
    "\n",
    "        if print_fusion_steps:\n",
    "            print(f\"MP (because soma touching verts) soma extension add: {time.time() - fusion_time }\")\n",
    "            fusion_time = time.time()\n",
    "\n",
    "    #building the limb correspondence\n",
    "    limb_correspondence_MP[sublimb_idx] = dict()\n",
    "\n",
    "    for zz,b_sk in enumerate(segment_branches):\n",
    "        limb_correspondence_MP[sublimb_idx][zz] = dict(\n",
    "            branch_skeleton = b_sk,\n",
    "            width_from_skeleton = segment_widths_median[zz],\n",
    "            branch_mesh = divided_submeshes[zz],\n",
    "            branch_face_idx = divided_submeshes_idx[zz]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "limb_correspondence_MP_saved = copy.deepcopy(limb_correspondence_MP)\n",
    "limb_correspondence_MAP_saved = copy.deepcopy(limb_correspondence_MAP)\n",
    "\n",
    "# ------------------------------------- Part C: Will make sure the correspondences can all be stitched together --------------- #\n",
    "\n",
    "\n",
    "\n",
    "#     su.compressed_pickle(limb_correspondence_MAP,\"limb_correspondence_MAP_before_stitch\")\n",
    "#     su.compressed_pickle(limb_correspondence_MP,\"limb_correspondence_MP_before_stitch\")\n",
    "\n",
    "\n",
    "if check_correspondence_branches:\n",
    "    sk.check_correspondence_branches_have_2_endpoints(limb_correspondence_MAP)\n",
    "    sk.check_correspondence_branches_have_2_endpoints(limb_correspondence_MP)\n",
    "\n",
    "#total_keep_endpoints = np.concatenate([list(v.values()) for v in limb_to_endpoints_must_keep_list]).reshape(-1,3)\n",
    "total_keep_endpoints = []\n",
    "for entry in limb_to_endpoints_must_keep_list:\n",
    "    for k,v in entry.items():\n",
    "        total_keep_endpoints.append(v)\n",
    "total_keep_endpoints = np.vstack(total_keep_endpoints)\n",
    "    \n",
    "    \n",
    "\n",
    "# Only want to perform this step if both MP and MAP pieces\n",
    "if len(limb_correspondence_MAP)>0 and len(limb_correspondence_MP)>0:\n",
    "\n",
    "    # -------------- Part 11: Getting Sublimb Mesh and Skeletons and Gets connectivitiy by Mesh -------#\n",
    "    # -------------(filtering connections to only MP to MAP edges)--------------- #\n",
    "\n",
    "    # ---- Doing the mesh connectivity ---------#\n",
    "    sublimb_meshes_MP = []\n",
    "    sublimb_skeletons_MP = []\n",
    "\n",
    "    for sublimb_key,sublimb_v in limb_correspondence_MP.items():\n",
    "        sublimb_meshes_MP.append(tu.combine_meshes([branch_v[\"branch_mesh\"] for branch_v in sublimb_v.values()]))\n",
    "        sublimb_skeletons_MP.append(sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in sublimb_v.values()]))\n",
    "\n",
    "\n",
    "\n",
    "    sublimb_meshes_MAP = []\n",
    "    sublimb_skeletons_MAP = []\n",
    "\n",
    "\n",
    "    for sublimb_key,sublimb_v in limb_correspondence_MAP.items():\n",
    "        sublimb_meshes_MAP.append(tu.combine_meshes([branch_v[\"branch_mesh\"] for branch_v in sublimb_v.values()]))\n",
    "        sublimb_skeletons_MAP.append(sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in sublimb_v.values()]))\n",
    "\n",
    "    sublimb_skeletons_MP_saved = copy.deepcopy(sublimb_skeletons_MP)\n",
    "    sublimb_skeletons_MAP_saved = copy.deepcopy(sublimb_skeletons_MAP)\n",
    "\n",
    "    connectivity_type = \"edges\"\n",
    "    for i in range(0,2):\n",
    "        mesh_conn,mesh_conn_vertex_groups = tu.mesh_list_connectivity(meshes = sublimb_meshes_MP + sublimb_meshes_MAP,\n",
    "                                            main_mesh = limb_mesh_mparty,\n",
    "                                            connectivity=connectivity_type,\n",
    "                                            min_common_vertices=1,\n",
    "                                            return_vertex_connection_groups=True,\n",
    "                                            return_largest_vertex_connection_group=True,\n",
    "                                            print_flag = False)\n",
    "        mesh_conn_old = copy.deepcopy(mesh_conn)\n",
    "\n",
    "\n",
    "\n",
    "        #check that every MAP piece mapped to a MP piece\n",
    "        mesh_conn_filt = []\n",
    "        mesh_conn_vertex_groups_filt = []\n",
    "        for j,(m1,m2) in enumerate(mesh_conn):\n",
    "            if m1 < len(sublimb_meshes_MP) and m2 >=len(sublimb_meshes_MP):\n",
    "                mesh_conn_filt.append([m1,m2])\n",
    "                mesh_conn_vertex_groups_filt.append(mesh_conn_vertex_groups[j])\n",
    "            else:\n",
    "                print(f\"Edge {(m1,m2)} was not kept\")\n",
    "        mesh_conn_filt = np.array(mesh_conn_filt)\n",
    "\n",
    "        mesh_conn = mesh_conn_filt\n",
    "        mesh_conn_vertex_groups = mesh_conn_vertex_groups_filt\n",
    "\n",
    "        #check that the mapping should create only one connected component\n",
    "        G = nx.from_edgelist(mesh_conn)\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            if len(G) != len(sublimb_meshes_MP) + len(sublimb_meshes_MAP):\n",
    "                raise Exception(\"Number of nodes in mesh connectivity graph is not equal to number of  MAP and MP sublimbs\")\n",
    "\n",
    "            connect_comp = list(nx.connected_components(G))\n",
    "            if len(connect_comp)>1:\n",
    "                raise Exception(f\"Mesh connectivity was not one component, instead it was ({len(connect_comp)}): {connect_comp} \")\n",
    "        except:\n",
    "\n",
    "            if connectivity_type == \"vertices\":\n",
    "                print(f\"mesh_conn_filt = {mesh_conn_filt}\")\n",
    "                print(f\"mesh_conn_old = {mesh_conn_old}\")\n",
    "                mesh_conn_adjusted = np.vstack([mesh_conn[:,0],mesh_conn[:,1]-len(sublimb_meshes_MP)]).T\n",
    "                print(f\"mesh_conn_adjusted = {mesh_conn_adjusted}\")\n",
    "                print(f\"len(sublimb_meshes_MP) = {len(sublimb_meshes_MP)}\")\n",
    "                print(f\"len(sublimb_meshes_MAP) = {len(sublimb_meshes_MAP)}\")\n",
    "                meshes = sublimb_meshes_MP + sublimb_meshes_MAP\n",
    "                #su.compressed_pickle(meshes,\"meshes\")\n",
    "                su.compressed_pickle(sublimb_meshes_MP,\"sublimb_meshes_MP\")\n",
    "                su.compressed_pickle(sublimb_meshes_MAP,\"sublimb_meshes_MAP\")\n",
    "                su.compressed_pickle(limb_mesh_mparty,\"limb_mesh_mparty\")\n",
    "                su.compressed_pickle(sublimb_skeletons_MP,\"sublimb_skeletons_MP\")\n",
    "                su.compressed_pickle(sublimb_skeletons_MAP,\"sublimb_skeletons_MAP\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                raise Exception(\"Something went wrong in the connectivity\")\n",
    "            else:\n",
    "                print(f\"Failed on connection type {connectivity_type} \")\n",
    "                connectivity_type = \"vertices\"\n",
    "                print(f\"so changing type to {connectivity_type}\")\n",
    "        else:\n",
    "            print(f\"Successful mesh connectivity with type {connectivity_type}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    #adjust the connection indices for MP and MAP indices\n",
    "    mesh_conn_adjusted = np.vstack([mesh_conn[:,0],mesh_conn[:,1]-len(sublimb_meshes_MP)]).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Pseudocode:\n",
    "    For each connection edge:\n",
    "        For each vertex connection group:\n",
    "            1) Get the endpoint vertices of the MP skeleton\n",
    "            2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "            3) Find the closest skeletal point on MAP pairing (MAP stitch) \n",
    "            4) Find the branches that have that MAP stitch point:\n",
    "            5A) If the number of branches corresponding to stitch point is multipled\n",
    "                --> then we are stitching at a branching oint\n",
    "                i) Just add the skeletal segment from MP_stitch to MAP stitch to the MP skeletal segment\n",
    "                ii) \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # -------------- STITCHING PHASE -------#\n",
    "    stitch_counter = 0\n",
    "    all_map_stitch_points = []\n",
    "    for (MP_idx,MAP_idx),v_g in zip(mesh_conn_adjusted,mesh_conn_vertex_groups):\n",
    "        print(f\"\\n---- Working on {(MP_idx,MAP_idx)} connection-----\")\n",
    "\n",
    "        \"\"\"\n",
    "        This old way of getting the endpoints was not good because could possibly just need\n",
    "        a stitching done between original branch junction\n",
    "\n",
    "        skeleton_MP_graph = sk.convert_skeleton_to_graph(curr_skeleton_MP)\n",
    "        endpoint_nodes = xu.get_nodes_of_degree_k(skeleton_MP_graph,1)\n",
    "        endpoint_nodes_coordinates = xu.get_node_attributes(skeleton_MP_graph,node_list=endpoint_nodes)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # -------------- Part 12: Find the MP and MAP stitching point and branches that contain the stitching point-------#\n",
    "\n",
    "        \"\"\"  OLD WAY THAT ALLOWED STITICHING POINTS TO NOT BE CONNECTED AT THE CONNECTING BRANCHES\n",
    "        #getting the skeletons that should be stitched\n",
    "        curr_skeleton_MP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MP[MP_idx].values()])\n",
    "        curr_skeleton_MAP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MAP[MAP_idx].values()])\n",
    "\n",
    "        #1) Get the endpoint vertices of the MP skeleton branches (so every endpoint or high degree node)\n",
    "        #(needs to be inside loop because limb correspondence will change)\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in np.sort(list(limb_correspondence_MP[MP_idx].keys()))]\n",
    "        endpoint_nodes_coordinates = np.array([sk.find_branch_endpoints(k) for k in curr_MP_branch_skeletons])\n",
    "        endpoint_nodes_coordinates = np.unique(endpoint_nodes_coordinates.reshape(-1,3),axis=0)\n",
    "\n",
    "        #2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "        av_vert = np.mean(v_g,axis=0)\n",
    "        winning_vertex = endpoint_nodes_coordinates[np.argmin(np.linalg.norm(endpoint_nodes_coordinates-av_vert,axis=1))]\n",
    "        print(f\"winning_vertex = {winning_vertex}\")\n",
    "\n",
    "\n",
    "        #2b) Find the branch points where the winning vertex is located\n",
    "        MP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MP_branch_skeletons,\n",
    "            current_coordinate = winning_vertex\n",
    "        )\n",
    "        print(f\"MP_branches_with_stitch_point = {MP_branches_with_stitch_point}\")\n",
    "\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP.reshape(-1,3),axis=0)\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-winning_vertex,axis=1))]\n",
    "\n",
    "\n",
    "        #3b) Consider if the stitch point is close enough to end or branch node in skeleton:\n",
    "        # and if so then reassign\n",
    "        if move_MAP_stitch_to_end_or_branch:\n",
    "            MAP_stitch_point_new,change_status = sk.move_point_to_nearest_branch_end_point_within_threshold(\n",
    "                                                    skeleton=curr_skeleton_MAP,\n",
    "                                                    coordinate=MAP_stitch_point,\n",
    "                                                    distance_to_move_point_threshold = distance_to_move_point_threshold,\n",
    "                                                    verbose=True\n",
    "\n",
    "                                                    )\n",
    "            MAP_stitch_point=MAP_stitch_point_new\n",
    "\n",
    "\n",
    "        #4) Find the branches that have that MAP stitch point:\n",
    "        curr_MAP_branch_skeletons = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"]\n",
    "                                         for k in np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))]\n",
    "\n",
    "        MAP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MAP_branch_skeletons,\n",
    "            current_coordinate = MAP_stitch_point\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        MAP_stitch_point_on_end_or_branch = False\n",
    "        if len(MAP_branches_with_stitch_point)>1:\n",
    "            MAP_stitch_point_on_end_or_branch = True\n",
    "        elif len(MAP_branches_with_stitch_point)==1:\n",
    "            if len(nu.matching_rows(sk.find_branch_endpoints(curr_MAP_branch_skeletons[MAP_branches_with_stitch_point[0]]),\n",
    "                                    MAP_stitch_point))>0:\n",
    "                MAP_stitch_point_on_end_or_branch=True\n",
    "        else:\n",
    "            raise Exception(\"No matching MAP values\")\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "        #*****should only get branches that are touching....****\n",
    "\n",
    "        #getting the skeletons that should be stitched\n",
    "        curr_skeleton_MP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MP[MP_idx].values()])\n",
    "        curr_skeleton_MAP = sk.stack_skeletons([branch_v[\"branch_skeleton\"] for branch_v in limb_correspondence_MAP[MAP_idx].values()])\n",
    "\n",
    "\n",
    "        av_vert = np.mean(v_g,axis=0)\n",
    "\n",
    "        # ---------------- Doing the MAP part first -------------- #\n",
    "        \"\"\"\n",
    "        The previous way did not ensure that the MAP point found will have a branch mesh that is touching the border vertices\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP.reshape(-1,3),axis=0)\n",
    "\n",
    "        #this does not guarentee that the MAP branch associated with the MAP stitch point is touching the border group\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-av_vert,axis=1))]\n",
    "        \"\"\"\n",
    "\n",
    "        # -------------- 11/9 NEW METHOD FOR FINDING MAP STITCH POINT ------------ #\n",
    "        o_keys = np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))\n",
    "        curr_MAP_branch_meshes = np.array([limb_correspondence_MAP[MAP_idx][k][\"branch_mesh\"]\n",
    "                                         for k in o_keys])\n",
    "        curr_MAP_branch_skeletons = np.array([limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"]\n",
    "                                         for k in o_keys])\n",
    "\n",
    "        MAP_pieces_idx_touching_border = tu.filter_meshes_by_containing_coordinates(mesh_list=curr_MAP_branch_meshes,\n",
    "                                       nullifying_points=v_g,\n",
    "                                        filter_away=False,\n",
    "                                       distance_threshold=0,\n",
    "                                       return_indices=True)\n",
    "\n",
    "        MAP_branches_considered = curr_MAP_branch_skeletons[MAP_pieces_idx_touching_border]\n",
    "        curr_skeleton_MAP_for_stitch = sk.stack_skeletons(MAP_branches_considered)\n",
    "\n",
    "        #3) Find the closest skeletal point on MAP pairing (MAP stitch)\n",
    "        MAP_skeleton_coords = np.unique(curr_skeleton_MAP_for_stitch.reshape(-1,3),axis=0)\n",
    "\n",
    "        \"\"\"\n",
    "        #------- OLD WAY: this does not guarentee that the MAP branch associated with the MAP stitch point is touching the border group\n",
    "        #MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-av_vert,axis=1))]\n",
    "        \n",
    "        # ------- 1/1/21 Change to make sure never stitches to soma connecting point ----\n",
    "        Pseudocode: \n",
    "        1) Get all the closest coordinates and sort in order of distance\n",
    "        2) Iterate through the top coordinates:\n",
    "        - check if not in the endpoints\n",
    "        a. if not --> make that the winning MAP stitch point\n",
    "        b. if not --> continue to next\n",
    "\n",
    "        3) if get to end and dont have winning coordinate then error\n",
    "        \"\"\"\n",
    "\n",
    "        MAP_stitch_point = MAP_skeleton_coords[np.argmin(np.linalg.norm(MAP_skeleton_coords-av_vert,axis=1))]\n",
    "\n",
    "        # --------- 11/13: Making so could possibly stitch to another point that was already stitched to\n",
    "        curr_br_endpts = np.array([sk.find_branch_endpoints(k) for k in MAP_branches_considered]).reshape(-1,3)\n",
    "        curr_br_endpts_unique = np.unique(curr_br_endpts,axis=0)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        #3b) Consider if the stitch point is close enough to end or branch node in skeleton:\n",
    "        # and if so then reassign\n",
    "        print(f\"total_keep_endpoints = {total_keep_endpoints}\")\n",
    "        print(f\"MAP_stitch_point BEFORE = {MAP_stitch_point}, move_MAP_stitch_to_end_or_branch = {move_MAP_stitch_to_end_or_branch}\")\n",
    "        \n",
    "        if move_MAP_stitch_to_end_or_branch:\n",
    "            MAP_stitch_point_new,change_status = sk.move_point_to_nearest_branch_end_point_within_threshold(\n",
    "                                                    skeleton=curr_skeleton_MAP,\n",
    "                                                    coordinate=MAP_stitch_point,\n",
    "                                                    distance_to_move_point_threshold = distance_to_move_point_threshold,\n",
    "                                                    verbose=True,\n",
    "                                                    possible_node_coordinates=curr_br_endpts_unique,\n",
    "                                                    excluded_node_coordinates=total_keep_endpoints,\n",
    "                                                    )\n",
    "            MAP_stitch_point=MAP_stitch_point_new\n",
    "            \n",
    "        print(f\"MAP_stitch_point AFTER = {MAP_stitch_point}\")\n",
    "        \n",
    "        if len(nu.matching_rows(total_keep_endpoints,MAP_stitch_point))>0:\n",
    "            raise Exception(\"About to stitch to soma connecting point\")\n",
    "\n",
    "        #4) Find the branches that have that MAP stitch point:\n",
    "\n",
    "        MAP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MAP_branch_skeletons,\n",
    "            current_coordinate = MAP_stitch_point\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        MAP_stitch_point_on_end_or_branch = False\n",
    "        if len(MAP_branches_with_stitch_point)>1:\n",
    "            MAP_stitch_point_on_end_or_branch = True\n",
    "        elif len(MAP_branches_with_stitch_point)==1:\n",
    "            if len(nu.matching_rows(sk.find_branch_endpoints(curr_MAP_branch_skeletons[MAP_branches_with_stitch_point[0]]),\n",
    "                                    MAP_stitch_point))>0:\n",
    "                MAP_stitch_point_on_end_or_branch=True\n",
    "        else:\n",
    "            raise Exception(\"No matching MAP values\")\n",
    "\n",
    "        #add the map stitch point to the history\n",
    "        all_map_stitch_points.append(MAP_stitch_point)\n",
    "\n",
    "        # ---------------- Doing the MP Part --------------------- #\n",
    "\n",
    "\n",
    "\n",
    "        ord_keys = np.sort(list(limb_correspondence_MP[MP_idx].keys()))\n",
    "        curr_MP_branch_meshes = [limb_correspondence_MP[MP_idx][k][\"branch_mesh\"] for k in ord_keys]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" old way of filtering MP pieces just to those touching the MAP, but just want the ones touching the connection group\n",
    "\n",
    "        MAP_meshes_with_stitch_point = tu.combine_meshes([limb_correspondence_MAP[MAP_idx][k][\"branch_mesh\"] for k in MAP_branches_with_stitch_point])\n",
    "\n",
    "        conn = tu.mesh_pieces_connectivity(main_mesh=limb_mesh_mparty,\n",
    "                                   central_piece=MAP_meshes_with_stitch_point,\n",
    "                                   periphery_pieces=curr_MP_branch_meshes)\n",
    "        \"\"\"\n",
    "        # 11/9 Addition: New way that filters meshes by their touching of the vertex connection group (this could possibly be an empty group)\n",
    "        conn = tu.filter_meshes_by_containing_coordinates(mesh_list=curr_MP_branch_meshes,\n",
    "                                       nullifying_points=v_g,\n",
    "                                        filter_away=False,\n",
    "                                       distance_threshold=0,\n",
    "                                       return_indices=True)\n",
    "\n",
    "        if len(conn) == 0:\n",
    "            print(\"Connectivity was 0 for the MP mesh groups touching the vertex group so not restricting by that anymore\")\n",
    "            sk_conn = np.arange(0,len(curr_MP_branch_meshes))\n",
    "        else:\n",
    "            sk_conn = conn\n",
    "\n",
    "        print(f\"sk_conn = {sk_conn}\")\n",
    "        print(f\"conn = {conn}\")\n",
    "\n",
    "\n",
    "        #1) Get the endpoint vertices of the MP skeleton branches (so every endpoint or high degree node)\n",
    "        #(needs to be inside loop because limb correspondence will change)\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in sk_conn]\n",
    "        endpoint_nodes_coordinates = np.array([sk.find_branch_endpoints(k) for k in curr_MP_branch_skeletons])\n",
    "        endpoint_nodes_coordinates = np.unique(endpoint_nodes_coordinates.reshape(-1,3),axis=0)\n",
    "        \n",
    "        \"\"\" ---------- 1 /5: Take out the possible endpoints --------------------\"\"\"\n",
    "        if prevent_MP_starter_branch_stitches:\n",
    "            endpoint_nodes_coordinates = nu.setdiff2d(endpoint_nodes_coordinates,total_keep_endpoints)\n",
    "\n",
    "\n",
    "        #2) Find the closest endpoint vertex to the vertex connection group (this is MP stitch point)\n",
    "\n",
    "        winning_vertex = endpoint_nodes_coordinates[np.argmin(np.linalg.norm(endpoint_nodes_coordinates-av_vert,axis=1))]\n",
    "        print(f\"winning_vertex = {winning_vertex}\")\n",
    "        \n",
    "        if len(nu.matching_rows(total_keep_endpoints,winning_vertex))>0:\n",
    "            raise Exception(\"Trying to stitch to MP starting point\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #2b) Find the branch points where the winning vertex is located\n",
    "        curr_MP_branch_skeletons = [limb_correspondence_MP[MP_idx][k][\"branch_skeleton\"] for k in np.sort(list(limb_correspondence_MP[MP_idx].keys()))]\n",
    "        MP_branches_with_stitch_point = sk.find_branch_skeleton_with_specific_coordinate(\n",
    "            divded_skeleton=curr_MP_branch_skeletons,\n",
    "            current_coordinate = winning_vertex\n",
    "        )\n",
    "        \n",
    "        print(f\"MP_branches_with_stitch_point = {MP_branches_with_stitch_point}\")\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"MAP_branches_with_stitch_point = {MAP_branches_with_stitch_point}\")\n",
    "        print(f\"MAP_stitch_point_on_end_or_branch = {MAP_stitch_point_on_end_or_branch}\")\n",
    "\n",
    "\n",
    "        # -------- 11/13 addition: Will see if the MP stitch point was already a MAP stitch point ---- #\n",
    "        if len(nu.matching_rows(np.array(all_map_stitch_points),winning_vertex)) > 0:\n",
    "            keep_MP_stitch_static = True\n",
    "        else:\n",
    "            keep_MP_stitch_static = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------- This part does the stitching -------------------- #\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        1) For all MP branches\n",
    "            a) Get neighbor coordinates to MP stitch points\n",
    "            b) Delete the MP Stitch points on each \n",
    "            c) Add skeleton segment from neighbor to MAP stitch point\n",
    "        2) Get skeletons and meshes from MP and MAP pieces\n",
    "        3) Run mesh correspondence to get new meshes and mesh_idx and widths\n",
    "        4a) If MAP_stitch_point_on_end_or_branch is False\n",
    "        - Delete the old MAP branch parts and replace with new MAP ones\n",
    "        4b) Revise the meshes,  mesh_idx, and widths of the MAP pieces\n",
    "        5) Revise the meshes,  mesh_idx, and widths of the MP pieces\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # -------------- Part 13: Will Adjust the MP branches that have the stitch point so extends to the MAP stitch point -------#\n",
    "        curr_MP_sk = []\n",
    "        for b_idx in MP_branches_with_stitch_point:\n",
    "            if not keep_MP_stitch_static:\n",
    "                #a) Get neighbor coordinates to MP stitch points\n",
    "                MP_stitch_branch_graph = sk.convert_skeleton_to_graph(curr_MP_branch_skeletons[b_idx])\n",
    "                stitch_node = xu.get_nodes_with_attributes_dict(MP_stitch_branch_graph,dict(coordinates=winning_vertex))[0]\n",
    "                stitch_neighbors = xu.get_neighbors(MP_stitch_branch_graph,stitch_node)\n",
    "\n",
    "                if len(stitch_neighbors) != 1:\n",
    "                    raise Exception(\"Not just one neighbor for stitch point of MP branch\")\n",
    "                keep_neighbor = stitch_neighbors[0]  \n",
    "                keep_neighbor_coordinates = xu.get_node_attributes(MP_stitch_branch_graph,node_list=[keep_neighbor])[0]\n",
    "\n",
    "                #b) Delete the MP Stitch points on each \n",
    "                MP_stitch_branch_graph.remove_node(stitch_node)\n",
    "\n",
    "                \"\"\" Old way that does not do smoothing\n",
    "\n",
    "                #c) Add skeleton segment from neighbor to MAP stitch point\n",
    "                new_node_name = np.max(MP_stitch_branch_graph.nodes())+1\n",
    "\n",
    "                MP_stitch_branch_graph.add_nodes_from([(int(new_node_name),{\"coordinates\":MAP_stitch_point})])\n",
    "                MP_stitch_branch_graph.add_weighted_edges_from([(keep_neighbor,new_node_name,np.linalg.norm(MAP_stitch_point - keep_neighbor_coordinates))])\n",
    "\n",
    "                new_MP_skeleton = sk.convert_graph_to_skeleton(MP_stitch_branch_graph)\n",
    "\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    if len(MP_stitch_branch_graph)>1:\n",
    "                        new_MP_skeleton = sk.add_and_smooth_segment_to_branch(skeleton=sk.convert_graph_to_skeleton(MP_stitch_branch_graph),\n",
    "                                                        skeleton_stitch_point=keep_neighbor_coordinates,\n",
    "                                                         new_stitch_point=MAP_stitch_point)\n",
    "                    else:\n",
    "                        print(\"Not even attempting smoothing segment because once keep_neighbor_coordinates\")\n",
    "                        new_MP_skeleton = np.vstack([keep_neighbor_coordinates,MAP_stitch_point]).reshape(-1,2,3)\n",
    "                except:\n",
    "                    su.compressed_pickle(MP_stitch_branch_graph,\"MP_stitch_branch_graph\")\n",
    "                    su.compressed_pickle(keep_neighbor_coordinates,\"keep_neighbor_coordinates\")\n",
    "                    su.compressed_pickle(MAP_stitch_point,\"MAP_stitch_point\")\n",
    "\n",
    "\n",
    "                    raise Exception(\"Something went wrong with add_and_smooth_segment_to_branch\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #smooth over the new skeleton\n",
    "                new_MP_skeleton_smooth = sk.resize_skeleton_branch(new_MP_skeleton,\n",
    "                                                                  segment_width=meshparty_segment_size)\n",
    "\n",
    "                curr_MP_sk.append(new_MP_skeleton_smooth)\n",
    "            else:\n",
    "                print(f\"Not adjusting MP skeletons because keep_MP_stitch_static = {keep_MP_stitch_static}\")\n",
    "                curr_MP_sk.append(curr_MP_branch_skeletons[b_idx])\n",
    "\n",
    "\n",
    "\n",
    "        #2) Get skeletons and meshes from MP and MAP pieces\n",
    "        curr_MAP_sk = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"] for k in MAP_branches_with_stitch_point]\n",
    "\n",
    "        #2.1) Going to break up the MAP skeleton if need be\n",
    "        \"\"\"\n",
    "        Pseudocode:\n",
    "        a) check to see if it needs to be broken up\n",
    "        If it does:\n",
    "        b) Convert the skeleton into a graph\n",
    "        c) Find the node of the MAP stitch point (where need to do the breaking)\n",
    "        d) Find the degree one nodes\n",
    "        e) For each degree one node:\n",
    "        - Find shortest path from stitch node to end node\n",
    "        - get a subgraph from that path\n",
    "        - convert graph to a skeleton and save as new skeletons\n",
    "\n",
    "        \"\"\"\n",
    "        # -------------- Part 14: Breaks Up MAP skeleton into 2 pieces if Needs (because MAP stitch point not on endpoint or branch point)  -------#\n",
    "\n",
    "        #a) check to see if it needs to be broken up\n",
    "        cut_flag = False\n",
    "        if not MAP_stitch_point_on_end_or_branch:\n",
    "            if len(curr_MAP_sk) > 1:\n",
    "                raise Exception(f\"There was more than one skeleton for MAP skeletons even though MAP_stitch_point_on_end_or_branch = {MAP_stitch_point_on_end_or_branch}\")\n",
    "\n",
    "\n",
    "            skeleton_to_cut = curr_MAP_sk[0]\n",
    "            curr_MAP_sk = sk.cut_skeleton_at_coordinate(skeleton=skeleton_to_cut,\n",
    "                                                        cut_coordinate=MAP_stitch_point)\n",
    "            cut_flag=True\n",
    "\n",
    "\n",
    "        # ------ 11/13 Addition: need to adjust the MAP points if have to keep MP static\n",
    "        if keep_MP_stitch_static:\n",
    "            curr_MAP_sk_final = []\n",
    "            for map_skel in curr_MAP_sk:\n",
    "                #a) Get neighbor coordinates to MP stitch points\n",
    "                MP_stitch_branch_graph = sk.convert_skeleton_to_graph(map_skel)\n",
    "                stitch_node = xu.get_nodes_with_attributes_dict(MP_stitch_branch_graph,dict(coordinates=MAP_stitch_point))[0]\n",
    "                stitch_neighbors = xu.get_neighbors(MP_stitch_branch_graph,stitch_node)\n",
    "\n",
    "                if len(stitch_neighbors) != 1:\n",
    "                    raise Exception(\"Not just one neighbor for stitch point of MP branch\")\n",
    "                keep_neighbor = stitch_neighbors[0]  \n",
    "                keep_neighbor_coordinates = xu.get_node_attributes(MP_stitch_branch_graph,node_list=[keep_neighbor])[0]\n",
    "\n",
    "                #b) Delete the MP Stitch points on each \n",
    "                MP_stitch_branch_graph.remove_node(stitch_node)\n",
    "\n",
    "                \"\"\" Old way that does not do smoothing\n",
    "\n",
    "                #c) Add skeleton segment from neighbor to MAP stitch point\n",
    "                new_node_name = np.max(MP_stitch_branch_graph.nodes())+1\n",
    "\n",
    "                MP_stitch_branch_graph.add_nodes_from([(int(new_node_name),{\"coordinates\":MAP_stitch_point})])\n",
    "                MP_stitch_branch_graph.add_weighted_edges_from([(keep_neighbor,new_node_name,np.linalg.norm(MAP_stitch_point - keep_neighbor_coordinates))])\n",
    "\n",
    "                new_MP_skeleton = sk.convert_graph_to_skeleton(MP_stitch_branch_graph)\n",
    "\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    if len(MP_stitch_branch_graph)>1:\n",
    "                        new_MP_skeleton = sk.add_and_smooth_segment_to_branch(skeleton=sk.convert_graph_to_skeleton(MP_stitch_branch_graph),\n",
    "                                                        skeleton_stitch_point=keep_neighbor_coordinates,\n",
    "                                                         new_stitch_point=winning_vertex)\n",
    "                    else:\n",
    "                        print(\"Not even attempting smoothing segment because once keep_neighbor_coordinates\")\n",
    "                        new_MP_skeleton = np.vstack([keep_neighbor_coordinates,MAP_stitch_point]).reshape(-1,2,3)\n",
    "                except:\n",
    "                    su.compressed_pickle(MP_stitch_branch_graph,\"MP_stitch_branch_graph\")\n",
    "                    su.compressed_pickle(keep_neighbor_coordinates,\"keep_neighbor_coordinates\")\n",
    "                    su.compressed_pickle(winning_vertex,\"winning_vertex\")\n",
    "\n",
    "\n",
    "                    raise Exception(\"Something went wrong with add_and_smooth_segment_to_branch\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #smooth over the new skeleton\n",
    "                new_MP_skeleton_smooth = sk.resize_skeleton_branch(new_MP_skeleton,\n",
    "                                                                  segment_width=meshparty_segment_size)\n",
    "\n",
    "                curr_MAP_sk_final.append(new_MP_skeleton_smooth)\n",
    "            curr_MAP_sk = copy.deepcopy(curr_MAP_sk_final)\n",
    "\n",
    "\n",
    "\n",
    "        # -------------- Part 15: Gets all of the skeletons and Mesh to divide u and does mesh correspondence -------#\n",
    "        # ------------- revise IDX so still references the whole limb mesh -----------#\n",
    "\n",
    "        # -------------- 11/10 Addition accounting for not all MAP pieces always touching each other --------------------#\n",
    "        if len(MAP_branches_with_stitch_point) > 1:\n",
    "            print(\"\\nRevising the MAP pieces index:\")\n",
    "            print(f\"MAP_pieces_idx_touching_border = {MAP_pieces_idx_touching_border}, MAP_branches_with_stitch_point = {MAP_branches_with_stitch_point}\")\n",
    "            MAP_pieces_for_correspondence = nu.intersect1d(MAP_pieces_idx_touching_border,MAP_branches_with_stitch_point)\n",
    "            print(f\"MAP_pieces_for_correspondence = {MAP_pieces_for_correspondence}\")\n",
    "            curr_MAP_sk = [limb_correspondence_MAP[MAP_idx][k][\"branch_skeleton\"] for k in MAP_pieces_for_correspondence]\n",
    "        else:\n",
    "            MAP_pieces_for_correspondence = MAP_branches_with_stitch_point\n",
    "\n",
    "        curr_MAP_meshes_idx = [limb_correspondence_MAP[MAP_idx][k][\"branch_face_idx\"] for k in MAP_pieces_for_correspondence]\n",
    "\n",
    "        # Have to adjust based on if the skeleton were split\n",
    "\n",
    "        if cut_flag:\n",
    "            #Then it was cut and have to do mesh correspondence to find what label to cut\n",
    "            if len(curr_MAP_meshes_idx) > 1:\n",
    "                raise Exception(\"MAP_pieces_for_correspondence was longer than 1 and cut flag was set\")\n",
    "            pre_stitch_mesh_idx = curr_MAP_meshes_idx[0]\n",
    "            pre_stitch_mesh = limb_mesh_mparty.submesh([pre_stitch_mesh_idx],append=True,repair=False)\n",
    "            local_correspondnece_stitch = mesh_correspondence_first_pass(mesh=pre_stitch_mesh,\n",
    "                                      skeleton_branches=curr_MAP_sk)\n",
    "            local_correspondence_stitch_revised_MAP = correspondence_1_to_1(mesh=pre_stitch_mesh,\n",
    "                                                        local_correspondence=local_correspondnece_stitch,\n",
    "                                                        curr_limb_endpoints_must_keep=None,\n",
    "                                                        curr_soma_to_piece_touching_vertices=None)\n",
    "\n",
    "#                 curr_MAP_meshes_idx = [pre_stitch_mesh_idx[local_correspondence_stitch_revised_MAP[nn][\"branch_face_idx\"]] for \n",
    "#                                                nn in local_correspondence_stitch_revised_MAP.keys()]\n",
    "\n",
    "            #Need to readjust the mesh correspondence idx\n",
    "            for k,v in local_correspondence_stitch_revised_MAP.items():\n",
    "                local_correspondence_stitch_revised_MAP[k][\"branch_face_idx\"] = pre_stitch_mesh_idx[local_correspondence_stitch_revised_MAP[k][\"branch_face_idx\"]]\n",
    "\n",
    "            curr_MAP_meshes_idx = [v[\"branch_face_idx\"] for v in local_correspondence_stitch_revised_MAP.values()]\n",
    "        else:\n",
    "            local_correspondence_stitch_revised_MAP = dict([(gg,limb_correspondence_MAP[MAP_idx][kk]) for gg,kk in enumerate(MAP_pieces_for_correspondence)])\n",
    "\n",
    "            for gg,kk in enumerate(MAP_pieces_for_correspondence):\n",
    "                local_correspondence_stitch_revised_MAP[gg][\"branch_skeleton\"] = curr_MAP_sk[gg]\n",
    "\n",
    "\n",
    "\n",
    "        #To make sure that the MAP never gives up ground on the labels\n",
    "        must_keep_labels_MAP = dict()\n",
    "        must_keep_counter = 0\n",
    "        for kk,b_idx in enumerate(curr_MAP_meshes_idx):\n",
    "            #must_keep_labels_MAP.update(dict([(ii,kk) for ii in range(must_keep_counter,must_keep_counter+len(b_idx))]))\n",
    "            must_keep_labels_MAP[kk] = np.arange(must_keep_counter,must_keep_counter+len(b_idx))\n",
    "            must_keep_counter += len(b_idx)\n",
    "\n",
    "\n",
    "\n",
    "        #this is where should send only the MP that apply\n",
    "        MP_branches_for_correspondence,conn_idx,MP_branches_with_stitch_point_idx = nu.intersect1d(conn,MP_branches_with_stitch_point,return_indices=True)\n",
    "\n",
    "        curr_MP_meshes_idx = [limb_correspondence_MP[MP_idx][k][\"branch_face_idx\"] for k in MP_branches_for_correspondence]\n",
    "        curr_MP_sk_for_correspondence = [curr_MP_sk[zz] for zz in MP_branches_with_stitch_point_idx]\n",
    "\n",
    "        stitching_mesh_idx = np.concatenate(curr_MAP_meshes_idx + curr_MP_meshes_idx)\n",
    "        stitching_mesh = limb_mesh_mparty.submesh([stitching_mesh_idx],append=True,repair=False)\n",
    "        stitching_skeleton_branches = curr_MAP_sk + curr_MP_sk_for_correspondence\n",
    "        \"\"\"\n",
    "\n",
    "        ****** NEED TO GET THE RIGHT MESH TO RUN HE IDX ON SO GETS A GOOD MESH (CAN'T BE LIMB_MESH_MPARTY)\n",
    "        BUT MUST BE THE ORIGINAL MAP MESH\n",
    "\n",
    "        mesh_pieces_for_MAP\n",
    "        sublimb_meshes_MP\n",
    "\n",
    "        mesh_pieces_for_MAP_face_idx\n",
    "        sublimb_meshes_MP_face_idx\n",
    "\n",
    "        stitching_mesh = tu.combine_meshes(curr_MAP_meshes + curr_MP_meshes)\n",
    "        stitching_skeleton_branches = curr_MAP_sk + curr_MP_sk\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # ******************************** this is where should do thing about no mesh correspondence ***************** #\n",
    "\n",
    "        # -------- 12/22: Trying to do the re-correspondence but if doesn't work then just resort to old one --------- #\n",
    "\n",
    "        try:\n",
    "\n",
    "            #3) Run mesh correspondence to get new meshes and mesh_idx and widths\n",
    "            local_correspondnece_stitch = mesh_correspondence_first_pass(mesh=stitching_mesh,\n",
    "                                          skeleton_branches=stitching_skeleton_branches)\n",
    "\n",
    "            local_correspondence_stitch_revised = correspondence_1_to_1(mesh=stitching_mesh,\n",
    "                                                        local_correspondence=local_correspondnece_stitch,\n",
    "                                                        curr_limb_endpoints_must_keep=None,\n",
    "                                                        curr_soma_to_piece_touching_vertices=None,\n",
    "                                                        must_keep_labels=must_keep_labels_MAP)\n",
    "\n",
    "            #Need to readjust the mesh correspondence idx\n",
    "            for k,v in local_correspondence_stitch_revised.items():\n",
    "                local_correspondence_stitch_revised[k][\"branch_face_idx\"] = stitching_mesh_idx[local_correspondence_stitch_revised[k][\"branch_face_idx\"]]\n",
    "        except:\n",
    "            print(\"Errored in 1 to 1 correspondence in stitching so just reverting to the original mesh assignments\")\n",
    "            # Setting the correspondence manually because the adaptive way did not work\n",
    "            local_counter = 0\n",
    "            local_correspondence_stitch_revised = dict()\n",
    "\n",
    "            # setting the MAP parts (the new skeletons have already been adjusted)\n",
    "            for k in local_correspondence_stitch_revised_MAP:\n",
    "                local_correspondence_stitch_revised[local_counter] = local_correspondence_stitch_revised_MAP[k]\n",
    "                local_counter += 1\n",
    "\n",
    "            # setting the MP parts (the new skeletons have not been adjusted yet so adjusting them here)\n",
    "            for mp_idx, k in enumerate(MP_branches_for_correspondence):\n",
    "                local_correspondence_stitch_revised[local_counter] = limb_correspondence_MP[MP_idx][k] \n",
    "                local_correspondence_stitch_revised[local_counter][\"branch_skeleton\"] = curr_MP_sk[mp_idx]\n",
    "                local_counter += 1\n",
    "\n",
    "\n",
    "#                 su.compressed_pickle(stitching_skeleton_branches,\"stitching_skeleton_branches\")\n",
    "#                 su.compressed_pickle(stitching_mesh,\"stitching_mesh\")\n",
    "#                 su.compressed_pickle(local_correspondnece_stitch,\"local_correspondnece_stitch\")\n",
    "#                 su.compressed_pickle(must_keep_labels_MAP,\"must_keep_labels_MAP\")\n",
    "\n",
    "#                 raise Exception(\"Something went wrong with 1 to 1 correspondence\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # -------------- Part 16: Overwrite old branch entries (and add on one new to MAP if required a split) -------#\n",
    "\n",
    "\n",
    "        #4a) If MAP_stitch_point_on_end_or_branch is False\n",
    "        #- Delete the old MAP branch parts and replace with new MAP ones\n",
    "        if not MAP_stitch_point_on_end_or_branch:\n",
    "            print(\"Deleting branches from dictionary\")\n",
    "            del limb_correspondence_MAP[MAP_idx][MAP_branches_with_stitch_point[0]]\n",
    "            #adding the two new branches created from the stitching\n",
    "            limb_correspondence_MAP[MAP_idx][MAP_branches_with_stitch_point[0]] = local_correspondence_stitch_revised[0]\n",
    "            limb_correspondence_MAP[MAP_idx][np.max(list(limb_correspondence_MAP[MAP_idx].keys()))+1] = local_correspondence_stitch_revised[1]\n",
    "\n",
    "            #have to reorder the keys\n",
    "            #limb_correspondence_MAP[MAP_idx] = dict([(k,limb_correspondence_MAP[MAP_idx][k]) for k in np.sort(list(limb_correspondence_MAP[MAP_idx].keys()))])\n",
    "            limb_correspondence_MAP[MAP_idx] = gu.order_dict_by_keys(limb_correspondence_MAP[MAP_idx])\n",
    "\n",
    "        else: #4b) Revise the meshes,  mesh_idx, and widths of the MAP pieces if weren't broken up\n",
    "            for j,curr_MAP_idx_fixed in enumerate(MAP_pieces_for_correspondence): \n",
    "                limb_correspondence_MAP[MAP_idx][curr_MAP_idx_fixed] = local_correspondence_stitch_revised[j]\n",
    "            #want to update all of the skeletons just in case was altered by keep_MP_stitch_static and not included in correspondence\n",
    "            if keep_MP_stitch_static:\n",
    "                if len(MAP_branches_with_stitch_point) != len(curr_MAP_sk_final):\n",
    "                    raise Exception(\"MAP_branches_with_stitch_point not same size as curr_MAP_sk_final\")\n",
    "                for gg,map_idx_curr in enumerate(MAP_branches_with_stitch_point):\n",
    "                    limb_correspondence_MAP[MAP_idx][map_idx_curr][\"branch_skeleton\"] = curr_MAP_sk_final[gg]\n",
    "\n",
    "\n",
    "        for j,curr_MP_idx_fixed in enumerate(MP_branches_for_correspondence): #************** right here just need to make only the ones that applied\n",
    "            limb_correspondence_MP[MP_idx][curr_MP_idx_fixed] = local_correspondence_stitch_revised[j+len(curr_MAP_sk)]\n",
    "\n",
    "\n",
    "        #5b) Fixing the branch skeletons that were not included in the correspondence\n",
    "        MP_leftover,MP_leftover_idx = nu.setdiff1d(MP_branches_with_stitch_point,MP_branches_for_correspondence)\n",
    "        print(f\"MP_branches_with_stitch_point= {MP_branches_with_stitch_point}\")\n",
    "        print(f\"MP_branches_for_correspondence = {MP_branches_for_correspondence}\")\n",
    "        print(f\"MP_leftover = {MP_leftover}, MP_leftover_idx = {MP_leftover_idx}\")\n",
    "\n",
    "        for curr_MP_leftover,curr_MP_leftover_idx in zip(MP_leftover,MP_leftover_idx):\n",
    "            limb_correspondence_MP[MP_idx][curr_MP_leftover][\"branch_skeleton\"] = curr_MP_sk[curr_MP_leftover_idx]\n",
    "\n",
    "\n",
    "        print(f\" Finished with {(MP_idx,MAP_idx)} \\n\\n\\n\")\n",
    "        stitch_counter += 1\n",
    "#         if cut_flag:\n",
    "#             raise Exception(\"Cut flag was activated\")\n",
    "\n",
    "        if check_correspondence_branches:\n",
    "            sk.check_correspondence_branches_have_2_endpoints(limb_correspondence_MAP[MAP_idx])\n",
    "            sk.check_correspondence_branches_have_2_endpoints(limb_correspondence_MP[MP_idx])\n",
    "\n",
    "#             su.compressed_pickle(limb_correspondence_MAP,f\"limb_correspondence_MAP_{MAP_idx}_{MP_idx}\")\n",
    "#             su.compressed_pickle(limb_correspondence_MP,f\"limb_correspondence_MP_{MAP_idx}_{MP_idx}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"There were not both MAP and MP pieces so skipping the stitch resolving phase\")\n",
    "\n",
    "print(f\"Time for decomp of Limb = {time.time() - curr_limb_time}\")\n",
    "#     # ------------- Saving the MAP and MP Decompositions ---------------- #\n",
    "#     proper_limb_mesh_correspondence_MAP[curr_limb_idx] = limb_correspondence_MAP\n",
    "#     proper_limb_mesh_correspondence_MP[curr_limb_idx] = limb_correspondence_MP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------- Part 17: Grouping the MP and MAP Correspondence into one correspondence dictionary -------#\n",
    "limb_correspondence_individual = dict()\n",
    "counter = 0\n",
    "\n",
    "for sublimb_idx,sublimb_branches in limb_correspondence_MAP.items():\n",
    "    for branch_dict in sublimb_branches.values():\n",
    "        limb_correspondence_individual[counter]= branch_dict\n",
    "        counter += 1\n",
    "for sublimb_idx,sublimb_branches in limb_correspondence_MP.items():\n",
    "    for branch_dict in sublimb_branches.values():\n",
    "        limb_correspondence_individual[counter]= branch_dict\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "#info that may be used for concept networks\n",
    "network_starting_info = dict(\n",
    "            touching_verts_list = limb_to_soma_touching_vertices_list,\n",
    "            endpoints_must_keep = limb_to_endpoints_must_keep_list\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------- Part 18: 11-17 Addition that filters the network starting info into a more clean presentation ------------ #\n",
    "\"\"\"\n",
    "Pseudocode: \n",
    "1) Rearrange the network starting info into a ditionary mapping\n",
    "  soma_idx --> branch_broder_group --> list of dict(touching_vertices,endpoint)\n",
    "\n",
    "2) iterate through all the somas and border vertex groups\n",
    "a. filter to only those with an endpoint that is on a branch of the skeleton\n",
    "b1: If 1 --> then keep that one\n",
    "b2: If more --> pick the one with the endpoint closest to the average fo the vertex group\n",
    "b3: If 0 --> find the best available soma extending branch endpoint\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Part 1: Rearrange network info\n",
    "\n",
    "\n",
    "t_verts_list_total,enpts_list_total = network_starting_info.values()\n",
    "network_starting_info_revised = dict()\n",
    "for j,(v_list_dict,enpts_list_dict) in enumerate(zip(t_verts_list_total,enpts_list_total)):\n",
    "    #print(f\"---- Working on {j} -----\")\n",
    "#     print(v_list_dict)\n",
    "#     print(enpts_list_dict)\n",
    "    if set(list(v_list_dict.keys())) != set(list(enpts_list_dict)):\n",
    "        raise Exception(\"Soma keys not match for touching vertices and endpoints\")\n",
    "    for sm_idx in v_list_dict.keys():\n",
    "        v_list_soma = v_list_dict[sm_idx]\n",
    "        endpt_soma = enpts_list_dict[sm_idx]\n",
    "        if len(v_list_soma) != len(endpt_soma):\n",
    "            raise Exception(f\"touching vertices list and endpoint list not match size for soma {sm_idx}\")\n",
    "\n",
    "        all_border_vertex_groups = soma_touching_vertices_dict[sm_idx]\n",
    "\n",
    "        for v_l,endpt in zip(v_list_soma,endpt_soma):\n",
    "\n",
    "            matching_border_group  = []\n",
    "            for i,curr_border_group in enumerate(all_border_vertex_groups):\n",
    "                if nu.test_matching_vertices_in_lists(curr_border_group,v_l,verbose=True):\n",
    "                    matching_border_group.append(i)\n",
    "\n",
    "            if len(matching_border_group) == 0 or len(matching_border_group)>1:\n",
    "                raise Exception(f\"Matching border groups was not exactly 1: {matching_border_group}\")\n",
    "\n",
    "            winning_border_group = matching_border_group[0]\n",
    "\n",
    "            if sm_idx not in network_starting_info_revised.keys():\n",
    "                network_starting_info_revised[sm_idx] = dict()\n",
    "\n",
    "            if winning_border_group not in network_starting_info_revised[sm_idx].keys():\n",
    "                network_starting_info_revised[sm_idx][winning_border_group] = []\n",
    "            network_starting_info_revised[sm_idx][winning_border_group].append(dict(touching_verts=v_l,endpoint=endpt))\n",
    "\n",
    "\n",
    "# Part 2 Filter\n",
    "\"\"\"\n",
    "2) iterate through all the somas and border vertex groups\n",
    "a. filter to only those with an endpoint that is on a branch of the skeleton\n",
    "b1: If 1 --> then keep that one\n",
    "b2: If more --> pick the one with the endpoint closest to the average fo the vertex group\n",
    "b3: If 0 --> find the best available soma extending branch endpoint\n",
    "\n",
    "Pseudocode for b3:\n",
    "i) get all meshes that touch the vertex group (and keep the vertices that overlap)\n",
    "--> error if none\n",
    "ii) Get all of the endpoints of all matching branches\n",
    "iii) Filter the endpoints to only those that are degree 1 in the overall skeleton\n",
    "--> if none then just keep all endpoints\n",
    "iv) Find the closest viable endpoint to the mean of the boundary group\n",
    "v) save the overlap vertices and the winning endpoint as a dictionary\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "limb_correspondence_individual_saved = copy.deepcopy(limb_correspondence_individual)\n",
    "\n",
    "sorted_keys = np.sort(list(limb_correspondence_individual.keys()))\n",
    "curr_branches = [limb_correspondence_individual[k][\"branch_skeleton\"] for k in sorted_keys]\n",
    "curr_meshes = [limb_correspondence_individual[k][\"branch_mesh\"] for k in sorted_keys]\n",
    "\n",
    "network_starting_info_revised_cleaned = dict()\n",
    "for soma_idx in network_starting_info_revised.keys():\n",
    "    network_starting_info_revised_cleaned[soma_idx] = dict()\n",
    "    for bound_g_idx,endpoint_list in network_starting_info_revised[soma_idx].items():\n",
    "        endpoint_list = np.array(endpoint_list)\n",
    "\n",
    "        filter_on_skeleton_list = []\n",
    "        for zz,endpt_dict in enumerate(endpoint_list):\n",
    "            #a. filter to only those with an endpoint that is on a branch of the skeleton\n",
    "            sk_indices = sk.find_branch_skeleton_with_specific_coordinate(divded_skeleton=curr_branches,\n",
    "                                                                        current_coordinate=endpt_dict[\"endpoint\"])\n",
    "            if len(sk_indices) > 0:\n",
    "                filter_on_skeleton_list.append(zz)\n",
    "\n",
    "        endpoint_list_filt = endpoint_list[filter_on_skeleton_list]\n",
    "\n",
    "\n",
    "\n",
    "        curr_border_group_coordinates = soma_touching_vertices_dict[soma_idx][bound_g_idx]\n",
    "        boundary_mean = np.mean(curr_border_group_coordinates,axis=0)\n",
    "\n",
    "        if len(endpoint_list_filt) == 1:\n",
    "            print(\"Only one endpoint after filtering away the endpoints that are not on the skeleton\")\n",
    "            winning_dict = endpoint_list_filt[0]\n",
    "        #b2: If more --> pick the one with the endpoint closest to the average fo the vertex group\n",
    "        elif len(endpoint_list_filt) > 1:\n",
    "            print(f\"MORE THAN one endpoint after filtering away the endpoints that are not on the skeleton: {len(endpoint_list_filt)}\")\n",
    "            viable_endpoints = [endpt_dict[\"endpoint\"] for endpt_dict in endpoint_list_filt]\n",
    "\n",
    "\n",
    "            distanes_from_mean = np.linalg.norm(viable_endpoints-boundary_mean,axis=1)\n",
    "            winning_endpoint_idx = np.argmin(distanes_from_mean)\n",
    "            winning_dict = endpoint_list_filt[winning_endpoint_idx]\n",
    "\n",
    "        #if there was no clear winner\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Pseudocode for no viable options:\n",
    "            i) get all meshes that touch the vertex group (and keep the vertices that overlap)\n",
    "            --> error if none\n",
    "            ii) Get all of the endpoints of all matching branches\n",
    "            iii) Filter the endpoints to only those that are degree 1 in the overall skeleton\n",
    "            --> if none then just keep all endpoints\n",
    "            iv) Find the closest viable endpoint to the mean of the boundary group\n",
    "            v) save the overlap vertices and the winning endpoint as a dictionary\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            print(\"Having to find a new branch point\")\n",
    "            #i) get all meshes that touch the vertex group (and keep the vertices that overlap)\n",
    "            mesh_indices_on_border = tu.filter_meshes_by_containing_coordinates(curr_meshes,\n",
    "                                          nullifying_points=curr_border_group_coordinates,\n",
    "                                          filter_away=False,\n",
    "                                          distance_threshold=0,\n",
    "                                          return_indices=True)\n",
    "            if len(mesh_indices_on_border) == 0:\n",
    "                raise Exception(\"There were no meshes that were touching the boundary group\")\n",
    "\n",
    "            total_skeleton_graph = sk.convert_skeleton_to_graph(sk.stack_skeletons(curr_branches))\n",
    "            skeleton_branches_on_border = [k for n,k in enumerate(curr_branches) if n in mesh_indices_on_border]\n",
    "            skeleton_branches_on_border_endpoints = np.array([sk.find_branch_endpoints(k) for k in skeleton_branches_on_border])\n",
    "\n",
    "\n",
    "\n",
    "            viable_endpoints = []\n",
    "            for enpt in skeleton_branches_on_border_endpoints.reshape(-1,3):\n",
    "                curr_enpt_node = xu.get_graph_node_by_coordinate(total_skeleton_graph,enpt,return_single_value=True)\n",
    "                curr_enpt_degree = xu.get_node_degree(total_skeleton_graph,curr_enpt_node)\n",
    "                #print(f\"curr_enpt_degree = {curr_enpt_degree}\")\n",
    "                if curr_enpt_degree == 1:\n",
    "                    viable_endpoints.append(enpt)\n",
    "\n",
    "            if len(viable_endpoints) == 0:\n",
    "                print(\"No branch endpoints were degree 1 so just using all endpoints\")\n",
    "                viable_endpoints = skeleton_branches_on_border_endpoints.reshape(-1,3)\n",
    "\n",
    "            distanes_from_mean = np.linalg.norm(viable_endpoints-boundary_mean,axis=1)\n",
    "            winning_endpoint = viable_endpoints[np.argmin(distanes_from_mean)]\n",
    "\n",
    "\n",
    "            sk_indices = sk.find_branch_skeleton_with_specific_coordinate(divded_skeleton=curr_branches,\n",
    "                                                                                    current_coordinate=winning_endpoint)\n",
    "\n",
    "            winning_branch = np.intersect1d(mesh_indices_on_border,sk_indices)\n",
    "            if len(winning_branch) == 0:\n",
    "                raise Exception(\"There was no winning branch for the creation of a new soma extending branch\")\n",
    "            else:\n",
    "                winning_branch_single = winning_branch[0]\n",
    "\n",
    "\n",
    "            winning_touching_vertices = tu.filter_vertices_by_mesh(curr_meshes[winning_branch_single],curr_border_group_coordinates)\n",
    "            winning_dict = dict(touching_verts=winning_touching_vertices,endpoint=winning_endpoint)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        network_starting_info_revised_cleaned[soma_idx][bound_g_idx] = winning_dict\n",
    "\n",
    "\n",
    "# -------------- Part 18: Filter the limb correspondence for any short stubs ------------ #\n",
    "if filter_end_nodes_from_correspondence:\n",
    "    limb_correspondence_individual = pre.filter_limb_correspondence_for_end_nodes(limb_correspondence=limb_correspondence_individual,\n",
    "                                                 mesh=limb_mesh_mparty,\n",
    "                                                 starting_info=network_starting_info_revised_cleaned,\n",
    "                                                filter_end_node_length=filter_end_node_length\n",
    "\n",
    "                                                )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not return_concept_network:\n",
    "    if return_concept_network_starting_info: #because may want to calculate the concept networks later\n",
    "        return_value = limb_correspondence_individual,network_starting_info_revised_cleaned\n",
    "    else:\n",
    "        return_value = limb_correspondence_individual\n",
    "    raise Exception(\"Returned\")\n",
    "    \n",
    "else:\n",
    "    limb_to_soma_concept_networks = calculate_limb_concept_networks(limb_correspondence_individual,\n",
    "                                                                    network_starting_info_revised_cleaned,\n",
    "                                                                    run_concept_network_checks=run_concept_network_checks,\n",
    "                                                                    error_on_starting_coordinates_not_endnodes= prevent_MP_starter_branch_stitches\n",
    "                                                                   )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "return_value =  limb_correspondence_individual,limb_to_soma_concept_networks\n",
    "raise Exception(\"Returned\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(limb_correspondence_individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the missing mesh piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_obj = (minnie.Decomposition & dict(segment_id=segment_id)).fetch1(\"decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mesh = mesh_pieces_for_MAP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(mesh_pieces_for_MAP[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = reload(sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sublimb_idx,(mesh,mesh_idx) in enumerate(zip(mesh_pieces_for_MAP,mesh_pieces_for_MAP_face_idx)):\n",
    "    print(f\"--- Working on MAP piece {sublimb_idx}---\")\n",
    "    #print(f\"soma_touching_vertices_dict = {soma_touching_vertices_dict}\")\n",
    "    mesh_start_time = time.time()\n",
    "    curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "    mesh = mesh,\n",
    "    curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "    )\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MAP Filtering Soma Pieces: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 0) Generating the Clean skeletons  -------------------------------------------#\n",
    "    if not curr_soma_to_piece_touching_vertices is None:\n",
    "        curr_total_border_vertices = dict([(k,np.vstack(v)) for k,v in curr_soma_to_piece_touching_vertices.items()])\n",
    "    else:\n",
    "        curr_total_border_vertices = None\n",
    "\n",
    "\n",
    "    cleaned_branch,curr_limb_endpoints_must_keep = sk.skeletonize_and_clean_connected_branch_CGAL(\n",
    "        mesh=mesh,\n",
    "        curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices,\n",
    "        total_border_vertices=curr_total_border_vertices,\n",
    "        filter_end_node_length=filter_end_node_length,\n",
    "        perform_cleaning_checks=perform_cleaning_checks,\n",
    "        combine_close_skeleton_nodes = combine_close_skeleton_nodes,\n",
    "        combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold,\n",
    "    use_surface_after_CGAL=use_surface_after_CGAL,\n",
    "    surface_reconstruction_size=surface_reconstruction_size,\n",
    "    verbose=True)\n",
    "\n",
    "    if not curr_limb_endpoints_must_keep is None:\n",
    "        limb_to_endpoints_must_keep_list.append(curr_limb_endpoints_must_keep)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices)\n",
    "    else:\n",
    "        print(\"Inside MAP decomposition and curr_limb_endpoints_must_keep was None\")\n",
    "\n",
    "    if len(cleaned_branch) == 0:\n",
    "        raise Exception(f\"Found a zero length skeleton for limb {z} of trmesh {branch}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"skeletonize_and_clean_connected_branch_CGAL: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 1) Generating Initial Mesh Correspondence -------------------------------------------#\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Working on limb correspondence for #{sublimb_idx} MAP piece\")\n",
    "    local_correspondence = mesh_correspondence_first_pass(mesh=mesh,\n",
    "                                                         skeleton=cleaned_branch,\n",
    "                                                         distance_by_mesh_center=distance_by_mesh_center,\n",
    "                                                         connectivity=\"edges\",\n",
    "                                                         remove_inside_pieces_threshold=100)\n",
    "\n",
    "\n",
    "    print(f\"Total time for decomposition = {time.time() - start_time}\")\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_correspondence_first_pass: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "\n",
    "    #------------- 2) Doing Some checks on the initial corespondence -------- #\n",
    "\n",
    "\n",
    "    if perform_cleaning_checks:\n",
    "        check_skeletonization_and_decomp(skeleton=cleaned_branch,\n",
    "                                        local_correspondence=local_correspondence)\n",
    "\n",
    "    # -------3) Finishing off the face correspondence so get 1-to-1 correspondence of mesh face to skeletal piece\n",
    "    local_correspondence_revised = correspondence_1_to_1(mesh=mesh,\n",
    "                                    local_correspondence=local_correspondence,\n",
    "                                    curr_limb_endpoints_must_keep=curr_limb_endpoints_must_keep,\n",
    "                                    curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices)\n",
    "\n",
    "    # -------3b) Fixing the mesh indices to correspond to the larger mesh as a whole\n",
    "    for k,v in local_correspondence_revised.items():\n",
    "        local_correspondence_revised[k][\"branch_face_idx\"] = mesh_idx[local_correspondence_revised[k][\"branch_face_idx\"]]\n",
    "\n",
    "    print(f\"Total time for MAP sublimb #{sublimb_idx} mesh processing = {time.time() - mesh_start_time}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"correspondence_1_to_1: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    limb_correspondence_MAP[sublimb_idx] = local_correspondence_revised\n",
    "    \n",
    "    raise Exception(\"Done #0 mesh piece\")\n",
    "\n",
    "print(f\"Total time for MAP sublimb processing {time.time() - global_start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_skeleton = su.decompress_pickle(\"current_skeleton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(debug_mesh,\n",
    "                 skeletons=[current_skeleton])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the new function where can protect the segments we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx_utils as xu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudocode: \n",
    "1) Turn the skeleton into a graph\n",
    "2) Get all of the end nodes\n",
    "3) Get all of the high degree nodes in the graph\n",
    "\n",
    "if there are high degree nodes, for each end nodes\n",
    "a. Find the path to the nearest high degree node\n",
    "b. Get the skeleton of that subgraph\n",
    "c. If length of that skeleton is within a certain range:\n",
    "    1) Run the first pass mesh correspondence\n",
    "    2) If the mesh is of a certain size, add the endpoint to the endpoints to keep\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mesh.submesh([[1]],append=True,repair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import trimesh_utils as tu\n",
    "                                                                \n",
    "return_value = tu.skeleton_to_mesh_correspondence( mesh = debug_mesh,\n",
    "                                                skeletons = viable_end_node_skeletons\n",
    "                                   )\n",
    "\n",
    "nviz.plot_objects(meshes=return_value,\n",
    "                  meshes_colors=\"random\",\n",
    "                  skeletons=viable_end_node_skeletons,\n",
    "                 skeletons_colors=\"random\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=return_value,\n",
    "                  meshes_colors=\"random\",\n",
    "                  skeletons=viable_end_node_skeletons,\n",
    "                 skeletons_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = current_skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.find_end_nodes_with_significant_mesh_correspondence(\n",
    "    mesh = debug_mesh,\n",
    "    skeleton = current_skeleton,\n",
    "    plot_viable_endpoint_correspondences = False,\n",
    "    plot_keep_endpoints = False,\n",
    "    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viable_end_node_skeletons_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.skeletonize_connected_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_col = nviz.visualize_neuron(retrieved_obj,\n",
    "                      visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=dict(L1=\"all\"),\n",
    "                     return_color_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_concept_network_2D(retrieved_obj,\n",
    "                                 node_colors=ret_col,\n",
    "                                 starting_soma=0,\n",
    "                                 starting_soma_group=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb = retrieved_obj[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb.set_concept_network_directional?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nru.all_soma_connnecting_endpionts_from_starting_info(network_starting_info_revised_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_vertex = np.array([1155881.9375  , 519313.2625  , 763731.68125])\n",
    "nu.matching_rows(total_keep_endpoints,winning_vertex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_correspondence_individual = pre.filter_limb_correspondence_for_end_nodes(limb_correspondence=limb_correspondence_individual,\n",
    "                                                 mesh=limb_mesh_mparty,\n",
    "                                                 starting_info=network_starting_info_revised_cleaned,\n",
    "                                                filter_end_node_length=filter_end_node_length\n",
    "\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_keep_endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_coord = nru.all_soma_connnecting_endpionts_from_starting_info(network_starting_info_revised_cleaned)\n",
    "st_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_keep_endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_to_endpoints_must_keep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_starting_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_verts_list_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_starting_info_revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_starting_info_revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_starting_info_revised[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nru.all_soma_connnecting_endpionts_from_starting_info(network_starting_info_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(limb_correspondence_MP_saved,\n",
    "                             meshes_colors=\"green\",\n",
    "                             skeleton_colors=\"blue\",\n",
    "                             scatters=total_keep_endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(limb_correspondence_MAP_saved,\n",
    "                             meshes_colors=\"green\",\n",
    "                             skeleton_colors=\"blue\",\n",
    "                             scatters=st_coord[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(limb_correspondence_individual,\n",
    "                             meshes_colors=\"green\",\n",
    "                             skeleton_colors=\"blue\",\n",
    "                             scatters=st_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the limb correspondence error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sublimb_idx,(mesh,mesh_idx) in enumerate(zip(mesh_pieces_for_MAP,mesh_pieces_for_MAP_face_idx)):\n",
    "    print(f\"--- Working on MAP piece {sublimb_idx}---\")\n",
    "    #print(f\"soma_touching_vertices_dict = {soma_touching_vertices_dict}\")\n",
    "    mesh_start_time = time.time()\n",
    "    curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "    mesh = mesh,\n",
    "    curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "    )\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MAP Filtering Soma Pieces: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 0) Generating the Clean skeletons  -------------------------------------------#\n",
    "    if not curr_soma_to_piece_touching_vertices is None:\n",
    "        curr_total_border_vertices = dict([(k,np.vstack(v)) for k,v in curr_soma_to_piece_touching_vertices.items()])\n",
    "    else:\n",
    "        curr_total_border_vertices = None\n",
    "\n",
    "\n",
    "    cleaned_branch,curr_limb_endpoints_must_keep = sk.skeletonize_and_clean_connected_branch_CGAL(\n",
    "        mesh=mesh,\n",
    "        curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices,\n",
    "        total_border_vertices=curr_total_border_vertices,\n",
    "        filter_end_node_length=filter_end_node_length,\n",
    "        perform_cleaning_checks=perform_cleaning_checks,\n",
    "        combine_close_skeleton_nodes = combine_close_skeleton_nodes,\n",
    "        combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold,\n",
    "    use_surface_after_CGAL=use_surface_after_CGAL,\n",
    "    surface_reconstruction_size=surface_reconstruction_size)\n",
    "\n",
    "    if not curr_limb_endpoints_must_keep is None:\n",
    "        limb_to_endpoints_must_keep_list.append(curr_limb_endpoints_must_keep)\n",
    "        limb_to_soma_touching_vertices_list.append(curr_soma_to_piece_touching_vertices)\n",
    "    else:\n",
    "        print(\"Inside MAP decomposition and curr_limb_endpoints_must_keep was None\")\n",
    "\n",
    "    if len(cleaned_branch) == 0:\n",
    "        raise Exception(f\"Found a zero length skeleton for limb {z} of trmesh {branch}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"skeletonize_and_clean_connected_branch_CGAL: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 1) Generating Initial Mesh Correspondence -------------------------------------------#\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Working on limb correspondence for #{sublimb_idx} MAP piece\")\n",
    "    local_correspondence = mesh_correspondence_first_pass(mesh=mesh,\n",
    "                                                         skeleton=cleaned_branch,\n",
    "                                                         distance_by_mesh_center=distance_by_mesh_center,\n",
    "                                                         connectivity=\"edges\",\n",
    "                                                         remove_inside_pieces_threshold=100)\n",
    "\n",
    "\n",
    "    print(f\"Total time for decomposition = {time.time() - start_time}\")\n",
    "    if print_fusion_steps:\n",
    "        print(f\"mesh_correspondence_first_pass: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "\n",
    "    #------------- 2) Doing Some checks on the initial corespondence -------- #\n",
    "\n",
    "\n",
    "    if perform_cleaning_checks:\n",
    "        check_skeletonization_and_decomp(skeleton=cleaned_branch,\n",
    "                                        local_correspondence=local_correspondence)\n",
    "\n",
    "    # -------3) Finishing off the face correspondence so get 1-to-1 correspondence of mesh face to skeletal piece\n",
    "    local_correspondence_revised = correspondence_1_to_1(mesh=mesh,\n",
    "                                    local_correspondence=local_correspondence,\n",
    "                                    curr_limb_endpoints_must_keep=curr_limb_endpoints_must_keep,\n",
    "                                    curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices)\n",
    "\n",
    "    # -------3b) Fixing the mesh indices to correspond to the larger mesh as a whole\n",
    "    for k,v in local_correspondence_revised.items():\n",
    "        local_correspondence_revised[k][\"branch_face_idx\"] = mesh_idx[local_correspondence_revised[k][\"branch_face_idx\"]]\n",
    "\n",
    "    print(f\"Total time for MAP sublimb #{sublimb_idx} mesh processing = {time.time() - mesh_start_time}\")\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"correspondence_1_to_1: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    limb_correspondence_MAP[sublimb_idx] = local_correspondence_revised\n",
    "    \n",
    "    raise Exception(\"Done #0 mesh piece\")\n",
    "\n",
    "print(f\"Total time for MAP sublimb processing {time.time() - global_start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nviz.plot_objects(mesh,\n",
    "                 skeletons=[cleaned_branch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(local_correspondence,mesh_name=\"correspondence_mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz = reload(nviz)\n",
    "nviz.plot_limb_correspondence(local_correspondence,mesh_name=\"correspondence_mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(local_correspondence_revised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the local correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh=mesh\n",
    "skeleton=cleaned_branch\n",
    "distance_by_mesh_center=distance_by_mesh_center\n",
    "connectivity=\"edges\"\n",
    "\n",
    "skeleton_branches=None\n",
    "\n",
    "\"\"\"\n",
    "Will come up with the mesh correspondences for all of the skeleton\n",
    "branches: where there can be overlaps and empty faces\n",
    "\n",
    "\"\"\"\n",
    "curr_limb_mesh = mesh\n",
    "curr_limb_sk = skeleton\n",
    "\n",
    "if skeleton_branches is None:\n",
    "    if skeleton is None:\n",
    "        raise Exception(\"Both skeleton and skeleton_branches is None\")\n",
    "    curr_limb_branches_sk_uneven = sk.decompose_skeleton_to_branches(curr_limb_sk) #the line that is decomposing to branches\n",
    "else:\n",
    "    curr_limb_branches_sk_uneven = skeleton_branches \n",
    "\n",
    "#Doing the limb correspondence for all of the branches of the skeleton\n",
    "local_correspondence = dict()\n",
    "for j,curr_branch_sk in tqdm(enumerate(curr_limb_branches_sk_uneven)):\n",
    "    local_correspondence[j] = dict()\n",
    "\n",
    "\n",
    "    returned_data = cu.mesh_correspondence_adaptive_distance(curr_branch_sk,\n",
    "                                  curr_limb_mesh,\n",
    "                                 skeleton_segment_width = 1000,\n",
    "                                 distance_by_mesh_center=distance_by_mesh_center,\n",
    "                                                            connectivity=connectivity)\n",
    "    if len(returned_data) == 0:\n",
    "        print(\"Got nothing from first pass so expanding the mesh correspondnece parameters \")\n",
    "        returned_data = cu.mesh_correspondence_adaptive_distance(curr_branch_sk,\n",
    "                                  curr_limb_mesh,\n",
    "                                 skeleton_segment_width = 1000,\n",
    "                                 distance_by_mesh_center=distance_by_mesh_center,\n",
    "                                buffer=300,\n",
    "                                 distance_threshold=6000,\n",
    "                                return_closest_face_on_empty=True,\n",
    "                                    connectivity=connectivity)\n",
    "\n",
    "    # Need to just pick the closest face is still didn't get anything\n",
    "\n",
    "    # ------ 12/3 Addition: Account for correspondence that does not work so just picking the closest face\n",
    "    curr_branch_face_correspondence, width_from_skeleton = returned_data\n",
    "\n",
    "\n",
    "#             print(f\"curr_branch_sk.shape = {curr_branch_sk.shape}\")\n",
    "#             np.savez(\"saved_skeleton_branch.npz\",curr_branch_sk=curr_branch_sk)\n",
    "#             tu.write_neuron_off(curr_limb_mesh,\"curr_limb_mesh.off\")\n",
    "#             #print(f\"returned_data = {returned_data}\")\n",
    "#             raise Exception(f\"The output from mesh_correspondence_adaptive_distance was nothing: curr_branch_face_correspondence\")\n",
    "\n",
    "\n",
    "    if len(curr_branch_face_correspondence) > 0:\n",
    "        curr_submesh = curr_limb_mesh.submesh([list(curr_branch_face_correspondence)],append=True,repair=False)\n",
    "    else:\n",
    "        curr_submesh = trimesh.Trimesh(vertices=np.array([]),faces=np.array([]))\n",
    "\n",
    "\n",
    "    local_correspondence[j][\"branch_skeleton\"] = curr_branch_sk\n",
    "    local_correspondence[j][\"correspondence_mesh\"] = curr_submesh\n",
    "    local_correspondence[j][\"correspondence_face_idx\"] = curr_branch_face_correspondence\n",
    "    local_correspondence[j][\"width_from_skeleton\"] = width_from_skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.original_mesh_faces_map(curr_limb_mesh,inside_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_limb_mesh,len(new_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mesh = tu.remove_mesh_interior(curr_limb_mesh,size_threshold_to_remove=100,try_hole_close=False,return_removed_pieces=False,\n",
    "                                  return_face_indices=True)\n",
    "\n",
    "nviz.plot_objects(curr_limb_mesh.submesh([new_mesh],append=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_skeleton = curr_limb_branches_sk_uneven[2]\n",
    "curr_branch_face_correspondence, width_from_skeleton = cu.mesh_correspondence_adaptive_distance(test_skeleton,\n",
    "                                 new_mesh,\n",
    "                                 skeleton_segment_width = 1000,\n",
    "                                 distance_by_mesh_center=distance_by_mesh_center,\n",
    "                                                            connectivity=connectivity,\n",
    "                                                                                               #buffer=3000\n",
    "                                                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_submesh = new_mesh.submesh([list(curr_branch_face_correspondence)],append=True,repair=False)\n",
    "nviz.plot_objects(curr_submesh,\n",
    "                 skeletons=[test_skeleton],\n",
    "                 meshes=inside_pieces,\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(face_subtract_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_subtract_indices = su.decompress_pickle(\"face_subtract_indices\")\n",
    "debug_mesh = curr_limb_mesh.submesh([np.unique(np.concatenate(face_subtract_indices))],append=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_val = tu.remove_mesh_interior(debug_mesh,size_threshold_to_remove=100,verbose=True,return_removed_pieces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mesh_revised,inside_pieces = ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(main_mesh=debug_mesh_revised,\n",
    "                meshes=inside_pieces,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_meshes = tu.split_significant_pieces(debug_mesh,connectivity=\"vertices\")\n",
    "nviz.plot_objects(meshes=split_meshes,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=tu.split(debug_mesh,connectivity=\"edges\")[0],\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(,\n",
    "                  skeletons=[test_skeleton])\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_subtract_indices = su.decompress_pickle(\"face_subtract_indices\")\n",
    "conn_face_components = nu.intersecting_array_components(face_subtract_indices,sort_components=True)\n",
    "conn_comps_lenghts = np.array([len(k) for k in conn_face_components])\n",
    "max_len_components_idx = np.where(conn_comps_lenghts == np.max(conn_comps_lenghts))[0]\n",
    "\n",
    "#2) Get the face indices for all those in the group\n",
    "max_len_components_unique_faces = [np.unique(np.concatenate([face_subtract_indices[k] \n",
    "                                                             for k in conn_face_components[cmp_idx]])) for cmp_idx in  max_len_components_idx]\n",
    "unique_removed_faces_pre = max_len_components_unique_faces[np.argmax([len(k) for k in max_len_components_unique_faces])]\n",
    "unique_removed_faces_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(curr_limb_mesh.submesh([unique_removed_faces_pre],append=True),\n",
    "                 skeletons=[test_skeleton])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(skeletons=curr_limb_branches_sk_uneven,\n",
    "                 scatters=[curr_limb_branches_sk_uneven[2].reshape(-1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_correspondence_individual[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([(k,v) for k,v in limb_correspondence_individual.items() if k in np.arange(10,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(dict([(k,v) for k,v in limb_correspondence_individual.items() if k in np.arange(19,20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=mesh_pieces_for_MAP,\n",
    "                  meshes_colors=[\"red\",\"black\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(limb_correspondence_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.visualize_neuron(\n",
    "                        recovered_neuron,\n",
    "                      visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                      limb_branch_dict=dict(L1=\"all\")\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_br_endpts_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(skeletons=[curr_skeleton_MAP,curr_skeleton_MP],\n",
    "                 skeletons_colors=[\"red\",\"black\"],\n",
    "                 scatters=[MAP_stitch_point.reshape(-1,3)],\n",
    "                 scatter_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_br_endpts_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.setdiff2d(curr_br_endpts_unique,total_keep_endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "np.array([k for k in curr_br_endpts_unique if len(nu.matching_rows(total_keep_endpoints,k))==0])\n",
    "print(f\"total time = {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "np.array([k for k in curr_br_endpts_unique if len(nu.matching_rows(total_keep_endpoints,k))==0])\n",
    "print(f\"total time = {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = reload(sk)\n",
    "sk.move_point_to_nearest_branch_end_point_within_threshold(\n",
    "                                                    skeleton=curr_skeleton_MAP,\n",
    "                                                    coordinate=MAP_stitch_point,\n",
    "                                                    distance_to_move_point_threshold = distance_to_move_point_threshold,\n",
    "                                                    verbose=True,\n",
    "                                                    possible_node_coordinates=nu.setdiff2d(curr_br_endpts_unique,total_keep_endpoints),\n",
    "                                                    excluded_node_coordinates=total_keep_endpoints,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_starting_info_revised_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_endpts = nru.all_soma_connnecting_endpionts_from_starting_info(network_starting_info_revised_cleaned,multiple_limbs=False)\n",
    "meshes,skeletons = nviz.limb_correspondence_plottable(limb_correspondence_MAP_saved)\n",
    "nviz.plot_objects(meshes=meshes,\n",
    "                  skeletons=skeletons,\n",
    "                             meshes_colors=\"green\",\n",
    "                             skeletons_colors=\"blue\",\n",
    "                 scatters=[st_endpts],\n",
    "                 scatter_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes,skeletons = nviz.limb_correspondence_plottable(limb_correspondence_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_skeleton = sk.stack_skeletons(skeletons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(\n",
    "                #meshes=meshes,\n",
    "                skeletons=[skeletons[k] for k in [1,86]],\n",
    "                 skeletons_colors=\"random\",\n",
    "                scatters=[skeletons[1].reshape(-1,3)],\n",
    "    scatter_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.calculate_skeleton_distance(skeletons[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.calculate_skeleton_distance(skeletons[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.find_branch_skeleton_with_specific_coordinate(skeletons,st_endpts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_endpts = nru.all_soma_connnecting_endpionts_from_starting_info(network_starting_info_revised_cleaned,multiple_limbs=False)\n",
    "meshes,skeletons = nviz.limb_correspondence_plottable(limb_correspondence_individual)\n",
    "nviz.plot_objects(meshes=meshes,\n",
    "                  skeletons=skeletons,\n",
    "                             meshes_colors=\"green\",\n",
    "                             skeletons_colors=\"blue\",\n",
    "                 scatters=[st_endpts[2]],\n",
    "                 scatter_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "st_endpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes,skeletons = nviz.limb_correspondence_plottable(limb_correspondence_MAP_saved)\n",
    "nviz.plot_objects(meshes=meshes,\n",
    "                  skeletons=skeletons,\n",
    "                             meshes_colors=\"green\",\n",
    "                             skeletons_colors=\"blue\",\n",
    "                 scatters=[st_endpts],\n",
    "                 scatter_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_correspondence(limb_correspondence_MP,\n",
    "                             meshes_colors=\"green\",\n",
    "                             skeleton_colors=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Big Conclusion: the large mesh pieces themselves (before combining into map pieces)\n",
    "themselves aren't totally connected by edges (can be split)\n",
    "\n",
    "- so even if large pieces do have a shared edge and you combine them together,\n",
    "they can still be split by the edges into multiple pieces\n",
    "\n",
    "Solution: should have to do split by vertices in the skeletonization\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sublimb_idx,(mesh,mesh_idx) in enumerate(zip(mesh_pieces_for_MAP,mesh_pieces_for_MAP_face_idx)):\n",
    "    print(f\"--- Working on MAP piece {sublimb_idx}---\")\n",
    "    #print(f\"soma_touching_vertices_dict = {soma_touching_vertices_dict}\")\n",
    "    mesh_start_time = time.time()\n",
    "    curr_soma_to_piece_touching_vertices = filter_soma_touching_vertices_dict_by_mesh(\n",
    "    mesh = mesh,\n",
    "    curr_piece_to_soma_touching_vertices = soma_touching_vertices_dict\n",
    "    )\n",
    "\n",
    "    if print_fusion_steps:\n",
    "        print(f\"MAP Filtering Soma Pieces: {time.time() - fusion_time }\")\n",
    "        fusion_time = time.time()\n",
    "\n",
    "    # ---- 0) Generating the Clean skeletons  -------------------------------------------#\n",
    "    if not curr_soma_to_piece_touching_vertices is None:\n",
    "        curr_total_border_vertices = dict([(k,np.vstack(v)) for k,v in curr_soma_to_piece_touching_vertices.items()])\n",
    "    else:\n",
    "        curr_total_border_vertices = None\n",
    "\n",
    "\n",
    "    cleaned_branch,curr_limb_endpoints_must_keep = sk.skeletonize_and_clean_connected_branch_CGAL(\n",
    "        mesh=mesh,\n",
    "        curr_soma_to_piece_touching_vertices=curr_soma_to_piece_touching_vertices,\n",
    "        total_border_vertices=curr_total_border_vertices,\n",
    "        filter_end_node_length=filter_end_node_length,\n",
    "        perform_cleaning_checks=perform_cleaning_checks,\n",
    "        combine_close_skeleton_nodes = combine_close_skeleton_nodes,\n",
    "        combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold,\n",
    "    use_surface_after_CGAL=use_surface_after_CGAL,\n",
    "    surface_reconstruction_size=surface_reconstruction_size,\n",
    "    skeleton_print=True,\n",
    "    connectivity=\"vertices\"\n",
    "    )\n",
    "    \n",
    "    raise Exception(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=[mesh_pieces_for_MAP[0]],\n",
    "                 skeletons=[cleaned_branch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mesh_splits = tu.split_significant_pieces(mesh_pieces_for_MAP[0],\n",
    "                               significance_threshold=1,\n",
    "                                                  connectivity=\"vertices\")\n",
    "current_mesh_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
