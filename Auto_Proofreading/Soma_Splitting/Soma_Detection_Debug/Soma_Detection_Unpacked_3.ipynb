{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To debug why certain somas are not being detected\n",
    "in agreement with nucleus table\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 02:52:49,155 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-13 02:52:49,157 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-13 02:52:49,157 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-13 02:52:49,162 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-13 02:52:49,162 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-13 02:52:49,175 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 02:52:49,440 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import soma_extraction_utils as sm\n",
    "import datajoint_utils as du\n",
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 02:52:49,513 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-13 02:52:49,759 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking what neurons did not have 2 somas which should have (so can test on them now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/6 Debugging Missed Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 864691135847950686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_neuron = du.fetch_segment_id_mesh(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07b08b8dd4b4f2aa40593620b55a793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 9595 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_88614.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_88614_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_205546.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_88614.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_88614_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_205546.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 25 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 25\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(17137, 3), faces.shape=(38449, 3))>, <trimesh.Trimesh(vertices.shape=(7795, 3), faces.shape=(15472, 3))>, <trimesh.Trimesh(vertices.shape=(5108, 3), faces.shape=(10760, 3))>, <trimesh.Trimesh(vertices.shape=(2310, 3), faces.shape=(5448, 3))>, <trimesh.Trimesh(vertices.shape=(1895, 3), faces.shape=(4542, 3))>, <trimesh.Trimesh(vertices.shape=(957, 3), faces.shape=(2216, 3))>, <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2034, 3))>, <trimesh.Trimesh(vertices.shape=(873, 3), faces.shape=(1974, 3))>, <trimesh.Trimesh(vertices.shape=(804, 3), faces.shape=(1812, 3))>, <trimesh.Trimesh(vertices.shape=(746, 3), faces.shape=(1691, 3))>, <trimesh.Trimesh(vertices.shape=(677, 3), faces.shape=(1533, 3))>, <trimesh.Trimesh(vertices.shape=(656, 3), faces.shape=(1458, 3))>, <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1214, 3))>, <trimesh.Trimesh(vertices.shape=(405, 3), faces.shape=(886, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 3191605, Final mesh size: 3102070\n",
      "Total time = 184.95952367782593\n",
      "xvfb-run -n 4872 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25862020.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(171086, 3), faces.shape=(337579, 3))>, <trimesh.Trimesh(vertices.shape=(128174, 3), faces.shape=(252513, 3))>, <trimesh.Trimesh(vertices.shape=(16894, 3), faces.shape=(33202, 3))>, <trimesh.Trimesh(vertices.shape=(6166, 3), faces.shape=(11522, 3))>, <trimesh.Trimesh(vertices.shape=(4173, 3), faces.shape=(8221, 3))>, <trimesh.Trimesh(vertices.shape=(3970, 3), faces.shape=(7745, 3))>, <trimesh.Trimesh(vertices.shape=(3921, 3), faces.shape=(7660, 3))>, <trimesh.Trimesh(vertices.shape=(3863, 3), faces.shape=(7562, 3))>, <trimesh.Trimesh(vertices.shape=(3491, 3), faces.shape=(6862, 3))>, <trimesh.Trimesh(vertices.shape=(3364, 3), faces.shape=(6430, 3))>, <trimesh.Trimesh(vertices.shape=(3257, 3), faces.shape=(6352, 3))>, <trimesh.Trimesh(vertices.shape=(2680, 3), faces.shape=(5131, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(171086, 3), faces.shape=(337579, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3508 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56909.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56909_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_189780.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56909.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56909_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_189780.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 14\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 6313 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(47374, 3), faces.shape=(94752, 3))>, <trimesh.Trimesh(vertices.shape=(3743, 3), faces.shape=(7482, 3))>, <trimesh.Trimesh(vertices.shape=(3615, 3), faces.shape=(7226, 3))>, <trimesh.Trimesh(vertices.shape=(2628, 3), faces.shape=(5252, 3))>, <trimesh.Trimesh(vertices.shape=(2147, 3), faces.shape=(4290, 3))>, <trimesh.Trimesh(vertices.shape=(1961, 3), faces.shape=(3918, 3))>, <trimesh.Trimesh(vertices.shape=(1841, 3), faces.shape=(3678, 3))>, <trimesh.Trimesh(vertices.shape=(1833, 3), faces.shape=(3662, 3))>, <trimesh.Trimesh(vertices.shape=(1773, 3), faces.shape=(3542, 3))>, <trimesh.Trimesh(vertices.shape=(1749, 3), faces.shape=(3494, 3))>, <trimesh.Trimesh(vertices.shape=(1748, 3), faces.shape=(3492, 3))>, <trimesh.Trimesh(vertices.shape=(1677, 3), faces.shape=(3350, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(47374, 3), faces.shape=(94752, 3))>\n",
      "xvfb-run -n 7627 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(11840, 3), faces.shape=(23684, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008897781372070312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068600_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 2.538649797439575\n",
      "2) Finished: Generating CGAL segmentation for neuron: 2.9378397464752197\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1, soma_sdf_value = 0.823097\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.008632659912109375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.936622619628906e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.022292137145996094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.11684703826904297\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.823097\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1, 11,  0, 14, 20,  8, 12,  5,  4, 16,  6, 22, 13, 10,  9, 19, 15,\n",
      "       18,  3, 17,  2,  7, 24, 21, 23]), array([0.823097 , 0.13618  , 0.1131635, 0.1115265, 0.0886942, 0.0866767,\n",
      "       0.0762347, 0.052294 , 0.0513055, 0.04895  , 0.0477849, 0.0465841,\n",
      "       0.0431792, 0.0429615, 0.0426522, 0.0399329, 0.0392385, 0.038995 ,\n",
      "       0.0379129, 0.036606 , 0.0351068, 0.0345068, 0.0330908, 0.0225283,\n",
      "       0.0148591]))\n",
      "Sizes = [3336, 615, 464, 502, 127, 3940, 410, 2037, 149, 1664, 647, 354, 175, 129, 487, 879, 1383, 1158, 1617, 1051, 1087, 725, 395, 266, 87]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 507 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_99176.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_99176_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_423970.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_99176.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_99176_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_423970.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.6926199263061608\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3743, 3), faces.shape=(7482, 3))>\n",
      "xvfb-run -n 6917 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(937, 3), faces.shape=(1870, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022554397583007812\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068601_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10142374038696289\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13027358055114746\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007121562957763672\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.364418029785156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0018310546875\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008769512176513672\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.624503 , 0.4541945, 0.379688 ]))\n",
      "Sizes = [187, 1262, 421]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "xy = 7.678741347301429 ratio was beyong 6 multiplier\n",
      "yz = 7.214312310954836 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_739391.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 535.8086070447544\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(634, 3), faces.shape=(1262, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/370_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31d6f358a8c400cbd82e563905f488a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yz = 7.424939994822383 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_639396.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 171.84595594682855\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(330, 3), faces.shape=(653, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(3615, 3), faces.shape=(7226, 3))>\n",
      "xvfb-run -n 6558 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(1806, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002484321594238281\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068602_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.12689971923828125\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.15812158584594727\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008816719055175781\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.054473876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00193023681640625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.009158134460449219\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 0, 1, 4, 3]), array([0.5795205, 0.4098825, 0.400068 , 0.243367 , 0.2311415]))\n",
      "Sizes = [956, 464, 157, 95, 134]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [2]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_334717.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 63.61996935238953\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(481, 3), faces.shape=(956, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/222_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e70727aea94415a97c956331c2e922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4922 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_721266.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_721266_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_597067.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_721266.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_721266_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_597067.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 26.597199947407685\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(290, 3), faces.shape=(569, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(2628, 3), faces.shape=(5252, 3))>\n",
      "xvfb-run -n 220 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(658, 3), faces.shape=(1312, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002377033233642578\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068603_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0705726146697998\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09269356727600098\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005447864532470703\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1021575927734375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012488365173339844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006426811218261719\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.501015, 0.146438]))\n",
      "Sizes = [1265, 47]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_376769.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1070.682322055472\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(635, 3), faces.shape=(1265, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/849_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c0d3d0e6ff43709e8040b519b46465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_657470.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 581.3149707432659\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(423, 3), faces.shape=(840, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(2147, 3), faces.shape=(4290, 3))>\n",
      "xvfb-run -n 3217 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(538, 3), faces.shape=(1072, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000286102294921875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068604_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0550694465637207\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07571840286254883\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005173683166503906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.8160552978515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010516643524169922\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0054357051849365234\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 4, 0, 3, 2, 1]), array([0.82615  , 0.483967 , 0.4432255, 0.200931 , 0.195852 , 0.171939 ]))\n",
      "Sizes = [55, 110, 822, 41, 19, 25]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 955 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_996719.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_996719_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_735007.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_996719.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_996719_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_735007.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 643.0389956195098\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(415, 3), faces.shape=(822, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/522_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca5de8382cf446599abd8609c25d349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(1961, 3), faces.shape=(3918, 3))>\n",
      "xvfb-run -n 1020 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(491, 3), faces.shape=(978, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003018379211425781\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068605_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05137491226196289\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07091188430786133\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00047326087951660156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.863739013671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009562969207763672\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00471186637878418\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 1, 0, 2]), array([0.830907 , 0.610574 , 0.4211915, 0.405974 ]))\n",
      "Sizes = [53, 152, 330, 443]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(224, 3), faces.shape=(443, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000186920166015625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068605_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.021635055541992188\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.030691862106323242\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00022459030151367188\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.0067901611328125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004458427429199219\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0021877288818359375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.501247]))\n",
      "Sizes = [443]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(224, 3), faces.shape=(443, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000186920166015625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068605_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.02182459831237793\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.030843019485473633\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00022339820861816406\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.719329833984375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005300045013427734\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0021774768829345703\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.501247]))\n",
      "Sizes = [443]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(1841, 3), faces.shape=(3678, 3))>\n",
      "xvfb-run -n 5235 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(918, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00035452842712402344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068606_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05151724815368652\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0717315673828125\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00045490264892578125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.696846008300781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009474754333496094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0046503543853759766\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.539502, 0.404462, 0.355925, 0.149079]))\n",
      "Sizes = [515, 117, 275, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(261, 3), faces.shape=(515, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020003318786621094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068606_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.028716325759887695\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03951287269592285\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002779960632324219\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.482269287109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005223751068115234\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002588033676147461\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.5109585, 0.382102 ]))\n",
      "Sizes = [398, 117]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(202, 3), faces.shape=(398, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021600723266601562\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068606_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.022073745727539062\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0445713996887207\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002601146697998047\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00022864341735839844\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013284683227539062\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002113819122314453\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.678304, 0.484701]))\n",
      "Sizes = [67, 331]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(1833, 3), faces.shape=(3662, 3))>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 6974 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(459, 3), faces.shape=(914, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022602081298828125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068607_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07100892066955566\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09581542015075684\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0013353824615478516\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0004303455352783203\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0019161701202392578\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00905156135559082\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.613149 , 0.4882185]))\n",
      "Sizes = [518, 396]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(262, 3), faces.shape=(518, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006868839263916016\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068607_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.02998185157775879\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03994870185852051\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002815723419189453\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.172325134277344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0006568431854248047\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0026161670684814453\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.709776, 0.573361]))\n",
      "Sizes = [185, 333]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(169, 3), faces.shape=(333, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00019979476928710938\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068607_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.01961517333984375\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.027625083923339844\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00020742416381835938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.57763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00034737586975097656\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0017514228820800781\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.588145]))\n",
      "Sizes = [333]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(1773, 3), faces.shape=(3542, 3))>\n",
      "xvfb-run -n 1491 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(444, 3), faces.shape=(884, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004398822784423828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068608_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05338239669799805\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06930088996887207\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00042319297790527344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.887580871582031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009963512420654297\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004342079162597656\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.489251, 0.31959 ]))\n",
      "Sizes = [795, 89]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_17134.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 976.3138681067418\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(400, 3), faces.shape=(795, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/649_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c876e09974d1475b8f5b354bc0baf2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(1749, 3), faces.shape=(3494, 3))>\n",
      "xvfb-run -n 1905 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(438, 3), faces.shape=(872, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006573200225830078\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068609_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04976487159729004\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07478880882263184\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00041556358337402344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.078315734863281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008757114410400391\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004415988922119141\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.623984, 0.416638]))\n",
      "Sizes = [751, 121]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_334456.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 560.3480734464212\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(378, 3), faces.shape=(751, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/783_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b290375ac63458e96b0de548659dd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(1748, 3), faces.shape=(3492, 3))>\n",
      "xvfb-run -n 5610 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(438, 3), faces.shape=(872, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002734661102294922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135847950686010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04793739318847656\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06462454795837402\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004596710205078125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.935264587402344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009608268737792969\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004391670227050781\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0]), array([0.586427, 0.489904, 0.447317]))\n",
      "Sizes = [166, 123, 583]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_674449.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 505.3427502288182\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(294, 3), faces.shape=(583, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/550_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b594b0bf81914b6ca5a70cb74d525ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #11: <trimesh.Trimesh(vertices.shape=(1677, 3), faces.shape=(3350, 3))>\n",
      "xvfb-run -n 5087 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(420, 3), faces.shape=(836, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000232696533203125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135847950686011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.046761274337768555\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06420326232910156\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00046372413635253906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1975250244140625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009365081787109375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0041468143463134766\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 1, 0, 2, 5, 4]), array([0.846262 , 0.4862655, 0.438222 , 0.3565205, 0.2714715, 0.255199 ]))\n",
      "Sizes = [73, 140, 342, 168, 74, 39]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(174, 3), faces.shape=(342, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001881122589111328\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135847950686011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.018134355545043945\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.026144742965698242\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002167224884033203\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004756450653076172\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0017235279083251953\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.618025]))\n",
      "Sizes = [342]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(174, 3), faces.shape=(342, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002009868621826172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135847950686011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.018155574798583984\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.026241064071655273\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002067089080810547\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.696846008300781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003561973571777344\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0016939640045166016\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.618025]))\n",
      "Sizes = [342]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(128174, 3), faces.shape=(252513, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 9875 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90069.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90069_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_842927.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90069.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90069_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_842927.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 117\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 120 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(48433, 3), faces.shape=(96862, 3))>, <trimesh.Trimesh(vertices.shape=(7168, 3), faces.shape=(14332, 3))>, <trimesh.Trimesh(vertices.shape=(3631, 3), faces.shape=(7258, 3))>, <trimesh.Trimesh(vertices.shape=(2890, 3), faces.shape=(5776, 3))>, <trimesh.Trimesh(vertices.shape=(2803, 3), faces.shape=(5606, 3))>, <trimesh.Trimesh(vertices.shape=(2553, 3), faces.shape=(5102, 3))>, <trimesh.Trimesh(vertices.shape=(2380, 3), faces.shape=(4756, 3))>, <trimesh.Trimesh(vertices.shape=(2341, 3), faces.shape=(4678, 3))>, <trimesh.Trimesh(vertices.shape=(1953, 3), faces.shape=(3902, 3))>, <trimesh.Trimesh(vertices.shape=(1946, 3), faces.shape=(3888, 3))>, <trimesh.Trimesh(vertices.shape=(1696, 3), faces.shape=(3388, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(48433, 3), faces.shape=(96862, 3))>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 3825 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(12107, 3), faces.shape=(24210, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006947517395019531\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068610_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 2.4001333713531494\n",
      "2) Finished: Generating CGAL segmentation for neuron: 2.781191825866699\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 5, soma_sdf_value = 0.879292\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.009096622467041016\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 6.008148193359375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.022864818572998047\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.12239217758178711\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.879292\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 5,  2, 10,  9,  8,  4,  1,  0,  7,  6,  3]), array([0.879292  , 0.613767  , 0.3716865 , 0.2009425 , 0.125081  ,\n",
      "       0.0684717 , 0.0643478 , 0.0567354 , 0.04055275, 0.0371252 ,\n",
      "       0.0368788 ]))\n",
      "Sizes = [3335, 420, 240, 158, 653, 706, 8736, 1941, 2608, 508, 4905]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [5]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7135 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_46403.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_46403_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_537277.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_46403.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_46403_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_537277.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.3838880744294673\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(7168, 3), faces.shape=(14332, 3))>\n",
      "xvfb-run -n 9950 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1793, 3), faces.shape=(3582, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006835460662841797\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068611_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.22765874862670898\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.2928774356842041\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0014805793762207031\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.601478576660156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.003505706787109375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.01780557632446289\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 4,  2,  9,  7,  3, 11,  1,  6,  8, 10,  0, 13,  5, 12, 14]), array([0.617051 , 0.572698 , 0.5714085, 0.562206 , 0.545801 , 0.4558485,\n",
      "       0.452258 , 0.4387675, 0.4146965, 0.3595655, 0.266252 , 0.253604 ,\n",
      "       0.229663 , 0.2201465, 0.184961 ]))\n",
      "Sizes = [156, 214, 278, 356, 396, 764, 638, 100, 296, 90, 76, 59, 40, 62, 57]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [11, 1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_379036.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 484.9081509304391\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(385, 3), faces.shape=(764, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/297_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3b3a3ce80f4312ae178438c22aa0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "xy = 7.028782804007273 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_929975.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 142.97764192127028\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(322, 3), faces.shape=(638, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/931_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15631c03d0454c29a4e4a2643d6e9b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(3631, 3), faces.shape=(7258, 3))>\n",
      "xvfb-run -n 2042 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(909, 3), faces.shape=(1814, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024580955505371094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068612_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10233807563781738\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13427424430847168\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008525848388671875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.221366882324219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00212860107421875\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.009055614471435547\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([6, 2, 8, 0, 1, 3, 7, 5, 4, 9]), array([0.6284255, 0.603442 , 0.594366 , 0.449255 , 0.434073 , 0.420303 ,\n",
      "       0.358195 , 0.258579 , 0.223471 , 0.0890111]))\n",
      "Sizes = [116, 93, 119, 183, 602, 207, 331, 63, 89, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_78913.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 695.8136095107732\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(304, 3), faces.shape=(602, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/192_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f31f78523bc4f70a11b9bcd647e3a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_75285.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 695.8136095107732\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(304, 3), faces.shape=(602, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(2890, 3), faces.shape=(5776, 3))>\n",
      "xvfb-run -n 6251 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(723, 3), faces.shape=(1442, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000247955322265625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068613_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08442950248718262\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11586427688598633\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007791519165039062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014293193817138672\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007380247116088867\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 3, 2, 4, 5, 6]), array([0.637952 , 0.63086  , 0.486856 , 0.425736 , 0.3090915, 0.186971 ,\n",
      "       0.108929 ]))\n",
      "Sizes = [223, 340, 537, 172, 110, 51, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(272, 3), faces.shape=(537, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002090930938720703\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068613_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.029308319091796875\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04100322723388672\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004558563232421875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.886222839355469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005426406860351562\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0028548240661621094\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 2, 0, 1, 4, 3]), array([0.7359345, 0.633423 , 0.50327  , 0.403857 , 0.3451325, 0.2278765]))\n",
      "Sizes = [70, 192, 123, 90, 16, 46]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(100, 3), faces.shape=(192, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00018453598022460938\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068613_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.010419368743896484\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0158536434173584\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00014257431030273438\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.124641418457031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003247261047363281\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0009746551513671875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.6887665]))\n",
      "Sizes = [192]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(2803, 3), faces.shape=(5606, 3))>\n",
      "xvfb-run -n 9603 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(700, 3), faces.shape=(1400, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002579689025878906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068614_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08359670639038086\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10715508460998535\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006437301635742188\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.200241088867188e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0017008781433105469\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007354259490966797\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 5, 4, 0, 2, 1]), array([0.7198495, 0.677131 , 0.583975 , 0.565054 , 0.528159 , 0.4881285]))\n",
      "Sizes = [160, 260, 225, 379, 246, 130]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(193, 3), faces.shape=(379, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002002716064453125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068614_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.02158498764038086\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.029701709747314453\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00024580955505371094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001583099365234375\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00039005279541015625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0019464492797851562\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 0, 3, 1]), array([0.723391, 0.487623, 0.33969 , 0.314873]))\n",
      "Sizes = [192, 101, 21, 65]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(100, 3), faces.shape=(192, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001990795135498047\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068614_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.011188745498657227\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.016764163970947266\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00014352798461914062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001506805419921875\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000217437744140625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0009758472442626953\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.648988]))\n",
      "Sizes = [192]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(2553, 3), faces.shape=(5102, 3))>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 1634 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(639, 3), faces.shape=(1274, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008885860443115234\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068615_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07201075553894043\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10386538505554199\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00072479248046875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.316734313964844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012867450714111328\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006430149078369141\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0, 3, 4]), array([0.7367025, 0.531408 , 0.508211 , 0.313671 , 0.312254 ]))\n",
      "Sizes = [126, 771, 253, 58, 66]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_157619.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 347.92724762906795\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(388, 3), faces.shape=(771, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/329_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b8d8d32c42468b8746c56662ad940f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_304863.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 347.92724762906795\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(388, 3), faces.shape=(771, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(2380, 3), faces.shape=(4756, 3))>\n",
      "xvfb-run -n 1166 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(596, 3), faces.shape=(1188, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022935867309570312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068616_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07693099975585938\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09898591041564941\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007836818695068359\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.57763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013768672943115234\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006161212921142578\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 4, 3, 2]), array([0.7132855, 0.6050165, 0.335205 , 0.329437 , 0.249196 ]))\n",
      "Sizes = [386, 646, 73, 52, 31]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_961840.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 157.21748192142925\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(326, 3), faces.shape=(646, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/650_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75565b96bdb64b1796ec9b62d90f3339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(2341, 3), faces.shape=(4678, 3))>\n",
      "xvfb-run -n 2769 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(586, 3), faces.shape=(1168, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004093647003173828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068617_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06553220748901367\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08637070655822754\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005207061767578125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.6253204345703125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011775493621826172\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0058934688568115234\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1]), array([0.578505, 0.350693, 0.136793]))\n",
      "Sizes = [1026, 119, 23]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_503780.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2208.188137925144\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(516, 3), faces.shape=(1026, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/205_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bc9854c1d4427eb2ec9a80d0455c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_920055.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2208.188137925144\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(516, 3), faces.shape=(1026, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(1953, 3), faces.shape=(3902, 3))>\n",
      "xvfb-run -n 7676 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(489, 3), faces.shape=(974, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002608299255371094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068618_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05173373222351074\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07323575019836426\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005335807800292969\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.054473876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0025281906127929688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006847381591796875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 5, 0, 3, 2, 6, 4]), array([0.604724 , 0.604413 , 0.5829465, 0.399946 , 0.354444 , 0.330336 ,\n",
      "       0.237515 ]))\n",
      "Sizes = [261, 97, 124, 130, 117, 222, 23]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(134, 3), faces.shape=(261, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024390220642089844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068618_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.012897014617919922\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.018669843673706055\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00017309188842773438\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.291534423828125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0002663135528564453\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0012590885162353516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.654266]))\n",
      "Sizes = [261]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(134, 3), faces.shape=(261, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00019502639770507812\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068618_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.012548446655273438\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.019038677215576172\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0001697540283203125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.291534423828125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003705024719238281\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.001262664794921875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.654266]))\n",
      "Sizes = [261]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(1946, 3), faces.shape=(3888, 3))>\n",
      "xvfb-run -n 7446 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(488, 3), faces.shape=(972, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00036978721618652344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068619_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05448150634765625\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07309603691101074\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005517005920410156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.482269287109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011096000671386719\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0048978328704833984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.574665]))\n",
      "Sizes = [972]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_166891.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 629.2843431892289\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(488, 3), faces.shape=(972, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/561_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649ac9d6967d494b8be095ddd8528ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_755888.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 629.2843431892289\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(488, 3), faces.shape=(972, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(1696, 3), faces.shape=(3388, 3))>\n",
      "xvfb-run -n 4628 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(425, 3), faces.shape=(846, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00026607513427734375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135847950686110_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04445695877075195\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.061281681060791016\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00043129920959472656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.9114227294921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008828639984130859\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004135847091674805\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.59061 , 0.152403, 0.108717]))\n",
      "Sizes = [822, 13, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_565055.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1013.4493460467205\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(414, 3), faces.shape=(822, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/177_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a491b00b36174044a9a14906ddc72b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_982618.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1013.4493460467205\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(414, 3), faces.shape=(822, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on large mesh #2: <trimesh.Trimesh(vertices.shape=(16894, 3), faces.shape=(33202, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 5365 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16139.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16139_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_716747.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16139.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16139_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_716747.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 2\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 3322 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = []\n",
      "----- working on large mesh #3: <trimesh.Trimesh(vertices.shape=(6166, 3), faces.shape=(11522, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3707 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29206.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29206_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_925796.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29206.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29206_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_925796.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 14\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 9397 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(11808, 3), faces.shape=(23612, 3))>, <trimesh.Trimesh(vertices.shape=(3016, 3), faces.shape=(6028, 3))>, <trimesh.Trimesh(vertices.shape=(1718, 3), faces.shape=(3432, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(11808, 3), faces.shape=(23612, 3))>\n",
      "xvfb-run -n 2711 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2952, 3), faces.shape=(5900, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007672309875488281\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068630_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.46695923805236816\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.5851643085479736\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0022106170654296875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.0067901611328125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00553584098815918\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.028182268142700195\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1, 3]), array([0.705756 , 0.561053 , 0.5479285, 0.408553 ]))\n",
      "Sizes = [2585, 2356, 840, 119]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [0, 2, 1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3899 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_685604.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_685604_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_440680.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_685604.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_685604_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_440680.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 90.64717938450507\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1298, 3), faces.shape=(2585, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/644_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45be90829ff04058b6876ea1638e30a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6003 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_710825.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_710825_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_258785.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_710825.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_710825_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_258785.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.45686221213365\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(477, 3), faces.shape=(942, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6268 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_57161.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_57161_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_672368.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_57161.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_57161_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_672368.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 382.34511871158986\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1182, 3), faces.shape=(2356, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/987_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265a43b2483d4275873e412333e66f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1001 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543142.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543142_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_883312.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543142.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543142_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_883312.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 91.09930828105944\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(692, 3), faces.shape=(1377, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2677 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_60558.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_60558_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_558159.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_60558.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_60558_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_558159.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 35.48860477303668\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(425, 3), faces.shape=(840, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/671_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d161e768b3f478fa19942ef851ec12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 691 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_45426.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_45426_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_956190.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_45426.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_45426_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_956190.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 35.48860477303668\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(425, 3), faces.shape=(840, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3016, 3), faces.shape=(6028, 3))>\n",
      "xvfb-run -n 3546 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(755, 3), faces.shape=(1506, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004737377166748047\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068631_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11483979225158691\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13907098770141602\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005934238433837891\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.57763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001369476318359375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007063627243041992\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1, 3, 4]), array([0.788323  , 0.680942  , 0.543503  , 0.122427  , 0.09154985]))\n",
      "Sizes = [176, 580, 695, 17, 38]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_940489.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 56.03869551031145\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(293, 3), faces.shape=(580, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/595_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0e31d565ae479bba2e708d7d81e8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_786742.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 106.2045626183124\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(352, 3), faces.shape=(695, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/479_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb383457a92c49f2b931ce669910731c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(1718, 3), faces.shape=(3432, 3))>\n",
      "xvfb-run -n 2890 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(431, 3), faces.shape=(858, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023698806762695312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068632_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06279730796813965\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07758116722106934\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00038552284240722656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002703666687011719\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008168220520019531\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0038874149322509766\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.68591  , 0.465029 , 0.391651 , 0.2550315]))\n",
      "Sizes = [247, 355, 92, 164]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(181, 3), faces.shape=(355, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00017309188842773438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068632_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.02351832389831543\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0308377742767334\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00020503997802734375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.552436828613281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003349781036376953\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0016252994537353516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1]), array([0.617808, 0.493232, 0.215197]))\n",
      "Sizes = [233, 95, 27]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(119, 3), faces.shape=(233, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00016689300537109375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068632_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.015347719192504883\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.020956039428710938\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002834796905517578\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.4809112548828125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00032711029052734375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0011000633239746094\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.617808]))\n",
      "Sizes = [233]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on large mesh #4: <trimesh.Trimesh(vertices.shape=(4173, 3), faces.shape=(8221, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 604 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93947.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93947_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_919263.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93947.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93947_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_919263.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 7\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 9350 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(3116, 3), faces.shape=(6228, 3))>, <trimesh.Trimesh(vertices.shape=(1820, 3), faces.shape=(3636, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(3116, 3), faces.shape=(6228, 3))>\n",
      "xvfb-run -n 4369 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(780, 3), faces.shape=(1556, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003409385681152344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068640_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11772584915161133\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.15018463134765625\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006735324859619141\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.673004150390625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0017082691192626953\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007822751998901367\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1, 3]), array([0.551503 , 0.42878  , 0.3464155, 0.297246 ]))\n",
      "Sizes = [1002, 237, 254, 63]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7330 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_549930.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_549930_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_648818.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_549930.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_549930_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_648818.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 131.17758097168087\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(1002, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/544_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451b8f9e22ac4e8bb0aabec407f995bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9559 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_331485.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_331485_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_549606.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_331485.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_331485_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_549606.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 131.17758097168087\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(1002, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1820, 3), faces.shape=(3636, 3))>\n",
      "xvfb-run -n 9767 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(456, 3), faces.shape=(908, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023603439331054688\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068641_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06434130668640137\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08139753341674805\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00044035911560058594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.601478576660156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009107589721679688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0045316219329833984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 3, 2]), array([0.56659  , 0.487312 , 0.120673 , 0.0467127]))\n",
      "Sizes = [607, 267, 17, 17]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4210 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_296751.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_296751_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_908432.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_296751.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_296751_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_908432.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 39.056136950564685\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(308, 3), faces.shape=(607, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/359_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec98a76e21804a9a8d16624712aa69bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on large mesh #5: <trimesh.Trimesh(vertices.shape=(3970, 3), faces.shape=(7745, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 7635 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7441.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7441_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_907441.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7441.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7441_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_907441.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 5\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 1549 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = []\n",
      "----- working on large mesh #6: <trimesh.Trimesh(vertices.shape=(3921, 3), faces.shape=(7660, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 390 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95499.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95499_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_10903.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95499.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95499_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_10903.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 8\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 964 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(3524, 3), faces.shape=(7044, 3))>, <trimesh.Trimesh(vertices.shape=(2446, 3), faces.shape=(4892, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(3524, 3), faces.shape=(7044, 3))>\n",
      "xvfb-run -n 7439 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(882, 3), faces.shape=(1760, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023102760314941406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068660_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.13710260391235352\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.16690421104431152\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007567405700683594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.7206878662109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015599727630615234\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008097648620605469\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 4, 1, 0, 6, 5, 2]), array([0.627902 , 0.61752  , 0.476145 , 0.4652845, 0.319952 , 0.249912 ,\n",
      "       0.2159305]))\n",
      "Sizes = [399, 285, 256, 652, 28, 46, 94]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9849 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_27572.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_27572_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_965537.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_27572.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_27572_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_965537.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 96.22776628976501\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(330, 3), faces.shape=(652, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/782_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34db4dce009245dd88f6983b3de5fdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2446, 3), faces.shape=(4892, 3))>\n",
      "xvfb-run -n 603 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(611, 3), faces.shape=(1222, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002872943878173828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068661_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08012819290161133\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10942435264587402\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005691051483154297\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1975250244140625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013079643249511719\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006208896636962891\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 5, 0, 3, 4]), array([0.683946 , 0.6050115, 0.5625485, 0.555198 , 0.149916 , 0.0858301]))\n",
      "Sizes = [292, 182, 114, 566, 49, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_607915.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 48.53499385268011\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(286, 3), faces.shape=(566, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/803_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428a03115a7b4a8e8e171a85b270504f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_577921.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 48.53499385268011\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(286, 3), faces.shape=(566, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on large mesh #7: <trimesh.Trimesh(vertices.shape=(3863, 3), faces.shape=(7562, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 6886 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8980.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8980_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_199157.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8980.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8980_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_199157.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 13\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 473 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(3778, 3), faces.shape=(7552, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(3778, 3), faces.shape=(7552, 3))>\n",
      "xvfb-run -n 5453 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(945, 3), faces.shape=(1886, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024127960205078125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068670_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1253054141998291\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.15730667114257812\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007753372192382812\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002129077911376953\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0018649101257324219\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00899505615234375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.7226655, 0.516381 , 0.470628 ]))\n",
      "Sizes = [422, 1281, 183]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6961 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_272590.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_272590_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_577424.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_272590.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_272590_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_577424.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 66.89433740231597\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(644, 3), faces.shape=(1281, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/228_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd9ceb6201447c3b6e3a41362a1ee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_940437.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 67.73449173314724\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(347, 3), faces.shape=(687, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on large mesh #8: <trimesh.Trimesh(vertices.shape=(3491, 3), faces.shape=(6862, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 767 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38687.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38687_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_781587.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38687.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38687_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_781587.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 4\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 7153 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(3345, 3), faces.shape=(6686, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(3345, 3), faces.shape=(6686, 3))>\n",
      "xvfb-run -n 1859 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(837, 3), faces.shape=(1670, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023245811462402344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068680_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09976339340209961\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12654542922973633\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008227825164794922\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.172325134277344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014653205871582031\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007875442504882812\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 4, 1, 3]), array([0.741349, 0.660784, 0.44773 , 0.410044, 0.172857]))\n",
      "Sizes = [151, 615, 277, 591, 36]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4722 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603609.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603609_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_440994.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603609.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603609_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_440994.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 116.25927313378727\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(313, 3), faces.shape=(615, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/549_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b96c7556ce4ed9b8f84feb2bcba0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_987136.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 294.4962204124293\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(298, 3), faces.shape=(591, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/760_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08382f669ff4e2aa58a0255bfafd3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on large mesh #9: <trimesh.Trimesh(vertices.shape=(3364, 3), faces.shape=(6430, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 9656 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13492.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13492_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_167873.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13492.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13492_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_167873.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 8\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 3520 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(6411, 3), faces.shape=(12818, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(6411, 3), faces.shape=(12818, 3))>\n",
      "xvfb-run -n 7724 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1604, 3), faces.shape=(3204, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007262229919433594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113584795068690_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.22185230255126953\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.28589344024658203\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.001190185546875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0030410289764404297\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.015506982803344727\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 5, 1, 4, 8, 7, 6, 3, 2]), array([0.738564 , 0.723921 , 0.61369  , 0.545722 , 0.486306 , 0.355743 ,\n",
      "       0.1378975, 0.136304 , 0.0930142]))\n",
      "Sizes = [828, 915, 1210, 107, 65, 25, 18, 23, 13]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [0, 5, 1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_191555.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 98.46451405939277\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(418, 3), faces.shape=(828, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/279_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b28bfed6261464ab9b23f56da8208ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_522321.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 105.63877027906281\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(765, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8460 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_545899.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_545899_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_28448.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_545899.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_545899_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_28448.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 74.91237036960706\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(463, 3), faces.shape=(915, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/550_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b13858d8a82419dbc33e0497d9b25d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3540 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_542151.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_542151_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_829893.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_542151.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_542151_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_829893.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 69.79823529839412\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(376, 3), faces.shape=(743, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_436402.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 408.44945158177956\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(609, 3), faces.shape=(1210, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/632_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d37824270940ad94ccebda350c50b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 606 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703175.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703175_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_450342.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703175.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703175_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_450342.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 82.98718619031688\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(410, 3), faces.shape=(810, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on large mesh #10: <trimesh.Trimesh(vertices.shape=(3257, 3), faces.shape=(6352, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3226 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_77009.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_77009_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_720787.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_77009.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_77009_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_720787.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 6\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 5053 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = []\n",
      "----- working on large mesh #11: <trimesh.Trimesh(vertices.shape=(2680, 3), faces.shape=(5131, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 2932 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50876.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50876_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_498352.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50876.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50876_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_498352.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 7\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off\n",
      "xvfb-run -n 894 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/poisson_796908.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(3609, 3), faces.shape=(7214, 3))>, <trimesh.Trimesh(vertices.shape=(2540, 3), faces.shape=(5076, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(3609, 3), faces.shape=(7214, 3))>\n",
      "xvfb-run -n 1764 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(903, 3), faces.shape=(1802, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000324249267578125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135847950686110_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.14737963676452637\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.18092656135559082\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006906986236572266\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.76837158203125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016620159149169922\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008538484573364258\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.6508385, 0.4796465]))\n",
      "Sizes = [776, 1026]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1790 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_86515.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_86515_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_972755.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_86515.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_86515_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_972755.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 27.815546240434134\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(392, 3), faces.shape=(776, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/672_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbeee2ded93f4bc38ab43b8f9b7fcffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5067 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_907039.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_907039_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_407669.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_907039.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_907039_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_407669.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 92.83671102279406\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(517, 3), faces.shape=(1026, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/858_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a1795425824bc8a0707e0475723322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 648 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_273637.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_273637_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_258111.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_273637.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_273637_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_258111.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 92.83671102279406\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(517, 3), faces.shape=(1026, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2540, 3), faces.shape=(5076, 3))>\n",
      "xvfb-run -n 3459 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135847950686/decimation_meshlab_25438029.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135847950686_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(636, 3), faces.shape=(1268, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002646446228027344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135847950686111_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09013557434082031\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12179303169250488\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005068778991699219\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.793571472167969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011594295501708984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005849123001098633\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.7274935, 0.539616 ]))\n",
      "Sizes = [546, 722]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_760171.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 51.66722343152975\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(364, 3), faces.shape=(722, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/62_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2e9d1a80a648e4841f3adbb4fc745a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 675.3960044384003\n",
      "Before Filtering the number of somas found = 2\n",
      "xvfb-run -n 3986 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_85249.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_85249_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_835652.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_85249.off loaded has 36176 vn 73605 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_85249_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_835652.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1751484\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1751484\n",
      "LOG: 2 Successfully removed 7297 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7297 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1663920\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_835652.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 5495 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25462.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25462_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_608971.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25462.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25462_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_608971.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(10422, 3), faces.shape=(23015, 3))>, <trimesh.Trimesh(vertices.shape=(319, 3), faces.shape=(756, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1207 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_93706.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_93706_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_276172.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_93706.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_93706_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_276172.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.618365712036549\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(17162, 3), faces.shape=(38476, 3))>, <trimesh.Trimesh(vertices.shape=(7808, 3), faces.shape=(15484, 3))>, <trimesh.Trimesh(vertices.shape=(5116, 3), faces.shape=(10767, 3))>, <trimesh.Trimesh(vertices.shape=(2310, 3), faces.shape=(5448, 3))>, <trimesh.Trimesh(vertices.shape=(1895, 3), faces.shape=(4542, 3))>, <trimesh.Trimesh(vertices.shape=(957, 3), faces.shape=(2216, 3))>, <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2034, 3))>, <trimesh.Trimesh(vertices.shape=(873, 3), faces.shape=(1974, 3))>, <trimesh.Trimesh(vertices.shape=(804, 3), faces.shape=(1812, 3))>, <trimesh.Trimesh(vertices.shape=(746, 3), faces.shape=(1691, 3))>, <trimesh.Trimesh(vertices.shape=(677, 3), faces.shape=(1533, 3))>, <trimesh.Trimesh(vertices.shape=(656, 3), faces.shape=(1458, 3))>, <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1214, 3))>, <trimesh.Trimesh(vertices.shape=(405, 3), faces.shape=(886, 3))>]\n",
      "xvfb-run -n 1474 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75372.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75372_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_573119.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75372.off loaded has 34852 vn 68853 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75372_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_573119.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1662684\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1662684\n",
      "LOG: 2 Successfully removed 7336 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7336 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1574652\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_573119.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 7861 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91261.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91261_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_807828.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91261.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91261_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_807828.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(4630, 3), faces.shape=(9610, 3))>, <trimesh.Trimesh(vertices.shape=(2838, 3), faces.shape=(5708, 3))>, <trimesh.Trimesh(vertices.shape=(754, 3), faces.shape=(1608, 3))>, <trimesh.Trimesh(vertices.shape=(267, 3), faces.shape=(556, 3))>, <trimesh.Trimesh(vertices.shape=(218, 3), faces.shape=(551, 3))>, <trimesh.Trimesh(vertices.shape=(145, 3), faces.shape=(360, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8503 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_373276.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_373276_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_320948.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_373276.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_373276_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_320948.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.337419474447971\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(17162, 3), faces.shape=(38476, 3))>, <trimesh.Trimesh(vertices.shape=(7808, 3), faces.shape=(15484, 3))>, <trimesh.Trimesh(vertices.shape=(5116, 3), faces.shape=(10767, 3))>, <trimesh.Trimesh(vertices.shape=(2310, 3), faces.shape=(5448, 3))>, <trimesh.Trimesh(vertices.shape=(1895, 3), faces.shape=(4542, 3))>, <trimesh.Trimesh(vertices.shape=(957, 3), faces.shape=(2216, 3))>, <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2034, 3))>, <trimesh.Trimesh(vertices.shape=(873, 3), faces.shape=(1974, 3))>, <trimesh.Trimesh(vertices.shape=(804, 3), faces.shape=(1812, 3))>, <trimesh.Trimesh(vertices.shape=(746, 3), faces.shape=(1691, 3))>, <trimesh.Trimesh(vertices.shape=(677, 3), faces.shape=(1533, 3))>, <trimesh.Trimesh(vertices.shape=(656, 3), faces.shape=(1458, 3))>, <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1214, 3))>, <trimesh.Trimesh(vertices.shape=(405, 3), faces.shape=(886, 3))>, <trimesh.Trimesh(vertices.shape=(10422, 3), faces.shape=(23015, 3))>, <trimesh.Trimesh(vertices.shape=(319, 3), faces.shape=(756, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 1953 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35288.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35288_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_817731.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35288.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35288_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_817731.mls is being deleted....\n",
      "xvfb-run -n 6524 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71477.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71477_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_529256.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71477.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71477_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_529256.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 121\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb5bb48c24448d7a5f209c9b30610eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 55274.83613549926, after = 151196.44560201257,\n",
      "ratio = 2.7353576450479857, difference = 95921.6094665133\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 9115 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18006.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18006_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_605769.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18006.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18006_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_605769.mls is being deleted....\n",
      "xvfb-run -n 7899 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59410.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59410_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_794347.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59410.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59410_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_794347.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 177\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f752e33e1d69437ea69d7e224e0b1216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 303554.73174905987, after = 319040.4772697762,\n",
      "ratio = 1.0510146734708719, difference = 15485.745520716358\n"
     ]
    }
   ],
   "source": [
    "somas = sm.extract_soma_center(segment_id,\n",
    "                      current_mesh_verts=current_neuron.vertices,\n",
    "                              current_mesh_faces=current_neuron.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 04:39:39,110 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-13 04:39:39,111 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-13 04:39:39,112 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-13 04:39:39,116 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-13 04:39:39,407 - settings - Setting enable_python_native_blobs to True\n",
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85699f6f1851401dae254911ace5a83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=somas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function that is unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1180dd8fd5fd4f1d949a6bb42784720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0cc998569d4311886b56d689b3716a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb365d1465b4bce8367768f52549285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 15000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 7506 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7892.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7892_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_124988.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7892.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7892_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_124988.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 17 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 17\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3789, 3), faces.shape=(8749, 3))>, <trimesh.Trimesh(vertices.shape=(3325, 3), faces.shape=(8110, 3))>, <trimesh.Trimesh(vertices.shape=(3323, 3), faces.shape=(5733, 3))>, <trimesh.Trimesh(vertices.shape=(1652, 3), faces.shape=(3781, 3))>, <trimesh.Trimesh(vertices.shape=(1360, 3), faces.shape=(3161, 3))>, <trimesh.Trimesh(vertices.shape=(1256, 3), faces.shape=(2879, 3))>, <trimesh.Trimesh(vertices.shape=(1090, 3), faces.shape=(2450, 3))>, <trimesh.Trimesh(vertices.shape=(1059, 3), faces.shape=(2420, 3))>, <trimesh.Trimesh(vertices.shape=(987, 3), faces.shape=(2238, 3))>, <trimesh.Trimesh(vertices.shape=(973, 3), faces.shape=(2199, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1802, 3))>, <trimesh.Trimesh(vertices.shape=(760, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(745, 3), faces.shape=(1675, 3))>, <trimesh.Trimesh(vertices.shape=(738, 3), faces.shape=(1621, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 1231744, Final mesh size: 1183183\n",
      "Total time = 60.19079661369324\n",
      "xvfb-run -n 7174 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25813232.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(142284, 3), faces.shape=(278888, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(142284, 3), faces.shape=(278888, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 120 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4314.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4314_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_393425.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4314.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4314_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_393425.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 595\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 9031 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/poisson_91961.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(51352, 3), faces.shape=(102708, 3))>, <trimesh.Trimesh(vertices.shape=(33765, 3), faces.shape=(67526, 3))>, <trimesh.Trimesh(vertices.shape=(8410, 3), faces.shape=(16816, 3))>, <trimesh.Trimesh(vertices.shape=(3533, 3), faces.shape=(7062, 3))>, <trimesh.Trimesh(vertices.shape=(3397, 3), faces.shape=(6790, 3))>, <trimesh.Trimesh(vertices.shape=(3199, 3), faces.shape=(6394, 3))>, <trimesh.Trimesh(vertices.shape=(3002, 3), faces.shape=(6000, 3))>, <trimesh.Trimesh(vertices.shape=(2748, 3), faces.shape=(5492, 3))>, <trimesh.Trimesh(vertices.shape=(2394, 3), faces.shape=(4784, 3))>, <trimesh.Trimesh(vertices.shape=(2266, 3), faces.shape=(4528, 3))>, <trimesh.Trimesh(vertices.shape=(2191, 3), faces.shape=(4378, 3))>, <trimesh.Trimesh(vertices.shape=(2160, 3), faces.shape=(4316, 3))>, <trimesh.Trimesh(vertices.shape=(1905, 3), faces.shape=(3806, 3))>, <trimesh.Trimesh(vertices.shape=(1896, 3), faces.shape=(3792, 3))>, <trimesh.Trimesh(vertices.shape=(1784, 3), faces.shape=(3564, 3))>, <trimesh.Trimesh(vertices.shape=(1709, 3), faces.shape=(3414, 3))>, <trimesh.Trimesh(vertices.shape=(1693, 3), faces.shape=(3382, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(51352, 3), faces.shape=(102708, 3))>\n",
      "xvfb-run -n 7413 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(12833, 3), faces.shape=(25670, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008618831634521484\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844700_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 2.6390132904052734\n",
      "2) Finished: Generating CGAL segmentation for neuron: 3.2155449390411377\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.820135\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.009178400039672852\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.458427429199219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.02329254150390625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.1300032138824463\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.820135\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 5, 9, 7, 4, 1, 8, 3, 6]), array([0.820135  , 0.433952  , 0.254663  , 0.226051  , 0.08983355,\n",
      "       0.0648245 , 0.0613911 , 0.06092235, 0.0605214 , 0.0547812 ]))\n",
      "Sizes = [4885, 372, 121, 91, 1546, 4463, 4244, 4682, 4707, 559]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6857 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603220.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603220_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_313220.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603220.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603220_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_313220.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.019449429979553\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(33765, 3), faces.shape=(67526, 3))>\n",
      "xvfb-run -n 6169 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(8442, 3), faces.shape=(16880, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000759124755859375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844701_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.4493517875671387\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.7244718074798584\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.8023405\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.005648374557495117\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.602836608886719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.014556169509887695\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.07752418518066406\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.8023405\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 0, 10,  9,  1,  2,  3,  8,  6,  4,  5,  7]), array([0.8023405, 0.163378 , 0.149441 , 0.0822792, 0.0820142, 0.0816153,\n",
      "       0.0776406, 0.0772089, 0.073556 , 0.0732601, 0.0350276]))\n",
      "Sizes = [4128, 175, 2432, 750, 2842, 4239, 580, 558, 535, 552, 89]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 648 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282178.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282178_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_267047.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282178.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282178_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_267047.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.812122414009875\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(8410, 3), faces.shape=(16816, 3))>\n",
      "xvfb-run -n 6513 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2103, 3), faces.shape=(4202, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003814697265625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844702_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.40262293815612793\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.4905984401702881\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0016887187957763672\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.364418029785156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004004001617431641\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02132415771484375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 3, 2]), array([0.842489  , 0.06029105, 0.0469546 , 0.0449292 ]))\n",
      "Sizes = [2327, 628, 1023, 224]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9943 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_175854.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_175854_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_361538.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_175854.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_175854_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_361538.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1.8413396070058836\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(3533, 3), faces.shape=(7062, 3))>\n",
      "xvfb-run -n 3366 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(884, 3), faces.shape=(1764, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006268024444580078\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844703_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.12027597427368164\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.15389800071716309\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007483959197998047\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016188621520996094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008758544921875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 3, 2, 0, 5, 7, 4, 6]), array([0.6916075, 0.6679655, 0.560453 , 0.54962  , 0.449362 , 0.167147 ,\n",
      "       0.153213 , 0.0624302]))\n",
      "Sizes = [318, 580, 189, 601, 31, 13, 21, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [3, 0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7869 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_558169.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_558169_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_586025.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_558169.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_558169_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_586025.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 22.1309599471319\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(295, 3), faces.shape=(580, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/395_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352f07cccda345cbba8792edd1466513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8555 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_458660.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_458660_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_283129.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_458660.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_458660_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_283129.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 22.1309599471319\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(295, 3), faces.shape=(580, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4936 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_205695.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_205695_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_341002.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_205695.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_205695_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_341002.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 169.9734706844722\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(307, 3), faces.shape=(601, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/213_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e3355d3fb04d5b81e24f750d382c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5347 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_659840.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_659840_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_278676.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_659840.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_659840_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_278676.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 169.9734706844722\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(307, 3), faces.shape=(601, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(3397, 3), faces.shape=(6790, 3))>\n",
      "xvfb-run -n 4887 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(850, 3), faces.shape=(1696, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024127960205078125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844704_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.12700557708740234\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.15671873092651367\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006783008575439453\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1975250244140625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016503334045410156\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008759260177612305\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.7031455, 0.6402205, 0.511901 ]))\n",
      "Sizes = [672, 900, 124]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_249114.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 89.45195510665131\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(340, 3), faces.shape=(672, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/549_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a662b96c2c9493d84f7049179b9a33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_766115.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 89.45195510665131\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(340, 3), faces.shape=(672, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_159443.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 169.14384024802362\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(453, 3), faces.shape=(900, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/160_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7c7f1e61544004ba5e46157310c51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_58217.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 169.14384024802362\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(453, 3), faces.shape=(900, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(3199, 3), faces.shape=(6394, 3))>\n",
      "xvfb-run -n 3290 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(801, 3), faces.shape=(1598, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023889541625976562\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844705_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1028599739074707\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13035321235656738\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006935596466064453\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.5299530029296875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016338825225830078\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.009028434753417969\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.7605665, 0.582313 , 0.567267 , 0.13107  ]))\n",
      "Sizes = [442, 797, 338, 21]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4214 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_144284.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_144284_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_705650.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_144284.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_144284_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_705650.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 75.91830704092608\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(403, 3), faces.shape=(797, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/586_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14be01ad604d4772a18d0cd430621b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(3002, 3), faces.shape=(6000, 3))>\n",
      "xvfb-run -n 528 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(751, 3), faces.shape=(1498, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022292137145996094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844706_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10043740272521973\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12689828872680664\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006427764892578125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.91278076171875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014917850494384766\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007597923278808594\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.599924 , 0.522224 , 0.3863035, 0.1625415]))\n",
      "Sizes = [839, 593, 32, 34]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "xz = 7.626764328227573 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_560465.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 41.435706655606474\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(423, 3), faces.shape=(839, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/295_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5f49914a954b1cb26e069dcbc394dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 7.626764328227573 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_151062.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 41.435706655606474\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(423, 3), faces.shape=(839, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_981489.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 103.90145018383676\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(593, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/370_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a137278eaf3b43ce944b648ea92f0091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(2748, 3), faces.shape=(5492, 3))>\n",
      "xvfb-run -n 915 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(688, 3), faces.shape=(1372, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002231597900390625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844707_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08609652519226074\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11163139343261719\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006308555603027344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.76837158203125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013527870178222656\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006987094879150391\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 4, 3, 2]), array([0.721087 , 0.6237415, 0.232255 , 0.152723 , 0.149686 ]))\n",
      "Sizes = [618, 706, 17, 11, 20]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "yz = 6.614666491336425 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_691625.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 86.99031713131082\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(312, 3), faces.shape=(618, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/723_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f825a4feeac74b1fb656d98541a3d48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_809076.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 183.99994666228082\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(356, 3), faces.shape=(706, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/79_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a967f9d9e6d409588c453ea766db6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_19541.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 184.57979252727685\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(352, 3), faces.shape=(696, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(2394, 3), faces.shape=(4784, 3))>\n",
      "xvfb-run -n 5509 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(600, 3), faces.shape=(1196, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00035500526428222656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844708_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08298206329345703\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10860395431518555\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005910396575927734\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00014829635620117188\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011925697326660156\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005976200103759766\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1]), array([0.561779, 0.54601 , 0.301048]))\n",
      "Sizes = [891, 203, 102]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_548533.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 260.6889065734272\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(449, 3), faces.shape=(891, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/383_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f1847d0df9450ead3e395891ac6540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_91088.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 260.6889065734272\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(449, 3), faces.shape=(891, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(2266, 3), faces.shape=(4528, 3))>\n",
      "xvfb-run -n 5983 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(568, 3), faces.shape=(1132, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021910667419433594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113572564844709_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06892991065979004\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09087324142456055\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005853176116943359\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.0067901611328125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011105537414550781\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005771636962890625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 5, 1, 3, 2, 4, 6]), array([0.699075 , 0.679679 , 0.498768 , 0.351833 , 0.262172 , 0.19804  ,\n",
      "       0.1862295]))\n",
      "Sizes = [647, 73, 205, 121, 57, 13, 16]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8061 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_882480.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_882480_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_834841.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_882480.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_882480_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_834841.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 230.7894435854952\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(328, 3), faces.shape=(647, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/164_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4e5efcfb684d71872a1ca78473ce5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(2191, 3), faces.shape=(4378, 3))>\n",
      "xvfb-run -n 6917 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(549, 3), faces.shape=(1094, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021886825561523438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07785558700561523\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1068120002746582\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006432533264160156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.553794860839844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012288093566894531\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005914926528930664\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 0, 3, 5, 1, 4]), array([0.6643795, 0.642525 , 0.503784 , 0.472833 , 0.3560585, 0.22969  ]))\n",
      "Sizes = [302, 551, 133, 39, 50, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(280, 3), faces.shape=(551, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002052783966064453\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0363917350769043\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04772758483886719\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002892017364501953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002071857452392578\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005581378936767578\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002694368362426758\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.613278, 0.480205]))\n",
      "Sizes = [282, 269]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(147, 3), faces.shape=(282, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002033710479736328\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.01956772804260254\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.026780366897583008\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00017595291137695312\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.601478576660156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0002918243408203125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0014979839324951172\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.6081905]))\n",
      "Sizes = [282]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #11: <trimesh.Trimesh(vertices.shape=(2160, 3), faces.shape=(4316, 3))>\n",
      "xvfb-run -n 1956 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(541, 3), faces.shape=(1078, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004603862762451172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06574654579162598\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08687424659729004\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004985332489013672\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1021575927734375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010478496551513672\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0055544376373291016\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 3, 0]), array([0.769151 , 0.632809 , 0.575446 , 0.5213315]))\n",
      "Sizes = [220, 467, 87, 304]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(236, 3), faces.shape=(467, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00019216537475585938\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.027529478073120117\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03773164749145508\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00028443336486816406\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.458427429199219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004642009735107422\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0023276805877685547\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1, 3]), array([0.817086, 0.769138, 0.602804, 0.600518]))\n",
      "Sizes = [65, 189, 92, 121]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(98, 3), faces.shape=(189, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002009868621826172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.011688709259033203\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.016492605209350586\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00015401840209960938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0002002716064453125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0009338855743408203\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.747078]))\n",
      "Sizes = [189]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #12: <trimesh.Trimesh(vertices.shape=(1905, 3), faces.shape=(3806, 3))>\n",
      "xvfb-run -n 9930 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(477, 3), faces.shape=(950, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003173351287841797\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447012_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06399393081665039\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08338022232055664\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005655288696289062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00016832351684570312\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009508132934570312\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0047566890716552734\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2, 3]), array([0.698551, 0.477507, 0.30008 , 0.275088]))\n",
      "Sizes = [469, 367, 93, 21]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(237, 3), faces.shape=(469, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020813941955566406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447012_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.03311276435852051\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.042295217514038086\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002396106719970703\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.8160552978515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004811286926269531\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0023870468139648438\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.698455]))\n",
      "Sizes = [469]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(237, 3), faces.shape=(469, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001971721649169922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447012_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.03213691711425781\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04118227958679199\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00024056434631347656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 3.886222839355469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00046896934509277344\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002480030059814453\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.698455]))\n",
      "Sizes = [469]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #13: <trimesh.Trimesh(vertices.shape=(1896, 3), faces.shape=(3792, 3))>\n",
      "xvfb-run -n 5015 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(474, 3), faces.shape=(948, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023055076599121094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447013_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0634007453918457\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08117175102233887\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004630088806152344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.57763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009551048278808594\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0047991275787353516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 3, 2]), array([0.58256 , 0.457399, 0.334042, 0.24471 ]))\n",
      "Sizes = [769, 126, 19, 34]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_664421.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 249.42776361739826\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(769, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/445_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90292cce7314591a6d3635c786f6930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_917922.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 249.42776361739826\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(769, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #14: <trimesh.Trimesh(vertices.shape=(1784, 3), faces.shape=(3564, 3))>\n",
      "xvfb-run -n 641 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(447, 3), faces.shape=(890, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023865699768066406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447014_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.057591915130615234\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07455921173095703\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004215240478515625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.3882598876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000982522964477539\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004448890686035156\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0]), array([0.6865335, 0.524411 , 0.471434 ]))\n",
      "Sizes = [140, 577, 173]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_963495.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 223.4832742635067\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(291, 3), faces.shape=(577, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/702_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740381789d5a4f509d07e6fc01b614b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_929553.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 223.4832742635067\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(291, 3), faces.shape=(577, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #15: <trimesh.Trimesh(vertices.shape=(1709, 3), faces.shape=(3414, 3))>\n",
      "xvfb-run -n 874 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(428, 3), faces.shape=(852, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023818016052246094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447015_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05915570259094238\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07509613037109375\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004019737243652344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008451938629150391\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004233598709106445\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.675999, 0.637264]))\n",
      "Sizes = [539, 313]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(272, 3), faces.shape=(539, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020885467529296875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447015_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04499483108520508\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.056565284729003906\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003132820129394531\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.9114227294921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007505416870117188\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003039836883544922\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.675999]))\n",
      "Sizes = [539]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(272, 3), faces.shape=(539, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021147727966308594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447015_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.03567218780517578\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.046376705169677734\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00029087066650390625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.744529724121094e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007252693176269531\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0026793479919433594\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.675999]))\n",
      "Sizes = [539]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #16: <trimesh.Trimesh(vertices.shape=(1693, 3), faces.shape=(3382, 3))>\n",
      "xvfb-run -n 7664 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447/decimation_meshlab_25623981.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135725648447_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(424, 3), faces.shape=(844, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022363662719726562\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135725648447016_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0684499740600586\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09481120109558105\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.001050710678100586\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00011897087097167969\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008742809295654297\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004312992095947266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.582791, 0.45264 , 0.443196, 0.1836  ]))\n",
      "Sizes = [637, 105, 81, 21]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_541401.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 144.08066817897353\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(322, 3), faces.shape=(637, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/37_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845067f07bca458994a84b3ca7b128df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_611982.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 144.08066817897353\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(322, 3), faces.shape=(637, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 234.4358265399933\n",
      "Before Filtering the number of somas found = 3\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 0\n",
      "xvfb-run -n 9803 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20620.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20620_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_34659.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20620.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20620_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_34659.mls is being deleted....\n",
      "xvfb-run -n 4918 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59421.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59421_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_599066.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59421.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59421_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_599066.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(770, 3), faces.shape=(1558, 3))>, <trimesh.Trimesh(vertices.shape=(761, 3), faces.shape=(1428, 3))>, <trimesh.Trimesh(vertices.shape=(640, 3), faces.shape=(1189, 3))>, <trimesh.Trimesh(vertices.shape=(615, 3), faces.shape=(1460, 3))>, <trimesh.Trimesh(vertices.shape=(497, 3), faces.shape=(945, 3))>, <trimesh.Trimesh(vertices.shape=(344, 3), faces.shape=(648, 3))>, <trimesh.Trimesh(vertices.shape=(252, 3), faces.shape=(467, 3))>]\n",
      "After backtrack the found 1 possible somas: [<trimesh.Trimesh(vertices.shape=(15326, 3), faces.shape=(30039, 3))>] \n",
      "\n",
      "--- workin on backtrack soma 0: <trimesh.Trimesh(vertices.shape=(15326, 3), faces.shape=(30039, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6187 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_391740.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_391740_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_667567.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_391740.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_391740_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_667567.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.02270335672332\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(3791, 3), faces.shape=(8750, 3))>, <trimesh.Trimesh(vertices.shape=(3325, 3), faces.shape=(8110, 3))>, <trimesh.Trimesh(vertices.shape=(3337, 3), faces.shape=(5747, 3))>, <trimesh.Trimesh(vertices.shape=(1652, 3), faces.shape=(3781, 3))>, <trimesh.Trimesh(vertices.shape=(1360, 3), faces.shape=(3161, 3))>, <trimesh.Trimesh(vertices.shape=(1256, 3), faces.shape=(2879, 3))>, <trimesh.Trimesh(vertices.shape=(1090, 3), faces.shape=(2450, 3))>, <trimesh.Trimesh(vertices.shape=(1059, 3), faces.shape=(2420, 3))>, <trimesh.Trimesh(vertices.shape=(987, 3), faces.shape=(2238, 3))>, <trimesh.Trimesh(vertices.shape=(973, 3), faces.shape=(2199, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1802, 3))>, <trimesh.Trimesh(vertices.shape=(760, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(745, 3), faces.shape=(1675, 3))>, <trimesh.Trimesh(vertices.shape=(738, 3), faces.shape=(1621, 3))>]\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 1\n",
      "Mesh was manifold\n",
      "xvfb-run -n 1756 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18623.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18623_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_321433.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18623.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_18623_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_321433.mls is being deleted....\n",
      "xvfb-run -n 6868 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_61740.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_61740_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_475812.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_61740.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_61740_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_475812.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 72\n",
      "After backtrack the found 1 possible somas: [<trimesh.Trimesh(vertices.shape=(14123, 3), faces.shape=(27997, 3))>] \n",
      "\n",
      "--- workin on backtrack soma 0: <trimesh.Trimesh(vertices.shape=(14123, 3), faces.shape=(27997, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8863 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_91809.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_91809_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_638520.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_91809.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_91809_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_638520.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.840337802205738\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 2\n",
      "xvfb-run -n 6437 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4566.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4566_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_931938.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4566.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_4566_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_931938.mls is being deleted....\n",
      "xvfb-run -n 2858 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48235.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48235_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_928633.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48235.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48235_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_928633.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(4274, 3), faces.shape=(8672, 3))>]\n",
      "After backtrack the found 0 possible somas: [] \n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 5001 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74963.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74963_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_238751.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74963.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74963_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_238751.mls is being deleted....\n",
      "xvfb-run -n 9273 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_17895.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_17895_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_224039.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_17895.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_17895_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_224039.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 226\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37cb0d8b16a4caab3c66db4a18341d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 110213.17482747804, after = 160478.91875939324,\n",
      "ratio = 1.4560774518164328, difference = 50265.7439319152\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "Mesh was manifold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 7242 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71586.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71586_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_829001.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71586.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_71586_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_829001.mls is being deleted....\n",
      "xvfb-run -n 5120 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14000.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14000_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_403855.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14000.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14000_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_403855.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 49\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1454c1cea89244f58ff87673e333f384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 39330.82127492283, after = 78453.93861551462,\n",
      "ratio = 1.9947190542277469, difference = 39123.11734059179\n"
     ]
    }
   ],
   "source": [
    "from soma_extraction_utils import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "segment_id = segment_id\n",
    "current_mesh_verts = current_neuron.vertices\n",
    "current_mesh_faces = current_neuron.faces\n",
    "current_mesh = None\n",
    "\n",
    "\n",
    "outer_decimation_ratio= 0.25\n",
    "large_mesh_threshold = 20000#60000,\n",
    "large_mesh_threshold_inner = 13000 #was changed so dont filter away som somas\n",
    "soma_width_threshold = 0.32\n",
    "soma_size_threshold = 9000 #changed this to smaller so didn't filter some somas away\n",
    "inner_decimation_ratio = 0.25\n",
    "volume_mulitplier=8\n",
    "#side_length_ratio_threshold=3\n",
    "side_length_ratio_threshold=6\n",
    "soma_size_threshold_max=240000#192000 #this puts at 12000 once decimated, another possible is 256000\n",
    "delete_files=True\n",
    "backtrack_soma_mesh_to_original=True #should either be None or \n",
    "boundary_vertices_threshold=None#700 the previous threshold used\n",
    "poisson_backtrack_distance_threshold=None#1500 the previous threshold used\n",
    "close_holes=False\n",
    "\n",
    "#------- 11/12 Additions --------------- #\n",
    "\n",
    "#these arguments are for removing inside pieces\n",
    "remove_inside_pieces = True\n",
    "size_threshold_to_remove=1000 #size accounting for the decimation\n",
    "\n",
    "\n",
    "pymeshfix_clean=False\n",
    "check_holes_before_pymeshfix=False\n",
    "second_poisson=False\n",
    "segmentation_at_end=True\n",
    "last_size_threshold = 2000#1300,\n",
    "\n",
    "largest_hole_threshold = 17000\n",
    "max_fail_loops = 10\n",
    "perform_pairing = False\n",
    "verbose = True\n",
    "return_glia_nuclei_pieces = True\n",
    "\n",
    "backtrack_soma_size_threshold = 13000\n",
    "\n",
    "filter_inside_meshes_after_glia_removal = False\n",
    "max_mesh_sized_filtered_away = 90000\n",
    "\n",
    "filter_inside_somas=True\n",
    "\n",
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "#Adjusting the thresholds based on the decimations\n",
    "large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "max_mesh_sized_filtered_away = max_mesh_sized_filtered_away*outer_decimation_ratio\n",
    "\n",
    "#adjusting for inner decimation\n",
    "soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "\n",
    "print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "             f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "              f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "             f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "             f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "             f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\"\n",
    "     f\"\\nmax_mesh_sized_filtered_away = {max_mesh_sized_filtered_away}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "temp_folder = f\"./{segment_id}\"\n",
    "temp_object = Path(temp_folder)\n",
    "#make the temp folder if it doesn't exist\n",
    "temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#making the decimation and poisson objections\n",
    "Dec_outer = meshlab.Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "Dec_inner = meshlab.Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "Poisson_obj = meshlab.Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "\n",
    "recov_orig_mesh = trimesh.Trimesh(vertices=current_mesh_verts,faces=current_mesh_faces)\n",
    "\n",
    "try:\n",
    "    recov_orig_mesh_no_interior, glia_pieces, nuclei_pieces  = tu.remove_nuclei_and_glia_meshes(recov_orig_mesh,verbose=True)\n",
    "except:\n",
    "    print(\"**Unable to remove_nuclei_and_glia_meshes: so just continuing without doing so **\")\n",
    "    recov_orig_mesh_no_interior = recov_orig_mesh\n",
    "    glia_pieces = []\n",
    "    nuclei_pieces = []\n",
    "#recov_orig_mesh_no_interior = tu.remove_mesh_interior(recov_orig_mesh)\n",
    "\n",
    "\n",
    "#Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "new_mesh,output_obj = Dec_outer(vertices=recov_orig_mesh_no_interior.vertices,\n",
    "         faces=recov_orig_mesh_no_interior.faces,\n",
    "         segment_id=segment_id,\n",
    "         return_mesh=True,\n",
    "         delete_temp_files=False)\n",
    "\n",
    "# if remove_inside_pieces:\n",
    "#     print(\"removing mesh interior after decimation\")\n",
    "#     new_mesh = tu.remove_mesh_interior(new_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "#preforming the splits of the decimated mesh\n",
    "\n",
    "mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "# --------- 1/11 Addition: Filtering away large meshes that are inside another --------- #\n",
    "if filter_inside_meshes_after_glia_removal:\n",
    "    print(f\"Filtering away larger meshes that are inside others, before # of meshes = {len(list_of_largest_mesh)}\")\n",
    "    list_of_largest_mesh = tu.filter_away_inside_meshes(list_of_largest_mesh,verbose=True,return_meshes=True,\n",
    "                                                       max_mesh_sized_filtered_away=max_mesh_sized_filtered_away)\n",
    "    print(f\"After # of meshes = {len(list_of_largest_mesh)}\")\n",
    "\n",
    "\n",
    "#if no significant pieces were found then will use smaller threshold\n",
    "if len(list_of_largest_mesh)<=0:\n",
    "    print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "    list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "total_soma_list = []\n",
    "total_classifier_list = []\n",
    "total_poisson_list = []\n",
    "total_soma_list_sdf = []\n",
    "\n",
    "\n",
    "\n",
    "#start iterating through where go through all pieces before the poisson reconstruction\n",
    "no_somas_found_in_big_loop = 0\n",
    "for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "    print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "    if remove_inside_pieces:\n",
    "        print(\"remove_inside_pieces requested \")\n",
    "        try:\n",
    "            largest_mesh = tu.remove_mesh_interior(largest_mesh,\n",
    "                                                   size_threshold_to_remove=size_threshold_to_remove,\n",
    "                                                  try_hole_close=False)\n",
    "        except:\n",
    "            print(\"Unable to remove inside pieces in list_of_largest_mesh\")\n",
    "            largest_mesh = largest_mesh\n",
    "\n",
    "\n",
    "    if pymeshfix_clean:\n",
    "        print(\"Requested pymeshfix_clean\")\n",
    "        \"\"\"\n",
    "        Don't have to check if manifold anymore actually just have to plug the holes\n",
    "        \"\"\"\n",
    "        hole_groups = tu.find_border_face_groups(largest_mesh)\n",
    "        if len(hole_groups) > 0:\n",
    "            largest_mesh_filled_holes = tu.fill_holes(largest_mesh,max_hole_size = 10000)\n",
    "        else:\n",
    "            largest_mesh_filled_holes = largest_mesh\n",
    "\n",
    "        if check_holes_before_pymeshfix:\n",
    "            hole_groups = tu.find_border_face_groups(largest_mesh_filled_holes)\n",
    "        else:\n",
    "            print(\"Not checking if there are still existing holes before pymeshfix\")\n",
    "            hole_groups = []\n",
    "\n",
    "        if len(hole_groups) > 0:\n",
    "            #segmentation_at_end = False\n",
    "            print(f\"*** COULD NOT FILL HOLES WITH MAX SIZE OF {np.max([len(k) for k in hole_groups])} so not applying pymeshfix and segmentation_at_end = {segmentation_at_end}\")\n",
    "\n",
    "#                 tu.write_neuron_off(largest_mesh_filled_holes,\"largest_mesh_filled_holes\")\n",
    "#                 raise Exception()\n",
    "        else:\n",
    "            print(\"Applying pymeshfix_clean because no more holes\")\n",
    "            largest_mesh = tu.pymeshfix_clean(largest_mesh_filled_holes,verbose=True)\n",
    "\n",
    "    if second_poisson:\n",
    "        print(\"Applying second poisson run\")\n",
    "        current_neuron_poisson = tu.poisson_surface_reconstruction(largest_mesh)\n",
    "        largest_mesh = tu.split_significant_pieces(current_neuron_poisson,connectivity=soma_connectivity)[0]\n",
    "\n",
    "    somas_found_in_big_loop = False\n",
    "\n",
    "    largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "    pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "    pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "    print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "    # ******* This ERRORED AND CALLED OUR NERUON NONE: 77697401493989254 *********\n",
    "    new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "               faces=largest_mesh.faces,\n",
    "               return_mesh=True,\n",
    "               mesh_filename=largest_file_name,\n",
    "               delete_temp_files=False)\n",
    "\n",
    "\n",
    "    #splitting the Poisson into the largest pieces and ordering them\n",
    "    mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "    list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "    print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "    n_failed_inner_soma_loops = 0\n",
    "    for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "        to_add_list = []\n",
    "        to_add_list_sdf = []\n",
    "\n",
    "        print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "        largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "        #Decimate the inner poisson piece\n",
    "        largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                            vertices=largest_mesh_inner.vertices,\n",
    "                             faces=largest_mesh_inner.faces,\n",
    "                            mesh_filename=largest_mesh_path_inner,\n",
    "                             return_mesh=True,\n",
    "                             delete_temp_files=False)\n",
    "\n",
    "        dec_splits = tu.split_significant_pieces(largest_mesh_path_inner_decimated,significance_threshold=15,\n",
    "                                                connectivity=soma_connectivity,)\n",
    "        print(f\"\\n-------Splits after inner decimation len = {len(dec_splits)}--------\\n\")\n",
    "\n",
    "        if len(dec_splits) == 0:\n",
    "            print(\"There were no signifcant splits after inner decimation\")\n",
    "            n_failed_inner_soma_loops += 1\n",
    "        else:\n",
    "            print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "            largest_mesh_path_inner_decimated_clean = dec_splits[0]\n",
    "            \"\"\" # ----------- 1/12: Addition that does the segmentation again -------------------- #\"\"\"\n",
    "\n",
    "            for ii in range(3):\n",
    "                print(f\"\\n    --- On segmentation loop {ii} --\")\n",
    "                print(f\"largest_mesh_path_inner_decimated_clean = {largest_mesh_path_inner_decimated_clean}\\n\")\n",
    "\n",
    "                faces = np.array(largest_mesh_path_inner_decimated_clean.faces)\n",
    "                verts = np.array(largest_mesh_path_inner_decimated_clean.vertices)\n",
    "\n",
    "                # may need to do some processing\n",
    "\n",
    "\n",
    "                segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "                #print(f\"Before the classifier the pymeshfix_clean = {pymeshfix_clean}\")\n",
    "                verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                        import_Off_Flag=False,\n",
    "                                        segment_id=segment_id_new,\n",
    "                                        vertices=verts,\n",
    "                                         triangles=faces,\n",
    "                                        pymeshfix_Flag=False,\n",
    "                                         import_CGAL_Flag=False,\n",
    "                                         return_Only_Labels=True,\n",
    "                                         clusters=3,\n",
    "                                         smoothness=0.2,\n",
    "                                        soma_only=True,\n",
    "                                        return_classifier = True\n",
    "                                        )\n",
    "                print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "                total_classifier_list.append(classifier)\n",
    "                #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "                # Save all of the portions that resemble a soma\n",
    "                median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "                segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "                #order the compartments by greatest to smallest\n",
    "                sorted_medians = np.flip(np.argsort(median_values))\n",
    "                print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "                print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "                print(f\"soma_size_threshold = {soma_size_threshold}\")\n",
    "                print(f\"soma_size_threshold_max={soma_size_threshold_max}\")\n",
    "\n",
    "                valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "                valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "                print(\"valid_soma_segments_width\")\n",
    "\n",
    "\n",
    "                \"\"\"# =------------- 1/12: Addition that will repeat this loop --------------\"\"\"\n",
    "                if len(valid_soma_segments_width) > 0:\n",
    "                    break\n",
    "                else:\n",
    "                    \"\"\"\n",
    "                    Pseudocode: \n",
    "                    Get the largest mesh segment\n",
    "                    \"\"\"\n",
    "                    new_mesh_try_faces = np.where(classifier.labels_list == nu.mode_1d(classifier.labels_list))[0]\n",
    "                    largest_mesh_path_inner_decimated_clean = largest_mesh_path_inner_decimated_clean.submesh([new_mesh_try_faces],append=True)\n",
    "\n",
    "            if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "\n",
    "\n",
    "                    if curr_side_len_check and curr_volume_check:\n",
    "                        #check if we can split this into two\n",
    "                        to_add_list.append(soma_mesh)\n",
    "                        to_add_list_sdf.append(sdf)\n",
    "\n",
    "                        \"\"\"  -----------Removed 1/12: When trying to force a split between them \n",
    "                        possible_smoothness = [0.2,0.05,0.01]\n",
    "                        for smooth_value in possible_smoothness:\n",
    "                            #1) Run th esegmentation algorithm again to segment the mesh (had to run the higher smoothing to seperate some)\n",
    "                            mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=smooth_value,verbose=True)\n",
    "                            mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                            #2) Filter out meshes by sizs and sdf threshold\n",
    "                            mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                            filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "                            if len(filtered_meshes_idx) >= 2:\n",
    "                                if verbose:\n",
    "                                    print(f\"Breakin on smoothness: {smooth_value}\")\n",
    "                                break\n",
    "\n",
    "                        if len(filtered_meshes_idx) >= 2:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            to_add_list_retry = []\n",
    "                            to_add_list_sdf_retry = []\n",
    "\n",
    "                            for f_m,f_m_sdf in zip(filtered_meshes,filtered_meshes_sdf):\n",
    "                                curr_side_len_check_retry = side_length_check(f_m,side_length_ratio_threshold)\n",
    "                                curr_volume_check_retry = soma_volume_check(f_m,volume_mulitplier)\n",
    "\n",
    "                                if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                    to_add_list_retry.append(f_m)\n",
    "                                    to_add_list_sdf_retry.append(f_m_sdf)\n",
    "\n",
    "                            if len(to_add_list_retry)>1:\n",
    "                                if verbose:\n",
    "                                    print(\"Using the new feature that split the soma further into more groups\")\n",
    "                                to_add_list += to_add_list_retry\n",
    "                                to_add_list_sdf += to_add_list_sdf_retry\n",
    "\n",
    "                            else:\n",
    "                                to_add_list.append(soma_mesh)\n",
    "                                to_add_list_sdf.append(sdf)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            to_add_list.append(soma_mesh)\n",
    "                            to_add_list_sdf.append(sdf)\n",
    "                        \"\"\"\n",
    "\n",
    "                    else:\n",
    "                        # ---------- 1/7 Addition: Trying one more additional cgal segmentation to see if there is actually a soma ---\n",
    "                        \"\"\"\n",
    "                        Pseudocode: \n",
    "                        1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        2) Filter out meshes by sizs and sdf threshold\n",
    "                        3) If there are any remaining meshes, pick the largest sdf mesh and test for volume and side length check\n",
    "                        --> if matches then adds\n",
    "                        \"\"\"\n",
    "\n",
    "                        print(f\"->Attempting retry of soma because failed first checks: \"\n",
    "                                 f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                        #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                        mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                        #2) Filter out meshes by sizs and sdf threshold\n",
    "                        mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                        filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "\n",
    "                        if len(filtered_meshes_idx) > 0:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            sdf_winning_index = np.argmax(filtered_meshes_sdf)\n",
    "                            soma_mesh_retry = filtered_meshes[sdf_winning_index]\n",
    "                            sdf_retry = filtered_meshes_sdf[sdf_winning_index]\n",
    "\n",
    "                            curr_side_len_check_retry = side_length_check(soma_mesh_retry,side_length_ratio_threshold)\n",
    "                            curr_volume_check_retry = soma_volume_check(soma_mesh_retry,volume_mulitplier)\n",
    "\n",
    "                            if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                to_add_list.append(soma_mesh_retry)\n",
    "                                to_add_list_sdf.append(sdf_retry)\n",
    "                            else:\n",
    "                                print(f\"--->This soma mesh was not added because failed retry of sphere validation:\\n \"\n",
    "                                     f\"soma_mesh = {soma_mesh_retry}, curr_side_len_check = {curr_side_len_check_retry}, curr_volume_check = {curr_volume_check_retry}\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(f\"Could not find valid soma mesh in retry\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "                n_failed_inner_soma_loops = 0\n",
    "\n",
    "            else:\n",
    "                n_failed_inner_soma_loops += 1\n",
    "\n",
    "        total_soma_list_sdf += to_add_list_sdf\n",
    "        total_soma_list += to_add_list\n",
    "\n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if n_failed_inner_soma_loops >= max_fail_loops:\n",
    "            print(f\"breaking inner loop because {max_fail_loops} soma fails in a row\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "    if somas_found_in_big_loop == False:\n",
    "        no_somas_found_in_big_loop += 1\n",
    "        if no_somas_found_in_big_loop >= max_fail_loops:\n",
    "            print(f\"breaking because {max_fail_loops} fails in a row in big loop\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        no_somas_found_in_big_loop = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "pairings = []\n",
    "\n",
    "if perform_pairing:\n",
    "    for y,soma_1 in enumerate(total_soma_list):\n",
    "        for z,soma_2 in enumerate(total_soma_list):\n",
    "            if y<z:\n",
    "                mesh_tree = KDTree(soma_1.vertices)\n",
    "                distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "                if np.min(distances) < 4000:\n",
    "                    pairings.append([y,z])\n",
    "\n",
    "\n",
    "#creating the combined meshes from the list\n",
    "total_soma_list_revised = []\n",
    "total_soma_list_revised_sdf = []\n",
    "if len(pairings) > 0:\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    Use a network function to find components\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    new_graph = nx.Graph()\n",
    "    new_graph.add_edges_from(pairings)\n",
    "    grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "    somas_being_combined = []\n",
    "    print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "    for comp in grouped_somas:\n",
    "        comp = list(comp)\n",
    "        somas_being_combined += list(comp)\n",
    "        current_mesh = total_soma_list[comp[0]]\n",
    "        for i in range(1,len(comp)):\n",
    "            current_mesh += total_soma_list[comp[i]] #just combining the actual meshes\n",
    "\n",
    "        total_soma_list_revised.append(current_mesh)\n",
    "        #where can average all of the sdf values\n",
    "        total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "    #add those that weren't combined to total_soma_list_revised\n",
    "    leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    if len(leftover_somas) > 0:\n",
    "        total_soma_list_revised += leftover_somas\n",
    "        total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "    print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "    print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "if len(total_soma_list_revised) == 0:\n",
    "    total_soma_list_revised = total_soma_list\n",
    "    total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "run_time = time.time() - global_start_time\n",
    "\n",
    "print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "#     import system_utils as su\n",
    "#     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "#     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "#need to erase all of the temporary files ******\n",
    "#import shutil\n",
    "#shutil.rmtree(directory)\n",
    "\n",
    "\"\"\"\n",
    "Running the extra tests that depend on\n",
    "- border vertices\n",
    "- how well the poisson matches the backtracked soma to the real mesh\n",
    "- other size checks\n",
    "\n",
    "\"\"\"\n",
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "\n",
    "for yy,(soma_mesh,curr_soma_sdf) in enumerate(zip(total_soma_list_revised,total_soma_list_revised_sdf)):\n",
    "    add_inside_pieces_flag = False\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        if verbose:\n",
    "            print(f\"\\n---Performing Soma Mesh Backtracking to original mesh for poisson soma {yy}\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "        try:\n",
    "            soma_mesh_list,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                            original_mesh = recov_orig_mesh_no_interior,\n",
    "                                            mesh=soma_mesh_poisson,\n",
    "                                            soma_size_threshold=backtrack_soma_size_threshold)\n",
    "\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "\n",
    "        if soma_mesh_list is None:\n",
    "                print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        if verbose: \n",
    "            print(f\"After backtrack the found {len(soma_mesh_list)} possible somas: {soma_mesh_list} \")\n",
    "\n",
    "        for rr,soma_mesh in enumerate(soma_mesh_list):\n",
    "            if verbose:\n",
    "                print(f\"\\n--- workin on backtrack soma {rr}: {soma_mesh}\")\n",
    "\n",
    "            print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "            #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "            if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "                #soma_mesh.export(\"soma_mesh.off\")\n",
    "                if close_holes: \n",
    "                    print(\"Using the close holes feature\")\n",
    "                    fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                     self_itersect_faces=False)\n",
    "\n",
    "                    soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                        vertices=soma_mesh.vertices,\n",
    "                                                         faces=soma_mesh.faces,\n",
    "                                                         return_mesh=True,\n",
    "                                                         delete_temp_files=True,\n",
    "                                                        )\n",
    "                else:\n",
    "                    soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "                #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "                print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "                mesh_1 = soma_mesh_filled_holes\n",
    "                mesh_2 = soma_mesh_poisson\n",
    "\n",
    "                poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                                  verbose=True)\n",
    "                print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "                if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                      f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #do the boundary check:\n",
    "            if not boundary_vertices_threshold is None:\n",
    "                print(\"USING boundary_vertices_threshold CHECK\")\n",
    "                soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "                print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "                large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "                print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "                if len(large_boundary_groups)>0:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                          f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "                    continue\n",
    "\n",
    "            curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "            curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "            if (not curr_side_len_check) or (not curr_volume_check):\n",
    "                print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "                     f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                continue\n",
    "\n",
    "            #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "            #If made it through all the checks then add to final list\n",
    "            filtered_soma_list.append(soma_mesh)\n",
    "            filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "            add_inside_pieces_flag = True #setting flag so will add inside pieces\n",
    "\n",
    "\n",
    "    if len(soma_mesh_inside_pieces) > 0 and add_inside_pieces_flag:\n",
    "        print(f\"About to add the following inside nuclei pieces after soma backtrack: {nuclei_pieces}\")\n",
    "        nuclei_pieces +=soma_mesh_inside_pieces\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Need to delete all files in the temp folder *****\n",
    "\"\"\"\n",
    "\n",
    "if delete_files:\n",
    "    #now erase all of the files used\n",
    "    from shutil import rmtree\n",
    "\n",
    "    #remove the directory with the meshes\n",
    "    rmtree(str(temp_object.absolute()))\n",
    "\n",
    "    #removing the temporary files\n",
    "    temp_folder = Path(\"./temp\")\n",
    "    temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "    seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "    for f in seg_temp_files:\n",
    "        f.unlink()\n",
    "\n",
    "# ----------- 11 /11 Addition that does a last step segmentation of the soma --------- #\n",
    "#return total_soma_list, run_time\n",
    "#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n",
    "\"\"\"\n",
    "Things we should ask about the segmentation:\n",
    "\n",
    "Advantages: \n",
    "1) could help filter away negatives\n",
    "\n",
    "Disadvantages:\n",
    "1) Can actually cut up the soma and then filter away the soma (not what we want)\n",
    "2) Could introduce a big hole (don't think can guard against this)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#filtered_soma_list_saved = copy.deepcopy(filtered_soma_list)\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "\n",
    "        print(\"Skipping the segmentatio filter at end\")\n",
    "        if not (len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold):\n",
    "            print(f\"Soma (size = {len(f_soma.faces)}, width={soma_width_threshold}) did not pass thresholds (size threshold={last_size_threshold}, width threshold = {soma_width_threshold}) \")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if segmentation_at_end:\n",
    "\n",
    "\n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "#                 print(f\"meshes_split = {meshes_split}\")\n",
    "#                 print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                print(f\"So just going with old somas\")\n",
    "\n",
    "                f_soma_final = f_soma\n",
    "                f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "            else:\n",
    "                meshes_split = np.array(meshes_split)\n",
    "                meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "                meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "                meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "                soma_width_threshold\n",
    "                #way to choose the index of the top candidate\n",
    "                top_candidate = 0\n",
    "\n",
    "\n",
    "                largest_hole_before_seg = tu.largest_hole_length(f_soma)\n",
    "                largest_hole_after_seg = tu.largest_hole_length(meshes_split_filtered[top_candidate])\n",
    "\n",
    "                print(f\"Largest hole before segmentation = {largest_hole_before_seg}, after = {largest_hole_after_seg},\"\n",
    "                      f\"\\nratio = {largest_hole_after_seg/largest_hole_before_seg}, difference = {largest_hole_after_seg - largest_hole_before_seg}\")\n",
    "\n",
    "                if largest_hole_after_seg < largest_hole_threshold:\n",
    "                    f_soma_final = meshes_split_filtered[top_candidate]\n",
    "                    f_soma_sdf_final = meshes_split_sdf_filtered[top_candidate]\n",
    "                else:\n",
    "                    f_soma_final = f_soma\n",
    "                    f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "        else:\n",
    "            f_soma_final = f_soma\n",
    "            f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "        filtered_soma_list_revised.append(f_soma_final)\n",
    "        filtered_soma_list_sdf_revised.append(f_soma_sdf_final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n",
    "\n",
    "    \"\"\"\n",
    "    # ----------- 1/7/21 ---------------#\n",
    "    Now was to stitch the somas together if they are touching\n",
    "\n",
    "    \"\"\"\n",
    "    if len(filtered_soma_list)>1:\n",
    "        connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                                 main_mesh=recov_orig_mesh_no_interior,\n",
    "                                                    return_connected_components=True)\n",
    "\n",
    "        filtered_soma_list_components = np.array([tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components])\n",
    "        filtered_soma_list_sdf_components = np.array([np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components])\n",
    "    elif len(filtered_soma_list)==1:\n",
    "        filtered_soma_list_components = filtered_soma_list\n",
    "        filtered_soma_list_sdf_components = filtered_soma_list_sdf\n",
    "    else:\n",
    "        filtered_soma_list_components = []\n",
    "        filtered_soma_list_sdf_components = np.array([])\n",
    "else:\n",
    "    filtered_soma_list_components = []\n",
    "    filtered_soma_list_sdf_components = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "#----------- 1/9 Addition: Final Size Threshold ------------- #\n",
    "if backtrack_soma_mesh_to_original:\n",
    "\n",
    "    filtered_soma_list_components_new = []\n",
    "    filtered_soma_list_sdf_components_new = []\n",
    "\n",
    "    for soma_mesh, soma_mesh_sdf in zip(filtered_soma_list_components,filtered_soma_list_sdf_components):\n",
    "        # --------- 1/9: Extra Size Threshold For Somas ------------- #\n",
    "        if len(soma_mesh.faces) < backtrack_soma_size_threshold:\n",
    "            print(f\"--->This soma mesh with size {len(soma_mesh.faces)} was not bigger than the threshold {backtrack_soma_size_threshold}\")\n",
    "            continue\n",
    "        else:\n",
    "            filtered_soma_list_components_new.append(soma_mesh)\n",
    "            filtered_soma_list_sdf_components_new.append(soma_mesh_sdf)\n",
    "\n",
    "    filtered_soma_list_components = filtered_soma_list_components_new\n",
    "    filtered_soma_list_sdf_components = np.array(filtered_soma_list_sdf_components_new)\n",
    "\n",
    "if filter_inside_somas:\n",
    "    if len(filtered_soma_list_components)>1:\n",
    "        keep_indices = tu.filter_away_inside_meshes(mesh_list = filtered_soma_list_components,\n",
    "                                    distance_type=\"shortest_vertex_distance\",\n",
    "                                    distance_threshold = 2000,\n",
    "                                    inside_percentage_threshold = 0.20,\n",
    "                                    verbose = False,\n",
    "                                    return_meshes = False,\n",
    "                                    )\n",
    "    else:\n",
    "        keep_indices = np.arange(len(filtered_soma_list_components))\n",
    "\n",
    "    filtered_soma_list_components = [k for i,k in enumerate(filtered_soma_list_components) if i in keep_indices]\n",
    "    filtered_soma_list_sdf_components = filtered_soma_list_sdf_components[keep_indices]\n",
    "\n",
    "\n",
    "if return_glia_nuclei_pieces:\n",
    "    return_value= list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components,glia_pieces, nuclei_pieces\n",
    "else:\n",
    "    return_value = list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c987e5a3cca3413d9e210e3e0f270835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=[total_soma_list_revised[2]],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 2\n",
      "xvfb-run -n 6527 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_94186.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_94186_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_843167.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_94186.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_94186_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_843167.mls is being deleted....\n",
      "xvfb-run -n 9915 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90771.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90771_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_188898.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90771.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90771_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_188898.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(4274, 3), faces.shape=(8672, 3))>]\n",
      "After backtrack the found 1 possible somas: [<trimesh.Trimesh(vertices.shape=(5506, 3), faces.shape=(9745, 3))>] \n",
      "\n",
      "--- workin on backtrack soma 0: <trimesh.Trimesh(vertices.shape=(5506, 3), faces.shape=(9745, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3667 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_317875.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_317875_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_444079.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_317875.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_317875_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_444079.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.2811443943090186\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(3791, 3), faces.shape=(8750, 3))>, <trimesh.Trimesh(vertices.shape=(3325, 3), faces.shape=(8110, 3))>, <trimesh.Trimesh(vertices.shape=(3337, 3), faces.shape=(5747, 3))>, <trimesh.Trimesh(vertices.shape=(1652, 3), faces.shape=(3781, 3))>, <trimesh.Trimesh(vertices.shape=(1360, 3), faces.shape=(3161, 3))>, <trimesh.Trimesh(vertices.shape=(1256, 3), faces.shape=(2879, 3))>, <trimesh.Trimesh(vertices.shape=(1090, 3), faces.shape=(2450, 3))>, <trimesh.Trimesh(vertices.shape=(1059, 3), faces.shape=(2420, 3))>, <trimesh.Trimesh(vertices.shape=(987, 3), faces.shape=(2238, 3))>, <trimesh.Trimesh(vertices.shape=(973, 3), faces.shape=(2199, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1802, 3))>, <trimesh.Trimesh(vertices.shape=(760, 3), faces.shape=(1728, 3))>, <trimesh.Trimesh(vertices.shape=(745, 3), faces.shape=(1675, 3))>, <trimesh.Trimesh(vertices.shape=(738, 3), faces.shape=(1621, 3))>, <trimesh.Trimesh(vertices.shape=(770, 3), faces.shape=(1513, 3))>, <trimesh.Trimesh(vertices.shape=(754, 3), faces.shape=(1180, 3))>, <trimesh.Trimesh(vertices.shape=(635, 3), faces.shape=(974, 3))>, <trimesh.Trimesh(vertices.shape=(614, 3), faces.shape=(1373, 3))>, <trimesh.Trimesh(vertices.shape=(497, 3), faces.shape=(789, 3))>, <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(605, 3))>, <trimesh.Trimesh(vertices.shape=(252, 3), faces.shape=(446, 3))>]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-32bba236ec78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m#remove the directory with the meshes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m#removing the temporary files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135725648447'"
     ]
    }
   ],
   "source": [
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "\n",
    "for yy,(soma_mesh,curr_soma_sdf) in enumerate(zip(total_soma_list_revised,total_soma_list_revised_sdf)):\n",
    "    if yy != 2:\n",
    "        continue\n",
    "    add_inside_pieces_flag = False\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        if verbose:\n",
    "            print(f\"\\n---Performing Soma Mesh Backtracking to original mesh for poisson soma {yy}\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "        try:\n",
    "            soma_mesh_list,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                            original_mesh = recov_orig_mesh_no_interior,\n",
    "                                            mesh=soma_mesh_poisson,\n",
    "                                            soma_size_threshold=5000)\n",
    "\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "\n",
    "        if soma_mesh_list is None:\n",
    "                print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        if verbose: \n",
    "            print(f\"After backtrack the found {len(soma_mesh_list)} possible somas: {soma_mesh_list} \")\n",
    "\n",
    "        for rr,soma_mesh in enumerate(soma_mesh_list):\n",
    "            if verbose:\n",
    "                print(f\"\\n--- workin on backtrack soma {rr}: {soma_mesh}\")\n",
    "\n",
    "            print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "            #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "            if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "                #soma_mesh.export(\"soma_mesh.off\")\n",
    "                if close_holes: \n",
    "                    print(\"Using the close holes feature\")\n",
    "                    fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                     self_itersect_faces=False)\n",
    "\n",
    "                    soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                        vertices=soma_mesh.vertices,\n",
    "                                                         faces=soma_mesh.faces,\n",
    "                                                         return_mesh=True,\n",
    "                                                         delete_temp_files=True,\n",
    "                                                        )\n",
    "                else:\n",
    "                    soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "                #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "                print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "                mesh_1 = soma_mesh_filled_holes\n",
    "                mesh_2 = soma_mesh_poisson\n",
    "\n",
    "                poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                                  verbose=True)\n",
    "                print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "                if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                      f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #do the boundary check:\n",
    "            if not boundary_vertices_threshold is None:\n",
    "                print(\"USING boundary_vertices_threshold CHECK\")\n",
    "                soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "                print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "                large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "                print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "                if len(large_boundary_groups)>0:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                          f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "                    continue\n",
    "\n",
    "            curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "            curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "            if (not curr_side_len_check) or (not curr_volume_check):\n",
    "                print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "                     f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                continue\n",
    "\n",
    "            #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "            #If made it through all the checks then add to final list\n",
    "            filtered_soma_list.append(soma_mesh)\n",
    "            filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "            add_inside_pieces_flag = True #setting flag so will add inside pieces\n",
    "\n",
    "\n",
    "    if len(soma_mesh_inside_pieces) > 0 and add_inside_pieces_flag:\n",
    "        print(f\"About to add the following inside nuclei pieces after soma backtrack: {nuclei_pieces}\")\n",
    "        nuclei_pieces +=soma_mesh_inside_pieces\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Need to delete all files in the temp folder *****\n",
    "\"\"\"\n",
    "\n",
    "if delete_files:\n",
    "    #now erase all of the files used\n",
    "    from shutil import rmtree\n",
    "\n",
    "    #remove the directory with the meshes\n",
    "    rmtree(str(temp_object.absolute()))\n",
    "\n",
    "    #removing the temporary files\n",
    "    temp_folder = Path(\"./temp\")\n",
    "    temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "    seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "    for f in seg_temp_files:\n",
    "        f.unlink()\n",
    "\n",
    "# ----------- 11 /11 Addition that does a last step segmentation of the soma --------- #\n",
    "#return total_soma_list, run_time\n",
    "#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n",
    "\"\"\"\n",
    "Things we should ask about the segmentation:\n",
    "\n",
    "Advantages: \n",
    "1) could help filter away negatives\n",
    "\n",
    "Disadvantages:\n",
    "1) Can actually cut up the soma and then filter away the soma (not what we want)\n",
    "2) Could introduce a big hole (don't think can guard against this)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#filtered_soma_list_saved = copy.deepcopy(filtered_soma_list)\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "\n",
    "        print(\"Skipping the segmentatio filter at end\")\n",
    "        if not (len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold):\n",
    "            print(f\"Soma (size = {len(f_soma.faces)}, width={soma_width_threshold}) did not pass thresholds (size threshold={last_size_threshold}, width threshold = {soma_width_threshold}) \")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if segmentation_at_end:\n",
    "\n",
    "\n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "#                 print(f\"meshes_split = {meshes_split}\")\n",
    "#                 print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                print(f\"So just going with old somas\")\n",
    "\n",
    "                f_soma_final = f_soma\n",
    "                f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "            else:\n",
    "                meshes_split = np.array(meshes_split)\n",
    "                meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "                meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "                meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "                soma_width_threshold\n",
    "                #way to choose the index of the top candidate\n",
    "                top_candidate = 0\n",
    "\n",
    "\n",
    "                largest_hole_before_seg = tu.largest_hole_length(f_soma)\n",
    "                largest_hole_after_seg = tu.largest_hole_length(meshes_split_filtered[top_candidate])\n",
    "\n",
    "                print(f\"Largest hole before segmentation = {largest_hole_before_seg}, after = {largest_hole_after_seg},\"\n",
    "                      f\"\\nratio = {largest_hole_after_seg/largest_hole_before_seg}, difference = {largest_hole_after_seg - largest_hole_before_seg}\")\n",
    "\n",
    "                if largest_hole_after_seg < largest_hole_threshold:\n",
    "                    f_soma_final = meshes_split_filtered[top_candidate]\n",
    "                    f_soma_sdf_final = meshes_split_sdf_filtered[top_candidate]\n",
    "                else:\n",
    "                    f_soma_final = f_soma\n",
    "                    f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "        else:\n",
    "            f_soma_final = f_soma\n",
    "            f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "        filtered_soma_list_revised.append(f_soma_final)\n",
    "        filtered_soma_list_sdf_revised.append(f_soma_sdf_final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n",
    "\n",
    "    \"\"\"\n",
    "    # ----------- 1/7/21 ---------------#\n",
    "    Now was to stitch the somas together if they are touching\n",
    "\n",
    "    \"\"\"\n",
    "    if len(filtered_soma_list)>1:\n",
    "        connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                                 main_mesh=recov_orig_mesh_no_interior,\n",
    "                                                    return_connected_components=True)\n",
    "\n",
    "        filtered_soma_list_components = np.array([tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components])\n",
    "        filtered_soma_list_sdf_components = np.array([np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components])\n",
    "    elif len(filtered_soma_list)==1:\n",
    "        filtered_soma_list_components = filtered_soma_list\n",
    "        filtered_soma_list_sdf_components = filtered_soma_list_sdf\n",
    "    else:\n",
    "        filtered_soma_list_components = []\n",
    "        filtered_soma_list_sdf_components = np.array([])\n",
    "else:\n",
    "    filtered_soma_list_components = []\n",
    "    filtered_soma_list_sdf_components = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "#----------- 1/9 Addition: Final Size Threshold ------------- #\n",
    "if backtrack_soma_mesh_to_original:\n",
    "\n",
    "    filtered_soma_list_components_new = []\n",
    "    filtered_soma_list_sdf_components_new = []\n",
    "\n",
    "    for soma_mesh, soma_mesh_sdf in zip(filtered_soma_list_components,filtered_soma_list_sdf_components):\n",
    "        # --------- 1/9: Extra Size Threshold For Somas ------------- #\n",
    "        if len(soma_mesh.faces) < backtrack_soma_size_threshold:\n",
    "            print(f\"--->This soma mesh with size {len(soma_mesh.faces)} was not bigger than the threshold {backtrack_soma_size_threshold}\")\n",
    "            continue\n",
    "        else:\n",
    "            filtered_soma_list_components_new.append(soma_mesh)\n",
    "            filtered_soma_list_sdf_components_new.append(soma_mesh_sdf)\n",
    "\n",
    "    filtered_soma_list_components = filtered_soma_list_components_new\n",
    "    filtered_soma_list_sdf_components = np.array(filtered_soma_list_sdf_components_new)\n",
    "\n",
    "if filter_inside_somas:\n",
    "    if len(filtered_soma_list_components)>1:\n",
    "        keep_indices = tu.filter_away_inside_meshes(mesh_list = filtered_soma_list_components,\n",
    "                                    distance_type=\"shortest_vertex_distance\",\n",
    "                                    distance_threshold = 2000,\n",
    "                                    inside_percentage_threshold = 0.20,\n",
    "                                    verbose = False,\n",
    "                                    return_meshes = False,\n",
    "                                    )\n",
    "    else:\n",
    "        keep_indices = np.arange(len(filtered_soma_list_components))\n",
    "\n",
    "    filtered_soma_list_components = [k for i,k in enumerate(filtered_soma_list_components) if i in keep_indices]\n",
    "    filtered_soma_list_sdf_components = filtered_soma_list_sdf_components[keep_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(5506, 3), faces.shape=(9745, 3))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[0],\n",
    "                  meshes=[soma_mesh], \n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = f\"./{segment_id}\"\n",
    "temp_object = Path(temp_folder)\n",
    "#make the temp folder if it doesn't exist\n",
    "temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#making the decimation and poisson objections\n",
    "Dec_outer = meshlab.Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "Dec_inner = meshlab.Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "Poisson_obj = meshlab.Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "\n",
    "for j, largest_mesh_inner in enumerate([list_of_largest_mesh_inner[0]]):\n",
    "    to_add_list = []\n",
    "    to_add_list_sdf = []\n",
    "\n",
    "    print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "    largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "    #Decimate the inner poisson piece\n",
    "    largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                        vertices=largest_mesh_inner.vertices,\n",
    "                         faces=largest_mesh_inner.faces,\n",
    "                        mesh_filename=largest_mesh_path_inner,\n",
    "                         return_mesh=True,\n",
    "                         delete_temp_files=False)\n",
    "\n",
    "    dec_splits = tu.split_significant_pieces(largest_mesh_path_inner_decimated,significance_threshold=15)\n",
    "    print(f\"\\n-------Splits after inner decimation len = {len(dec_splits)}--------\\n\")\n",
    "\n",
    "    if len(dec_splits) == 0:\n",
    "        print(\"There were no signifcant splits after inner decimation\")\n",
    "        n_failed_inner_soma_loops += 1\n",
    "    else:\n",
    "        print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "        largest_mesh_path_inner_decimated_clean = dec_splits[0]\n",
    "        \n",
    "        \"\"\" # ----------- 1/12: Addition that does the segmentation again -------------------- #\"\"\"\n",
    "        \n",
    "        for ii in range(3):\n",
    "            print(f\"\\n    --- On segmentation loop {ii} --\")\n",
    "            print(f\"largest_mesh_path_inner_decimated_clean = {largest_mesh_path_inner_decimated_clean}\\n\")\n",
    "\n",
    "            faces = np.array(largest_mesh_path_inner_decimated_clean.faces)\n",
    "            verts = np.array(largest_mesh_path_inner_decimated_clean.vertices)\n",
    "\n",
    "            # may need to do some processing\n",
    "\n",
    "\n",
    "            segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "            #print(f\"Before the classifier the pymeshfix_clean = {pymeshfix_clean}\")\n",
    "            verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                    import_Off_Flag=False,\n",
    "                                    segment_id=segment_id_new,\n",
    "                                    vertices=verts,\n",
    "                                     triangles=faces,\n",
    "                                    pymeshfix_Flag=False,\n",
    "                                     import_CGAL_Flag=False,\n",
    "                                     return_Only_Labels=True,\n",
    "                                     clusters=3,\n",
    "                                     smoothness=0.2,\n",
    "                                    soma_only=True,\n",
    "                                    return_classifier = True\n",
    "                                    )\n",
    "            print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "            total_classifier_list.append(classifier)\n",
    "            #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "            # Save all of the portions that resemble a soma\n",
    "            median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "            segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "            #order the compartments by greatest to smallest\n",
    "            sorted_medians = np.flip(np.argsort(median_values))\n",
    "            print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "            print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "            print(f\"soma_size_threshold = {soma_size_threshold}\")\n",
    "            print(f\"soma_size_threshold_max={soma_size_threshold_max}\")\n",
    "\n",
    "            valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "            valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "            print(\"valid_soma_segments_width\")\n",
    "            \n",
    "            \n",
    "            \"\"\"# =------------- 1/12: Addition that will repeat this loop --------------\"\"\"\n",
    "            if len(valid_soma_segments_width) > 0:\n",
    "                break\n",
    "            else:\n",
    "                \"\"\"\n",
    "                Pseudocode: \n",
    "                Get the largest mesh segment\n",
    "                \"\"\"\n",
    "                new_mesh_try_faces = np.where(classifier.labels_list == nu.mode_1d(classifier.labels_list))[0]\n",
    "                largest_mesh_path_inner_decimated_clean = largest_mesh_path_inner_decimated_clean.submesh([new_mesh_try_faces],append=True)\n",
    "                \n",
    "\n",
    "        if len(valid_soma_segments_width) > 0:\n",
    "            print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "            somas_found_in_big_loop = True\n",
    "            #get the meshes only if signfiicant length\n",
    "            labels_list = classifier.labels_list\n",
    "\n",
    "            for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "                curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "\n",
    "\n",
    "                if curr_side_len_check and curr_volume_check:\n",
    "                    #check if we can split this into two\n",
    "                    to_add_list.append(soma_mesh)\n",
    "                    to_add_list_sdf.append(sdf)\n",
    "\n",
    "                    \"\"\"  -----------Removed 1/12: When trying to force a split between them \n",
    "                    possible_smoothness = [0.2,0.05,0.01]\n",
    "                    for smooth_value in possible_smoothness:\n",
    "                        #1) Run th esegmentation algorithm again to segment the mesh (had to run the higher smoothing to seperate some)\n",
    "                        mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=smooth_value,verbose=True)\n",
    "                        mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                        #2) Filter out meshes by sizs and sdf threshold\n",
    "                        mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                        filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "                        if len(filtered_meshes_idx) >= 2:\n",
    "                            if verbose:\n",
    "                                print(f\"Breakin on smoothness: {smooth_value}\")\n",
    "                            break\n",
    "\n",
    "                    if len(filtered_meshes_idx) >= 2:\n",
    "                        filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                        filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                        to_add_list_retry = []\n",
    "                        to_add_list_sdf_retry = []\n",
    "\n",
    "                        for f_m,f_m_sdf in zip(filtered_meshes,filtered_meshes_sdf):\n",
    "                            curr_side_len_check_retry = side_length_check(f_m,side_length_ratio_threshold)\n",
    "                            curr_volume_check_retry = soma_volume_check(f_m,volume_mulitplier)\n",
    "\n",
    "                            if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                to_add_list_retry.append(f_m)\n",
    "                                to_add_list_sdf_retry.append(f_m_sdf)\n",
    "\n",
    "                        if len(to_add_list_retry)>1:\n",
    "                            if verbose:\n",
    "                                print(\"Using the new feature that split the soma further into more groups\")\n",
    "                            to_add_list += to_add_list_retry\n",
    "                            to_add_list_sdf += to_add_list_sdf_retry\n",
    "\n",
    "                        else:\n",
    "                            to_add_list.append(soma_mesh)\n",
    "                            to_add_list_sdf.append(sdf)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        to_add_list.append(soma_mesh)\n",
    "                        to_add_list_sdf.append(sdf)\n",
    "                    \"\"\"\n",
    "\n",
    "                else:\n",
    "                    # ---------- 1/7 Addition: Trying one more additional cgal segmentation to see if there is actually a soma ---\n",
    "                    \"\"\"\n",
    "                    Pseudocode: \n",
    "                    1) Run th esegmentation algorithm again to segment the mesh\n",
    "                    2) Filter out meshes by sizs and sdf threshold\n",
    "                    3) If there are any remaining meshes, pick the largest sdf mesh and test for volume and side length check\n",
    "                    --> if matches then adds\n",
    "                    \"\"\"\n",
    "\n",
    "                    print(f\"->Attempting retry of soma because failed first checks: \"\n",
    "                             f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                    #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                    mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                    mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                    #2) Filter out meshes by sizs and sdf threshold\n",
    "                    mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                    filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "\n",
    "                    if len(filtered_meshes_idx) > 0:\n",
    "                        filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                        filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                        sdf_winning_index = np.argmax(filtered_meshes_sdf)\n",
    "                        soma_mesh_retry = filtered_meshes[sdf_winning_index]\n",
    "                        sdf_retry = filtered_meshes_sdf[sdf_winning_index]\n",
    "\n",
    "                        curr_side_len_check_retry = side_length_check(soma_mesh_retry,side_length_ratio_threshold)\n",
    "                        curr_volume_check_retry = soma_volume_check(soma_mesh_retry,volume_mulitplier)\n",
    "\n",
    "                        if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                            to_add_list.append(soma_mesh_retry)\n",
    "                            to_add_list_sdf.append(sdf_retry)\n",
    "                        else:\n",
    "                            print(f\"--->This soma mesh was not added because failed retry of sphere validation:\\n \"\n",
    "                                 f\"soma_mesh = {soma_mesh_retry}, curr_side_len_check = {curr_side_len_check_retry}, curr_volume_check = {curr_volume_check_retry}\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        print(f\"Could not find valid soma mesh in retry\")\n",
    "                        continue\n",
    "\n",
    "\n",
    "            n_failed_inner_soma_loops = 0\n",
    "\n",
    "        else:\n",
    "            n_failed_inner_soma_loops += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_utils as nu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_mesh_path_inner_decimated_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(largest_mesh_path_inner_decimated_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_m, curr_s = tu.mesh_segmentation(largest_mesh_path_inner_decimated_clean,\n",
    "                     clusters=3,\n",
    "                     smoothness=0.2,\n",
    "                     verbose=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=curr_m,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtracked_somas = []\n",
    "for soma_mesh,curr_soma_sdf in zip(total_soma_list_revised,total_soma_list_revised_sdf):\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        print(\"Performing Soma Mesh Backtracking to original mesh\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "\n",
    "        soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)\n",
    "        backtracked_somas.append(soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Original Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(filtered_soma_list_components[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The New Original Mesh Soma Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recov_orig_mesh_no_interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_big_mesh,faces = tu.bbox_mesh_restriction(recov_orig_mesh_no_interior,soma_mesh_poisson,mult_ratio=2)\n",
    "restricted_big_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.original_mesh_soma(restricted_big_mesh,soma_meshes=[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_mesh_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_split = tu.split_significant_pieces(restricted_big_mesh,significance_threshold=1000,connectivity=\"edges\")\n",
    "restr_mesh_to_test = restr_split[0]\n",
    "restr_mesh_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.mesh_interior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_without_interior,rem_pieces = tu.remove_mesh_interior(restr_mesh_to_test,return_removed_pieces=True,size_threshold_to_remove=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_without_interior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restricted_big_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_somas = sm.original_mesh_soma(restr_without_interior,[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(new_somas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The new Soma Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_soma = sm.original_mesh_soma(restr_without_interior_largest,\n",
    "                      soma_mesh_poisson,\n",
    "    subtract_soma_distance_threshold=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(back_soma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = soma_mesh_poisson\n",
    "original_mesh = recov_orig_mesh_no_interior \n",
    "bbox_restriction_multiplying_ratio = 1.7\n",
    "match_distance_threshold = 1500\n",
    "mesh_significance_threshold = 1000\n",
    "return_inside_pieces = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_soma_mesh,soma_inside_pieces = original_mesh_soma(\n",
    "    mesh = soma_mesh_poisson,\n",
    "    original_mesh = recov_orig_mesh_no_interior ,\n",
    "    bbox_restriction_multiplying_ratio = 1.7,\n",
    "    match_distance_threshold = 1500,\n",
    "    mesh_significance_threshold = 1000,\n",
    "    return_inside_pieces = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(final_soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=soma_inside_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_without_interior_largest = tu.split_significant_pieces(restr_without_interior)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes,sdf_results = tu.mesh_segmentation(restr_without_interior_largest,clusters=3,smoothness=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes[np.argmax(sdf_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes = np.array(divided_meshes)\n",
    "sdf_results = np.array(sdf_results)\n",
    "\n",
    "meshes_len = np.array([len(k.faces) for k in divided_meshes ])\n",
    "possible_soma_idxs = np.where(meshes_len > 13000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_without_interior_largest,\n",
    "                meshes=[divided_meshes[0],soma_mesh_poisson],\n",
    "                 meshes_colors=[\"red\",\"purple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(Out[129][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.bounding_box_corners(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.bbox_mesh_restriction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_soma_segments_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_somas = []\n",
    "if len(valid_soma_segments_width) > 0:\n",
    "    print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "    somas_found_in_big_loop = True\n",
    "    #get the meshes only if signfiicant length\n",
    "    labels_list = classifier.labels_list\n",
    "\n",
    "    for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "        submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "        soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "        total_somas.append(soma_mesh)\n",
    "\n",
    "        # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "\n",
    "        curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "        curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "        \n",
    "        print(f\"\\n\\n {curr_side_len_check}, {curr_volume_check} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(total_somas[1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Run th esegmentation algorithm again to segment the mesh\n",
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(total_somas[1],clusters=3,smoothness=0.01,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                  meshes_colors=\"random\"\n",
    "                 )\n",
    "#2) Filter out meshes by sizs and sdf threshold\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "nviz.plot_objects(meshes=mesh_extra[filtered_meshes_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mesh = mesh_extra[filtered_meshes_idx][0]\n",
    "\n",
    "side_length_check(test_mesh,side_length_ratio_threshold), soma_volume_check(test_mesh,volume_mulitplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[-1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "                    \n",
    "                    #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                    mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                    mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                    #2) Filter out meshes by sizs and sdf threshold\n",
    "                    mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                    filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.05,verbose=True)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "            mesh = recov_orig_mesh_no_interior,\n",
    "            soma_meshes=[soma_mesh_poisson],\n",
    "            sig_th_initial_split=15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ----------- 1/7/21 ---------------#\n",
    "Now was to stitch the somas together if they are touching\n",
    "\n",
    "\"\"\"\n",
    "connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                         main_mesh=recov_orig_mesh,\n",
    "                                            return_connected_components=True)\n",
    "\n",
    "filtered_soma_list_components = [tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components]\n",
    "filtered_soma_list_sdf_components = [np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "                                            mesh = recov_orig_mesh_no_interior,\n",
    "                                            soma_meshes=[soma_mesh_poisson],\n",
    "                                            sig_th_initial_split=15)[0]\n",
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_soma_meshes = su.decompress_pickle(\"seperate_soma_meshes\")\n",
    "nviz.plot_objects(meshes=seperate_soma_meshes,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_saved = su.decompress_pickle(\"filtered_soma_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(current_neuron,\n",
    "                #meshes=[return_value[0][0]],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "if len(filtered_meshes_idx) > 0:\n",
    "    filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "    filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "    \n",
    "    soma_mesh_retry = filtered_meshes[np.argmax(filtered_meshes_sdf)]\n",
    "\n",
    "nviz.plot_objects(soma_mesh_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_size_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(mesh_extra[0],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(largest_mesh_path_inner_decimated_clean,\n",
    "                 meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mesh_threshold_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=[k for k in ordered_mesh_splits_inner if len(k.faces)>800],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=dec_splits,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh[1],\n",
    "                  meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh,\n",
    "                 meshes_colors=[\"red\",\"black\"],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(main_mesh=current_neuron,\n",
    "                 meshes=filtered_soma_list,\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                                 current_neuron.vertices,\n",
    "                                                 current_neuron.faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
