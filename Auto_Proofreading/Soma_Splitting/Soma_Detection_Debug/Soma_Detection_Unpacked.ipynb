{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To debug why certain somas are not being detected\n",
    "in agreement with nucleus table\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:39:23,083 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-12 00:39:23,084 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-12 00:39:23,085 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-12 00:39:23,133 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-12 00:39:23,133 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-12 00:39:23,145 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:39:23,430 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import soma_extraction_utils as sm\n",
    "import datajoint_utils as du\n",
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:39:23,524 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-12 00:39:23,783 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking what neurons did not have 2 somas which should have (so can test on them now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/6 Debugging Missed Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 864691135654121154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_neuron = du.fetch_segment_id_mesh(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 6355 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86548.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86548_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_782521.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86548.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86548_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_782521.mls is being deleted....\n",
      "There were 49 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 49\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(23298, 3), faces.shape=(50603, 3))>, <trimesh.Trimesh(vertices.shape=(21540, 3), faces.shape=(46467, 3))>, <trimesh.Trimesh(vertices.shape=(16734, 3), faces.shape=(37184, 3))>, <trimesh.Trimesh(vertices.shape=(2323, 3), faces.shape=(4219, 3))>, <trimesh.Trimesh(vertices.shape=(2274, 3), faces.shape=(4133, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4430, 3))>, <trimesh.Trimesh(vertices.shape=(1382, 3), faces.shape=(3130, 3))>, <trimesh.Trimesh(vertices.shape=(1216, 3), faces.shape=(2664, 3))>, <trimesh.Trimesh(vertices.shape=(1141, 3), faces.shape=(2524, 3))>, <trimesh.Trimesh(vertices.shape=(1096, 3), faces.shape=(2432, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2359, 3))>, <trimesh.Trimesh(vertices.shape=(954, 3), faces.shape=(2137, 3))>, <trimesh.Trimesh(vertices.shape=(927, 3), faces.shape=(2058, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(1997, 3))>, <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(2005, 3))>, <trimesh.Trimesh(vertices.shape=(897, 3), faces.shape=(1979, 3))>, <trimesh.Trimesh(vertices.shape=(798, 3), faces.shape=(1761, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(666, 3), faces.shape=(1169, 3))>, <trimesh.Trimesh(vertices.shape=(664, 3), faces.shape=(1451, 3))>, <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(970, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(880, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(907, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(817, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 3893934, Final mesh size: 3713763\n",
      "Total time = 217.8666615486145\n",
      "xvfb-run -n 2749 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25131320.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(432654, 3), faces.shape=(853661, 3))>, <trimesh.Trimesh(vertices.shape=(7080, 3), faces.shape=(13923, 3))>, <trimesh.Trimesh(vertices.shape=(4843, 3), faces.shape=(7205, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(432654, 3), faces.shape=(853661, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 1988 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93921.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93921_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_863473.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93921.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93921_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_863473.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 269\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off\n",
      "xvfb-run -n 1512 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/poisson_712556.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(57846, 3), faces.shape=(115700, 3))>, <trimesh.Trimesh(vertices.shape=(2848, 3), faces.shape=(5692, 3))>, <trimesh.Trimesh(vertices.shape=(2715, 3), faces.shape=(5426, 3))>, <trimesh.Trimesh(vertices.shape=(2477, 3), faces.shape=(4950, 3))>, <trimesh.Trimesh(vertices.shape=(2244, 3), faces.shape=(4488, 3))>, <trimesh.Trimesh(vertices.shape=(2100, 3), faces.shape=(4196, 3))>, <trimesh.Trimesh(vertices.shape=(1898, 3), faces.shape=(3796, 3))>, <trimesh.Trimesh(vertices.shape=(1875, 3), faces.shape=(3750, 3))>, <trimesh.Trimesh(vertices.shape=(1767, 3), faces.shape=(3538, 3))>, <trimesh.Trimesh(vertices.shape=(1696, 3), faces.shape=(3388, 3))>, <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(57846, 3), faces.shape=(115700, 3))>\n",
      "xvfb-run -n 1384 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(14455, 3), faces.shape=(28918, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005521774291992188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115400_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 3.4391872882843018\n",
      "2) Finished: Generating CGAL segmentation for neuron: 3.9248931407928467\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.7670395\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.011034727096557617\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 6.4849853515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.027181386947631836\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.1521308422088623\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.7670395\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 0, 34, 35, 41, 33, 12, 18,  8, 14, 24,  3, 44, 13, 16,  6, 23, 21,\n",
      "        1,  7, 22,  9, 11, 39, 42, 15, 10, 30, 40, 43, 37,  2, 25, 28,  4,\n",
      "        5, 31, 36, 19, 20, 32, 29, 17, 38, 26, 27]), array([0.7670395 , 0.142273  , 0.103885  , 0.0920161 , 0.09093865,\n",
      "       0.09070015, 0.086696  , 0.0855804 , 0.0837012 , 0.08192535,\n",
      "       0.07968135, 0.0772857 , 0.07591035, 0.07573255, 0.0700934 ,\n",
      "       0.0699022 , 0.06149105, 0.0596518 , 0.0583475 , 0.0581237 ,\n",
      "       0.0579349 , 0.0566743 , 0.0524235 , 0.0519075 , 0.0515534 ,\n",
      "       0.05109585, 0.0506271 , 0.0496821 , 0.0495547 , 0.0481628 ,\n",
      "       0.0477939 , 0.0456554 , 0.04457315, 0.0444382 , 0.0431447 ,\n",
      "       0.0431379 , 0.0421053 , 0.0403091 , 0.03975745, 0.0395464 ,\n",
      "       0.0377897 , 0.0354938 , 0.03450595, 0.03291815, 0.0278645 ]))\n",
      "Sizes = [5554, 63, 179, 37, 160, 1652, 2115, 117, 373, 40, 3542, 258, 168, 218, 115, 429, 544, 425, 260, 920, 308, 495, 507, 179, 109, 170, 1079, 909, 39, 337, 323, 143, 1566, 283, 553, 131, 763, 681, 684, 214, 1358, 129, 610, 124, 55]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3423 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_512127.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_512127_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_657731.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_512127.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_512127_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_657731.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 6.432186540201337\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2848, 3), faces.shape=(5692, 3))>\n",
      "xvfb-run -n 5653 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(713, 3), faces.shape=(1422, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002269744873046875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08082151412963867\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10721993446350098\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006551742553710938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.3882598876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016026496887207031\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007285118103027344\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 4, 3, 0]), array([0.852138 , 0.372811 , 0.2151145, 0.150057 , 0.125077 ]))\n",
      "Sizes = [125, 65, 118, 301, 813]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(409, 3), faces.shape=(813, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002014636993408203\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.03956246376037598\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.05586695671081543\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004322528839111328\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.553794860839844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009057521820068359\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003998756408691406\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 1, 4, 0, 2, 3]), array([0.584389, 0.545621, 0.459352, 0.370279, 0.366455, 0.33795 ]))\n",
      "Sizes = [76, 174, 222, 111, 136, 94]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(114, 3), faces.shape=(222, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021004676818847656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.011260509490966797\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.02018451690673828\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002989768981933594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.628036499023438e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00037360191345214844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0016932487487792969\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.887441, 0.473899]))\n",
      "Sizes = [27, 195]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(2715, 3), faces.shape=(5426, 3))>\n",
      "xvfb-run -n 5317 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(679, 3), faces.shape=(1354, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002696514129638672\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115402_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.12715697288513184\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.15146851539611816\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006940364837646484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.412101745605469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013403892517089844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0069310665130615234\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 5, 3, 0, 7, 2, 4, 6]), array([0.8728845, 0.774169 , 0.58868  , 0.573648 , 0.373987 , 0.269168 ,\n",
      "       0.251319 , 0.232877 ]))\n",
      "Sizes = [238, 271, 279, 321, 118, 35, 52, 40]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(165, 3), faces.shape=(321, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001933574676513672\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115402_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.02716374397277832\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.034996986389160156\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00020742416381835938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.553794860839844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003371238708496094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0017428398132324219\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.73012]))\n",
      "Sizes = [321]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(165, 3), faces.shape=(321, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002110004425048828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115402_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.027213335037231445\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0366206169128418\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00021219253540039062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.649162292480469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003414154052734375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0016522407531738281\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.73012]))\n",
      "Sizes = [321]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(2477, 3), faces.shape=(4950, 3))>\n",
      "xvfb-run -n 5457 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(620, 3), faces.shape=(1236, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024008750915527344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115403_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11313223838806152\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13625597953796387\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006372928619384766\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.245208740234375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014145374298095703\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007204532623291016\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 4, 3, 0, 5]), array([0.853208 , 0.462021 , 0.4574875, 0.2572435, 0.0950371, 0.0600612]))\n",
      "Sizes = [299, 299, 496, 42, 71, 29]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(251, 3), faces.shape=(496, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022602081298828125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115403_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04209756851196289\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.051578521728515625\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002665519714355469\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.696846008300781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007395744323730469\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002825498580932617\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.629675]))\n",
      "Sizes = [496]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(251, 3), faces.shape=(496, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021696090698242188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115403_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0421147346496582\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.05386042594909668\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002543926239013672\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.2438507080078125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00048351287841796875\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0024149417877197266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.629675]))\n",
      "Sizes = [496]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(2244, 3), faces.shape=(4488, 3))>\n",
      "xvfb-run -n 8699 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(561, 3), faces.shape=(1122, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024771690368652344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115404_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11256670951843262\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13306212425231934\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006008148193359375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.555152893066406e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011277198791503906\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005838155746459961\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 4, 0, 3, 1]), array([0.82308 , 0.747646, 0.586211, 0.342029, 0.114341]))\n",
      "Sizes = [307, 266, 350, 157, 42]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(181, 3), faces.shape=(350, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002434253692626953\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115404_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.03288888931274414\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.041126251220703125\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00035381317138671875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.14984130859375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0004930496215820312\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0018000602722167969\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7223455]))\n",
      "Sizes = [350]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(181, 3), faces.shape=(350, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021982192993164062\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115404_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0327916145324707\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.042253971099853516\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00022649765014648438\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.220008850097656e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003650188446044922\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0017938613891601562\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7223455]))\n",
      "Sizes = [350]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(2100, 3), faces.shape=(4196, 3))>\n",
      "xvfb-run -n 5921 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(526, 3), faces.shape=(1048, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024819374084472656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115405_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.12320303916931152\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.14503264427185059\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007762908935546875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.390975952148438e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0018982887268066406\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008104562759399414\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.52226 , 0.485363]))\n",
      "Sizes = [218, 830]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 155 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603272.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603272_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_374386.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603272.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_603272_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_374386.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.402030441552503\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(1898, 3), faces.shape=(3796, 3))>\n",
      "xvfb-run -n 411 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(474, 3), faces.shape=(948, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023436546325683594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115406_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08853793144226074\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10583090782165527\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00048804283142089844\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.9591064453125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012454986572265625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00478053092956543\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 3, 2, 4]), array([0.811042  , 0.389099  , 0.242819  , 0.214927  , 0.08927015]))\n",
      "Sizes = [372, 413, 38, 91, 34]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(209, 3), faces.shape=(413, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007569789886474609\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115406_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.040155649185180664\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.05276036262512207\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002522468566894531\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.3392181396484375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00042057037353515625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.002435922622680664\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.4787   , 0.1703635, 0.166315 ]))\n",
      "Sizes = [314, 40, 59]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(161, 3), faces.shape=(314, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0001823902130126953\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115406_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.025762557983398438\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.033031463623046875\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00020265579223632812\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.744529724121094e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003304481506347656\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0015921592712402344\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.4377005]))\n",
      "Sizes = [314]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(1875, 3), faces.shape=(3750, 3))>\n",
      "xvfb-run -n 794 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(468, 3), faces.shape=(936, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00038123130798339844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115407_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.056823015213012695\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07533931732177734\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005109310150146484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.817413330078125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011343955993652344\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004929542541503906\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0]), array([0.645915, 0.511165, 0.456919]))\n",
      "Sizes = [193, 522, 221]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(262, 3), faces.shape=(522, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021457672119140625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115407_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.030318737030029297\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04033207893371582\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002970695495605469\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.078315734863281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0006177425384521484\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0029108524322509766\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5117775]))\n",
      "Sizes = [522]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(262, 3), faces.shape=(522, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005486011505126953\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115407_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.031243562698364258\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.040802717208862305\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003180503845214844\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.269050598144531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0022385120391845703\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006869316101074219\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5117775]))\n",
      "Sizes = [522]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(1767, 3), faces.shape=(3538, 3))>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 7822 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(440, 3), faces.shape=(884, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002319812774658203\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115408_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05196499824523926\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06918525695800781\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005440711975097656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.887580871582031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008876323699951172\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004354715347290039\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.392913]))\n",
      "Sizes = [884]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_521261.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 459.7237708784857\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(440, 3), faces.shape=(884, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/639_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186d9bcc25ac40b48ad6149985442c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_273242.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 459.7237708784857\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(440, 3), faces.shape=(884, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(1696, 3), faces.shape=(3388, 3))>\n",
      "xvfb-run -n 8277 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(425, 3), faces.shape=(846, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002262592315673828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115409_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07759714126586914\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09396791458129883\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005049705505371094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008552074432373047\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00414276123046875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([4, 3, 0, 2, 5, 6, 7, 1]), array([0.835255 , 0.8347375, 0.7589165, 0.453566 , 0.431922 , 0.340356 ,\n",
      "       0.168269 , 0.141433 ]))\n",
      "Sizes = [191, 210, 156, 69, 70, 67, 18, 65]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(108, 3), faces.shape=(210, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003097057342529297\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115409_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.018631458282470703\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.02481245994567871\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00015854835510253906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.124641418457031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00022983551025390625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0010557174682617188\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7647155]))\n",
      "Sizes = [210]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(108, 3), faces.shape=(210, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00035071372985839844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115409_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05788111686706543\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06616735458374023\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00015473365783691406\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.124641418457031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009479522705078125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.001026153564453125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7647155]))\n",
      "Sizes = [210]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>\n",
      "xvfb-run -n 8916 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(422, 3), faces.shape=(840, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022339820861816406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135654121154010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04511094093322754\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.061266183853149414\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00042891502380371094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.8160552978515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008215904235839844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003922224044799805\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 0, 1, 2, 4]), array([0.821113 , 0.520434 , 0.477387 , 0.397839 , 0.2818235]))\n",
      "Sizes = [30, 636, 93, 61, 20]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_775117.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 438.8521472797833\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(321, 3), faces.shape=(636, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/537_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f1842b45c14d618efb4f261b87ed2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_43603.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 438.8521472797833\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(321, 3), faces.shape=(636, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(7080, 3), faces.shape=(13923, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3784 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65788.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65788_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_623781.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65788.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65788_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_623781.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off\n",
      "xvfb-run -n 6700 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/poisson_712556.mls\n",
      "Total found significant pieces AFTER Poisson = []\n",
      "----- working on large mesh #2: <trimesh.Trimesh(vertices.shape=(4843, 3), faces.shape=(7205, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 2928 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58253.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58253_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_879493.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58253.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58253_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_879493.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 82\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off\n",
      "xvfb-run -n 5549 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/poisson_712556.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(30895, 3), faces.shape=(61483, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(30895, 3), faces.shape=(61483, 3))>\n",
      "xvfb-run -n 9912 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25434477.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(7832, 3), faces.shape=(15357, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006389617919921875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115420_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 2.1673717498779297\n",
      "2) Finished: Generating CGAL segmentation for neuron: 2.5010781288146973\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "soma_index = 2, soma_sdf_value = 0.7145589999999999\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00594782829284668\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.459785461425781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.018817663192749023\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.1077725887298584\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.7145589999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 2, 0, 1, 4]), array([0.7203975, 0.714559 , 0.515193 , 0.28007  , 0.0494622]))\n",
      "Sizes = [2176, 3192, 8766, 1214, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [3, 2, 0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9328 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_292922.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_292922_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_7236.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_292922.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_292922_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_7236.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.006129384047377571\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6855 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_945631.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_945631_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_222030.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_945631.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_945631_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_222030.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.027184592542104393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 447 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_438823.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_438823_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_696182.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_438823.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_438823_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_696182.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.02551870668431357\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 564.3634572029114\n",
      "Before Filtering the number of somas found = 5\n",
      "xvfb-run -n 9722 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25947.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25947_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_743748.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25947.off loaded has 149178 vn 294641 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25947_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_743748.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Successfully removed 22676 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 22676 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 6843852\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_743748.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 8608 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87199.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87199_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_343721.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87199.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87199_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_343721.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11691, 3), faces.shape=(24005, 3))>, <trimesh.Trimesh(vertices.shape=(5625, 3), faces.shape=(11631, 3))>, <trimesh.Trimesh(vertices.shape=(5542, 3), faces.shape=(11755, 3))>, <trimesh.Trimesh(vertices.shape=(2140, 3), faces.shape=(4393, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(5759, 3))>, <trimesh.Trimesh(vertices.shape=(1614, 3), faces.shape=(3209, 3))>, <trimesh.Trimesh(vertices.shape=(1041, 3), faces.shape=(2022, 3))>, <trimesh.Trimesh(vertices.shape=(683, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(1069, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(533, 3))>, <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(540, 3))>, <trimesh.Trimesh(vertices.shape=(315, 3), faces.shape=(510, 3))>, <trimesh.Trimesh(vertices.shape=(258, 3), faces.shape=(396, 3))>, <trimesh.Trimesh(vertices.shape=(217, 3), faces.shape=(389, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(320, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5562 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_354082.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_354082_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_692033.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_354082.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_354082_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_692033.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.284280228241844\n",
      "Trying backtrack segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ae54c2ba4e459986d1161efa2a1cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=95.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8098 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_600332.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_600332_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_479451.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_600332.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_600332_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_479451.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.246214159682605\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7789 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_560018.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_560018_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_761906.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_560018.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_560018_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_761906.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.731465215534266\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(23352, 3), faces.shape=(50653, 3))>, <trimesh.Trimesh(vertices.shape=(21656, 3), faces.shape=(46562, 3))>, <trimesh.Trimesh(vertices.shape=(16787, 3), faces.shape=(37230, 3))>, <trimesh.Trimesh(vertices.shape=(2323, 3), faces.shape=(4219, 3))>, <trimesh.Trimesh(vertices.shape=(2274, 3), faces.shape=(4133, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4430, 3))>, <trimesh.Trimesh(vertices.shape=(1382, 3), faces.shape=(3130, 3))>, <trimesh.Trimesh(vertices.shape=(1216, 3), faces.shape=(2664, 3))>, <trimesh.Trimesh(vertices.shape=(1141, 3), faces.shape=(2524, 3))>, <trimesh.Trimesh(vertices.shape=(1096, 3), faces.shape=(2432, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2359, 3))>, <trimesh.Trimesh(vertices.shape=(954, 3), faces.shape=(2137, 3))>, <trimesh.Trimesh(vertices.shape=(927, 3), faces.shape=(2058, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(1997, 3))>, <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(2005, 3))>, <trimesh.Trimesh(vertices.shape=(897, 3), faces.shape=(1979, 3))>, <trimesh.Trimesh(vertices.shape=(798, 3), faces.shape=(1761, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(666, 3), faces.shape=(1169, 3))>, <trimesh.Trimesh(vertices.shape=(664, 3), faces.shape=(1451, 3))>, <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(970, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(880, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(907, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(817, 3))>]\n",
      "xvfb-run -n 5048 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59482.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59482_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_49679.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59482.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59482_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_49679.mls is being deleted....\n",
      "xvfb-run -n 107 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20573.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20573_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_20588.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20573.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20573_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_20588.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "xvfb-run -n 459 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_22257.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_22257_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_488136.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_22257.off loaded has 14593 vn 27922 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_22257_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_488136.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 685296\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 685296\n",
      "LOG: 2 Successfully removed 4504 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 4504 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 631248\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_488136.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 9301 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52636.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52636_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_458353.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52636.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52636_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_458353.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5716, 3), faces.shape=(11173, 3))>, <trimesh.Trimesh(vertices.shape=(292, 3), faces.shape=(683, 3))>]\n",
      "xvfb-run -n 8231 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_37666.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_37666_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_697277.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_37666.off loaded has 32168 vn 62946 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_37666_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_697277.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1527384\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1527384\n",
      "LOG: 2 Successfully removed 7432 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7432 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1438200\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_697277.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 1356 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63713.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63713_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_657069.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63713.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63713_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_657069.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11636, 3), faces.shape=(23588, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(216, 3), faces.shape=(388, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(317, 3))>]\n",
      "xvfb-run -n 4120 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35898.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35898_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_222864.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35898.off loaded has 34492 vn 67359 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35898_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_222864.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1636116\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1636116\n",
      "LOG: 2 Successfully removed 7432 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7432 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1546932\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_222864.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 3924 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90055.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90055_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_445725.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90055.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90055_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_445725.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11956, 3), faces.shape=(24547, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(216, 3), faces.shape=(386, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(316, 3))>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9789 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_434094.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_434094_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_74662.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_434094.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_434094_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_74662.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.13129291878587065\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(23352, 3), faces.shape=(50653, 3))>, <trimesh.Trimesh(vertices.shape=(21656, 3), faces.shape=(46562, 3))>, <trimesh.Trimesh(vertices.shape=(16787, 3), faces.shape=(37230, 3))>, <trimesh.Trimesh(vertices.shape=(2323, 3), faces.shape=(4219, 3))>, <trimesh.Trimesh(vertices.shape=(2274, 3), faces.shape=(4133, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4430, 3))>, <trimesh.Trimesh(vertices.shape=(1382, 3), faces.shape=(3130, 3))>, <trimesh.Trimesh(vertices.shape=(1216, 3), faces.shape=(2664, 3))>, <trimesh.Trimesh(vertices.shape=(1141, 3), faces.shape=(2524, 3))>, <trimesh.Trimesh(vertices.shape=(1096, 3), faces.shape=(2432, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2359, 3))>, <trimesh.Trimesh(vertices.shape=(954, 3), faces.shape=(2137, 3))>, <trimesh.Trimesh(vertices.shape=(927, 3), faces.shape=(2058, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(1997, 3))>, <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(2005, 3))>, <trimesh.Trimesh(vertices.shape=(897, 3), faces.shape=(1979, 3))>, <trimesh.Trimesh(vertices.shape=(798, 3), faces.shape=(1761, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(666, 3), faces.shape=(1169, 3))>, <trimesh.Trimesh(vertices.shape=(664, 3), faces.shape=(1451, 3))>, <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(970, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(880, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(907, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(817, 3))>, <trimesh.Trimesh(vertices.shape=(11691, 3), faces.shape=(24005, 3))>, <trimesh.Trimesh(vertices.shape=(5625, 3), faces.shape=(11631, 3))>, <trimesh.Trimesh(vertices.shape=(5542, 3), faces.shape=(11755, 3))>, <trimesh.Trimesh(vertices.shape=(2140, 3), faces.shape=(4393, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(5759, 3))>, <trimesh.Trimesh(vertices.shape=(1614, 3), faces.shape=(3209, 3))>, <trimesh.Trimesh(vertices.shape=(1041, 3), faces.shape=(2022, 3))>, <trimesh.Trimesh(vertices.shape=(683, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(1069, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(533, 3))>, <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(540, 3))>, <trimesh.Trimesh(vertices.shape=(315, 3), faces.shape=(510, 3))>, <trimesh.Trimesh(vertices.shape=(258, 3), faces.shape=(396, 3))>, <trimesh.Trimesh(vertices.shape=(217, 3), faces.shape=(389, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(320, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 342 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30420.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30420_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_83377.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30420.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30420_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_83377.mls is being deleted....\n",
      "xvfb-run -n 4777 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74986.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74986_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_498109.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74986.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74986_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_498109.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 334\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aba2e61a7e4c4b94e2b9c6c97fe3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1632192.770903119, after = 1632192.770903119,\n",
      "ratio = 1.0, difference = 0.0\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 9501 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_26275.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_26275_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_761604.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_26275.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_26275_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_761604.mls is being deleted....\n",
      "xvfb-run -n 5825 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36835.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36835_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_924496.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36835.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36835_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_924496.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 500\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7145b42d328c4a0f958335ae524094d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1222998.0250010542, after = 1222998.0250010542,\n",
      "ratio = 1.0, difference = 0.0\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 1056 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_70144.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_70144_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_978388.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_70144.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_70144_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_978388.mls is being deleted....\n",
      "xvfb-run -n 8979 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_76508.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_76508_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_260524.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_76508.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_76508_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_260524.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 287\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f733f65bfcb449aaacd0f1d54532a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 3296354.0779659273, after = 3242978.1697124294,\n",
      "ratio = 0.9838075925731757, difference = -53375.90825349791\n"
     ]
    }
   ],
   "source": [
    "somas = sm.extract_soma_center(segment_id,\n",
    "                      current_mesh_verts=current_neuron.vertices,\n",
    "                              current_mesh_faces=current_neuron.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-13 04:40:11,876 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-13 04:40:11,877 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-13 04:40:11,878 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-13 04:40:11,882 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-13 04:40:12,182 - settings - Setting enable_python_native_blobs to True\n",
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f35b364a4864a8faf0e0be484af258c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=somas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<trimesh.Trimesh(vertices.shape=(16618, 3), faces.shape=(32100, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(19122, 3), faces.shape=(38027, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(11595, 3), faces.shape=(22998, 3))>],\n",
       " 724.3477878570557,\n",
       " array([0.837648, 0.876341, 0.914713]),\n",
       " [],\n",
       " [<trimesh.Trimesh(vertices.shape=(29321, 3), faces.shape=(67347, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(19381, 3), faces.shape=(43426, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(11703, 3), faces.shape=(27556, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2589, 3), faces.shape=(5982, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2333, 3), faces.shape=(5392, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2330, 3), faces.shape=(5321, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2285, 3), faces.shape=(5270, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2132, 3), faces.shape=(4757, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1874, 3), faces.shape=(4197, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1667, 3), faces.shape=(3678, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3204, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1377, 3), faces.shape=(3147, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1109, 3), faces.shape=(2547, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(959, 3), faces.shape=(2136, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(841, 3), faces.shape=(1836, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(834, 3), faces.shape=(1817, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(710, 3), faces.shape=(1154, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(597, 3), faces.shape=(1336, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(545, 3), faces.shape=(1201, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(904, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(423, 3), faces.shape=(886, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(348, 3), faces.shape=(758, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(342, 3), faces.shape=(756, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(11347, 3), faces.shape=(22278, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1555, 3), faces.shape=(3692, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(509, 3), faces.shape=(1096, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(483, 3), faces.shape=(912, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(374, 3), faces.shape=(914, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(251, 3), faces.shape=(624, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(165, 3), faces.shape=(356, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(126, 3), faces.shape=(308, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1170, 3), faces.shape=(1921, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(502, 3), faces.shape=(971, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(460, 3), faces.shape=(902, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(420, 3), faces.shape=(819, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(323, 3), faces.shape=(477, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(251, 3), faces.shape=(517, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(235, 3), faces.shape=(486, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(187, 3), faces.shape=(392, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(181, 3), faces.shape=(321, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(146, 3), faces.shape=(300, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(3405, 3), faces.shape=(6968, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2927, 3), faces.shape=(5904, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(651, 3), faces.shape=(1206, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(256, 3), faces.shape=(598, 3))>])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function that is unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a822e0fd8e4d4ea4a8b1b6a8f8d8a583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19840d712a5d4da79974a3312431e097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 15000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 8352 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5516.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5516_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_156084.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5516.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5516_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_156084.mls is being deleted....\n",
      "There were 49 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 49\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(23298, 3), faces.shape=(50603, 3))>, <trimesh.Trimesh(vertices.shape=(21540, 3), faces.shape=(46467, 3))>, <trimesh.Trimesh(vertices.shape=(16734, 3), faces.shape=(37184, 3))>, <trimesh.Trimesh(vertices.shape=(2323, 3), faces.shape=(4219, 3))>, <trimesh.Trimesh(vertices.shape=(2274, 3), faces.shape=(4133, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4430, 3))>, <trimesh.Trimesh(vertices.shape=(1382, 3), faces.shape=(3130, 3))>, <trimesh.Trimesh(vertices.shape=(1216, 3), faces.shape=(2664, 3))>, <trimesh.Trimesh(vertices.shape=(1141, 3), faces.shape=(2524, 3))>, <trimesh.Trimesh(vertices.shape=(1096, 3), faces.shape=(2432, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2359, 3))>, <trimesh.Trimesh(vertices.shape=(954, 3), faces.shape=(2137, 3))>, <trimesh.Trimesh(vertices.shape=(927, 3), faces.shape=(2058, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(1997, 3))>, <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(2005, 3))>, <trimesh.Trimesh(vertices.shape=(897, 3), faces.shape=(1979, 3))>, <trimesh.Trimesh(vertices.shape=(798, 3), faces.shape=(1761, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(666, 3), faces.shape=(1169, 3))>, <trimesh.Trimesh(vertices.shape=(664, 3), faces.shape=(1451, 3))>, <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(970, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(880, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(907, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(817, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 3893934, Final mesh size: 3713763\n",
      "Total time = 190.4515504837036\n",
      "xvfb-run -n 7505 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25901700.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(432654, 3), faces.shape=(853661, 3))>, <trimesh.Trimesh(vertices.shape=(7080, 3), faces.shape=(13923, 3))>, <trimesh.Trimesh(vertices.shape=(4843, 3), faces.shape=(7205, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(432654, 3), faces.shape=(853661, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 751 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_27509.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_27509_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_868788.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_27509.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_27509_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_868788.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 269\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 6299 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/poisson_140559.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(57846, 3), faces.shape=(115700, 3))>, <trimesh.Trimesh(vertices.shape=(2848, 3), faces.shape=(5692, 3))>, <trimesh.Trimesh(vertices.shape=(2715, 3), faces.shape=(5426, 3))>, <trimesh.Trimesh(vertices.shape=(2477, 3), faces.shape=(4950, 3))>, <trimesh.Trimesh(vertices.shape=(2244, 3), faces.shape=(4488, 3))>, <trimesh.Trimesh(vertices.shape=(2100, 3), faces.shape=(4196, 3))>, <trimesh.Trimesh(vertices.shape=(1898, 3), faces.shape=(3796, 3))>, <trimesh.Trimesh(vertices.shape=(1875, 3), faces.shape=(3750, 3))>, <trimesh.Trimesh(vertices.shape=(1767, 3), faces.shape=(3538, 3))>, <trimesh.Trimesh(vertices.shape=(1696, 3), faces.shape=(3388, 3))>, <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(57846, 3), faces.shape=(115700, 3))>\n",
      "xvfb-run -n 9401 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(14455, 3), faces.shape=(28918, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0009527206420898438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115400_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 3.4502837657928467\n",
      "2) Finished: Generating CGAL segmentation for neuron: 3.937178134918213\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0, soma_sdf_value = 0.7670395\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.01096343994140625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 6.270408630371094e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.02631378173828125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.16086912155151367\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.7670395\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 0, 34, 35, 41, 33, 12, 18,  8, 14, 24,  3, 44, 13, 16,  6, 23, 21,\n",
      "        1,  7, 22,  9, 11, 39, 42, 15, 10, 30, 40, 43, 37,  2, 25, 28,  4,\n",
      "        5, 31, 36, 19, 20, 32, 29, 17, 38, 26, 27]), array([0.7670395 , 0.142273  , 0.103885  , 0.0920161 , 0.09093865,\n",
      "       0.09070015, 0.086696  , 0.0855804 , 0.0837012 , 0.08192535,\n",
      "       0.07968135, 0.0772857 , 0.07591035, 0.07573255, 0.0700934 ,\n",
      "       0.0699022 , 0.06149105, 0.0596518 , 0.0583475 , 0.0581237 ,\n",
      "       0.0579349 , 0.0566743 , 0.0524235 , 0.0519075 , 0.0515534 ,\n",
      "       0.05109585, 0.0506271 , 0.0496821 , 0.0495547 , 0.0481628 ,\n",
      "       0.0477939 , 0.0456554 , 0.04457315, 0.0444382 , 0.0431447 ,\n",
      "       0.0431379 , 0.0421053 , 0.0403091 , 0.03975745, 0.0395464 ,\n",
      "       0.0377897 , 0.0354938 , 0.03450595, 0.03291815, 0.0278645 ]))\n",
      "Sizes = [5554, 63, 179, 37, 160, 1652, 2115, 117, 373, 40, 3542, 258, 168, 218, 115, 429, 544, 425, 260, 920, 308, 495, 507, 179, 109, 170, 1079, 909, 39, 337, 323, 143, 1566, 283, 553, 131, 763, 681, 684, 214, 1358, 129, 610, 124, 55]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9623 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_779338.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_779338_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_890095.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_779338.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_779338_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_890095.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 6.432186540201337\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(2848, 3), faces.shape=(5692, 3))>\n",
      "xvfb-run -n 8877 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(713, 3), faces.shape=(1422, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002162456512451172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08254289627075195\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11824154853820801\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006885528564453125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.245208740234375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001615762710571289\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007380247116088867\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 4, 3, 0]), array([0.852138 , 0.372811 , 0.2151145, 0.150057 , 0.125077 ]))\n",
      "Sizes = [125, 65, 118, 301, 813]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(409, 3), faces.shape=(813, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021338462829589844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.040807485580444336\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.05800175666809082\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005261898040771484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.9591064453125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009412765502929688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003981590270996094\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 1, 4, 0, 2, 3]), array([0.584389, 0.545621, 0.459352, 0.370279, 0.366455, 0.33795 ]))\n",
      "Sizes = [76, 174, 222, 111, 136, 94]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(114, 3), faces.shape=(222, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020360946655273438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.01085805892944336\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.018845319747924805\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0001800060272216797\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.124641418457031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000408172607421875\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0011050701141357422\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.887441, 0.473899]))\n",
      "Sizes = [27, 195]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(2715, 3), faces.shape=(5426, 3))>\n",
      "xvfb-run -n 1514 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(679, 3), faces.shape=(1354, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004754066467285156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115402_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1475973129272461\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.17308950424194336\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008394718170166016\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001804828643798828\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014295578002929688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007049083709716797\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 5, 3, 0, 7, 2, 4, 6]), array([0.8728845, 0.774169 , 0.58868  , 0.573648 , 0.373987 , 0.269168 ,\n",
      "       0.251319 , 0.232877 ]))\n",
      "Sizes = [238, 271, 279, 321, 118, 35, 52, 40]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(165, 3), faces.shape=(321, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000194549560546875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115402_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.027236223220825195\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03458690643310547\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00018978118896484375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001270771026611328\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00032830238342285156\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0020711421966552734\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.73012]))\n",
      "Sizes = [321]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(165, 3), faces.shape=(321, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020313262939453125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115402_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.027141571044921875\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.036223411560058594\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00020122528076171875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002434253692626953\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00032901763916015625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0016300678253173828\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.73012]))\n",
      "Sizes = [321]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(2477, 3), faces.shape=(4950, 3))>\n",
      "xvfb-run -n 6631 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(620, 3), faces.shape=(1236, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004355907440185547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115403_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10888814926147461\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13816165924072266\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006031990051269531\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002033710479736328\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013630390167236328\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006330251693725586\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 4, 3, 0, 5]), array([0.853208 , 0.462021 , 0.4574875, 0.2572435, 0.0950371, 0.0600612]))\n",
      "Sizes = [299, 299, 496, 42, 71, 29]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(251, 3), faces.shape=(496, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003256797790527344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115403_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04249930381774902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Finished: Generating CGAL segmentation for neuron: 0.05433464050292969\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002574920654296875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.1961669921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005419254302978516\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0024902820587158203\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.629675]))\n",
      "Sizes = [496]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(251, 3), faces.shape=(496, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020623207092285156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115403_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04710984230041504\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06093573570251465\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002665519714355469\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.3392181396484375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0006535053253173828\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0024788379669189453\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.629675]))\n",
      "Sizes = [496]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(2244, 3), faces.shape=(4488, 3))>\n",
      "xvfb-run -n 6117 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(561, 3), faces.shape=(1122, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000293731689453125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115404_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10756278038024902\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13450169563293457\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005507469177246094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00018310546875\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010764598846435547\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005379676818847656\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 4, 0, 3, 1]), array([0.82308 , 0.747646, 0.586211, 0.342029, 0.114341]))\n",
      "Sizes = [307, 266, 350, 157, 42]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(181, 3), faces.shape=(350, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002875328063964844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115404_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.03650665283203125\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04622316360473633\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00021910667419433594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.410743713378906e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005209445953369141\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.001836538314819336\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7223455]))\n",
      "Sizes = [350]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(181, 3), faces.shape=(350, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021457672119140625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115404_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.033005714416503906\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04234004020690918\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002913475036621094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.3392181396484375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003662109375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0019021034240722656\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7223455]))\n",
      "Sizes = [350]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(2100, 3), faces.shape=(4196, 3))>\n",
      "xvfb-run -n 3332 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(526, 3), faces.shape=(1048, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00030159950256347656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115405_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11030936241149902\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13049793243408203\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004999637603759766\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.173683166503906e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011010169982910156\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005019187927246094\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.52226 , 0.485363]))\n",
      "Sizes = [218, 830]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3731 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_206243.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_206243_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_207395.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_206243.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_206243_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_207395.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.402030441552503\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(1898, 3), faces.shape=(3796, 3))>\n",
      "xvfb-run -n 9311 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(474, 3), faces.shape=(948, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022983551025390625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115406_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09038352966308594\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10878634452819824\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005941390991210938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.2928924560546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016646385192871094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004900217056274414\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 3, 2, 4]), array([0.811042  , 0.389099  , 0.242819  , 0.214927  , 0.08927015]))\n",
      "Sizes = [372, 413, 38, 91, 34]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(209, 3), faces.shape=(413, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020456314086914062\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115406_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04458737373352051\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.053319454193115234\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002474784851074219\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.220008850097656e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00041747093200683594\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0020415782928466797\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.4787   , 0.1703635, 0.166315 ]))\n",
      "Sizes = [314, 40, 59]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(161, 3), faces.shape=(314, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002014636993408203\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115406_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.02755880355834961\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.034806251525878906\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0001926422119140625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0003237724304199219\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0015654563903808594\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.4377005]))\n",
      "Sizes = [314]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(1875, 3), faces.shape=(3750, 3))>\n",
      "xvfb-run -n 5529 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(468, 3), faces.shape=(936, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021886825561523438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115407_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0586698055267334\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07534170150756836\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005891323089599609\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.412101745605469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009393692016601562\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004533529281616211\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0]), array([0.645915, 0.511165, 0.456919]))\n",
      "Sizes = [193, 522, 221]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(262, 3), faces.shape=(522, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021719932556152344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115407_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.028942346572875977\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.04132270812988281\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0002675056457519531\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005190372467041016\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0025854110717773438\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5117775]))\n",
      "Sizes = [522]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(262, 3), faces.shape=(522, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022339820861816406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115407_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.029804468154907227\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.03977775573730469\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00028014183044433594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.291534423828125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0005574226379394531\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0028839111328125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5117775]))\n",
      "Sizes = [522]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(1767, 3), faces.shape=(3538, 3))>\n",
      "xvfb-run -n 2889 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(440, 3), faces.shape=(884, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023245811462402344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115408_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05696678161621094\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07513093948364258\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004119873046875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.030632019042969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008988380432128906\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004303455352783203\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.392913]))\n",
      "Sizes = [884]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_800131.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 459.7237708784857\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(440, 3), faces.shape=(884, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/826_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881331b189e34c6289e968dbc48dc0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_649435.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 459.7237708784857\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(440, 3), faces.shape=(884, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(1696, 3), faces.shape=(3388, 3))>\n",
      "xvfb-run -n 2892 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(425, 3), faces.shape=(846, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002541542053222656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115409_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08057689666748047\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10483908653259277\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005271434783935547\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.221366882324219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008668899536132812\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004106044769287109\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([4, 3, 0, 2, 5, 6, 7, 1]), array([0.835255 , 0.8347375, 0.7589165, 0.453566 , 0.431922 , 0.340356 ,\n",
      "       0.168269 , 0.141433 ]))\n",
      "Sizes = [191, 210, 156, 69, 70, 67, 18, 65]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(108, 3), faces.shape=(210, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021386146545410156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115409_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.01863408088684082\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.024353504180908203\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.000164031982421875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.3392181396484375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00022530555725097656\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0010199546813964844\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7647155]))\n",
      "Sizes = [210]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(108, 3), faces.shape=(210, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021076202392578125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115409_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.018591880798339844\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.025274991989135742\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00016188621520996094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00016546249389648438\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0002300739288330078\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0016524791717529297\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.7647155]))\n",
      "Sizes = [210]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>\n",
      "xvfb-run -n 5025 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(422, 3), faces.shape=(840, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003440380096435547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135654121154010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.052346229553222656\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07681083679199219\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1, soma_sdf_value = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0016396045684814453\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001533031463623047\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0037245750427246094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005063533782958984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 0, 1, 2, 4]), array([0.821113 , 0.520434 , 0.477387 , 0.397839 , 0.2818235]))\n",
      "Sizes = [30, 636, 93, 61, 20]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_975472.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 438.8521472797833\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(321, 3), faces.shape=(636, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/346_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5830f536c754ddb8bbd2520ba47bb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_158708.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 438.8521472797833\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(321, 3), faces.shape=(636, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(7080, 3), faces.shape=(13923, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 5277 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80659.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80659_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_892597.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80659.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80659_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_892597.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off\n",
      "xvfb-run -n 2446 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/poisson_140559.mls\n",
      "Total found significant pieces AFTER Poisson = []\n",
      "----- working on large mesh #2: <trimesh.Trimesh(vertices.shape=(4843, 3), faces.shape=(7205, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8381 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32358.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32358_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_745676.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32358.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32358_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_745676.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 82\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off\n",
      "xvfb-run -n 1540 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/poisson_140559.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(30895, 3), faces.shape=(61483, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(30895, 3), faces.shape=(61483, 3))>\n",
      "xvfb-run -n 2955 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135654121154/decimation_meshlab_25925615.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135654121154_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(7832, 3), faces.shape=(15357, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007343292236328125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113565412115420_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.7398414611816406\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.9975850582122803\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "soma_index = 2, soma_sdf_value = 0.7145589999999999\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00586247444152832\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.817413330078125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.013631582260131836\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.08914399147033691\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.7145589999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 2, 0, 1, 4]), array([0.7203975, 0.714559 , 0.515193 , 0.28007  , 0.0494622]))\n",
      "Sizes = [2176, 3192, 8766, 1214, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [3, 2, 0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4934 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_249915.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_249915_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_606153.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_249915.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_249915_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_606153.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.006129384047377571\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4098 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_544379.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_544379_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_790642.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_544379.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_544379_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_790642.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.027184592542104393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3388 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_33623.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_33623_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_548504.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_33623.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_33623_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_548504.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.02551870668431357\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 502.74911856651306\n",
      "Before Filtering the number of somas found = 5\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 0\n",
      "xvfb-run -n 7526 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_33131.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_33131_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_982448.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_33131.off loaded has 149178 vn 294641 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_33131_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_982448.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Successfully removed 22676 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 22676 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 6843852\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_982448.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 1451 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48768.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48768_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_567249.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48768.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48768_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_567249.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11691, 3), faces.shape=(24005, 3))>, <trimesh.Trimesh(vertices.shape=(5625, 3), faces.shape=(11631, 3))>, <trimesh.Trimesh(vertices.shape=(5542, 3), faces.shape=(11755, 3))>, <trimesh.Trimesh(vertices.shape=(2140, 3), faces.shape=(4393, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(5759, 3))>, <trimesh.Trimesh(vertices.shape=(1614, 3), faces.shape=(3209, 3))>, <trimesh.Trimesh(vertices.shape=(1041, 3), faces.shape=(2022, 3))>, <trimesh.Trimesh(vertices.shape=(683, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(1069, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(533, 3))>, <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(540, 3))>, <trimesh.Trimesh(vertices.shape=(315, 3), faces.shape=(510, 3))>, <trimesh.Trimesh(vertices.shape=(258, 3), faces.shape=(396, 3))>, <trimesh.Trimesh(vertices.shape=(217, 3), faces.shape=(389, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(320, 3))>]\n",
      "After backtrack the found 1 possible somas: [<trimesh.Trimesh(vertices.shape=(49870, 3), faces.shape=(97939, 3))>] \n",
      "\n",
      "--- workin on backtrack soma 0: <trimesh.Trimesh(vertices.shape=(49870, 3), faces.shape=(97939, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2200 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_774002.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_774002_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_624697.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_774002.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_774002_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_624697.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.284280228241844\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(49870, 3), faces.shape=(97939, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 1\n",
      "xvfb-run -n 301 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75045.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75045_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_486087.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75045.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75045_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_486087.mls is being deleted....\n",
      "xvfb-run -n 4729 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99332.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99332_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_795700.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99332.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99332_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_795700.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "After backtrack the found 0 possible somas: [] \n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 2\n",
      "xvfb-run -n 6072 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68529.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68529_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_329009.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68529.off loaded has 14593 vn 27922 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68529_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_329009.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 685296\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 685296\n",
      "LOG: 2 Successfully removed 4504 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 4504 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 631248\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_329009.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 7031 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_78276.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_78276_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_150101.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_78276.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_78276_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_150101.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5716, 3), faces.shape=(11173, 3))>, <trimesh.Trimesh(vertices.shape=(292, 3), faces.shape=(683, 3))>]\n",
      "After backtrack the found 0 possible somas: [] \n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 3\n",
      "xvfb-run -n 3920 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55815.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55815_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_796869.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55815.off loaded has 32168 vn 62946 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55815_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_796869.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1527384\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1527384\n",
      "LOG: 2 Successfully removed 7432 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7432 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1438200\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_796869.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 9544 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65228.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65228_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_431117.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65228.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65228_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_431117.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11636, 3), faces.shape=(23588, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(216, 3), faces.shape=(388, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(317, 3))>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backtrack the found 0 possible somas: [] \n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 4\n",
      "xvfb-run -n 9629 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_47354.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_47354_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_987967.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_47354.off loaded has 34492 vn 67359 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_47354_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_987967.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1636116\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1636116\n",
      "LOG: 2 Successfully removed 7432 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 7432 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1546932\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_987967.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 1132 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32334.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32334_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_87982.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32334.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_32334_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_87982.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11956, 3), faces.shape=(24547, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(216, 3), faces.shape=(386, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(316, 3))>]\n",
      "After backtrack the found 1 possible somas: [<trimesh.Trimesh(vertices.shape=(7017, 3), faces.shape=(13301, 3))>] \n",
      "\n",
      "--- workin on backtrack soma 0: <trimesh.Trimesh(vertices.shape=(7017, 3), faces.shape=(13301, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9179 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_986363.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_986363_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_194206.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_986363.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_986363_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_194206.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.13129291878587065\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(23352, 3), faces.shape=(50653, 3))>, <trimesh.Trimesh(vertices.shape=(21656, 3), faces.shape=(46562, 3))>, <trimesh.Trimesh(vertices.shape=(16787, 3), faces.shape=(37230, 3))>, <trimesh.Trimesh(vertices.shape=(2323, 3), faces.shape=(4219, 3))>, <trimesh.Trimesh(vertices.shape=(2274, 3), faces.shape=(4133, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4430, 3))>, <trimesh.Trimesh(vertices.shape=(1382, 3), faces.shape=(3130, 3))>, <trimesh.Trimesh(vertices.shape=(1216, 3), faces.shape=(2664, 3))>, <trimesh.Trimesh(vertices.shape=(1141, 3), faces.shape=(2524, 3))>, <trimesh.Trimesh(vertices.shape=(1096, 3), faces.shape=(2432, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2359, 3))>, <trimesh.Trimesh(vertices.shape=(954, 3), faces.shape=(2137, 3))>, <trimesh.Trimesh(vertices.shape=(927, 3), faces.shape=(2058, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(1997, 3))>, <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(2005, 3))>, <trimesh.Trimesh(vertices.shape=(897, 3), faces.shape=(1979, 3))>, <trimesh.Trimesh(vertices.shape=(798, 3), faces.shape=(1761, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(666, 3), faces.shape=(1169, 3))>, <trimesh.Trimesh(vertices.shape=(664, 3), faces.shape=(1451, 3))>, <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(970, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(880, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(907, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(817, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 4112 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_98204.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_98204_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_652620.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_98204.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_98204_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_652620.mls is being deleted....\n",
      "xvfb-run -n 9918 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_6320.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_6320_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_976330.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_6320.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_6320_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_976330.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 287\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5610656dd44a14a61176845249f88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 3296354.0779659273, after = 3242978.1697124294,\n",
      "ratio = 0.9838075925731757, difference = -53375.90825349791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n",
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    }
   ],
   "source": [
    "from soma_extraction_utils import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "segment_id = segment_id\n",
    "current_mesh_verts = current_neuron.vertices\n",
    "current_mesh_faces = current_neuron.faces\n",
    "current_mesh = None\n",
    "\n",
    "\n",
    "outer_decimation_ratio= 0.25\n",
    "large_mesh_threshold = 20000#60000,\n",
    "large_mesh_threshold_inner = 13000 #was changed so dont filter away som somas\n",
    "soma_width_threshold = 0.32\n",
    "soma_size_threshold = 9000 #changed this to smaller so didn't filter some somas away\n",
    "inner_decimation_ratio = 0.25\n",
    "volume_mulitplier=8\n",
    "#side_length_ratio_threshold=3\n",
    "side_length_ratio_threshold=6\n",
    "soma_size_threshold_max=240000#192000 #this puts at 12000 once decimated, another possible is 256000\n",
    "delete_files=True\n",
    "backtrack_soma_mesh_to_original=True #should either be None or \n",
    "boundary_vertices_threshold=None#700 the previous threshold used\n",
    "poisson_backtrack_distance_threshold=None#1500 the previous threshold used\n",
    "close_holes=False\n",
    "\n",
    "#------- 11/12 Additions --------------- #\n",
    "\n",
    "#these arguments are for removing inside pieces\n",
    "remove_inside_pieces = True\n",
    "size_threshold_to_remove=1000 #size accounting for the decimation\n",
    "\n",
    "\n",
    "pymeshfix_clean=False\n",
    "check_holes_before_pymeshfix=False\n",
    "second_poisson=False\n",
    "segmentation_at_end=True\n",
    "last_size_threshold = 2000#1300,\n",
    "\n",
    "largest_hole_threshold = 17000\n",
    "max_fail_loops = 10\n",
    "perform_pairing = False\n",
    "verbose = True\n",
    "return_glia_nuclei_pieces = True\n",
    "\n",
    "backtrack_soma_size_threshold = 13000\n",
    "\n",
    "filter_inside_meshes_after_glia_removal = False\n",
    "max_mesh_sized_filtered_away = 90000\n",
    "\n",
    "filter_inside_somas=True\n",
    "\n",
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "#Adjusting the thresholds based on the decimations\n",
    "large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "max_mesh_sized_filtered_away = max_mesh_sized_filtered_away*outer_decimation_ratio\n",
    "\n",
    "#adjusting for inner decimation\n",
    "soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "\n",
    "print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "             f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "              f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "             f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "             f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "             f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\"\n",
    "     f\"\\nmax_mesh_sized_filtered_away = {max_mesh_sized_filtered_away}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "temp_folder = f\"./{segment_id}\"\n",
    "temp_object = Path(temp_folder)\n",
    "#make the temp folder if it doesn't exist\n",
    "temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#making the decimation and poisson objections\n",
    "Dec_outer = meshlab.Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "Dec_inner = meshlab.Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "Poisson_obj = meshlab.Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "\n",
    "recov_orig_mesh = trimesh.Trimesh(vertices=current_mesh_verts,faces=current_mesh_faces)\n",
    "\n",
    "try:\n",
    "    recov_orig_mesh_no_interior, glia_pieces, nuclei_pieces  = tu.remove_nuclei_and_glia_meshes(recov_orig_mesh,verbose=True)\n",
    "except:\n",
    "    print(\"**Unable to remove_nuclei_and_glia_meshes: so just continuing without doing so **\")\n",
    "    recov_orig_mesh_no_interior = recov_orig_mesh\n",
    "    glia_pieces = []\n",
    "    nuclei_pieces = []\n",
    "#recov_orig_mesh_no_interior = tu.remove_mesh_interior(recov_orig_mesh)\n",
    "\n",
    "\n",
    "#Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "new_mesh,output_obj = Dec_outer(vertices=recov_orig_mesh_no_interior.vertices,\n",
    "         faces=recov_orig_mesh_no_interior.faces,\n",
    "         segment_id=segment_id,\n",
    "         return_mesh=True,\n",
    "         delete_temp_files=False)\n",
    "\n",
    "# if remove_inside_pieces:\n",
    "#     print(\"removing mesh interior after decimation\")\n",
    "#     new_mesh = tu.remove_mesh_interior(new_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "#preforming the splits of the decimated mesh\n",
    "\n",
    "mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "# --------- 1/11 Addition: Filtering away large meshes that are inside another --------- #\n",
    "if filter_inside_meshes_after_glia_removal:\n",
    "    print(f\"Filtering away larger meshes that are inside others, before # of meshes = {len(list_of_largest_mesh)}\")\n",
    "    list_of_largest_mesh = tu.filter_away_inside_meshes(list_of_largest_mesh,verbose=True,return_meshes=True,\n",
    "                                                       max_mesh_sized_filtered_away=max_mesh_sized_filtered_away)\n",
    "    print(f\"After # of meshes = {len(list_of_largest_mesh)}\")\n",
    "\n",
    "\n",
    "#if no significant pieces were found then will use smaller threshold\n",
    "if len(list_of_largest_mesh)<=0:\n",
    "    print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "    list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "total_soma_list = []\n",
    "total_classifier_list = []\n",
    "total_poisson_list = []\n",
    "total_soma_list_sdf = []\n",
    "\n",
    "\n",
    "\n",
    "#start iterating through where go through all pieces before the poisson reconstruction\n",
    "no_somas_found_in_big_loop = 0\n",
    "for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "    print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "    if remove_inside_pieces:\n",
    "        print(\"remove_inside_pieces requested \")\n",
    "        try:\n",
    "            largest_mesh = tu.remove_mesh_interior(largest_mesh,\n",
    "                                                   size_threshold_to_remove=size_threshold_to_remove,\n",
    "                                                  try_hole_close=False)\n",
    "        except:\n",
    "            print(\"Unable to remove inside pieces in list_of_largest_mesh\")\n",
    "            largest_mesh = largest_mesh\n",
    "\n",
    "\n",
    "    if pymeshfix_clean:\n",
    "        print(\"Requested pymeshfix_clean\")\n",
    "        \"\"\"\n",
    "        Don't have to check if manifold anymore actually just have to plug the holes\n",
    "        \"\"\"\n",
    "        hole_groups = tu.find_border_face_groups(largest_mesh)\n",
    "        if len(hole_groups) > 0:\n",
    "            largest_mesh_filled_holes = tu.fill_holes(largest_mesh,max_hole_size = 10000)\n",
    "        else:\n",
    "            largest_mesh_filled_holes = largest_mesh\n",
    "\n",
    "        if check_holes_before_pymeshfix:\n",
    "            hole_groups = tu.find_border_face_groups(largest_mesh_filled_holes)\n",
    "        else:\n",
    "            print(\"Not checking if there are still existing holes before pymeshfix\")\n",
    "            hole_groups = []\n",
    "\n",
    "        if len(hole_groups) > 0:\n",
    "            #segmentation_at_end = False\n",
    "            print(f\"*** COULD NOT FILL HOLES WITH MAX SIZE OF {np.max([len(k) for k in hole_groups])} so not applying pymeshfix and segmentation_at_end = {segmentation_at_end}\")\n",
    "\n",
    "#                 tu.write_neuron_off(largest_mesh_filled_holes,\"largest_mesh_filled_holes\")\n",
    "#                 raise Exception()\n",
    "        else:\n",
    "            print(\"Applying pymeshfix_clean because no more holes\")\n",
    "            largest_mesh = tu.pymeshfix_clean(largest_mesh_filled_holes,verbose=True)\n",
    "\n",
    "    if second_poisson:\n",
    "        print(\"Applying second poisson run\")\n",
    "        current_neuron_poisson = tu.poisson_surface_reconstruction(largest_mesh)\n",
    "        largest_mesh = tu.split_significant_pieces(current_neuron_poisson,connectivity=soma_connectivity)[0]\n",
    "\n",
    "    somas_found_in_big_loop = False\n",
    "\n",
    "    largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "    pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "    pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "    print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "    # ******* This ERRORED AND CALLED OUR NERUON NONE: 77697401493989254 *********\n",
    "    new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "               faces=largest_mesh.faces,\n",
    "               return_mesh=True,\n",
    "               mesh_filename=largest_file_name,\n",
    "               delete_temp_files=False)\n",
    "\n",
    "\n",
    "    #splitting the Poisson into the largest pieces and ordering them\n",
    "    mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "    list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "    print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "    n_failed_inner_soma_loops = 0\n",
    "    for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "        to_add_list = []\n",
    "        to_add_list_sdf = []\n",
    "\n",
    "        print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "        largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "        #Decimate the inner poisson piece\n",
    "        largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                            vertices=largest_mesh_inner.vertices,\n",
    "                             faces=largest_mesh_inner.faces,\n",
    "                            mesh_filename=largest_mesh_path_inner,\n",
    "                             return_mesh=True,\n",
    "                             delete_temp_files=False)\n",
    "\n",
    "        dec_splits = tu.split_significant_pieces(largest_mesh_path_inner_decimated,significance_threshold=15,\n",
    "                                                connectivity=soma_connectivity,)\n",
    "        print(f\"\\n-------Splits after inner decimation len = {len(dec_splits)}--------\\n\")\n",
    "\n",
    "        if len(dec_splits) == 0:\n",
    "            print(\"There were no signifcant splits after inner decimation\")\n",
    "            n_failed_inner_soma_loops += 1\n",
    "        else:\n",
    "            print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "            largest_mesh_path_inner_decimated_clean = dec_splits[0]\n",
    "            \"\"\" # ----------- 1/12: Addition that does the segmentation again -------------------- #\"\"\"\n",
    "\n",
    "            for ii in range(3):\n",
    "                print(f\"\\n    --- On segmentation loop {ii} --\")\n",
    "                print(f\"largest_mesh_path_inner_decimated_clean = {largest_mesh_path_inner_decimated_clean}\\n\")\n",
    "\n",
    "                faces = np.array(largest_mesh_path_inner_decimated_clean.faces)\n",
    "                verts = np.array(largest_mesh_path_inner_decimated_clean.vertices)\n",
    "\n",
    "                # may need to do some processing\n",
    "\n",
    "\n",
    "                segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "                #print(f\"Before the classifier the pymeshfix_clean = {pymeshfix_clean}\")\n",
    "                verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                        import_Off_Flag=False,\n",
    "                                        segment_id=segment_id_new,\n",
    "                                        vertices=verts,\n",
    "                                         triangles=faces,\n",
    "                                        pymeshfix_Flag=False,\n",
    "                                         import_CGAL_Flag=False,\n",
    "                                         return_Only_Labels=True,\n",
    "                                         clusters=3,\n",
    "                                         smoothness=0.2,\n",
    "                                        soma_only=True,\n",
    "                                        return_classifier = True\n",
    "                                        )\n",
    "                print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "                total_classifier_list.append(classifier)\n",
    "                #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "                # Save all of the portions that resemble a soma\n",
    "                median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "                segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "                #order the compartments by greatest to smallest\n",
    "                sorted_medians = np.flip(np.argsort(median_values))\n",
    "                print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "                print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "                print(f\"soma_size_threshold = {soma_size_threshold}\")\n",
    "                print(f\"soma_size_threshold_max={soma_size_threshold_max}\")\n",
    "\n",
    "                valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "                valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                    and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "                print(\"valid_soma_segments_width\")\n",
    "\n",
    "\n",
    "                \"\"\"# =------------- 1/12: Addition that will repeat this loop --------------\"\"\"\n",
    "                if len(valid_soma_segments_width) > 0:\n",
    "                    break\n",
    "                else:\n",
    "                    \"\"\"\n",
    "                    Pseudocode: \n",
    "                    Get the largest mesh segment\n",
    "                    \"\"\"\n",
    "                    new_mesh_try_faces = np.where(classifier.labels_list == nu.mode_1d(classifier.labels_list))[0]\n",
    "                    largest_mesh_path_inner_decimated_clean = largest_mesh_path_inner_decimated_clean.submesh([new_mesh_try_faces],append=True)\n",
    "\n",
    "            if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "\n",
    "\n",
    "                    if curr_side_len_check and curr_volume_check:\n",
    "                        #check if we can split this into two\n",
    "                        to_add_list.append(soma_mesh)\n",
    "                        to_add_list_sdf.append(sdf)\n",
    "\n",
    "                        \"\"\"  -----------Removed 1/12: When trying to force a split between them \n",
    "                        possible_smoothness = [0.2,0.05,0.01]\n",
    "                        for smooth_value in possible_smoothness:\n",
    "                            #1) Run th esegmentation algorithm again to segment the mesh (had to run the higher smoothing to seperate some)\n",
    "                            mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=smooth_value,verbose=True)\n",
    "                            mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                            #2) Filter out meshes by sizs and sdf threshold\n",
    "                            mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                            filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "                            if len(filtered_meshes_idx) >= 2:\n",
    "                                if verbose:\n",
    "                                    print(f\"Breakin on smoothness: {smooth_value}\")\n",
    "                                break\n",
    "\n",
    "                        if len(filtered_meshes_idx) >= 2:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            to_add_list_retry = []\n",
    "                            to_add_list_sdf_retry = []\n",
    "\n",
    "                            for f_m,f_m_sdf in zip(filtered_meshes,filtered_meshes_sdf):\n",
    "                                curr_side_len_check_retry = side_length_check(f_m,side_length_ratio_threshold)\n",
    "                                curr_volume_check_retry = soma_volume_check(f_m,volume_mulitplier)\n",
    "\n",
    "                                if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                    to_add_list_retry.append(f_m)\n",
    "                                    to_add_list_sdf_retry.append(f_m_sdf)\n",
    "\n",
    "                            if len(to_add_list_retry)>1:\n",
    "                                if verbose:\n",
    "                                    print(\"Using the new feature that split the soma further into more groups\")\n",
    "                                to_add_list += to_add_list_retry\n",
    "                                to_add_list_sdf += to_add_list_sdf_retry\n",
    "\n",
    "                            else:\n",
    "                                to_add_list.append(soma_mesh)\n",
    "                                to_add_list_sdf.append(sdf)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            to_add_list.append(soma_mesh)\n",
    "                            to_add_list_sdf.append(sdf)\n",
    "                        \"\"\"\n",
    "\n",
    "                    else:\n",
    "                        # ---------- 1/7 Addition: Trying one more additional cgal segmentation to see if there is actually a soma ---\n",
    "                        \"\"\"\n",
    "                        Pseudocode: \n",
    "                        1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        2) Filter out meshes by sizs and sdf threshold\n",
    "                        3) If there are any remaining meshes, pick the largest sdf mesh and test for volume and side length check\n",
    "                        --> if matches then adds\n",
    "                        \"\"\"\n",
    "\n",
    "                        print(f\"->Attempting retry of soma because failed first checks: \"\n",
    "                                 f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                        #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                        mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                        #2) Filter out meshes by sizs and sdf threshold\n",
    "                        mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                        filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "\n",
    "                        if len(filtered_meshes_idx) > 0:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            sdf_winning_index = np.argmax(filtered_meshes_sdf)\n",
    "                            soma_mesh_retry = filtered_meshes[sdf_winning_index]\n",
    "                            sdf_retry = filtered_meshes_sdf[sdf_winning_index]\n",
    "\n",
    "                            curr_side_len_check_retry = side_length_check(soma_mesh_retry,side_length_ratio_threshold)\n",
    "                            curr_volume_check_retry = soma_volume_check(soma_mesh_retry,volume_mulitplier)\n",
    "\n",
    "                            if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                to_add_list.append(soma_mesh_retry)\n",
    "                                to_add_list_sdf.append(sdf_retry)\n",
    "                            else:\n",
    "                                print(f\"--->This soma mesh was not added because failed retry of sphere validation:\\n \"\n",
    "                                     f\"soma_mesh = {soma_mesh_retry}, curr_side_len_check = {curr_side_len_check_retry}, curr_volume_check = {curr_volume_check_retry}\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(f\"Could not find valid soma mesh in retry\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "                n_failed_inner_soma_loops = 0\n",
    "\n",
    "            else:\n",
    "                n_failed_inner_soma_loops += 1\n",
    "\n",
    "        total_soma_list_sdf += to_add_list_sdf\n",
    "        total_soma_list += to_add_list\n",
    "\n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if n_failed_inner_soma_loops >= max_fail_loops:\n",
    "            print(f\"breaking inner loop because {max_fail_loops} soma fails in a row\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "    if somas_found_in_big_loop == False:\n",
    "        no_somas_found_in_big_loop += 1\n",
    "        if no_somas_found_in_big_loop >= max_fail_loops:\n",
    "            print(f\"breaking because {max_fail_loops} fails in a row in big loop\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        no_somas_found_in_big_loop = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "pairings = []\n",
    "\n",
    "if perform_pairing:\n",
    "    for y,soma_1 in enumerate(total_soma_list):\n",
    "        for z,soma_2 in enumerate(total_soma_list):\n",
    "            if y<z:\n",
    "                mesh_tree = KDTree(soma_1.vertices)\n",
    "                distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "                if np.min(distances) < 4000:\n",
    "                    pairings.append([y,z])\n",
    "\n",
    "\n",
    "#creating the combined meshes from the list\n",
    "total_soma_list_revised = []\n",
    "total_soma_list_revised_sdf = []\n",
    "if len(pairings) > 0:\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    Use a network function to find components\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    new_graph = nx.Graph()\n",
    "    new_graph.add_edges_from(pairings)\n",
    "    grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "    somas_being_combined = []\n",
    "    print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "    for comp in grouped_somas:\n",
    "        comp = list(comp)\n",
    "        somas_being_combined += list(comp)\n",
    "        current_mesh = total_soma_list[comp[0]]\n",
    "        for i in range(1,len(comp)):\n",
    "            current_mesh += total_soma_list[comp[i]] #just combining the actual meshes\n",
    "\n",
    "        total_soma_list_revised.append(current_mesh)\n",
    "        #where can average all of the sdf values\n",
    "        total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "    #add those that weren't combined to total_soma_list_revised\n",
    "    leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    if len(leftover_somas) > 0:\n",
    "        total_soma_list_revised += leftover_somas\n",
    "        total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "    print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "    print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "if len(total_soma_list_revised) == 0:\n",
    "    total_soma_list_revised = total_soma_list\n",
    "    total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "run_time = time.time() - global_start_time\n",
    "\n",
    "print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "#     import system_utils as su\n",
    "#     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "#     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "#need to erase all of the temporary files ******\n",
    "#import shutil\n",
    "#shutil.rmtree(directory)\n",
    "\n",
    "\"\"\"\n",
    "Running the extra tests that depend on\n",
    "- border vertices\n",
    "- how well the poisson matches the backtracked soma to the real mesh\n",
    "- other size checks\n",
    "\n",
    "\"\"\"\n",
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "\n",
    "for yy,(soma_mesh,curr_soma_sdf) in enumerate(zip(total_soma_list_revised,total_soma_list_revised_sdf)):\n",
    "    add_inside_pieces_flag = False\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        if verbose:\n",
    "            print(f\"\\n---Performing Soma Mesh Backtracking to original mesh for poisson soma {yy}\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "        try:\n",
    "            soma_mesh_list,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                            original_mesh = recov_orig_mesh_no_interior,\n",
    "                                            mesh=soma_mesh_poisson,\n",
    "                                            soma_size_threshold=backtrack_soma_size_threshold)\n",
    "\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "\n",
    "        if soma_mesh_list is None:\n",
    "                print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        if verbose: \n",
    "            print(f\"After backtrack the found {len(soma_mesh_list)} possible somas: {soma_mesh_list} \")\n",
    "\n",
    "        for rr,soma_mesh in enumerate(soma_mesh_list):\n",
    "            if verbose:\n",
    "                print(f\"\\n--- workin on backtrack soma {rr}: {soma_mesh}\")\n",
    "\n",
    "            print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "            #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "            if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "                #soma_mesh.export(\"soma_mesh.off\")\n",
    "                if close_holes: \n",
    "                    print(\"Using the close holes feature\")\n",
    "                    fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                     self_itersect_faces=False)\n",
    "\n",
    "                    soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                        vertices=soma_mesh.vertices,\n",
    "                                                         faces=soma_mesh.faces,\n",
    "                                                         return_mesh=True,\n",
    "                                                         delete_temp_files=True,\n",
    "                                                        )\n",
    "                else:\n",
    "                    soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "                #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "                print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "                mesh_1 = soma_mesh_filled_holes\n",
    "                mesh_2 = soma_mesh_poisson\n",
    "\n",
    "                poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                                  verbose=True)\n",
    "                print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "                if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                      f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #do the boundary check:\n",
    "            if not boundary_vertices_threshold is None:\n",
    "                print(\"USING boundary_vertices_threshold CHECK\")\n",
    "                soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "                print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "                large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "                print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "                if len(large_boundary_groups)>0:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                          f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "                    continue\n",
    "\n",
    "            curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "            curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "            if (not curr_side_len_check) or (not curr_volume_check):\n",
    "                print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "                     f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                continue\n",
    "\n",
    "            #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "            #If made it through all the checks then add to final list\n",
    "            filtered_soma_list.append(soma_mesh)\n",
    "            filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "            add_inside_pieces_flag = True #setting flag so will add inside pieces\n",
    "\n",
    "\n",
    "    if len(soma_mesh_inside_pieces) > 0 and add_inside_pieces_flag:\n",
    "        print(f\"About to add the following inside nuclei pieces after soma backtrack: {nuclei_pieces}\")\n",
    "        nuclei_pieces +=soma_mesh_inside_pieces\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Need to delete all files in the temp folder *****\n",
    "\"\"\"\n",
    "\n",
    "if delete_files:\n",
    "    #now erase all of the files used\n",
    "    from shutil import rmtree\n",
    "\n",
    "    #remove the directory with the meshes\n",
    "    rmtree(str(temp_object.absolute()))\n",
    "\n",
    "    #removing the temporary files\n",
    "    temp_folder = Path(\"./temp\")\n",
    "    temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "    seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "    for f in seg_temp_files:\n",
    "        f.unlink()\n",
    "\n",
    "# ----------- 11 /11 Addition that does a last step segmentation of the soma --------- #\n",
    "#return total_soma_list, run_time\n",
    "#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n",
    "\"\"\"\n",
    "Things we should ask about the segmentation:\n",
    "\n",
    "Advantages: \n",
    "1) could help filter away negatives\n",
    "\n",
    "Disadvantages:\n",
    "1) Can actually cut up the soma and then filter away the soma (not what we want)\n",
    "2) Could introduce a big hole (don't think can guard against this)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#filtered_soma_list_saved = copy.deepcopy(filtered_soma_list)\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "\n",
    "        print(\"Skipping the segmentatio filter at end\")\n",
    "        if not (len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold):\n",
    "            print(f\"Soma (size = {len(f_soma.faces)}, width={soma_width_threshold}) did not pass thresholds (size threshold={last_size_threshold}, width threshold = {soma_width_threshold}) \")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if segmentation_at_end:\n",
    "\n",
    "\n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "#                 print(f\"meshes_split = {meshes_split}\")\n",
    "#                 print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                print(f\"So just going with old somas\")\n",
    "\n",
    "                f_soma_final = f_soma\n",
    "                f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "            else:\n",
    "                meshes_split = np.array(meshes_split)\n",
    "                meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "                meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "                meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "                soma_width_threshold\n",
    "                #way to choose the index of the top candidate\n",
    "                top_candidate = 0\n",
    "\n",
    "\n",
    "                largest_hole_before_seg = tu.largest_hole_length(f_soma)\n",
    "                largest_hole_after_seg = tu.largest_hole_length(meshes_split_filtered[top_candidate])\n",
    "\n",
    "                print(f\"Largest hole before segmentation = {largest_hole_before_seg}, after = {largest_hole_after_seg},\"\n",
    "                      f\"\\nratio = {largest_hole_after_seg/largest_hole_before_seg}, difference = {largest_hole_after_seg - largest_hole_before_seg}\")\n",
    "\n",
    "                if largest_hole_after_seg < largest_hole_threshold:\n",
    "                    f_soma_final = meshes_split_filtered[top_candidate]\n",
    "                    f_soma_sdf_final = meshes_split_sdf_filtered[top_candidate]\n",
    "                else:\n",
    "                    f_soma_final = f_soma\n",
    "                    f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "        else:\n",
    "            f_soma_final = f_soma\n",
    "            f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "        filtered_soma_list_revised.append(f_soma_final)\n",
    "        filtered_soma_list_sdf_revised.append(f_soma_sdf_final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n",
    "\n",
    "    \"\"\"\n",
    "    # ----------- 1/7/21 ---------------#\n",
    "    Now was to stitch the somas together if they are touching\n",
    "\n",
    "    \"\"\"\n",
    "    if len(filtered_soma_list)>1:\n",
    "        connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                                 main_mesh=recov_orig_mesh_no_interior,\n",
    "                                                    return_connected_components=True)\n",
    "\n",
    "        filtered_soma_list_components = np.array([tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components])\n",
    "        filtered_soma_list_sdf_components = np.array([np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components])\n",
    "    elif len(filtered_soma_list)==1:\n",
    "        filtered_soma_list_components = filtered_soma_list\n",
    "        filtered_soma_list_sdf_components = filtered_soma_list_sdf\n",
    "    else:\n",
    "        filtered_soma_list_components = []\n",
    "        filtered_soma_list_sdf_components = np.array([])\n",
    "else:\n",
    "    filtered_soma_list_components = []\n",
    "    filtered_soma_list_sdf_components = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "#----------- 1/9 Addition: Final Size Threshold ------------- #\n",
    "if backtrack_soma_mesh_to_original:\n",
    "\n",
    "    filtered_soma_list_components_new = []\n",
    "    filtered_soma_list_sdf_components_new = []\n",
    "\n",
    "    for soma_mesh, soma_mesh_sdf in zip(filtered_soma_list_components,filtered_soma_list_sdf_components):\n",
    "        # --------- 1/9: Extra Size Threshold For Somas ------------- #\n",
    "        if len(soma_mesh.faces) < backtrack_soma_size_threshold:\n",
    "            print(f\"--->This soma mesh with size {len(soma_mesh.faces)} was not bigger than the threshold {backtrack_soma_size_threshold}\")\n",
    "            continue\n",
    "        else:\n",
    "            filtered_soma_list_components_new.append(soma_mesh)\n",
    "            filtered_soma_list_sdf_components_new.append(soma_mesh_sdf)\n",
    "\n",
    "    filtered_soma_list_components = filtered_soma_list_components_new\n",
    "    filtered_soma_list_sdf_components = np.array(filtered_soma_list_sdf_components_new)\n",
    "\n",
    "if filter_inside_somas:\n",
    "    if len(filtered_soma_list_components)>1:\n",
    "        keep_indices = tu.filter_away_inside_meshes(mesh_list = filtered_soma_list_components,\n",
    "                                    distance_type=\"shortest_vertex_distance\",\n",
    "                                    distance_threshold = 2000,\n",
    "                                    inside_percentage_threshold = 0.20,\n",
    "                                    verbose = False,\n",
    "                                    return_meshes = False,\n",
    "                                    )\n",
    "    else:\n",
    "        keep_indices = np.arange(len(filtered_soma_list_components))\n",
    "\n",
    "    filtered_soma_list_components = [k for i,k in enumerate(filtered_soma_list_components) if i in keep_indices]\n",
    "    filtered_soma_list_sdf_components = filtered_soma_list_sdf_components[keep_indices]\n",
    "\n",
    "\n",
    "if return_glia_nuclei_pieces:\n",
    "    return_value= list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components,glia_pieces, nuclei_pieces\n",
    "else:\n",
    "    return_value = list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036e3727329f4caf9c63fc03e7877579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 2620 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68252.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68252_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_597853.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68252.off loaded has 149178 vn 294641 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68252_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_597853.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Successfully removed 22676 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 22676 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 6843852\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_597853.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 9712 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58908.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58908_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_695366.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58908.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_58908_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_695366.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11691, 3), faces.shape=(24005, 3))>, <trimesh.Trimesh(vertices.shape=(5625, 3), faces.shape=(11631, 3))>, <trimesh.Trimesh(vertices.shape=(5542, 3), faces.shape=(11755, 3))>, <trimesh.Trimesh(vertices.shape=(2140, 3), faces.shape=(4393, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(5759, 3))>, <trimesh.Trimesh(vertices.shape=(1614, 3), faces.shape=(3209, 3))>, <trimesh.Trimesh(vertices.shape=(1041, 3), faces.shape=(2022, 3))>, <trimesh.Trimesh(vertices.shape=(683, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(1069, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(533, 3))>, <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(540, 3))>, <trimesh.Trimesh(vertices.shape=(315, 3), faces.shape=(510, 3))>, <trimesh.Trimesh(vertices.shape=(258, 3), faces.shape=(396, 3))>, <trimesh.Trimesh(vertices.shape=(217, 3), faces.shape=(389, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(320, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    }
   ],
   "source": [
    "soma_mesh = total_soma_list_revised[0]\n",
    "\n",
    "soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "    #print(\"About to find original mesh\")\n",
    "\n",
    "\n",
    "soma_mesh_list,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                original_mesh = recov_orig_mesh_no_interior,\n",
    "                                mesh=soma_mesh_poisson,\n",
    "                                soma_size_threshold=backtrack_soma_size_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(49870, 3), faces.shape=(97939, 3))>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma_mesh_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(23697, 3), faces.shape=(46411, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(10737, 3), faces.shape=(20720, 3))>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4112bbba1a8140cb9e8fec3685410d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=mesh_tests,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma_mesh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403a831c99574205afa29c24bd2f0289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    }
   ],
   "source": [
    "mesh_tests,mesh_tests_sdf = tu.mesh_segmentation(total_soma_list_revised[0],clusters=3,smoothness=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7e67494b694d63a636c3d4ef087474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list_revised,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrack_segmentation_on_fail = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Total time for run = 4269.89186167717\n",
      "Before Filtering the number of somas found = 2\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 0\n",
      "xvfb-run -n 1918 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_46403.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_46403_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_61701.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_46403.off loaded has 149178 vn 294641 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_46403_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_61701.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 7115964\n",
      "LOG: 2 Successfully removed 22676 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 22676 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 6843852\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_61701.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 5904 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13511.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13511_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_145136.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13511.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_13511_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_145136.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11691, 3), faces.shape=(24005, 3))>, <trimesh.Trimesh(vertices.shape=(5625, 3), faces.shape=(11631, 3))>, <trimesh.Trimesh(vertices.shape=(5542, 3), faces.shape=(11755, 3))>, <trimesh.Trimesh(vertices.shape=(2140, 3), faces.shape=(4393, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(5759, 3))>, <trimesh.Trimesh(vertices.shape=(1614, 3), faces.shape=(3209, 3))>, <trimesh.Trimesh(vertices.shape=(1041, 3), faces.shape=(2022, 3))>, <trimesh.Trimesh(vertices.shape=(683, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(1069, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(533, 3))>, <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(540, 3))>, <trimesh.Trimesh(vertices.shape=(315, 3), faces.shape=(510, 3))>, <trimesh.Trimesh(vertices.shape=(258, 3), faces.shape=(396, 3))>, <trimesh.Trimesh(vertices.shape=(217, 3), faces.shape=(389, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(320, 3))>]\n",
      "After backtrack the found 1 possible somas: [<trimesh.Trimesh(vertices.shape=(49870, 3), faces.shape=(97939, 3))>] \n",
      "\n",
      "--- workin on backtrack soma 0: <trimesh.Trimesh(vertices.shape=(49870, 3), faces.shape=(97939, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 335 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_405302.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_405302_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_711913.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_405302.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_405302_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_711913.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.284280228241844\n",
      "Trying backtrack segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dca7654064d49a68c80b4150d9dde7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=95.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7213 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_939725.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_939725_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_67148.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_939725.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_939725_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_67148.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.246214159682605\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7890 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_358944.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_358944_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_77235.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_358944.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_358944_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_77235.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.731465215534266\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(23352, 3), faces.shape=(50653, 3))>, <trimesh.Trimesh(vertices.shape=(21656, 3), faces.shape=(46562, 3))>, <trimesh.Trimesh(vertices.shape=(16787, 3), faces.shape=(37230, 3))>, <trimesh.Trimesh(vertices.shape=(2323, 3), faces.shape=(4219, 3))>, <trimesh.Trimesh(vertices.shape=(2274, 3), faces.shape=(4133, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4430, 3))>, <trimesh.Trimesh(vertices.shape=(1382, 3), faces.shape=(3130, 3))>, <trimesh.Trimesh(vertices.shape=(1216, 3), faces.shape=(2664, 3))>, <trimesh.Trimesh(vertices.shape=(1141, 3), faces.shape=(2524, 3))>, <trimesh.Trimesh(vertices.shape=(1096, 3), faces.shape=(2432, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2359, 3))>, <trimesh.Trimesh(vertices.shape=(954, 3), faces.shape=(2137, 3))>, <trimesh.Trimesh(vertices.shape=(927, 3), faces.shape=(2058, 3))>, <trimesh.Trimesh(vertices.shape=(914, 3), faces.shape=(1997, 3))>, <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(2005, 3))>, <trimesh.Trimesh(vertices.shape=(897, 3), faces.shape=(1979, 3))>, <trimesh.Trimesh(vertices.shape=(798, 3), faces.shape=(1761, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1704, 3))>, <trimesh.Trimesh(vertices.shape=(666, 3), faces.shape=(1169, 3))>, <trimesh.Trimesh(vertices.shape=(664, 3), faces.shape=(1451, 3))>, <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(970, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(880, 3))>, <trimesh.Trimesh(vertices.shape=(411, 3), faces.shape=(907, 3))>, <trimesh.Trimesh(vertices.shape=(387, 3), faces.shape=(817, 3))>, <trimesh.Trimesh(vertices.shape=(11956, 3), faces.shape=(24547, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(216, 3), faces.shape=(386, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(316, 3))>, <trimesh.Trimesh(vertices.shape=(11691, 3), faces.shape=(24005, 3))>, <trimesh.Trimesh(vertices.shape=(5625, 3), faces.shape=(11631, 3))>, <trimesh.Trimesh(vertices.shape=(5542, 3), faces.shape=(11755, 3))>, <trimesh.Trimesh(vertices.shape=(2140, 3), faces.shape=(4393, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(5759, 3))>, <trimesh.Trimesh(vertices.shape=(1614, 3), faces.shape=(3209, 3))>, <trimesh.Trimesh(vertices.shape=(1041, 3), faces.shape=(2022, 3))>, <trimesh.Trimesh(vertices.shape=(683, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(1069, 3))>, <trimesh.Trimesh(vertices.shape=(397, 3), faces.shape=(1006, 3))>, <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(533, 3))>, <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(540, 3))>, <trimesh.Trimesh(vertices.shape=(315, 3), faces.shape=(510, 3))>, <trimesh.Trimesh(vertices.shape=(258, 3), faces.shape=(396, 3))>, <trimesh.Trimesh(vertices.shape=(217, 3), faces.shape=(389, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(320, 3))>]\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 1\n",
      "xvfb-run -n 9527 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31311.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31311_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_503960.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31311.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31311_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_503960.mls is being deleted....\n",
      "xvfb-run -n 4185 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89256.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89256_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_175483.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89256.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89256_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_175483.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "After backtrack the found 0 possible somas: [] \n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 9757 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87561.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87561_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_951915.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87561.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87561_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_951915.mls is being deleted....\n",
      "xvfb-run -n 7598 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40446.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40446_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_617984.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40446.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40446_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_617984.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 334\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db1536bde7940f98faa69031168ebc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1632192.770903119, after = 1632192.770903119,\n",
      "ratio = 1.0, difference = 0.0\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 354 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90224.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90224_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_222588.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90224.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_90224_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_222588.mls is being deleted....\n",
      "xvfb-run -n 2790 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2873.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2873_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_261757.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2873.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2873_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_261757.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 500\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589985d93af0402eab771b744a946777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1222998.0250010542, after = 1222998.0250010542,\n",
      "ratio = 1.0, difference = 0.0\n"
     ]
    }
   ],
   "source": [
    "#creating the combined meshes from the list\n",
    "total_soma_list_revised = []\n",
    "total_soma_list_revised_sdf = []\n",
    "if len(pairings) > 0:\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    Use a network function to find components\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    new_graph = nx.Graph()\n",
    "    new_graph.add_edges_from(pairings)\n",
    "    grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "    somas_being_combined = []\n",
    "    print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "    for comp in grouped_somas:\n",
    "        comp = list(comp)\n",
    "        somas_being_combined += list(comp)\n",
    "        current_mesh = total_soma_list[comp[0]]\n",
    "        for i in range(1,len(comp)):\n",
    "            current_mesh += total_soma_list[comp[i]] #just combining the actual meshes\n",
    "\n",
    "        total_soma_list_revised.append(current_mesh)\n",
    "        #where can average all of the sdf values\n",
    "        total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "    #add those that weren't combined to total_soma_list_revised\n",
    "    leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    if len(leftover_somas) > 0:\n",
    "        total_soma_list_revised += leftover_somas\n",
    "        total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "    print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "    print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "if len(total_soma_list_revised) == 0:\n",
    "    total_soma_list_revised = total_soma_list\n",
    "    total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "run_time = time.time() - global_start_time\n",
    "\n",
    "print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "#     import system_utils as su\n",
    "#     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "#     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "#need to erase all of the temporary files ******\n",
    "#import shutil\n",
    "#shutil.rmtree(directory)\n",
    "\n",
    "\"\"\"\n",
    "Running the extra tests that depend on\n",
    "- border vertices\n",
    "- how well the poisson matches the backtracked soma to the real mesh\n",
    "- other size checks\n",
    "\n",
    "\"\"\"\n",
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "\n",
    "for yy,(soma_mesh,curr_soma_sdf) in enumerate(zip(total_soma_list_revised,total_soma_list_revised_sdf)):\n",
    "    add_inside_pieces_flag = False\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        if verbose:\n",
    "            print(f\"\\n---Performing Soma Mesh Backtracking to original mesh for poisson soma {yy}\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "        try:\n",
    "            soma_mesh_list,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                            original_mesh = recov_orig_mesh_no_interior,\n",
    "                                            mesh=soma_mesh_poisson,\n",
    "                                            soma_size_threshold=backtrack_soma_size_threshold)\n",
    "\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "\n",
    "        if soma_mesh_list is None:\n",
    "                print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        if verbose: \n",
    "            print(f\"After backtrack the found {len(soma_mesh_list)} possible somas: {soma_mesh_list} \")\n",
    "\n",
    "        for rr,soma_mesh in enumerate(soma_mesh_list):\n",
    "            if verbose:\n",
    "                print(f\"\\n--- workin on backtrack soma {rr}: {soma_mesh}\")\n",
    "\n",
    "            print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "            #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "            if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "                #soma_mesh.export(\"soma_mesh.off\")\n",
    "                if close_holes: \n",
    "                    print(\"Using the close holes feature\")\n",
    "                    fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                     self_itersect_faces=False)\n",
    "\n",
    "                    soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                        vertices=soma_mesh.vertices,\n",
    "                                                         faces=soma_mesh.faces,\n",
    "                                                         return_mesh=True,\n",
    "                                                         delete_temp_files=True,\n",
    "                                                        )\n",
    "                else:\n",
    "                    soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "                #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "                print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "                mesh_1 = soma_mesh_filled_holes\n",
    "                mesh_2 = soma_mesh_poisson\n",
    "\n",
    "                poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                                  verbose=True)\n",
    "                print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "                if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                      f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #do the boundary check:\n",
    "            if not boundary_vertices_threshold is None:\n",
    "                print(\"USING boundary_vertices_threshold CHECK\")\n",
    "                soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "                print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "                large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "                print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "                if len(large_boundary_groups)>0:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                          f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "                    continue\n",
    "\n",
    "            curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "            curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "            \n",
    "            # -------- 1/12 Addition: Does a second round of segmentation after to see if can split somas at all ---- #\n",
    "            if (not curr_side_len_check) or (not curr_volume_check):\n",
    "                \n",
    "                if backtrack_segmentation_on_fail:\n",
    "                    print(\"Trying backtrack segmentation\")\n",
    "                    mesh_tests,mesh_tests_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2)\n",
    "                    \n",
    "                    soma_mesh_filtered = []\n",
    "                    soma_mesh_sdf_filtered = []\n",
    "                    \n",
    "                    for m_test,m_test_sdf in zip(mesh_tests,mesh_tests_sdf):\n",
    "                        \n",
    "                        if len(m_test.faces) >= backtrack_soma_size_threshold and m_test_sdf >=soma_width_threshold:\n",
    "                            \n",
    "                            if side_length_check(m_test,side_length_ratio_threshold) and soma_volume_check(m_test,volume_mulitplier):\n",
    "                                \n",
    "                                soma_mesh_filtered.append(m_test)\n",
    "                                soma_mesh_sdf_filtered.append(m_test_sdf)\n",
    "                                \n",
    "                    if len(soma_mesh_filtered) == 0:\n",
    "                        print(f\"--->This soma mesh was not added because it did not pass the sphere validation EVEN AFTER SEGMENTATION:\\n \"\n",
    "                         f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                        continue\n",
    "\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "                     f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                    continue\n",
    "            else:\n",
    "                \n",
    "                    \n",
    "                soma_mesh_filtered = [soma_mesh]\n",
    "                soma_mesh_sdf_filtered = [curr_soma_sdf]\n",
    "                    \n",
    "                    \n",
    "\n",
    "            #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "            #If made it through all the checks then add to final list\n",
    "            filtered_soma_list += soma_mesh_filtered\n",
    "            filtered_soma_list_sdf += soma_mesh_sdf_filtered\n",
    "            add_inside_pieces_flag = True #setting flag so will add inside pieces\n",
    "\n",
    "\n",
    "    if len(soma_mesh_inside_pieces) > 0 and add_inside_pieces_flag:\n",
    "        print(f\"About to add the following inside nuclei pieces after soma backtrack: {nuclei_pieces}\")\n",
    "        nuclei_pieces +=soma_mesh_inside_pieces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Things we should ask about the segmentation:\n",
    "\n",
    "Advantages: \n",
    "1) could help filter away negatives\n",
    "\n",
    "Disadvantages:\n",
    "1) Can actually cut up the soma and then filter away the soma (not what we want)\n",
    "2) Could introduce a big hole (don't think can guard against this)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#filtered_soma_list_saved = copy.deepcopy(filtered_soma_list)\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "\n",
    "        print(\"Skipping the segmentatio filter at end\")\n",
    "        if not (len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold):\n",
    "            print(f\"Soma (size = {len(f_soma.faces)}, width={soma_width_threshold}) did not pass thresholds (size threshold={last_size_threshold}, width threshold = {soma_width_threshold}) \")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if segmentation_at_end:\n",
    "\n",
    "\n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "#                 print(f\"meshes_split = {meshes_split}\")\n",
    "#                 print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                print(f\"So just going with old somas\")\n",
    "\n",
    "                f_soma_final = f_soma\n",
    "                f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "            else:\n",
    "                meshes_split = np.array(meshes_split)\n",
    "                meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "                meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "                meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "                soma_width_threshold\n",
    "                #way to choose the index of the top candidate\n",
    "                top_candidate = 0\n",
    "\n",
    "\n",
    "                largest_hole_before_seg = tu.largest_hole_length(f_soma)\n",
    "                largest_hole_after_seg = tu.largest_hole_length(meshes_split_filtered[top_candidate])\n",
    "\n",
    "                print(f\"Largest hole before segmentation = {largest_hole_before_seg}, after = {largest_hole_after_seg},\"\n",
    "                      f\"\\nratio = {largest_hole_after_seg/largest_hole_before_seg}, difference = {largest_hole_after_seg - largest_hole_before_seg}\")\n",
    "\n",
    "                if largest_hole_after_seg < largest_hole_threshold:\n",
    "                    f_soma_final = meshes_split_filtered[top_candidate]\n",
    "                    f_soma_sdf_final = meshes_split_sdf_filtered[top_candidate]\n",
    "                else:\n",
    "                    f_soma_final = f_soma\n",
    "                    f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "        else:\n",
    "            f_soma_final = f_soma\n",
    "            f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "        filtered_soma_list_revised.append(f_soma_final)\n",
    "        filtered_soma_list_sdf_revised.append(f_soma_sdf_final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n",
    "\n",
    "    \"\"\"\n",
    "    # ----------- 1/7/21 ---------------#\n",
    "    Now was to stitch the somas together if they are touching\n",
    "\n",
    "    \"\"\"\n",
    "    if len(filtered_soma_list)>1:\n",
    "        connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                                 main_mesh=recov_orig_mesh_no_interior,\n",
    "                                                    return_connected_components=True)\n",
    "\n",
    "        filtered_soma_list_components = np.array([tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components])\n",
    "        filtered_soma_list_sdf_components = np.array([np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components])\n",
    "    elif len(filtered_soma_list)==1:\n",
    "        filtered_soma_list_components = filtered_soma_list\n",
    "        filtered_soma_list_sdf_components = filtered_soma_list_sdf\n",
    "    else:\n",
    "        filtered_soma_list_components = []\n",
    "        filtered_soma_list_sdf_components = np.array([])\n",
    "else:\n",
    "    filtered_soma_list_components = []\n",
    "    filtered_soma_list_sdf_components = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "#----------- 1/9 Addition: Final Size Threshold ------------- #\n",
    "if backtrack_soma_mesh_to_original:\n",
    "\n",
    "    filtered_soma_list_components_new = []\n",
    "    filtered_soma_list_sdf_components_new = []\n",
    "\n",
    "    for soma_mesh, soma_mesh_sdf in zip(filtered_soma_list_components,filtered_soma_list_sdf_components):\n",
    "        # --------- 1/9: Extra Size Threshold For Somas ------------- #\n",
    "        if len(soma_mesh.faces) < backtrack_soma_size_threshold:\n",
    "            print(f\"--->This soma mesh with size {len(soma_mesh.faces)} was not bigger than the threshold {backtrack_soma_size_threshold}\")\n",
    "            continue\n",
    "        else:\n",
    "            filtered_soma_list_components_new.append(soma_mesh)\n",
    "            filtered_soma_list_sdf_components_new.append(soma_mesh_sdf)\n",
    "\n",
    "    filtered_soma_list_components = filtered_soma_list_components_new\n",
    "    filtered_soma_list_sdf_components = np.array(filtered_soma_list_sdf_components_new)\n",
    "\n",
    "if filter_inside_somas:\n",
    "    if len(filtered_soma_list_components)>1:\n",
    "        keep_indices = tu.filter_away_inside_meshes(mesh_list = filtered_soma_list_components,\n",
    "                                    distance_type=\"shortest_vertex_distance\",\n",
    "                                    distance_threshold = 2000,\n",
    "                                    inside_percentage_threshold = 0.20,\n",
    "                                    verbose = False,\n",
    "                                    return_meshes = False,\n",
    "                                    )\n",
    "    else:\n",
    "        keep_indices = np.arange(len(filtered_soma_list_components))\n",
    "\n",
    "    filtered_soma_list_components = [k for i,k in enumerate(filtered_soma_list_components) if i in keep_indices]\n",
    "    filtered_soma_list_sdf_components = filtered_soma_list_sdf_components[keep_indices]\n",
    "\n",
    "\n",
    "if return_glia_nuclei_pieces:\n",
    "    return_value= list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components,glia_pieces, nuclei_pieces\n",
    "else:\n",
    "    return_value = list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(23532, 3), faces.shape=(45924, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(10626, 3), faces.shape=(20400, 3))>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nviz.plot_objects(soma_mesh_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_soma_list_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c6f338f5924d759ce3e5ef8ac4680f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8deeafe8beec4a9d8d2f20f53dbd2bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(to_add_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b898a420e8c94cb2bf8e4bbc6fd41e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy_utils as nu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(6153, 3), faces.shape=(12302, 3))>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_mesh_path_inner_decimated_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7acc4dd8f44b8d981e979781550a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(largest_mesh_path_inner_decimated_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/548_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4871e1aa6426468481ed1ce594dfd61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    }
   ],
   "source": [
    "curr_m, curr_s = tu.mesh_segmentation(largest_mesh_path_inner_decimated_clean,\n",
    "                     clusters=3,\n",
    "                     smoothness=0.2,\n",
    "                     verbose=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73cdc8f0f1e424283e1f8e68a943cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=curr_m,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1048c19a0bb24db98a20553595d1cc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb1f049788f492faf75a59500ea6e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8551 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_499305.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_499305.mls is being deleted....\n",
      "xvfb-run -n 4817 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_687930.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_687930.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 86\n",
      "viable_meshes = [0]\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 7660 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_482671.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_482671.mls is being deleted....\n",
      "xvfb-run -n 7046 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_70205.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_70205.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 86\n",
      "viable_meshes = [0]\n"
     ]
    }
   ],
   "source": [
    "backtracked_somas = []\n",
    "for soma_mesh,curr_soma_sdf in zip(total_soma_list_revised,total_soma_list_revised_sdf):\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        print(\"Performing Soma Mesh Backtracking to original mesh\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "\n",
    "        soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)\n",
    "        backtracked_somas.append(soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 5197 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_344509.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363.off loaded has 60255 vn 118370 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_344509.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 2866560\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 2866560\n",
      "LOG: 2 Successfully removed 12914 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 12914 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 2711592\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_344509.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 9872 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_192902.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_192902.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(6098, 3), faces.shape=(14038, 3))>, <trimesh.Trimesh(vertices.shape=(811, 3), faces.shape=(1540, 3))>, <trimesh.Trimesh(vertices.shape=(774, 3), faces.shape=(1990, 3))>, <trimesh.Trimesh(vertices.shape=(644, 3), faces.shape=(1332, 3))>, <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1482, 3))>, <trimesh.Trimesh(vertices.shape=(383, 3), faces.shape=(904, 3))>, <trimesh.Trimesh(vertices.shape=(365, 3), faces.shape=(681, 3))>, <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(874, 3))>, <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(692, 3))>, <trimesh.Trimesh(vertices.shape=(296, 3), faces.shape=(707, 3))>, <trimesh.Trimesh(vertices.shape=(249, 3), faces.shape=(821, 3))>, <trimesh.Trimesh(vertices.shape=(243, 3), faces.shape=(577, 3))>, <trimesh.Trimesh(vertices.shape=(241, 3), faces.shape=(362, 3))>, <trimesh.Trimesh(vertices.shape=(155, 3), faces.shape=(310, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    }
   ],
   "source": [
    "soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c04c65023942f0b6afec7192d9e4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Original Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(12841, 3), faces.shape=(25096, 3))>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd76d8adea649158df9fb728aa91870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(filtered_soma_list_components[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The New Original Mesh Soma Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recov_orig_mesh_no_interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_big_mesh,faces = tu.bbox_mesh_restriction(recov_orig_mesh_no_interior,soma_mesh_poisson,mult_ratio=2)\n",
    "restricted_big_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.original_mesh_soma(restricted_big_mesh,soma_meshes=[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_mesh_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_split = tu.split_significant_pieces(restricted_big_mesh,significance_threshold=1000,connectivity=\"edges\")\n",
    "restr_mesh_to_test = restr_split[0]\n",
    "restr_mesh_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.mesh_interior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_without_interior,rem_pieces = tu.remove_mesh_interior(restr_mesh_to_test,return_removed_pieces=True,size_threshold_to_remove=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_without_interior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restricted_big_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_somas = sm.original_mesh_soma(restr_without_interior,[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(new_somas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The new Soma Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_soma = sm.original_mesh_soma(restr_without_interior_largest,\n",
    "                      soma_mesh_poisson,\n",
    "    subtract_soma_distance_threshold=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(back_soma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = soma_mesh_poisson\n",
    "original_mesh = recov_orig_mesh_no_interior \n",
    "bbox_restriction_multiplying_ratio = 1.7\n",
    "match_distance_threshold = 1500\n",
    "mesh_significance_threshold = 1000\n",
    "return_inside_pieces = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_soma_mesh,soma_inside_pieces = original_mesh_soma(\n",
    "    mesh = soma_mesh_poisson,\n",
    "    original_mesh = recov_orig_mesh_no_interior ,\n",
    "    bbox_restriction_multiplying_ratio = 1.7,\n",
    "    match_distance_threshold = 1500,\n",
    "    mesh_significance_threshold = 1000,\n",
    "    return_inside_pieces = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(final_soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=soma_inside_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_without_interior_largest = tu.split_significant_pieces(restr_without_interior)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes,sdf_results = tu.mesh_segmentation(restr_without_interior_largest,clusters=3,smoothness=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes[np.argmax(sdf_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes = np.array(divided_meshes)\n",
    "sdf_results = np.array(sdf_results)\n",
    "\n",
    "meshes_len = np.array([len(k.faces) for k in divided_meshes ])\n",
    "possible_soma_idxs = np.where(meshes_len > 13000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_without_interior_largest,\n",
    "                meshes=[divided_meshes[0],soma_mesh_poisson],\n",
    "                 meshes_colors=[\"red\",\"purple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(Out[129][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.bounding_box_corners(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.bbox_mesh_restriction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_soma_segments_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_somas = []\n",
    "if len(valid_soma_segments_width) > 0:\n",
    "    print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "    somas_found_in_big_loop = True\n",
    "    #get the meshes only if signfiicant length\n",
    "    labels_list = classifier.labels_list\n",
    "\n",
    "    for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "        submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "        soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "        total_somas.append(soma_mesh)\n",
    "\n",
    "        # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "\n",
    "        curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "        curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "        \n",
    "        print(f\"\\n\\n {curr_side_len_check}, {curr_volume_check} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(total_somas[1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Run th esegmentation algorithm again to segment the mesh\n",
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(total_somas[1],clusters=3,smoothness=0.01,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                  meshes_colors=\"random\"\n",
    "                 )\n",
    "#2) Filter out meshes by sizs and sdf threshold\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "nviz.plot_objects(meshes=mesh_extra[filtered_meshes_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mesh = mesh_extra[filtered_meshes_idx][0]\n",
    "\n",
    "side_length_check(test_mesh,side_length_ratio_threshold), soma_volume_check(test_mesh,volume_mulitplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[-1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "                    \n",
    "                    #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                    mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                    mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                    #2) Filter out meshes by sizs and sdf threshold\n",
    "                    mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                    filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.05,verbose=True)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "            mesh = recov_orig_mesh_no_interior,\n",
    "            soma_meshes=[soma_mesh_poisson],\n",
    "            sig_th_initial_split=15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ----------- 1/7/21 ---------------#\n",
    "Now was to stitch the somas together if they are touching\n",
    "\n",
    "\"\"\"\n",
    "connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                         main_mesh=recov_orig_mesh,\n",
    "                                            return_connected_components=True)\n",
    "\n",
    "filtered_soma_list_components = [tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components]\n",
    "filtered_soma_list_sdf_components = [np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "                                            mesh = recov_orig_mesh_no_interior,\n",
    "                                            soma_meshes=[soma_mesh_poisson],\n",
    "                                            sig_th_initial_split=15)[0]\n",
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_soma_meshes = su.decompress_pickle(\"seperate_soma_meshes\")\n",
    "nviz.plot_objects(meshes=seperate_soma_meshes,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_saved = su.decompress_pickle(\"filtered_soma_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(current_neuron,\n",
    "                #meshes=[return_value[0][0]],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "if len(filtered_meshes_idx) > 0:\n",
    "    filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "    filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "    \n",
    "    soma_mesh_retry = filtered_meshes[np.argmax(filtered_meshes_sdf)]\n",
    "\n",
    "nviz.plot_objects(soma_mesh_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_size_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(mesh_extra[0],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(largest_mesh_path_inner_decimated_clean,\n",
    "                 meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mesh_threshold_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=[k for k in ordered_mesh_splits_inner if len(k.faces)>800],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=dec_splits,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh[1],\n",
    "                  meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh,\n",
    "                 meshes_colors=[\"red\",\"black\"],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(main_mesh=current_neuron,\n",
    "                 meshes=filtered_soma_list,\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                                 current_neuron.vertices,\n",
    "                                                 current_neuron.faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
