{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To debug why certain somas are not being detected\n",
    "in agreement with nucleus table\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-10 02:03:50,623 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-10 02:03:50,625 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-10 02:03:50,626 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-10 02:03:51,112 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-10 02:03:51,113 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-10 02:03:51,131 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-10 02:03:51,415 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import soma_extraction_utils as sm\n",
    "import datajoint_utils as du\n",
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-10 02:03:51,511 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-10 02:03:51,794 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking what neurons did not have 2 somas which should have (so can test on them now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/6 Debugging Missed Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-11 07:23:07,017 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-11 07:23:07,018 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-11 07:23:07,019 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-11 07:23:07,022 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-11 07:23:07,323 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "segment_id = 864691135081745143\n",
    "segment_id = 864691135081756919 #did not find the glia\n",
    "segment_id = 864691136309708378 #repeat of somas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_neuron = du.fetch_segment_id_mesh(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a898464f6e5f4b5fab549333cce437f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b></b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_version</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_ratio</p>\n",
       "                                <span class=\"djtooltiptext\">ratio of remaining mesh vertices/faces (which ones depends on what metric the decimation technique uses)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">ver</p>\n",
       "                                <span class=\"djtooltiptext\">the version number of the materializaiton</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_glia_faces</p>\n",
       "                                <span class=\"djtooltiptext\">The number of faces that were saved off as belonging to glia</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">glia_faces</p>\n",
       "                                <span class=\"djtooltiptext\">faces indices that were saved off as belonging to glia</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_nuclei_faces</p>\n",
       "                                <span class=\"djtooltiptext\">The number of faces that were saved off as belonging to nuclie</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">nuclei_faces</p>\n",
       "                                <span class=\"djtooltiptext\">faces indices that were saved off as belonging to nuclei</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>864691135081756919</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>29.00</td>\n",
       "<td>0</td>\n",
       "<td>=BLOB=</td>\n",
       "<td>258577</td>\n",
       "<td>=BLOB=</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 1</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segment_id    *decimation_ve *decimation_ra *ver      n_glia_faces   glia_faces n_nuclei_faces nuclei_fac\n",
       "+------------+ +------------+ +------------+ +-------+ +------------+ +--------+ +------------+ +--------+\n",
       "86469113508175 0              0.25           29.00     0              =BLOB=     258577         =BLOB=    \n",
       " (Total: 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minnie.NeuronGliaNuclei() & dict(segment_id=segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 2965 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87793.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87793_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_717810.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87793.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_87793_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_717810.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:02,396 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,398 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,462 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,470 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,747 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,917 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,924 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,941 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,942 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,944 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,945 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,955 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,956 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,959 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:02,960 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,281 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,283 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,536 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,537 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,538 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,542 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,543 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,544 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,566 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,567 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,759 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:03,908 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,054 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,056 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,113 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,114 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,172 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,179 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,197 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,199 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,327 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,329 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,332 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,725 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,731 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,811 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,967 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:04,969 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,038 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,040 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,099 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,110 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,119 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,123 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,124 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,128 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,155 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,180 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,281 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,284 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,297 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,298 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,318 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,318 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,377 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,378 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,385 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,392 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,392 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,393 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,396 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,396 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,399 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,407 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,424 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,428 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,429 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,430 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,431 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,434 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,435 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,435 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,436 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,438 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,446 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,447 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,457 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,458 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,463 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,464 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,485 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,505 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,534 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,536 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,539 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,554 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,555 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,558 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,561 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,567 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,568 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,574 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,869 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,870 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,876 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:05,877 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:06,020 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:06,022 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:06,037 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:06,041 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,132 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,147 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,506 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:07,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,554 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,588 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,627 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,637 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,676 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,678 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,679 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,683 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,684 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,773 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,780 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,850 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,868 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,902 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,922 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,953 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,956 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,957 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,960 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,961 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,966 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:07,979 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,088 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,096 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,118 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,217 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,218 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,240 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,241 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,254 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,255 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,262 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,263 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,266 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,270 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,272 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,273 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,275 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,281 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,561 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,562 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,617 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,635 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,636 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,744 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,745 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,777 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,851 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,891 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,917 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,930 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,931 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:08,998 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,082 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,091 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,279 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,280 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,281 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,285 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,344 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,345 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,348 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,354 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,357 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,358 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,389 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,575 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,583 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,637 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,638 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,639 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,642 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,650 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,651 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,652 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,667 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,711 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,730 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,749 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,751 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,819 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,832 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,835 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,892 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,897 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,927 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,928 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,947 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,964 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,965 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,990 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,994 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,996 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:09,997 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,013 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,049 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,068 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,069 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,070 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,098 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,117 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,130 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,134 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,185 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,521 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,565 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:10,731 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,732 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,795 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,799 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,840 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,841 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,995 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:10,996 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,006 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,012 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,355 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,357 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,376 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,433 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,434 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,449 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,453 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,484 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,484 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,648 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,662 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,739 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,740 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,774 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,776 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,847 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,855 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,954 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,955 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,958 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:11,961 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,009 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,010 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,015 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,016 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,017 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,018 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,171 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,174 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,183 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,215 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,216 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,218 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,219 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,364 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,365 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,366 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,377 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,378 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,409 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,417 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,422 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,424 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,433 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,439 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,440 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,467 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,510 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,517 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,687 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,688 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:12,689 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,019 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,050 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,051 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,057 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,075 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,081 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,133 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,169 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,177 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,183 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,184 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,225 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,254 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,857 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,868 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,870 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,871 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,872 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,874 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,876 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,948 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,949 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,950 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,952 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:13,954 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,145 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,636 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,637 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,639 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,640 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,648 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,696 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,697 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,709 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,710 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,712 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,713 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,724 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,729 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,729 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,735 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,736 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,751 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,764 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,766 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,778 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:14,783 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,786 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,788 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,791 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,792 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,796 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,819 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,830 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,884 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,887 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,910 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,911 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,914 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,915 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,945 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,946 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:14,998 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,028 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,393 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,394 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,395 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,396 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,396 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,427 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,428 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,442 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,443 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,477 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,477 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,480 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,481 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,505 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,505 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,509 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,509 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,517 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,519 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,522 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,523 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,524 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,528 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,530 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,536 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,539 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,546 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,547 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,548 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,549 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,595 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,645 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,651 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,699 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,700 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,712 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,713 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,833 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,847 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,900 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,901 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:15,994 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,236 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,237 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,238 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,280 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,286 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,290 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,293 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,295 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,302 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,302 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,309 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,310 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,311 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,313 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,316 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,317 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,321 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,322 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,324 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,324 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,325 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,326 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,327 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,329 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,330 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,331 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,331 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,334 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,349 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,350 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,351 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,352 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,357 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,359 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,369 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,370 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,371 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,374 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,376 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,382 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,386 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,390 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,391 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,397 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,399 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,412 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:17,425 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,427 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,428 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,429 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:17,459 - base - face_normals all zero, ignoring!\n",
      "/meshAfterParty/trimesh_utils.py:660: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 74 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 1\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 73\n",
      "using precomputed glia pieces\n",
      "\n",
      " ---- Working on inside piece 0 ------\n",
      "For glia mesh 0 there were 3015068 faces within 3000 distane\n",
      "New mesh size is <trimesh.Trimesh(vertices.shape=(1468337, 3), faces.shape=(3015068, 3))>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:32,199 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,200 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,268 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,277 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,575 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,733 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,740 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,755 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,756 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,758 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,759 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,769 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,770 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,773 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:32,773 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,074 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,075 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,144 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,145 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,147 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,148 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,306 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,307 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,308 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,313 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,314 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,314 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,337 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,338 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,532 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,680 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,827 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,828 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,885 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,886 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,944 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,951 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,969 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:33,970 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,080 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,083 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,086 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,457 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,465 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,539 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,690 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,692 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,757 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,759 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,814 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,824 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,834 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,837 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,838 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,842 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,871 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,896 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,996 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:34,999 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,012 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,014 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,032 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,033 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,089 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,090 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,097 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,103 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,104 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,105 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,108 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,109 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,112 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,119 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,137 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,141 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,142 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,143 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,144 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,145 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,146 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,147 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,148 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,150 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,158 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,159 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,168 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,169 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,173 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,174 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,190 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,193 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,193 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,206 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,209 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,213 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,215 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,236 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,239 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,242 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,255 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,257 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,259 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,262 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,270 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,271 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,277 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,606 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:35,607 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,612 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,613 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,763 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,766 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,776 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,778 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,874 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:35,890 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,244 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,246 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,287 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,351 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,361 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,399 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,401 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,402 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,405 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,406 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,494 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,500 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,572 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,589 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,620 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,639 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,666 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,670 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,671 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,674 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,675 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,677 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,683 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,684 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,776 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,784 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,803 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,886 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,887 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,906 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,907 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,927 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,927 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,930 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,935 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,936 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,938 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,940 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:36,947 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,182 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,183 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,221 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,240 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,241 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,263 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,340 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,341 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,368 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,437 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,478 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,506 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,521 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,522 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,586 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,668 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,676 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,861 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,862 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,864 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,870 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,928 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,929 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,932 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,940 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,942 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,943 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:37,974 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,149 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,156 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,212 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,213 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,217 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,225 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,226 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,227 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,239 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,286 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,288 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,299 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,320 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,322 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,390 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,391 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,402 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,404 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,461 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,466 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,490 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:38,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,135 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,136 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,161 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,164 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 02:14:40,166 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,167 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,182 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,219 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,234 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,235 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,235 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,243 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,258 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,275 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,287 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,291 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,342 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,664 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,672 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,709 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,872 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,873 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,937 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,941 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,983 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:40,984 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,137 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,138 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,147 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,153 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,491 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,510 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,560 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,561 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,571 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,576 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,578 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,609 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,610 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,619 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,661 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,776 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,790 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,864 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,866 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,870 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,877 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,899 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,901 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,903 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,908 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,979 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:41,987 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,082 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,083 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,087 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,091 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,136 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,138 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,142 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,143 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,144 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,145 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,290 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,292 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,302 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,334 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,334 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,337 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,338 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,471 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,472 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,472 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,483 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,483 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,515 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,523 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,527 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,537 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,544 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,545 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,571 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,615 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,622 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,684 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,688 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,789 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,789 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:42,790 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,080 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,111 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,112 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,117 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,135 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,143 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,190 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,225 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,233 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,240 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,240 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,283 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 02:14:43,310 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36407 and going to remove 257 that were inside bounding box\n",
      "After removal of floating pieces the mesh is <trimesh.Trimesh(vertices.shape=(1430389, 3), faces.shape=(2940955, 3))>\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(33492, 3), faces.shape=(73920, 3))>, <trimesh.Trimesh(vertices.shape=(32324, 3), faces.shape=(70285, 3))>, <trimesh.Trimesh(vertices.shape=(4249, 3), faces.shape=(10508, 3))>, <trimesh.Trimesh(vertices.shape=(3871, 3), faces.shape=(9314, 3))>, <trimesh.Trimesh(vertices.shape=(2381, 3), faces.shape=(5518, 3))>, <trimesh.Trimesh(vertices.shape=(2238, 3), faces.shape=(5238, 3))>, <trimesh.Trimesh(vertices.shape=(1946, 3), faces.shape=(3133, 3))>, <trimesh.Trimesh(vertices.shape=(1832, 3), faces.shape=(4151, 3))>, <trimesh.Trimesh(vertices.shape=(1647, 3), faces.shape=(2893, 3))>, <trimesh.Trimesh(vertices.shape=(1570, 3), faces.shape=(2612, 3))>, <trimesh.Trimesh(vertices.shape=(1510, 3), faces.shape=(3388, 3))>, <trimesh.Trimesh(vertices.shape=(1416, 3), faces.shape=(2319, 3))>, <trimesh.Trimesh(vertices.shape=(1391, 3), faces.shape=(2413, 3))>, <trimesh.Trimesh(vertices.shape=(1342, 3), faces.shape=(3089, 3))>, <trimesh.Trimesh(vertices.shape=(1325, 3), faces.shape=(3052, 3))>, <trimesh.Trimesh(vertices.shape=(1308, 3), faces.shape=(2218, 3))>, <trimesh.Trimesh(vertices.shape=(1161, 3), faces.shape=(2638, 3))>, <trimesh.Trimesh(vertices.shape=(1114, 3), faces.shape=(2530, 3))>, <trimesh.Trimesh(vertices.shape=(1106, 3), faces.shape=(1750, 3))>, <trimesh.Trimesh(vertices.shape=(1096, 3), faces.shape=(2522, 3))>, <trimesh.Trimesh(vertices.shape=(1073, 3), faces.shape=(2448, 3))>, <trimesh.Trimesh(vertices.shape=(995, 3), faces.shape=(2234, 3))>, <trimesh.Trimesh(vertices.shape=(985, 3), faces.shape=(2160, 3))>, <trimesh.Trimesh(vertices.shape=(982, 3), faces.shape=(2190, 3))>, <trimesh.Trimesh(vertices.shape=(971, 3), faces.shape=(2167, 3))>, <trimesh.Trimesh(vertices.shape=(959, 3), faces.shape=(1825, 3))>, <trimesh.Trimesh(vertices.shape=(901, 3), faces.shape=(2035, 3))>, <trimesh.Trimesh(vertices.shape=(870, 3), faces.shape=(1974, 3))>, <trimesh.Trimesh(vertices.shape=(850, 3), faces.shape=(1924, 3))>, <trimesh.Trimesh(vertices.shape=(843, 3), faces.shape=(1342, 3))>, <trimesh.Trimesh(vertices.shape=(832, 3), faces.shape=(1872, 3))>, <trimesh.Trimesh(vertices.shape=(792, 3), faces.shape=(1743, 3))>, <trimesh.Trimesh(vertices.shape=(787, 3), faces.shape=(1757, 3))>, <trimesh.Trimesh(vertices.shape=(777, 3), faces.shape=(1733, 3))>, <trimesh.Trimesh(vertices.shape=(773, 3), faces.shape=(1708, 3))>, <trimesh.Trimesh(vertices.shape=(754, 3), faces.shape=(1703, 3))>, <trimesh.Trimesh(vertices.shape=(705, 3), faces.shape=(1566, 3))>, <trimesh.Trimesh(vertices.shape=(669, 3), faces.shape=(1072, 3))>, <trimesh.Trimesh(vertices.shape=(658, 3), faces.shape=(1019, 3))>, <trimesh.Trimesh(vertices.shape=(654, 3), faces.shape=(1450, 3))>, <trimesh.Trimesh(vertices.shape=(616, 3), faces.shape=(1338, 3))>, <trimesh.Trimesh(vertices.shape=(578, 3), faces.shape=(954, 3))>, <trimesh.Trimesh(vertices.shape=(540, 3), faces.shape=(1215, 3))>, <trimesh.Trimesh(vertices.shape=(513, 3), faces.shape=(802, 3))>, <trimesh.Trimesh(vertices.shape=(512, 3), faces.shape=(897, 3))>, <trimesh.Trimesh(vertices.shape=(510, 3), faces.shape=(769, 3))>, <trimesh.Trimesh(vertices.shape=(484, 3), faces.shape=(704, 3))>, <trimesh.Trimesh(vertices.shape=(447, 3), faces.shape=(711, 3))>, <trimesh.Trimesh(vertices.shape=(443, 3), faces.shape=(700, 3))>, <trimesh.Trimesh(vertices.shape=(436, 3), faces.shape=(944, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 6102497, Final mesh size: 2724144\n",
      "Total time = 383.75517535209656\n"
     ]
    }
   ],
   "source": [
    "recov_orig_mesh_no_interior, glia_pieces, nuclei_pieces  = tu.remove_nuclei_and_glia_meshes(current_neuron,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_interior_mesh = su.decompress_pickle(\"curr_interior_mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "glia_volume_threshold = 2500*1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_interior_mesh_volume[0] > glia_volume_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_interior_mesh_volume = np.array([k.convex_hull.volume for k in curr_interior_mesh])\n",
    "curr_interior_mesh_len = np.array([len(k.faces) for k in curr_interior_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2389053,   73920,   66516,   10508,    9314,    5518,    5238,\n",
       "          2893,    2612,    2319,    2098,    2053,    2218,    1898,\n",
       "          1706,    1702,    1682,    1750,    2522,    1550,    1539,\n",
       "          2190,    1531,    1521,    2167,    1825,    1324,    1314,\n",
       "          1274,    1256,    1924,    1342,    1287,    1228,    1220,\n",
       "          1743,    1143,    1091,    1095,    1065,    1076,    1566,\n",
       "          1033,    1002,    1001,    1072,     983,    1019,     973,\n",
       "           947,     925,    1338,     880,     877,     855,     853,\n",
       "           877,     856,     852,     851,     954,     863,     795,\n",
       "          1215,     747,     802,     897,     769,     703,     704,\n",
       "           711,     711,     700,     944])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_interior_mesh_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_interior_mesh_len >= 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(curr_interior_mesh_volume >= glia_volume_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<trimesh.Trimesh(vertices.shape=(1243392, 3), faces.shape=(2389053, 3))>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_interior_mesh = np.array(curr_interior_mesh)\n",
    "glia_pieces = curr_interior_mesh[ (curr_interior_mesh_volume >= glia_volume_threshold) &\n",
    "                                           (curr_interior_mesh_len >= 100000)]\n",
    "glia_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9277f6f8580f457d9be08c58ce4fd664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(curr_interior_mesh[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc0ace266564e669821ac63c3bfa878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=inside_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 1198 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65785.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65785_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_264419.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65785.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65785_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_264419.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2624: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  except:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(30373, 3), faces.shape=(80733, 3))>, <trimesh.Trimesh(vertices.shape=(25564, 3), faces.shape=(70482, 3))>, <trimesh.Trimesh(vertices.shape=(318, 3), faces.shape=(672, 3))>, <trimesh.Trimesh(vertices.shape=(245, 3), faces.shape=(534, 3))>, <trimesh.Trimesh(vertices.shape=(189, 3), faces.shape=(285, 3))>, <trimesh.Trimesh(vertices.shape=(189, 3), faces.shape=(374, 3))>, <trimesh.Trimesh(vertices.shape=(160, 3), faces.shape=(294, 3))>, <trimesh.Trimesh(vertices.shape=(131, 3), faces.shape=(290, 3))>, <trimesh.Trimesh(vertices.shape=(101, 3), faces.shape=(202, 3))>, <trimesh.Trimesh(vertices.shape=(85, 3), faces.shape=(127, 3))>, <trimesh.Trimesh(vertices.shape=(77, 3), faces.shape=(117, 3))>, <trimesh.Trimesh(vertices.shape=(76, 3), faces.shape=(139, 3))>, <trimesh.Trimesh(vertices.shape=(72, 3), faces.shape=(100, 3))>, <trimesh.Trimesh(vertices.shape=(67, 3), faces.shape=(132, 3))>, <trimesh.Trimesh(vertices.shape=(58, 3), faces.shape=(109, 3))>, <trimesh.Trimesh(vertices.shape=(51, 3), faces.shape=(102, 3))>, <trimesh.Trimesh(vertices.shape=(49, 3), faces.shape=(76, 3))>, <trimesh.Trimesh(vertices.shape=(47, 3), faces.shape=(65, 3))>, <trimesh.Trimesh(vertices.shape=(46, 3), faces.shape=(92, 3))>, <trimesh.Trimesh(vertices.shape=(44, 3), faces.shape=(84, 3))>, <trimesh.Trimesh(vertices.shape=(43, 3), faces.shape=(58, 3))>, <trimesh.Trimesh(vertices.shape=(42, 3), faces.shape=(80, 3))>, <trimesh.Trimesh(vertices.shape=(41, 3), faces.shape=(53, 3))>, <trimesh.Trimesh(vertices.shape=(36, 3), faces.shape=(68, 3))>, <trimesh.Trimesh(vertices.shape=(33, 3), faces.shape=(49, 3))>, <trimesh.Trimesh(vertices.shape=(32, 3), faces.shape=(51, 3))>, <trimesh.Trimesh(vertices.shape=(31, 3), faces.shape=(38, 3))>, <trimesh.Trimesh(vertices.shape=(29, 3), faces.shape=(42, 3))>, <trimesh.Trimesh(vertices.shape=(29, 3), faces.shape=(54, 3))>, <trimesh.Trimesh(vertices.shape=(28, 3), faces.shape=(42, 3))>, <trimesh.Trimesh(vertices.shape=(28, 3), faces.shape=(47, 3))>, <trimesh.Trimesh(vertices.shape=(26, 3), faces.shape=(36, 3))>, <trimesh.Trimesh(vertices.shape=(25, 3), faces.shape=(46, 3))>, <trimesh.Trimesh(vertices.shape=(24, 3), faces.shape=(43, 3))>, <trimesh.Trimesh(vertices.shape=(24, 3), faces.shape=(44, 3))>, <trimesh.Trimesh(vertices.shape=(23, 3), faces.shape=(42, 3))>, <trimesh.Trimesh(vertices.shape=(22, 3), faces.shape=(29, 3))>, <trimesh.Trimesh(vertices.shape=(21, 3), faces.shape=(38, 3))>, <trimesh.Trimesh(vertices.shape=(20, 3), faces.shape=(36, 3))>, <trimesh.Trimesh(vertices.shape=(19, 3), faces.shape=(30, 3))>, <trimesh.Trimesh(vertices.shape=(19, 3), faces.shape=(34, 3))>, <trimesh.Trimesh(vertices.shape=(18, 3), faces.shape=(26, 3))>, <trimesh.Trimesh(vertices.shape=(17, 3), faces.shape=(30, 3))>, <trimesh.Trimesh(vertices.shape=(16, 3), faces.shape=(28, 3))>, <trimesh.Trimesh(vertices.shape=(16, 3), faces.shape=(28, 3))>, <trimesh.Trimesh(vertices.shape=(13, 3), faces.shape=(20, 3))>, <trimesh.Trimesh(vertices.shape=(13, 3), faces.shape=(20, 3))>, <trimesh.Trimesh(vertices.shape=(13, 3), faces.shape=(22, 3))>, <trimesh.Trimesh(vertices.shape=(12, 3), faces.shape=(20, 3))>, <trimesh.Trimesh(vertices.shape=(12, 3), faces.shape=(20, 3))>, <trimesh.Trimesh(vertices.shape=(11, 3), faces.shape=(22, 3))>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(30378, 3), faces.shape=(80752, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(25567, 3), faces.shape=(70491, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(318, 3), faces.shape=(672, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(245, 3), faces.shape=(534, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(189, 3), faces.shape=(285, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(189, 3), faces.shape=(374, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(160, 3), faces.shape=(294, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(131, 3), faces.shape=(290, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(101, 3), faces.shape=(202, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(85, 3), faces.shape=(127, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(77, 3), faces.shape=(117, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(76, 3), faces.shape=(139, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(72, 3), faces.shape=(100, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(67, 3), faces.shape=(132, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(58, 3), faces.shape=(109, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(51, 3), faces.shape=(102, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(49, 3), faces.shape=(76, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(47, 3), faces.shape=(65, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(46, 3), faces.shape=(92, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(44, 3), faces.shape=(84, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(43, 3), faces.shape=(58, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(42, 3), faces.shape=(80, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(41, 3), faces.shape=(53, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(36, 3), faces.shape=(68, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(33, 3), faces.shape=(49, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(32, 3), faces.shape=(51, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(31, 3), faces.shape=(38, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(29, 3), faces.shape=(42, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(29, 3), faces.shape=(54, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(28, 3), faces.shape=(42, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(28, 3), faces.shape=(47, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(26, 3), faces.shape=(36, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(25, 3), faces.shape=(46, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(24, 3), faces.shape=(43, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(24, 3), faces.shape=(44, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(23, 3), faces.shape=(42, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(22, 3), faces.shape=(29, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(21, 3), faces.shape=(38, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(20, 3), faces.shape=(36, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(19, 3), faces.shape=(30, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(19, 3), faces.shape=(34, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(18, 3), faces.shape=(26, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(17, 3), faces.shape=(30, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(16, 3), faces.shape=(28, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(16, 3), faces.shape=(28, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(13, 3), faces.shape=(20, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(13, 3), faces.shape=(20, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(13, 3), faces.shape=(22, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(12, 3), faces.shape=(20, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(12, 3), faces.shape=(20, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(11, 3), faces.shape=(22, 3))>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mesh,inside_pieces = tu.remove_mesh_interior(current_neuron,\n",
    "                                                size_threshold_to_remove=20,\n",
    "                                                 return_removed_pieces=True,\n",
    "                                                 try_hole_close=False\n",
    "                                                )\n",
    "inside_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 8835 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_28311.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_28311_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_29257.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_28311.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_28311_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_29257.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:47,084 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,224 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,225 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,229 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,230 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,239 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,273 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,380 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,386 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,531 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,532 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,533 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,533 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,638 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,663 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,664 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,667 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,670 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,700 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,705 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,778 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:47,788 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,366 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,367 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,382 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,383 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,385 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,386 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,602 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,612 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:48,614 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,078 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,084 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,086 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,087 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,105 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,106 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,111 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,115 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,118 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,121 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,130 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,133 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,148 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,149 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,157 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,157 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,158 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,164 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,172 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,173 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,182 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,183 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,186 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,190 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,193 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,195 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,208 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,211 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,214 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,215 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,216 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,217 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,223 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,226 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,259 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,259 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,260 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,261 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,290 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:49,293 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,502 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,504 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,523 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,535 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,537 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,549 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,550 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,551 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,552 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,563 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,565 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,568 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,590 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,592 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,624 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,625 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,626 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,627 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,657 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,666 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,667 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,671 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,673 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,684 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,686 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,780 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,781 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,783 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,784 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,807 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,809 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,810 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,812 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,816 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,817 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,818 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:50,821 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,823 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,824 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,829 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,838 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,839 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,852 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,853 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,856 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,858 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,860 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,865 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,868 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,872 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,875 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,878 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,879 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,883 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,884 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,923 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,925 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,954 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,955 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,957 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,958 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:50,965 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,013 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,094 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,096 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,097 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,110 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,111 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,115 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,126 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,127 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,128 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,131 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,135 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,136 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,145 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,150 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,151 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,327 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,330 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,467 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,468 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,468 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,472 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,473 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,488 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,493 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,496 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,509 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,530 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,532 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,538 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,539 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,541 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,542 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,549 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,550 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,551 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,552 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,554 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,554 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,558 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,558 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,559 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,562 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,568 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,570 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,581 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,582 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,588 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,588 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,594 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,601 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,607 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,608 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,609 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,632 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,634 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,634 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,635 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,640 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,669 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,684 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,684 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,685 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,686 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,686 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,688 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,692 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,751 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,758 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,758 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,760 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,761 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,767 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,768 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,768 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,769 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,770 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,771 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,772 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,773 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,792 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,793 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:51,823 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,824 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,875 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,880 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,893 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,942 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:51,944 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,028 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,034 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,069 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,070 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,071 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,073 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,073 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,074 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,075 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,077 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,083 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,083 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,085 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,085 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,130 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,132 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,251 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,264 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,312 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,319 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,327 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,335 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,335 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,337 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,343 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,349 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,360 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,393 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,394 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,413 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,415 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,430 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,436 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,458 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,465 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,477 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,516 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,573 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,574 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,584 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,627 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,628 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,651 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,677 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,749 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,788 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,815 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,818 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,820 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,821 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,824 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,826 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,829 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,832 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,834 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,836 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,839 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,841 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,846 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,849 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,850 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,850 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,851 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,852 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,852 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,856 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,861 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,867 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,869 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,872 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,878 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,882 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,883 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,890 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,891 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,892 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,899 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,901 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,902 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,904 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,908 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,940 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,949 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,959 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,969 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:52,993 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,111 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,119 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,124 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,127 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,146 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,149 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,156 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,160 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,161 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,165 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,166 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,169 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,177 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,205 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:53,206 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,211 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,212 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,216 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,232 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,235 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,240 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,241 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,241 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,243 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,243 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,252 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,253 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,267 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,268 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,269 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,270 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,277 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,277 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,279 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,280 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,282 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,315 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,323 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,325 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,327 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,331 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,333 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,338 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,341 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,344 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,350 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,404 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,405 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,406 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,407 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,411 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,445 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,446 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,447 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,448 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,486 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,491 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,494 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,496 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,506 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,509 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,512 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,512 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,515 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,517 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,520 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,521 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,522 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,528 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,577 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,591 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,592 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,593 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,594 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,609 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,610 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,610 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,614 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,615 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,616 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,622 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,624 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,633 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,633 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,634 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,658 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,661 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,663 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,673 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,734 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,738 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,740 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,749 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,772 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,778 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,802 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,803 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,803 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,804 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,817 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,817 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,821 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,823 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,844 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,845 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,952 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,953 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,966 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,967 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,974 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,975 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,980 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:53,982 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,049 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,056 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,065 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,069 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,070 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:54,072 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,073 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,084 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,085 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,113 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,114 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,117 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,118 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,119 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,120 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,127 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,128 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,128 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,137 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,138 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,141 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,142 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,175 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,213 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,217 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,219 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,221 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,243 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,245 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,268 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,269 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,271 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,272 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,273 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,274 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,275 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,275 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,276 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,277 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,279 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,280 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,292 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,293 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,302 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,307 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,310 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,314 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,321 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,321 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,338 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,356 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,379 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,384 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,385 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,399 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,410 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,411 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,413 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,413 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,417 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,419 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,455 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,456 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,460 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,461 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,464 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,466 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,470 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,572 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,574 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,779 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,787 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,803 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,808 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,810 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,811 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,813 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,825 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,826 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,830 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,830 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,850 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,851 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,860 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,860 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,864 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,865 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,868 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,894 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,895 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,906 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,907 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,953 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,953 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,962 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:54,963 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,035 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,050 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,051 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,088 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,089 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,144 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,180 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,181 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,191 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,196 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,214 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,233 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,237 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,240 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,255 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,257 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:55,259 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,262 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,265 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,266 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,267 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,288 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,318 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,330 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,331 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,333 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,334 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,358 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,360 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,361 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,363 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,364 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,365 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,368 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,373 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,381 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,389 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,400 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,503 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,505 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,506 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,578 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,579 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,600 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,617 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,642 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,663 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,674 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,684 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,687 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,737 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,738 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,757 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,760 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,780 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,791 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,799 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,822 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,830 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,837 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,838 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,850 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,889 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,891 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,901 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,904 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,908 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,909 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,917 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,957 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:55,969 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,001 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,002 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,026 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,029 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,051 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,057 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,916 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,918 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,921 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,922 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,934 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,936 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,937 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,939 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,942 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,969 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,977 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,981 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:56,981 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,022 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,025 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,025 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,049 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,056 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,068 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,085 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,088 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,091 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,096 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,100 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,106 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,108 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,119 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,149 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,151 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,154 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,193 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,196 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,212 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,214 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,272 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,274 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,313 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,315 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,337 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,337 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,340 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,341 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,392 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:57,412 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,421 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,422 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,452 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,454 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,457 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,477 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,478 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,480 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,481 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,515 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,517 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,527 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,568 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,569 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,572 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,572 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,593 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,593 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,609 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,610 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,611 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,612 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,628 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,629 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,634 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,636 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,638 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,639 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,657 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,678 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,792 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,794 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,799 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,799 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,800 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,803 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,804 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:57,804 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,026 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,033 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,035 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,041 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,045 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,096 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,097 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,208 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,425 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,426 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,429 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,430 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,454 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,490 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,528 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,536 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,545 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,563 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,570 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,570 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,613 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,618 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,644 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,646 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,650 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,661 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,673 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,679 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,680 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,680 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,683 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,690 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,691 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,704 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,704 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,724 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,729 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,730 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,734 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,755 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,771 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,774 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,775 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,792 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,804 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,805 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,807 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,811 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,812 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,816 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,859 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,879 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,880 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,899 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,933 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,936 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,938 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,939 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,940 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,941 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,942 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,954 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,956 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,960 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:17:58,961 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,987 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:58,989 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,016 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,042 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,150 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,151 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,159 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,162 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,215 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,223 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,257 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,258 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,259 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,277 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,278 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,280 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,309 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,310 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,321 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,330 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,345 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,351 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,353 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,398 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,399 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,400 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,412 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,413 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,415 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,417 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,421 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,433 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,445 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,445 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,449 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,462 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,465 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,488 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,491 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,501 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,502 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,515 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,539 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,540 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,541 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,544 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,614 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,638 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,639 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,659 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,687 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,688 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,715 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,716 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,721 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,726 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,738 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,740 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,741 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,742 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,743 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,745 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,748 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,772 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:17:59,795 - base - face_normals all zero, ignoring!\n",
      "/meshAfterParty/trimesh_utils.py:660: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 50 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 50\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(47215, 3), faces.shape=(104271, 3))>, <trimesh.Trimesh(vertices.shape=(23629, 3), faces.shape=(50037, 3))>, <trimesh.Trimesh(vertices.shape=(22324, 3), faces.shape=(42173, 3))>, <trimesh.Trimesh(vertices.shape=(2925, 3), faces.shape=(7265, 3))>, <trimesh.Trimesh(vertices.shape=(1615, 3), faces.shape=(3558, 3))>, <trimesh.Trimesh(vertices.shape=(1528, 3), faces.shape=(3871, 3))>, <trimesh.Trimesh(vertices.shape=(1475, 3), faces.shape=(3390, 3))>, <trimesh.Trimesh(vertices.shape=(1368, 3), faces.shape=(3101, 3))>, <trimesh.Trimesh(vertices.shape=(1287, 3), faces.shape=(2888, 3))>, <trimesh.Trimesh(vertices.shape=(1242, 3), faces.shape=(2815, 3))>, <trimesh.Trimesh(vertices.shape=(1197, 3), faces.shape=(2636, 3))>, <trimesh.Trimesh(vertices.shape=(1184, 3), faces.shape=(2668, 3))>, <trimesh.Trimesh(vertices.shape=(1117, 3), faces.shape=(2430, 3))>, <trimesh.Trimesh(vertices.shape=(1115, 3), faces.shape=(2457, 3))>, <trimesh.Trimesh(vertices.shape=(978, 3), faces.shape=(2130, 3))>, <trimesh.Trimesh(vertices.shape=(937, 3), faces.shape=(2021, 3))>, <trimesh.Trimesh(vertices.shape=(883, 3), faces.shape=(1932, 3))>, <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1842, 3))>, <trimesh.Trimesh(vertices.shape=(825, 3), faces.shape=(1826, 3))>, <trimesh.Trimesh(vertices.shape=(815, 3), faces.shape=(1784, 3))>, <trimesh.Trimesh(vertices.shape=(747, 3), faces.shape=(1650, 3))>, <trimesh.Trimesh(vertices.shape=(695, 3), faces.shape=(1519, 3))>, <trimesh.Trimesh(vertices.shape=(483, 3), faces.shape=(1078, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 7197224, Final mesh size: 6947494\n",
      "Total time = 390.35546112060547\n",
      "xvfb-run -n 8291 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25801553.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:22:41,014 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,015 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,018 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,020 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,029 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,049 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,121 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,126 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,252 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,254 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,352 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,353 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,355 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,357 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,377 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,381 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,873 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,874 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,885 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,886 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,887 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:41,888 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,061 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,063 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,438 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,444 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,446 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,447 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,463 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,463 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,468 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,471 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,474 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,477 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,486 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,500 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,500 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,513 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,523 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,523 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,528 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,530 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,533 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,544 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,548 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,549 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,550 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,551 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,556 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,558 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,584 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,585 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,585 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,586 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,602 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:42,604 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,656 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,658 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,672 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,677 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,691 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,692 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,704 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,705 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,715 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,717 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,720 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,722 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,731 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,738 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,740 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,761 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,762 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,762 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,763 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,780 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,788 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,789 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,793 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,794 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,876 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,877 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,882 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,883 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,884 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,887 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,890 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,891 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,897 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,905 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,906 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,914 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,914 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,916 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,917 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,924 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,926 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,927 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,929 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,931 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,932 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,934 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,934 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:22:44,955 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,957 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,958 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,960 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,981 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,982 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,984 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,985 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:44,990 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,022 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,082 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,085 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,085 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,092 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,093 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,097 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,108 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,109 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,110 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,112 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,116 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,116 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,127 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,128 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,369 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,370 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,371 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,373 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,374 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,377 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,382 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,384 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,393 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,411 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,412 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,417 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,417 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,418 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,426 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,426 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,428 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,429 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,431 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,432 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,435 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,436 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,437 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,441 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,445 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,447 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,456 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,457 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,458 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,458 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,461 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,461 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,465 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,470 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,473 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,474 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,475 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,485 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,485 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,486 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,487 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,488 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,516 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,524 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,525 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,526 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,527 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,528 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,534 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,535 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,602 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,607 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,608 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,615 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,616 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,617 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,618 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,619 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,622 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,624 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,624 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,641 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,642 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,652 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,674 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,675 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,718 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,722 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,846 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,852 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,887 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,888 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,889 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,891 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,892 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,893 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,894 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,895 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,901 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,902 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:22:45,938 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:45,940 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,113 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,134 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,135 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,143 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,150 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,151 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,197 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,197 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,216 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,218 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,228 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,254 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,265 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,297 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,308 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,316 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,317 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,479 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,482 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,483 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,484 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,487 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,491 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,494 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,494 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,496 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,500 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,502 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,509 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,510 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,511 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,516 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,521 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,523 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,526 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,528 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,530 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,536 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,537 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,539 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,589 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,619 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,710 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,723 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,740 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,747 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,749 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,750 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,754 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,755 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,762 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,796 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,820 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,823 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,845 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,854 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,856 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,857 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,861 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,864 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,868 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,870 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,874 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,878 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,936 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,937 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,968 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,972 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,976 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,978 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,984 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,987 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,990 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,990 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,992 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,993 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,994 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,995 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,997 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:46,998 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,000 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,006 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,053 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,054 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,055 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,057 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,058 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,059 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,075 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,076 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,097 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,109 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,159 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,160 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,189 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,190 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,204 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,206 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,296 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,297 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,306 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:22:47,307 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,309 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,310 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,311 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,312 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,313 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,315 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,376 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,377 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,378 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,379 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,389 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,390 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,413 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,414 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,430 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,431 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,448 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,469 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,477 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,510 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,530 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,533 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,534 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,534 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,535 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,536 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,537 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,538 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,539 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,541 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,542 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,559 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,564 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,567 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,570 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,587 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,599 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,625 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,631 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,642 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,653 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,655 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,656 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,658 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,659 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,661 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,689 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,690 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,693 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,694 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,696 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,699 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,702 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,978 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,979 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,988 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:47,990 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,011 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,014 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,018 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,038 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,038 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,047 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,048 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,080 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,081 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,087 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,088 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,145 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,146 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,154 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,155 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,166 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,167 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,191 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,192 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,240 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,268 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,285 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,286 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,306 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,342 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,342 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,347 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,348 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,350 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,367 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,412 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,414 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,415 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,429 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,450 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,450 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,458 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,531 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,532 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,534 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,596 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,677 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,677 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,697 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,700 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,718 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:22:48,725 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,729 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,753 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,763 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,764 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,809 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,841 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,851 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,874 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,875 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:48,913 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,411 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,468 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,625 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,638 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,640 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,642 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,643 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,647 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,671 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,671 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,700 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,701 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,804 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,805 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,842 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,843 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,864 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,866 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,883 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,883 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,885 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,886 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,955 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,956 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,963 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,979 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:49,999 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,006 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,030 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,044 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,066 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,067 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,069 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,072 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,073 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,074 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,184 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,186 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,191 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,192 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,193 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,196 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,197 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,198 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,360 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,368 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,369 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,375 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,378 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:50,487 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,070 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,073 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,096 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,194 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,201 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,202 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,273 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,303 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,323 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,324 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,341 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,342 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,380 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,382 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,383 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,410 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,410 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,412 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,417 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,524 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,531 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,543 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,546 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,548 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,552 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,553 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,630 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,800 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,802 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,818 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,831 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,839 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,839 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,853 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,866 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,869 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,870 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,877 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,878 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,891 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,896 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,897 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,901 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,902 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,906 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,906 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:22:51,908 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,981 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,982 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,984 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,986 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:51,989 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:52,000 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:52,002 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:22:52,012 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(826236, 3), faces.shape=(1632868, 3))>, <trimesh.Trimesh(vertices.shape=(10689, 3), faces.shape=(17319, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(826236, 3), faces.shape=(1632868, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 8264 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89675.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89675_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_194652.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89675.off loaded has 826236 vn 1632868 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_89675_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_194652.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 39424080\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 39424080\n",
      "LOG: 2 Successfully removed 921 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 921 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 39413028\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_194652.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 4663 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_72233.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_72233_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_651808.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_72233.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_72233_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_651808.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2833: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 285\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece.off\n",
      "xvfb-run -n 1026 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/poisson_160799.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(48520, 3), faces.shape=(97048, 3))>, <trimesh.Trimesh(vertices.shape=(15949, 3), faces.shape=(31902, 3))>, <trimesh.Trimesh(vertices.shape=(14015, 3), faces.shape=(28030, 3))>, <trimesh.Trimesh(vertices.shape=(12403, 3), faces.shape=(24810, 3))>, <trimesh.Trimesh(vertices.shape=(11231, 3), faces.shape=(22462, 3))>, <trimesh.Trimesh(vertices.shape=(3598, 3), faces.shape=(7192, 3))>, <trimesh.Trimesh(vertices.shape=(3036, 3), faces.shape=(6068, 3))>, <trimesh.Trimesh(vertices.shape=(2683, 3), faces.shape=(5362, 3))>, <trimesh.Trimesh(vertices.shape=(2465, 3), faces.shape=(4934, 3))>, <trimesh.Trimesh(vertices.shape=(2426, 3), faces.shape=(4852, 3))>, <trimesh.Trimesh(vertices.shape=(2413, 3), faces.shape=(4826, 3))>, <trimesh.Trimesh(vertices.shape=(2395, 3), faces.shape=(4798, 3))>, <trimesh.Trimesh(vertices.shape=(2362, 3), faces.shape=(4732, 3))>, <trimesh.Trimesh(vertices.shape=(2309, 3), faces.shape=(4622, 3))>, <trimesh.Trimesh(vertices.shape=(2302, 3), faces.shape=(4600, 3))>, <trimesh.Trimesh(vertices.shape=(2148, 3), faces.shape=(4296, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(4248, 3))>, <trimesh.Trimesh(vertices.shape=(2110, 3), faces.shape=(4216, 3))>, <trimesh.Trimesh(vertices.shape=(2095, 3), faces.shape=(4190, 3))>, <trimesh.Trimesh(vertices.shape=(2078, 3), faces.shape=(4156, 3))>, <trimesh.Trimesh(vertices.shape=(2058, 3), faces.shape=(4112, 3))>, <trimesh.Trimesh(vertices.shape=(2023, 3), faces.shape=(4050, 3))>, <trimesh.Trimesh(vertices.shape=(1995, 3), faces.shape=(3986, 3))>, <trimesh.Trimesh(vertices.shape=(1966, 3), faces.shape=(3940, 3))>, <trimesh.Trimesh(vertices.shape=(1893, 3), faces.shape=(3786, 3))>, <trimesh.Trimesh(vertices.shape=(1853, 3), faces.shape=(3710, 3))>, <trimesh.Trimesh(vertices.shape=(1848, 3), faces.shape=(3696, 3))>, <trimesh.Trimesh(vertices.shape=(1833, 3), faces.shape=(3666, 3))>, <trimesh.Trimesh(vertices.shape=(1799, 3), faces.shape=(3594, 3))>, <trimesh.Trimesh(vertices.shape=(1752, 3), faces.shape=(3504, 3))>, <trimesh.Trimesh(vertices.shape=(1743, 3), faces.shape=(3486, 3))>, <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>, <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>, <trimesh.Trimesh(vertices.shape=(1728, 3), faces.shape=(3452, 3))>, <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3446, 3))>, <trimesh.Trimesh(vertices.shape=(1721, 3), faces.shape=(3438, 3))>, <trimesh.Trimesh(vertices.shape=(1712, 3), faces.shape=(3420, 3))>, <trimesh.Trimesh(vertices.shape=(1694, 3), faces.shape=(3388, 3))>, <trimesh.Trimesh(vertices.shape=(1671, 3), faces.shape=(3338, 3))>, <trimesh.Trimesh(vertices.shape=(1653, 3), faces.shape=(3302, 3))>, <trimesh.Trimesh(vertices.shape=(1632, 3), faces.shape=(3260, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(48520, 3), faces.shape=(97048, 3))>\n",
      "xvfb-run -n 2657 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(12126, 3), faces.shape=(24260, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008702278137207031\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 2.0414791107177734\n",
      "2) Finished: Generating CGAL segmentation for neuron: 2.415855884552002\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.008307456970214844\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.555152893066406e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.019779443740844727\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.11762499809265137\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.14330500000000002\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1, 16,  0, 13,  8,  5,  4, 21,  9, 14, 18, 10, 20,  2, 11, 15, 12,\n",
      "        6,  7, 22, 17,  3, 19]), array([0.817645  , 0.153899  , 0.143305  , 0.132864  , 0.114123  ,\n",
      "       0.0695834 , 0.0692177 , 0.0637264 , 0.0606013 , 0.06005705,\n",
      "       0.0592976 , 0.0557351 , 0.0541269 , 0.0534251 , 0.0533066 ,\n",
      "       0.0532643 , 0.0513733 , 0.0482504 , 0.0462964 , 0.0408732 ,\n",
      "       0.0372993 , 0.0371331 , 0.03297225]))\n",
      "Sizes = [2227, 343, 7664, 99, 183, 3888, 1344, 713, 1269, 950, 427, 144, 181, 65, 835, 1179, 161, 968, 625, 15, 365, 539, 76]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6944 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_170379.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_170379_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_416189.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_170379.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_170379_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_416189.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.0850103852915223\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/108_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c180fa47f7f74405a3582167bb6c20b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/424_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5f2bc78bcb42988e5239b6cbd1b96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/431_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1455: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ab865937534ca3987da12cef689326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(15949, 3), faces.shape=(31902, 3))>\n",
      "xvfb-run -n 7139 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3985, 3), faces.shape=(7974, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007255077362060547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837801_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.5399975776672363\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6911485195159912\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0027513504028320312\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00016045570373535156\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007142543792724609\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03681206703186035\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 8,  3,  5,  6, 11, 12,  0, 14,  4,  1,  2,  7, 13, 10,  9]), array([0.7061495, 0.70383  , 0.68655  , 0.6828125, 0.6389545, 0.586836 ,\n",
      "       0.5623685, 0.542515 , 0.5322625, 0.422495 , 0.3962545, 0.379725 ,\n",
      "       0.353034 , 0.344464 , 0.170751 ]))\n",
      "Sizes = [1082, 1813, 338, 910, 456, 447, 1478, 92, 320, 196, 72, 443, 91, 219, 17]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 4 viable somas: [8, 3, 6, 0]\n",
      "xz = 9.929323108283386 ratio was beyong 6 multiplier\n",
      "yz = 9.984464866392544 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_984361.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 135.41151091556304\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(545, 3), faces.shape=(1082, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/665_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0e4f0a3cb245c0a38c5f07f6f439b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_181872.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 46.535160958442795\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(323, 3), faces.shape=(639, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_29749.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 568.536891901537\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(1813, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/985_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069ff5c1fbaf45aa903f549da26f8671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3292 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_642855.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_642855_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_433000.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_642855.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_642855_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_433000.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 266.32932291736785\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(682, 3), faces.shape=(1356, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_493872.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 258.85814827668946\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(459, 3), faces.shape=(910, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/876_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ce43255790465e9340b9ef2a90d890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_131749.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 170.91515185292263\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(350, 3), faces.shape=(693, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_314168.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1983.3510668964152\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(743, 3), faces.shape=(1478, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/216_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe03a74089b44bd877c22938f923d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_449126.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 617.7067750486528\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(342, 3), faces.shape=(677, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(14015, 3), faces.shape=(28030, 3))>\n",
      "xvfb-run -n 3683 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3503, 3), faces.shape=(7006, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007300376892089844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837802_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.591062068939209\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.7268810272216797\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002788543701171875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.482269287109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006394624710083008\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.032839298248291016\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 8, 5, 0, 1, 7, 2, 4, 6, 9]), array([0.719792  , 0.159522  , 0.07951335, 0.0748191 , 0.07255355,\n",
      "       0.0645982 , 0.0645651 , 0.0611307 , 0.0418272 , 0.0371311 ]))\n",
      "Sizes = [2091, 245, 366, 1591, 138, 83, 1367, 833, 271, 21]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6491 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_901521.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_901521_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_500068.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_901521.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_901521_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_500068.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.5938767408303427\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/507_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafaf045213d4a209a3c6cd14d47918c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/508_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b262da838a749068e6a8f3c4e740903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/182_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba7c9e2efd64dad9b3d92eaf90ee964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(12403, 3), faces.shape=(24810, 3))>\n",
      "xvfb-run -n 2402 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3099, 3), faces.shape=(6202, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007994174957275391\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837803_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.49437713623046875\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6187326908111572\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002134084701538086\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00015282630920410156\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00557708740234375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02871394157409668\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([4, 5, 7, 3, 0, 1, 8, 9, 2, 6]), array([0.805872  , 0.120394  , 0.103532  , 0.0750936 , 0.07453455,\n",
      "       0.0736238 , 0.0706298 , 0.0695376 , 0.0639401 , 0.0357858 ]))\n",
      "Sizes = [1619, 433, 367, 53, 616, 2124, 247, 231, 403, 109]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [4]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5966 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_894328.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_894328_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_804217.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_894328.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_894328_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_804217.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.024140735327679\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/544_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1288c141f02246b6b77c4125524036a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/207_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d389626f093f474e89329997481f90f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/879_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed37598e0b74768b3ff98add3a9edf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(11231, 3), faces.shape=(22462, 3))>\n",
      "xvfb-run -n 4392 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2806, 3), faces.shape=(5612, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00042128562927246094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837804_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.3142573833465576\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.4280416965484619\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0019497871398925781\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005032539367675781\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02606821060180664\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 3, 10,  1, 11,  2,  9, 12,  0,  6,  4,  8,  7,  5, 13]), array([0.732599 , 0.730422 , 0.6779985, 0.621895 , 0.541875 , 0.519333 ,\n",
      "       0.508099 , 0.5048265, 0.487588 , 0.403319 , 0.352397 , 0.317647 ,\n",
      "       0.251915 , 0.2374135]))\n",
      "Sizes = [459, 172, 736, 108, 1785, 231, 233, 786, 477, 191, 159, 190, 19, 66]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [1, 2, 0]\n",
      "xz = 6.185601456799217 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_557859.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 123.70004543403331\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(372, 3), faces.shape=(736, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/863_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686e13fa9e174494a08b76329b155d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "xy = 15.990309086491207 ratio was beyong 6 multiplier\n",
      "xz = 10.991247232825687 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_326478.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 138.36670280934857\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(896, 3), faces.shape=(1785, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/890_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966e506d7ec04c41b933c48cec637b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xy = 7.132653584271114 ratio was beyong 6 multiplier\n",
      "xz = 12.471530129063982 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_241851.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 44.76840828773376\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(378, 3), faces.shape=(750, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_913200.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 579.7773521070712\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(396, 3), faces.shape=(786, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/106_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f726f65cb91c4c52b6acccb929e3c11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(3598, 3), faces.shape=(7192, 3))>\n",
      "xvfb-run -n 7172 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(901, 3), faces.shape=(1798, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002276897430419922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837805_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1660597324371338\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.20441746711730957\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0011851787567138672\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.76837158203125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015714168548583984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008330345153808594\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 5,  2,  9,  0,  4,  1, 10,  6,  7,  3,  8]), array([0.864727 , 0.6419095, 0.5860125, 0.4914945, 0.388476 , 0.317355 ,\n",
      "       0.223423 , 0.205865 , 0.153111 , 0.115377 , 0.0373903]))\n",
      "Sizes = [208, 486, 88, 148, 296, 394, 58, 16, 35, 57, 12]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(3036, 3), faces.shape=(6068, 3))>\n",
      "xvfb-run -n 6930 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(760, 3), faces.shape=(1516, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023674964904785156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837806_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08822107315063477\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11580801010131836\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006594657897949219\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.269050598144531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015118122100830078\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007718801498413086\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 5, 4, 1, 0]), array([0.660338, 0.49801 , 0.400623, 0.259123, 0.24726 , 0.196706]))\n",
      "Sizes = [278, 159, 115, 166, 199, 599]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(2683, 3), faces.shape=(5362, 3))>\n",
      "xvfb-run -n 5095 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(672, 3), faces.shape=(1340, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002396106719970703\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837807_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07079887390136719\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09444737434387207\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006184577941894531\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002155303955078125\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00135040283203125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00690460205078125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 2, 0, 4, 1, 6, 3]), array([0.738041 , 0.661579 , 0.550076 , 0.50333  , 0.3728035, 0.207627 ,\n",
      "       0.130756 ]))\n",
      "Sizes = [74, 116, 684, 206, 176, 55, 29]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_411474.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 895.671827817885\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/283_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b86841f1134e449e5ff48d5d590e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_176424.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 895.671827817885\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(2465, 3), faces.shape=(4934, 3))>\n",
      "xvfb-run -n 2621 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(614, 3), faces.shape=(1232, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002262592315673828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837808_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10683655738830566\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13701677322387695\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005946159362792969\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.696846008300781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012392997741699219\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006378650665283203\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 4, 0, 2, 3]), array([0.795044, 0.555128, 0.450513, 0.440104, 0.115918]))\n",
      "Sizes = [529, 88, 455, 122, 38]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(2426, 3), faces.shape=(4852, 3))>\n",
      "xvfb-run -n 3649 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(606, 3), faces.shape=(1212, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020170211791992188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837809_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09484457969665527\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12316441535949707\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005269050598144531\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.601478576660156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011773109436035156\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005959033966064453\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3, 4]), array([0.833541 , 0.611483 , 0.422296 , 0.258399 , 0.0708488]))\n",
      "Sizes = [195, 328, 401, 276, 12]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(2413, 3), faces.shape=(4826, 3))>\n",
      "xvfb-run -n 4305 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(603, 3), faces.shape=(1206, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008678436279296875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10075926780700684\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13031578063964844\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005562305450439453\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.2928924560546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013124942779541016\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006193399429321289\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 4, 3, 1, 2]), array([0.8141725, 0.3817665, 0.236384 , 0.118656 , 0.092212 ]))\n",
      "Sizes = [488, 274, 329, 70, 45]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #11: <trimesh.Trimesh(vertices.shape=(2395, 3), faces.shape=(4798, 3))>\n",
      "xvfb-run -n 7385 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(595, 3), faces.shape=(1198, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022459030151367188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1172950267791748\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13979291915893555\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005512237548828125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00017404556274414062\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012965202331542969\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006025791168212891\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 1, 4, 5, 0]), array([0.585668  , 0.5807065 , 0.450853  , 0.181399  , 0.0805994 ,\n",
      "       0.05613955]))\n",
      "Sizes = [223, 790, 51, 55, 27, 52]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_728761.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.054306900000702\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(395, 3), faces.shape=(790, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/963_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c942734cc144bffb0405fe552af25ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_814030.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.11221507977423\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(771, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #12: <trimesh.Trimesh(vertices.shape=(2362, 3), faces.shape=(4732, 3))>\n",
      "xvfb-run -n 6301 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(587, 3), faces.shape=(1182, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002162456512451172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378012_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10768008232116699\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12946796417236328\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005109310150146484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.6253204345703125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011734962463378906\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005972623825073242\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.450774, 0.141932]))\n",
      "Sizes = [1163, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_545652.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 69.63800274263164\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(578, 3), faces.shape=(1163, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/586_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af46788031d4a5ba10c21d85dbd606a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_793871.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 69.63800274263164\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(578, 3), faces.shape=(1163, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #13: <trimesh.Trimesh(vertices.shape=(2309, 3), faces.shape=(4622, 3))>\n",
      "xvfb-run -n 119 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(575, 3), faces.shape=(1154, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021219253540039062\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378013_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10146617889404297\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12265300750732422\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005350112915039062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.176399230957031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011854171752929688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005693912506103516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 5, 0, 4, 6, 1, 3]), array([0.778447 , 0.6065485, 0.40835  , 0.394006 , 0.359206 , 0.250187 ,\n",
      "       0.0850951]))\n",
      "Sizes = [412, 282, 106, 77, 147, 74, 56]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #14: <trimesh.Trimesh(vertices.shape=(2302, 3), faces.shape=(4600, 3))>\n",
      "xvfb-run -n 3050 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(577, 3), faces.shape=(1150, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000301361083984375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378014_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10684871673583984\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1297760009765625\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005342960357666016\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.53131103515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011415481567382812\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006254673004150391\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 1, 0, 4]), array([0.803642  , 0.442355  , 0.438445  , 0.131663  , 0.03917375]))\n",
      "Sizes = [445, 113, 519, 53, 20]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #15: <trimesh.Trimesh(vertices.shape=(2148, 3), faces.shape=(4296, 3))>\n",
      "xvfb-run -n 2655 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(537, 3), faces.shape=(1074, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00025391578674316406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378015_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08280038833618164\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10040998458862305\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004551410675048828\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.673004150390625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000990152359008789\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004907131195068359\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 3, 2, 4]), array([0.7004175, 0.573456 , 0.316827 , 0.10969  , 0.0395501]))\n",
      "Sizes = [660, 97, 262, 30, 25]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_255119.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.849953270789564\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(333, 3), faces.shape=(660, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/238_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf02d2e73c446668982790804261358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_97793.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.849953270789564\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(333, 3), faces.shape=(660, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #16: <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(4248, 3))>\n",
      "xvfb-run -n 9279 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(533, 3), faces.shape=(1062, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002465248107910156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378016_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08538436889648438\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10421919822692871\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004627704620361328\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.696846008300781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010161399841308594\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005053043365478516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.815914, 0.355768]))\n",
      "Sizes = [357, 705]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3320 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_32706.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_32706_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_585027.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_32706.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_32706_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_585027.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.291618617059151\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/430_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12647e8aadcb4655b2f83a3790513922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/835_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a831aebe4fca4555bc4c635e7393e828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/251_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05a160dc89948b3b59eecf535f6cfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #17: <trimesh.Trimesh(vertices.shape=(2110, 3), faces.shape=(4216, 3))>\n",
      "xvfb-run -n 5393 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(529, 3), faces.shape=(1054, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022459030151367188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378017_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0844411849975586\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10462331771850586\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004906654357910156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00016427040100097656\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011143684387207031\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004949092864990234\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([4, 1, 6, 3, 2, 0, 5]), array([0.6957455, 0.681171 , 0.663943 , 0.479034 , 0.341061 , 0.320237 ,\n",
      "       0.0387986]))\n",
      "Sizes = [120, 309, 69, 112, 67, 359, 18]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #18: <trimesh.Trimesh(vertices.shape=(2095, 3), faces.shape=(4190, 3))>\n",
      "xvfb-run -n 8479 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(523, 3), faces.shape=(1046, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022101402282714844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378018_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08930444717407227\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1097555160522461\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005185604095458984\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.246566772460938e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012059211730957031\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00532841682434082\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 0, 4, 1, 2]), array([0.857085 , 0.74002  , 0.4682425, 0.3759775, 0.264959 ]))\n",
      "Sizes = [238, 144, 260, 372, 32]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #19: <trimesh.Trimesh(vertices.shape=(2078, 3), faces.shape=(4156, 3))>\n",
      "xvfb-run -n 8725 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(519, 3), faces.shape=(1038, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021719932556152344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378019_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08925771713256836\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10902976989746094\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00047516822814941406\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.14984130859375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001115560531616211\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005017518997192383\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 4, 2, 5, 3]), array([0.811039, 0.671971, 0.616674, 0.520867, 0.135781, 0.124959]))\n",
      "Sizes = [366, 182, 161, 229, 28, 72]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #20: <trimesh.Trimesh(vertices.shape=(2058, 3), faces.shape=(4112, 3))>\n",
      "xvfb-run -n 9605 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(516, 3), faces.shape=(1028, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021839141845703125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378020_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09267711639404297\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11182641983032227\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00045680999755859375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1021575927734375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010492801666259766\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005347013473510742\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.694526 , 0.3827955]))\n",
      "Sizes = [686, 342]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4144 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_674601.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_674601_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_99781.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_674601.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_674601_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_99781.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 7.624178687645888\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/304_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e511031174604c0abeba9b574b62d7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/548_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4844eb97d40241bbaf6e2abcbf4f281e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/778_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d631e74ab8a24ee79524b0459f7359d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #21: <trimesh.Trimesh(vertices.shape=(2023, 3), faces.shape=(4050, 3))>\n",
      "xvfb-run -n 7508 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(504, 3), faces.shape=(1012, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022482872009277344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378021_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07945418357849121\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09814977645874023\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006203651428222656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.38690185546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009806156158447266\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004505634307861328\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 4, 0, 1, 3]), array([0.9015405, 0.632912 , 0.350319 , 0.329872 , 0.195833 ]))\n",
      "Sizes = [204, 529, 93, 64, 122]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #22: <trimesh.Trimesh(vertices.shape=(1995, 3), faces.shape=(3986, 3))>\n",
      "xvfb-run -n 5148 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(500, 3), faces.shape=(996, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000213623046875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378022_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05676770210266113\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07405996322631836\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003905296325683594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.982948303222656e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009829998016357422\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004542350769042969\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.287128, 0.113131]))\n",
      "Sizes = [851, 145]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #23: <trimesh.Trimesh(vertices.shape=(1966, 3), faces.shape=(3940, 3))>\n",
      "xvfb-run -n 9278 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(488, 3), faces.shape=(984, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022363662719726562\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378023_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09025907516479492\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10900092124938965\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005781650543212891\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.340576171875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010018348693847656\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0048980712890625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.488003 , 0.260311 , 0.1437635]))\n",
      "Sizes = [839, 119, 26]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_235940.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 16.672579043791114\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(839, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/639_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a072c7df593b4705943d17db99b0c8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_893773.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 16.672579043791114\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(839, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #24: <trimesh.Trimesh(vertices.shape=(1893, 3), faces.shape=(3786, 3))>\n",
      "xvfb-run -n 7923 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(473, 3), faces.shape=(946, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020813941955566406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378024_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08487248420715332\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1009681224822998\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004229545593261719\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.57763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010099411010742188\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0042476654052734375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 0, 1]), array([0.869201 , 0.4992765, 0.342949 , 0.322056 ]))\n",
      "Sizes = [231, 478, 61, 176]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #25: <trimesh.Trimesh(vertices.shape=(1853, 3), faces.shape=(3710, 3))>\n",
      "xvfb-run -n 8947 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(926, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002491474151611328\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378025_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.055478811264038086\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08169698715209961\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004398822784423828\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.841255187988281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009324550628662109\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00491023063659668\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5069765]))\n",
      "Sizes = [926]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_109838.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1090.437812159592\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(926, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/953_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f2756aefc54a0a8450c72c904fa69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_395816.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1090.437812159592\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(926, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #26: <trimesh.Trimesh(vertices.shape=(1848, 3), faces.shape=(3696, 3))>\n",
      "xvfb-run -n 4492 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(922, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002307891845703125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378026_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08732724189758301\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10410594940185547\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00044274330139160156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.008148193359375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001819610595703125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004683494567871094\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.950704, 0.567639]))\n",
      "Sizes = [109, 813]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_708042.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 76.08359507498268\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(407, 3), faces.shape=(813, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/67_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26df5981d8fa40aeb12a5c8c082914b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8326 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_274025.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_274025_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_264520.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_274025.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_274025_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_264520.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 43.44296998828287\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(320, 3), faces.shape=(636, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #27: <trimesh.Trimesh(vertices.shape=(1833, 3), faces.shape=(3666, 3))>\n",
      "xvfb-run -n 6501 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(458, 3), faces.shape=(916, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023674964904785156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378027_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0849144458770752\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10267758369445801\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005028247833251953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.7206878662109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009438991546630859\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004845857620239258\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.680617 , 0.576481 , 0.1993095]))\n",
      "Sizes = [241, 623, 52]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_301026.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.072649477915286\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(313, 3), faces.shape=(623, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/897_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bca2a727d52408f9c45a3f64978f493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_222867.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.072649477915286\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(313, 3), faces.shape=(623, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #28: <trimesh.Trimesh(vertices.shape=(1799, 3), faces.shape=(3594, 3))>\n",
      "xvfb-run -n 9520 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(451, 3), faces.shape=(898, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024509429931640625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378028_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07555699348449707\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09238004684448242\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004112720489501953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.315376281738281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008518695831298828\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0041997432708740234\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 3, 2, 1]), array([0.7380135, 0.513742 , 0.3604765, 0.256314 ]))\n",
      "Sizes = [492, 191, 160, 55]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #29: <trimesh.Trimesh(vertices.shape=(1752, 3), faces.shape=(3504, 3))>\n",
      "xvfb-run -n 2420 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(438, 3), faces.shape=(876, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002117156982421875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378029_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.069183349609375\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08519935607910156\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004317760467529297\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.76837158203125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008182525634765625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0041065216064453125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 5, 0, 1, 4, 3]), array([0.847436 , 0.815448 , 0.519697 , 0.4579105, 0.308722 , 0.1494015]))\n",
      "Sizes = [233, 149, 111, 262, 49, 72]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #30: <trimesh.Trimesh(vertices.shape=(1743, 3), faces.shape=(3486, 3))>\n",
      "xvfb-run -n 3144 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(435, 3), faces.shape=(870, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002665519714355469\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378030_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07147359848022461\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0886993408203125\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004851818084716797\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.9114227294921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008313655853271484\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004104137420654297\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 5, 3, 7, 4, 2, 0, 6]), array([0.834288 , 0.777868 , 0.705495 , 0.359084 , 0.3286575, 0.1959   ,\n",
      "       0.11813  , 0.0909822]))\n",
      "Sizes = [265, 195, 206, 65, 68, 19, 21, 31]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #31: <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>\n",
      "xvfb-run -n 7883 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002224445343017578\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378031_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04912090301513672\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06539583206176758\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.000377655029296875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00010585784912109375\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009527206420898438\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004251718521118164\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5436805]))\n",
      "Sizes = [864]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_652959.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 192.8042238651348\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/708_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49a0d2495e84d68b0897803ba71429f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_460629.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 192.8042238651348\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #32: <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>\n",
      "xvfb-run -n 1223 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022530555725097656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378032_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08116269111633301\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0984494686126709\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0013363361358642578\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.0067901611328125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008795261383056641\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0043027400970458984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.4931345, 0.151261 , 0.129293 ]))\n",
      "Sizes = [782, 51, 31]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_85890.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.988688335851641\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(394, 3), faces.shape=(782, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/862_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a923ceef54499e93e55224a1e2ffae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #33: <trimesh.Trimesh(vertices.shape=(1728, 3), faces.shape=(3452, 3))>\n",
      "xvfb-run -n 5302 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(433, 3), faces.shape=(862, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021576881408691406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378033_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07780623435974121\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09394693374633789\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00045490264892578125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.5789947509765625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009748935699462891\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004204988479614258\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0, 3, 4]), array([0.861865  , 0.752679  , 0.339548  , 0.1312655 , 0.09738355]))\n",
      "Sizes = [380, 339, 73, 34, 36]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #34: <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3446, 3))>\n",
      "xvfb-run -n 8026 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(432, 3), faces.shape=(860, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00025343894958496094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378034_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07626771926879883\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0937192440032959\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004496574401855469\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.269050598144531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009710788726806641\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0045621395111083984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 4, 1, 2, 3]), array([0.833676, 0.755489, 0.53277 , 0.46087 , 0.300906]))\n",
      "Sizes = [310, 84, 275, 164, 27]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #35: <trimesh.Trimesh(vertices.shape=(1721, 3), faces.shape=(3438, 3))>\n",
      "xvfb-run -n 2605 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(431, 3), faces.shape=(858, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003044605255126953\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378035_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07820391654968262\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09595823287963867\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00041174888610839844\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.626678466796875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008800029754638672\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004301786422729492\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1, 3]), array([0.774578 , 0.5554635, 0.196183 , 0.086586 ]))\n",
      "Sizes = [367, 286, 196, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #36: <trimesh.Trimesh(vertices.shape=(1712, 3), faces.shape=(3420, 3))>\n",
      "xvfb-run -n 8858 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(429, 3), faces.shape=(854, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002276897430419922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378036_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07595396041870117\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09226560592651367\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004093647003173828\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008835792541503906\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004567861557006836\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.79745 , 0.616087, 0.486414]))\n",
      "Sizes = [194, 599, 61]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_960876.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 11.236096309695613\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(302, 3), faces.shape=(599, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/339_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65affefa114d4874894a36d1d7317b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #37: <trimesh.Trimesh(vertices.shape=(1694, 3), faces.shape=(3388, 3))>\n",
      "xvfb-run -n 3818 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(423, 3), faces.shape=(846, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00029730796813964844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378037_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0859220027923584\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10426044464111328\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00040984153747558594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.626678466796875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008540153503417969\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0042247772216796875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.5473465, 0.329473 , 0.145199 , 0.092385 ]))\n",
      "Sizes = [652, 121, 22, 51]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_411642.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 11.212033409933984\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(328, 3), faces.shape=(652, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/794_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3149c072887b4f499b93401169c88c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_556685.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 11.212033409933984\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(328, 3), faces.shape=(652, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #38: <trimesh.Trimesh(vertices.shape=(1671, 3), faces.shape=(3338, 3))>\n",
      "xvfb-run -n 4146 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(419, 3), faces.shape=(834, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002105236053466797\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378038_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06755566596984863\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08354330062866211\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003998279571533203\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.482269287109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008308887481689453\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0037462711334228516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3]), array([0.559573 , 0.396167 , 0.360544 , 0.0417005]))\n",
      "Sizes = [408, 174, 243, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #39: <trimesh.Trimesh(vertices.shape=(1653, 3), faces.shape=(3302, 3))>\n",
      "xvfb-run -n 153 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(414, 3), faces.shape=(824, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002117156982421875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378039_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06314444541931152\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07957625389099121\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00036787986755371094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.673004150390625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008144378662109375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003985881805419922\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.48478 , 0.176214]))\n",
      "Sizes = [719, 105]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_465699.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 29.66519948271356\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(362, 3), faces.shape=(719, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/535_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edc919e18ca4e0e9b32f1d4e8b967ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #40: <trimesh.Trimesh(vertices.shape=(1632, 3), faces.shape=(3260, 3))>\n",
      "xvfb-run -n 5524 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(409, 3), faces.shape=(814, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002224445343017578\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378040_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08726143836975098\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10290288925170898\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00038623809814453125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.506111145019531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000873565673828125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0037615299224853516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2, 3]), array([0.712997, 0.581829, 0.571061, 0.107179]))\n",
      "Sizes = [396, 115, 283, 20]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(10689, 3), faces.shape=(17319, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 971 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56515.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56515_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_846460.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56515.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_56515_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_846460.mls is being deleted....\n",
      "xvfb-run -n 4585 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93776.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93776_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_998781.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93776.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93776_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_998781.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 47\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece.off\n",
      "xvfb-run -n 8645 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/poisson_160799.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(51640, 3), faces.shape=(103220, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(51640, 3), faces.shape=(103220, 3))>\n",
      "xvfb-run -n 5433 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25260535.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(12922, 3), faces.shape=(25784, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007271766662597656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837810_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 3.165787696838379\n",
      "2) Finished: Generating CGAL segmentation for neuron: 3.563584327697754\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.008846759796142578\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.888938903808594e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.019380569458007812\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.13086199760437012\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.72945\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.72945  , 0.5396075, 0.439216 ]))\n",
      "Sizes = [14317, 3692, 7775]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [0, 1, 2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3318 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_664973.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_664973_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_563435.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_664973.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_664973_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_563435.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.745534207508541\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/848_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143cf75e5cd749bbac1492757dcede10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/611_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2d8b4b96654d28837e15642d012e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7408 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_795879.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_795879_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_687249.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_795879.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_795879_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_687249.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.04267229716028498\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4730 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_654879.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_654879_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_951719.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_654879.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_654879_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_951719.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.008619583829290909\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2473 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_485065.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_485065_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_198087.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_485065.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_485065_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_198087.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.0028079664630739506\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8613 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543722.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543722_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_877711.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543722.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_543722_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_877711.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.005420757336351983\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7020 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_155953.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_155953_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_871347.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_155953.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_155953_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_871347.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.05333461288280058\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/583_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abf56cefca04d9191cef8155aa79c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/768_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d187e4fa704177a00d712322733c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 806 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_518637.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_518637_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_929892.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_518637.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_518637_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_929892.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.026637478781537775\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6881 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_35968.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_35968_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_858024.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_35968.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_35968_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_858024.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.007082055678742263\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6966 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_95714.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_95714_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_844559.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_95714.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_95714_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_844559.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.03041630315906993\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/111_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb568b1e52b4b6d90c6249725a55e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9697 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_396642.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_396642_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_949780.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_396642.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_396642_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_949780.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.017773757479747698\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3197 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_613104.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_613104_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_631109.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_613104.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_613104_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_631109.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.381117328759949\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 1049.0121879577637\n",
      "Before Filtering the number of somas found = 12\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2853, in split_by_vertices\n",
      "    faces_per_component = [np.unique(np.concatenate(mesh.vertex_faces[k])) for k in conn_verts]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2853, in <listcomp>\n",
      "    faces_per_component = [np.unique(np.concatenate(mesh.vertex_faces[k])) for k in conn_verts]\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 577\n",
      "viable_meshes = [0 1]\n",
      "min_distances_to_soma = [119745.27048990648, 2583838.1371501773]\n",
      "dist_min_to_soma = [7.699999999992743, 192.72597126489867]\n",
      "There were 576 pieces found after size threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 507, in original_mesh_soma\n",
      "    return_inside_pieces = True)\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 184, in filter_away_inside_soma_pieces\n",
      "    signed_distance = trimesh.proximity.signed_distance(main_mesh,points)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/trimesh/proximity.py\", line 227, in signed_distance\n",
      "    closest, distance, triangle_id = closest_point(mesh, points)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/trimesh/proximity.py\", line 150, in closest_point\n",
      "    query_close = closest_point_corresponding(query_tri, query_point)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/trimesh/triangles.py\", line 590, in closest_point\n",
      "    d1 = np.dot(ab * ap, ones)\n",
      "  File \"<__array_function__ internals>\", line 6, in dot\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/classes/coreviews.py\", line 81, in __getitem__\n",
      "    return AtlasView(self._atlas[name])\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 193, in _plain_bfs\n",
      "    for v in thislevel:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 194, in _plain_bfs\n",
      "    if v not in seen:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/classes/coreviews.py\", line 81, in __getitem__\n",
      "    return AtlasView(self._atlas[name])\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/classes/coreviews.py\", line 81, in __getitem__\n",
      "    return AtlasView(self._atlas[name])\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/classes/coreviews.py\", line 50, in __iter__\n",
      "    def __iter__(self):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "--->This soma mesh was not added because Was not able to backtrack soma to mesh\n",
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/filtered_soma_list.pbz2\n",
      "File size is 4.8e-05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 1082, in extract_soma_center\n",
      "    sig_th_initial_split=100)[0]\n",
      "  File \"/meshAfterParty/soma_extraction_utils.py\", line 484, in original_mesh_soma\n",
      "    print_flag=False)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 452, in split_significant_pieces\n",
      "    mesh_pieces,mesh_pieces_idx = split_by_vertices(new_submesh,return_components=True)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2849, in split_by_vertices\n",
      "    conn_verts = vertex_components(mesh)\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in vertex_components\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/meshAfterParty/trimesh_utils.py\", line 2792, in <listcomp>\n",
      "    return [list(k) for k in nx.connected_components(mesh.vertex_adjacency_graph)]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 75, in connected_components\n",
      "    c = set(_plain_bfs(G, v))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/algorithms/components/connected.py\", line 197, in _plain_bfs\n",
      "    nextlevel.update(G_adj[v])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/networkx/classes/coreviews.py\", line 81, in __getitem__\n",
      "    return AtlasView(self._atlas[name])\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "somas = sm.extract_soma_center(segment_id,\n",
    "                      current_mesh_verts=current_neuron.vertices,\n",
    "                              current_mesh_faces=current_neuron.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-117-8688d9dac96f>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_largest_mesh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "*** Oldest frame\n",
      "ipdb> total_soma_list_revised\n",
      "[<trimesh.Trimesh(vertices.shape=(1134, 3), faces.shape=(2227, 3))>, <trimesh.Trimesh(vertices.shape=(1059, 3), faces.shape=(2091, 3))>, <trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1619, 3))>, <trimesh.Trimesh(vertices.shape=(359, 3), faces.shape=(705, 3))>, <trimesh.Trimesh(vertices.shape=(348, 3), faces.shape=(686, 3))>, <trimesh.Trimesh(vertices.shape=(3729, 3), faces.shape=(7159, 3))>, <trimesh.Trimesh(vertices.shape=(1394, 3), faces.shape=(2639, 3))>, <trimesh.Trimesh(vertices.shape=(482, 3), faces.shape=(888, 3))>, <trimesh.Trimesh(vertices.shape=(435, 3), faces.shape=(804, 3))>, <trimesh.Trimesh(vertices.shape=(1180, 3), faces.shape=(2181, 3))>, <trimesh.Trimesh(vertices.shape=(399, 3), faces.shape=(713, 3))>, <trimesh.Trimesh(vertices.shape=(3956, 3), faces.shape=(7775, 3))>]\n",
      "ipdb> len(total_soma_list_revised)\n",
      "12\n",
      "ipdb> soma_mesh = original_mesh_soma(                                                 mesh = recov_orig_mesh_no_interior,                                                 soma_meshes=[total_soma_list_revised[0],                                                 sig_th_initial_split=100)[0]\n",
      "*** SyntaxError: invalid syntax\n",
      "ipdb> original_mesh_soma(mesh=recov_orig_mesh_no_interior,soma_meshes=[total_soma_list_revised[0]],sig_th_initial_split=100)[0]\n",
      "# total split meshes = 60\n",
      "viable_meshes = [0]\n",
      "There were 59 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1134, 3), faces.shape=(2227, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(3424941, 3), faces.shape=(6837503, 3))>\n",
      "\n",
      "inside Soma subtraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:45:51,126 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,128 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,143 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,148 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,161 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,162 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,171 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,172 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,178 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,181 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,183 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,185 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,194 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,201 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,202 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,222 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,223 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,224 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,225 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,242 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,250 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,251 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,255 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,257 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,275 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,276 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,281 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,282 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,283 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,287 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,290 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,290 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,296 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,304 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,305 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,312 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,313 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,315 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,316 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,317 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,322 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,324 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,325 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,327 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,330 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,331 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,333 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,333 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,355 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,357 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,358 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,360 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,383 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,383 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,385 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,386 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,390 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,418 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,486 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,497 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,498 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,501 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,510 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,511 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,512 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,515 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,519 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,529 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,530 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,768 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,769 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,770 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,772 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,773 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,776 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,780 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,782 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,792 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,810 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,812 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,816 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,817 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,818 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,818 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,825 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,825 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,827 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,827 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,829 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,830 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,833 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,834 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,834 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,838 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,841 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,843 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,852 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,853 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,853 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,854 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,857 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,857 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,861 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,866 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,869 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:45:51,870 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,871 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,881 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,882 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,882 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,884 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,885 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,905 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,911 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,920 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,921 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,921 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,922 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,923 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,924 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,927 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,928 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,967 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,975 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:51,976 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,015 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,017 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,043 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,049 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,072 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,073 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,117 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,120 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,122 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,123 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,125 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,128 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,131 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,133 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,134 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,135 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,140 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,141 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,145 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,146 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,146 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,148 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,148 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,149 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,154 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,159 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,160 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,164 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,209 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,237 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,312 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,323 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,341 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,347 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,353 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,379 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,395 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,398 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,420 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,428 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,430 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,432 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,435 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,441 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,451 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,453 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,457 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,463 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,488 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,496 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,499 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,502 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,504 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,511 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,515 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,516 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,519 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,521 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,522 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,524 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,528 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,536 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,537 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,543 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,549 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,550 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,551 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,563 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,564 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,584 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,595 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,649 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,650 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,731 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,732 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,734 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,735 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,743 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,744 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,758 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,759 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,772 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 10:45:52,773 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,775 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,776 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,777 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,777 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,778 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,779 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,779 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,780 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,782 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,783 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,803 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:52,816 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,051 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,052 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,059 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,059 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,068 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,074 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,095 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,096 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,197 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,198 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,224 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,224 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,260 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,262 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,300 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,301 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,319 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,321 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,361 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,362 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,369 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,387 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,413 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,414 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,418 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,419 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,420 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,500 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,502 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,506 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,508 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,512 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,513 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,664 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,674 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,675 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,723 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,752 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,785 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,787 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,788 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,823 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 10:45:53,829 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for soma mesh cancellation = 14.03\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(1899853, 3), faces.shape=(3789603, 3))>, <trimesh.Trimesh(vertices.shape=(943944, 3), faces.shape=(1881994, 3))>, <trimesh.Trimesh(vertices.shape=(160534, 3), faces.shape=(320155, 3))>, <trimesh.Trimesh(vertices.shape=(146888, 3), faces.shape=(292940, 3))>, <trimesh.Trimesh(vertices.shape=(87507, 3), faces.shape=(174583, 3))>, <trimesh.Trimesh(vertices.shape=(67191, 3), faces.shape=(133955, 3))>, <trimesh.Trimesh(vertices.shape=(61477, 3), faces.shape=(122444, 3))>, <trimesh.Trimesh(vertices.shape=(3853, 3), faces.shape=(7669, 3))>, <trimesh.Trimesh(vertices.shape=(2238, 3), faces.shape=(3668, 3))>, <trimesh.Trimesh(vertices.shape=(1348, 3), faces.shape=(2685, 3))>, <trimesh.Trimesh(vertices.shape=(617, 3), faces.shape=(1349, 3))>, <trimesh.Trimesh(vertices.shape=(583, 3), faces.shape=(1252, 3))>, <trimesh.Trimesh(vertices.shape=(572, 3), faces.shape=(1212, 3))>, <trimesh.Trimesh(vertices.shape=(570, 3), faces.shape=(1238, 3))>, <trimesh.Trimesh(vertices.shape=(548, 3), faces.shape=(1180, 3))>, <trimesh.Trimesh(vertices.shape=(545, 3), faces.shape=(853, 3))>, <trimesh.Trimesh(vertices.shape=(539, 3), faces.shape=(1068, 3))>, <trimesh.Trimesh(vertices.shape=(523, 3), faces.shape=(1122, 3))>, <trimesh.Trimesh(vertices.shape=(459, 3), faces.shape=(990, 3))>, <trimesh.Trimesh(vertices.shape=(385, 3), faces.shape=(828, 3))>, <trimesh.Trimesh(vertices.shape=(353, 3), faces.shape=(705, 3))>, <trimesh.Trimesh(vertices.shape=(311, 3), faces.shape=(650, 3))>, <trimesh.Trimesh(vertices.shape=(257, 3), faces.shape=(515, 3))>, <trimesh.Trimesh(vertices.shape=(235, 3), faces.shape=(460, 3))>]\n",
      "Total time for Subtract Soam = 14.031274318695068\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 87.37944865226746\n",
      "<trimesh.Trimesh(vertices.shape=(42213, 3), faces.shape=(82148, 3))>\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function that is unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(47344, 3), faces.shape=(104378, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(23783, 3), faces.shape=(50144, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(22545, 3), faces.shape=(42346, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(2926, 3), faces.shape=(7266, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1615, 3), faces.shape=(3558, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1528, 3), faces.shape=(3871, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1475, 3), faces.shape=(3390, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1368, 3), faces.shape=(3101, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1287, 3), faces.shape=(2888, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1242, 3), faces.shape=(2815, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1197, 3), faces.shape=(2636, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1184, 3), faces.shape=(2668, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1117, 3), faces.shape=(2430, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(1115, 3), faces.shape=(2457, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(978, 3), faces.shape=(2130, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(937, 3), faces.shape=(2021, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(883, 3), faces.shape=(1932, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1842, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(825, 3), faces.shape=(1826, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(815, 3), faces.shape=(1784, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(747, 3), faces.shape=(1650, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(695, 3), faces.shape=(1519, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(483, 3), faces.shape=(1078, 3))>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuclei_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17319"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_largest_mesh[-1].faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd7f33e9ec54bc0b82edc26be5199a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5a89747e884f09a75de432cc4dd7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh,\n",
    "                 meshes_colors = \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 15000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 827 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86272.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86272_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_888909.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86272.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86272_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_888909.mls is being deleted....\n",
      "There were 50 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 50\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(47215, 3), faces.shape=(104271, 3))>, <trimesh.Trimesh(vertices.shape=(23629, 3), faces.shape=(50037, 3))>, <trimesh.Trimesh(vertices.shape=(22324, 3), faces.shape=(42173, 3))>, <trimesh.Trimesh(vertices.shape=(2925, 3), faces.shape=(7265, 3))>, <trimesh.Trimesh(vertices.shape=(1615, 3), faces.shape=(3558, 3))>, <trimesh.Trimesh(vertices.shape=(1528, 3), faces.shape=(3871, 3))>, <trimesh.Trimesh(vertices.shape=(1475, 3), faces.shape=(3390, 3))>, <trimesh.Trimesh(vertices.shape=(1368, 3), faces.shape=(3101, 3))>, <trimesh.Trimesh(vertices.shape=(1287, 3), faces.shape=(2888, 3))>, <trimesh.Trimesh(vertices.shape=(1242, 3), faces.shape=(2815, 3))>, <trimesh.Trimesh(vertices.shape=(1197, 3), faces.shape=(2636, 3))>, <trimesh.Trimesh(vertices.shape=(1184, 3), faces.shape=(2668, 3))>, <trimesh.Trimesh(vertices.shape=(1117, 3), faces.shape=(2430, 3))>, <trimesh.Trimesh(vertices.shape=(1115, 3), faces.shape=(2457, 3))>, <trimesh.Trimesh(vertices.shape=(978, 3), faces.shape=(2130, 3))>, <trimesh.Trimesh(vertices.shape=(937, 3), faces.shape=(2021, 3))>, <trimesh.Trimesh(vertices.shape=(883, 3), faces.shape=(1932, 3))>, <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1842, 3))>, <trimesh.Trimesh(vertices.shape=(825, 3), faces.shape=(1826, 3))>, <trimesh.Trimesh(vertices.shape=(815, 3), faces.shape=(1784, 3))>, <trimesh.Trimesh(vertices.shape=(747, 3), faces.shape=(1650, 3))>, <trimesh.Trimesh(vertices.shape=(695, 3), faces.shape=(1519, 3))>, <trimesh.Trimesh(vertices.shape=(483, 3), faces.shape=(1078, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 7197224, Final mesh size: 6947494\n",
      "Total time = 374.7728111743927\n",
      "xvfb-run -n 5362 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25563335.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(826236, 3), faces.shape=(1632868, 3))>, <trimesh.Trimesh(vertices.shape=(10689, 3), faces.shape=(17319, 3))>]\n",
      "Filtering away larger meshes that are inside others, before # of meshes = 2\n",
      "Using distance_type = shortest_vertex_distance\n",
      "dist_matrix_adj = [[        inf 126.3694979]\n",
      " [126.3694979         inf]]\n",
      "return_pairings = [[0 1]]\n",
      "pair_distances = [126.3694979]\n",
      "\n",
      "-- working on pair: [0 1] --\n",
      "inside_percentages = [0.    0.334]\n",
      "Only 1 above the threshold: mesh 1\n",
      "After # of meshes = 1\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(826236, 3), faces.shape=(1632868, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3383 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31967.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31967_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_743521.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31967.off loaded has 826236 vn 1632868 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_31967_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_743521.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 39424080\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 39424080\n",
      "LOG: 2 Successfully removed 921 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 921 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 39413028\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_743521.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 7973 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14456.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14456_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_796097.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14456.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_14456_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_796097.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 285\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece.off\n",
      "xvfb-run -n 7228 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/poisson_715834.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(48520, 3), faces.shape=(97048, 3))>, <trimesh.Trimesh(vertices.shape=(15949, 3), faces.shape=(31902, 3))>, <trimesh.Trimesh(vertices.shape=(14015, 3), faces.shape=(28030, 3))>, <trimesh.Trimesh(vertices.shape=(12403, 3), faces.shape=(24810, 3))>, <trimesh.Trimesh(vertices.shape=(11231, 3), faces.shape=(22462, 3))>, <trimesh.Trimesh(vertices.shape=(3598, 3), faces.shape=(7192, 3))>, <trimesh.Trimesh(vertices.shape=(3036, 3), faces.shape=(6068, 3))>, <trimesh.Trimesh(vertices.shape=(2683, 3), faces.shape=(5362, 3))>, <trimesh.Trimesh(vertices.shape=(2465, 3), faces.shape=(4934, 3))>, <trimesh.Trimesh(vertices.shape=(2426, 3), faces.shape=(4852, 3))>, <trimesh.Trimesh(vertices.shape=(2413, 3), faces.shape=(4826, 3))>, <trimesh.Trimesh(vertices.shape=(2395, 3), faces.shape=(4798, 3))>, <trimesh.Trimesh(vertices.shape=(2362, 3), faces.shape=(4732, 3))>, <trimesh.Trimesh(vertices.shape=(2309, 3), faces.shape=(4622, 3))>, <trimesh.Trimesh(vertices.shape=(2302, 3), faces.shape=(4600, 3))>, <trimesh.Trimesh(vertices.shape=(2148, 3), faces.shape=(4296, 3))>, <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(4248, 3))>, <trimesh.Trimesh(vertices.shape=(2110, 3), faces.shape=(4216, 3))>, <trimesh.Trimesh(vertices.shape=(2095, 3), faces.shape=(4190, 3))>, <trimesh.Trimesh(vertices.shape=(2078, 3), faces.shape=(4156, 3))>, <trimesh.Trimesh(vertices.shape=(2058, 3), faces.shape=(4112, 3))>, <trimesh.Trimesh(vertices.shape=(2023, 3), faces.shape=(4050, 3))>, <trimesh.Trimesh(vertices.shape=(1995, 3), faces.shape=(3986, 3))>, <trimesh.Trimesh(vertices.shape=(1966, 3), faces.shape=(3940, 3))>, <trimesh.Trimesh(vertices.shape=(1893, 3), faces.shape=(3786, 3))>, <trimesh.Trimesh(vertices.shape=(1853, 3), faces.shape=(3710, 3))>, <trimesh.Trimesh(vertices.shape=(1848, 3), faces.shape=(3696, 3))>, <trimesh.Trimesh(vertices.shape=(1833, 3), faces.shape=(3666, 3))>, <trimesh.Trimesh(vertices.shape=(1799, 3), faces.shape=(3594, 3))>, <trimesh.Trimesh(vertices.shape=(1752, 3), faces.shape=(3504, 3))>, <trimesh.Trimesh(vertices.shape=(1743, 3), faces.shape=(3486, 3))>, <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>, <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>, <trimesh.Trimesh(vertices.shape=(1728, 3), faces.shape=(3452, 3))>, <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3446, 3))>, <trimesh.Trimesh(vertices.shape=(1721, 3), faces.shape=(3438, 3))>, <trimesh.Trimesh(vertices.shape=(1712, 3), faces.shape=(3420, 3))>, <trimesh.Trimesh(vertices.shape=(1694, 3), faces.shape=(3388, 3))>, <trimesh.Trimesh(vertices.shape=(1671, 3), faces.shape=(3338, 3))>, <trimesh.Trimesh(vertices.shape=(1653, 3), faces.shape=(3302, 3))>, <trimesh.Trimesh(vertices.shape=(1632, 3), faces.shape=(3260, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(48520, 3), faces.shape=(97048, 3))>\n",
      "xvfb-run -n 2304 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(12126, 3), faces.shape=(24260, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008630752563476562\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.9973118305206299\n",
      "2) Finished: Generating CGAL segmentation for neuron: 2.3677561283111572\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.008058547973632812\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 6.151199340820312e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.01991724967956543\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.11436915397644043\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.14330500000000002\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1, 16,  0, 13,  8,  5,  4, 21,  9, 14, 18, 10, 20,  2, 11, 15, 12,\n",
      "        6,  7, 22, 17,  3, 19]), array([0.817645  , 0.153899  , 0.143305  , 0.132864  , 0.114123  ,\n",
      "       0.0695834 , 0.0692177 , 0.0637264 , 0.0606013 , 0.06005705,\n",
      "       0.0592976 , 0.0557351 , 0.0541269 , 0.0534251 , 0.0533066 ,\n",
      "       0.0532643 , 0.0513733 , 0.0482504 , 0.0462964 , 0.0408732 ,\n",
      "       0.0372993 , 0.0371331 , 0.03297225]))\n",
      "Sizes = [2227, 343, 7664, 99, 183, 3888, 1344, 713, 1269, 950, 427, 144, 181, 65, 835, 1179, 161, 968, 625, 15, 365, 539, 76]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8366 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_245719.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_245719_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_500744.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_245719.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_245719_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_500744.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.0850103852915223\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/639_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1efb8e72ccc4eefbf9b64225240ce23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/28_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58cf8118353419aa5b7426ae8a4c36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/902_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd8aa7d1c8e4711a9578e237ce55d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(15949, 3), faces.shape=(31902, 3))>\n",
      "xvfb-run -n 9492 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3985, 3), faces.shape=(7974, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003540515899658203\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837801_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.5237894058227539\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6767964363098145\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0028290748596191406\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.4836273193359375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007361412048339844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.037516117095947266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 8,  3,  5,  6, 11, 12,  0, 14,  4,  1,  2,  7, 13, 10,  9]), array([0.7061495, 0.70383  , 0.68655  , 0.6828125, 0.6389545, 0.586836 ,\n",
      "       0.5623685, 0.542515 , 0.5322625, 0.422495 , 0.3962545, 0.379725 ,\n",
      "       0.353034 , 0.344464 , 0.170751 ]))\n",
      "Sizes = [1082, 1813, 338, 910, 456, 447, 1478, 92, 320, 196, 72, 443, 91, 219, 17]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 4 viable somas: [8, 3, 6, 0]\n",
      "xz = 9.929323108283386 ratio was beyong 6 multiplier\n",
      "yz = 9.984464866392544 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_406593.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 135.41151091556304\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(545, 3), faces.shape=(1082, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/32_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994b8647bb274457a93a31e5bf49806c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_142585.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 46.535160958442795\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(323, 3), faces.shape=(639, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_843277.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 568.536891901537\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(910, 3), faces.shape=(1813, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/53_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14c3fac85d44f60b76a02db243704fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 235 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_711096.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_711096_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_406314.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_711096.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_711096_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_406314.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 266.32932291736785\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(682, 3), faces.shape=(1356, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_156290.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 258.85814827668946\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(459, 3), faces.shape=(910, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/66_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2fa7f4143a4812956c23d802f69592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_675367.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 170.91515185292263\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(350, 3), faces.shape=(693, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_953513.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1983.3510668964152\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(743, 3), faces.shape=(1478, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/905_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1edae26f87e4f1bab7df0e1de95464c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_533156.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 617.7067750486528\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(342, 3), faces.shape=(677, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(14015, 3), faces.shape=(28030, 3))>\n",
      "xvfb-run -n 789 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3503, 3), faces.shape=(7006, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0013895034790039062\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837802_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.5651788711547852\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.7071735858917236\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0024602413177490234\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001544952392578125\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006354808807373047\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03240537643432617\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 8, 5, 0, 1, 7, 2, 4, 6, 9]), array([0.719792  , 0.159522  , 0.07951335, 0.0748191 , 0.07255355,\n",
      "       0.0645982 , 0.0645651 , 0.0611307 , 0.0418272 , 0.0371311 ]))\n",
      "Sizes = [2091, 245, 366, 1591, 138, 83, 1367, 833, 271, 21]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2201 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_302885.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_302885_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_561149.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_302885.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_302885_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_561149.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.5938767408303427\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/217_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c35545f7e6246e4a20b61fbf636aa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/435_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3e25fb0c1549a6befa02e7726ac221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/745_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b927901187423eb7e964b4fb969791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(12403, 3), faces.shape=(24810, 3))>\n",
      "xvfb-run -n 1363 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(3099, 3), faces.shape=(6202, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007915496826171875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837803_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.4978663921356201\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6257894039154053\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002159595489501953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.506111145019531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005667448043823242\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.029341936111450195\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([4, 5, 7, 3, 0, 1, 8, 9, 2, 6]), array([0.805872  , 0.120394  , 0.103532  , 0.0750936 , 0.07453455,\n",
      "       0.0736238 , 0.0706298 , 0.0695376 , 0.0639401 , 0.0357858 ]))\n",
      "Sizes = [1619, 433, 367, 53, 616, 2124, 247, 231, 403, 109]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [4]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6660 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_859312.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_859312_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_164051.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_859312.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_859312_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_164051.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.024140735327679\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/393_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8abb6a9479e42928a3e0d6e3d08e80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/904_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4930678e99f4641abfc43902027f8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/480_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3045601461f44419bebda32611abb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(11231, 3), faces.shape=(22462, 3))>\n",
      "xvfb-run -n 9035 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(2806, 3), faces.shape=(5612, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007328987121582031\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837804_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.30670666694641113\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.41940832138061523\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0019488334655761719\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.2438507080078125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004943370819091797\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.025755643844604492\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 3, 10,  1, 11,  2,  9, 12,  0,  6,  4,  8,  7,  5, 13]), array([0.732599 , 0.730422 , 0.6779985, 0.621895 , 0.541875 , 0.519333 ,\n",
      "       0.508099 , 0.5048265, 0.487588 , 0.403319 , 0.352397 , 0.317647 ,\n",
      "       0.251915 , 0.2374135]))\n",
      "Sizes = [459, 172, 736, 108, 1785, 231, 233, 786, 477, 191, 159, 190, 19, 66]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 3 viable somas: [1, 2, 0]\n",
      "xz = 6.185601456799217 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_843680.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 123.70004543403331\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(372, 3), faces.shape=(736, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/951_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e86ed580b0411ca1bf618f313330ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "xy = 15.990309086491207 ratio was beyong 6 multiplier\n",
      "xz = 10.991247232825687 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_532406.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 138.36670280934857\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(896, 3), faces.shape=(1785, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/517_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d798c4c18b3043f2bee399e715f8ba55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xy = 7.132653584271114 ratio was beyong 6 multiplier\n",
      "xz = 12.471530129063982 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_620903.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 44.76840828773376\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(378, 3), faces.shape=(750, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_807929.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 579.7773521070712\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(396, 3), faces.shape=(786, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/940_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18065ba8a7c0415b9068edcfd068d842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(3598, 3), faces.shape=(7192, 3))>\n",
      "xvfb-run -n 5469 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(901, 3), faces.shape=(1798, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022721290588378906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837805_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1726083755493164\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.2079906463623047\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008397102355957031\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.008148193359375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0017855167388916016\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.008788347244262695\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 5,  2,  9,  0,  4,  1, 10,  6,  7,  3,  8]), array([0.864727 , 0.6419095, 0.5860125, 0.4914945, 0.388476 , 0.317355 ,\n",
      "       0.223423 , 0.205865 , 0.153111 , 0.115377 , 0.0373903]))\n",
      "Sizes = [208, 486, 88, 148, 296, 394, 58, 16, 35, 57, 12]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(3036, 3), faces.shape=(6068, 3))>\n",
      "xvfb-run -n 378 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(760, 3), faces.shape=(1516, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002162456512451172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837806_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08025264739990234\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10450267791748047\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005881786346435547\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.6253204345703125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014431476593017578\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006985902786254883\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 5, 4, 1, 0]), array([0.660338, 0.49801 , 0.400623, 0.259123, 0.24726 , 0.196706]))\n",
      "Sizes = [278, 159, 115, 166, 199, 599]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(2683, 3), faces.shape=(5362, 3))>\n",
      "xvfb-run -n 6177 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(672, 3), faces.shape=(1340, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00026917457580566406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837807_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06489682197570801\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08756327629089355\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005550384521484375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.8160552978515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012102127075195312\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0062847137451171875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 2, 0, 4, 1, 6, 3]), array([0.738041 , 0.661579 , 0.550076 , 0.50333  , 0.3728035, 0.207627 ,\n",
      "       0.130756 ]))\n",
      "Sizes = [74, 116, 684, 206, 176, 55, 29]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_532912.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 895.671827817885\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/452_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2c71d6b12e47eb8058231eb7b866b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_65305.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 895.671827817885\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(2465, 3), faces.shape=(4934, 3))>\n",
      "xvfb-run -n 6590 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(614, 3), faces.shape=(1232, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022983551025390625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837808_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10716056823730469\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13019156455993652\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006690025329589844\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1975250244140625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001241445541381836\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0063626766204833984\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 4, 0, 2, 3]), array([0.795044, 0.555128, 0.450513, 0.440104, 0.115918]))\n",
      "Sizes = [529, 88, 455, 122, 38]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(2426, 3), faces.shape=(4852, 3))>\n",
      "xvfb-run -n 8029 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(606, 3), faces.shape=(1212, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022840499877929688\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113630970837809_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10044002532958984\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12275886535644531\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007259845733642578\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.9114227294921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012357234954833984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006177186965942383\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3, 4]), array([0.833541 , 0.611483 , 0.422296 , 0.258399 , 0.0708488]))\n",
      "Sizes = [195, 328, 401, 276, 12]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(2413, 3), faces.shape=(4826, 3))>\n",
      "xvfb-run -n 866 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(603, 3), faces.shape=(1206, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023818016052246094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10262608528137207\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12583446502685547\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005829334259033203\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.7697296142578125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012021064758300781\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0062139034271240234\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 4, 3, 1, 2]), array([0.8141725, 0.3817665, 0.236384 , 0.118656 , 0.092212 ]))\n",
      "Sizes = [488, 274, 329, 70, 45]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #11: <trimesh.Trimesh(vertices.shape=(2395, 3), faces.shape=(4798, 3))>\n",
      "xvfb-run -n 6719 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(595, 3), faces.shape=(1198, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022268295288085938\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11833596229553223\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.14127182960510254\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005645751953125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0001914501190185547\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011820793151855469\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00615692138671875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 1, 4, 5, 0]), array([0.585668  , 0.5807065 , 0.450853  , 0.181399  , 0.0805994 ,\n",
      "       0.05613955]))\n",
      "Sizes = [223, 790, 51, 55, 27, 52]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_386545.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.054306900000702\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(395, 3), faces.shape=(790, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/554_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e52df0b6b1f4b81bfcd5e66e5710414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_829269.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.11221507977423\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(771, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #12: <trimesh.Trimesh(vertices.shape=(2362, 3), faces.shape=(4732, 3))>\n",
      "xvfb-run -n 2545 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(587, 3), faces.shape=(1182, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022268295288085938\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378012_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10843348503112793\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12906670570373535\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005095005035400391\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.4836273193359375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011827945709228516\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00605010986328125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.450774, 0.141932]))\n",
      "Sizes = [1163, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_260388.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 69.63800274263164\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(578, 3), faces.shape=(1163, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/357_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53984c46295a426c8d1bc6ec816d4416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_411707.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 69.63800274263164\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(578, 3), faces.shape=(1163, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #13: <trimesh.Trimesh(vertices.shape=(2309, 3), faces.shape=(4622, 3))>\n",
      "xvfb-run -n 5922 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(575, 3), faces.shape=(1154, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022292137145996094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378013_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10129570960998535\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1213223934173584\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005846023559570312\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.555152893066406e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0019588470458984375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006158351898193359\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 5, 0, 4, 6, 1, 3]), array([0.778447 , 0.6065485, 0.40835  , 0.394006 , 0.359206 , 0.250187 ,\n",
      "       0.0850951]))\n",
      "Sizes = [412, 282, 106, 77, 147, 74, 56]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #14: <trimesh.Trimesh(vertices.shape=(2302, 3), faces.shape=(4600, 3))>\n",
      "xvfb-run -n 5887 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(577, 3), faces.shape=(1150, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022411346435546875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378014_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10811018943786621\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12941265106201172\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005316734313964844\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.364418029785156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011441707611083984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006226301193237305\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 1, 0, 4]), array([0.803642  , 0.442355  , 0.438445  , 0.131663  , 0.03917375]))\n",
      "Sizes = [445, 113, 519, 53, 20]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #15: <trimesh.Trimesh(vertices.shape=(2148, 3), faces.shape=(4296, 3))>\n",
      "xvfb-run -n 9188 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(537, 3), faces.shape=(1074, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003132820129394531\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378015_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09156274795532227\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11249732971191406\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005984306335449219\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.982948303222656e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010790824890136719\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0055866241455078125\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 3, 2, 4]), array([0.7004175, 0.573456 , 0.316827 , 0.10969  , 0.0395501]))\n",
      "Sizes = [660, 97, 262, 30, 25]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_272709.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.849953270789564\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(333, 3), faces.shape=(660, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/467_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04feb38344b148eaa813036bc414ec4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_381671.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 10.849953270789564\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(333, 3), faces.shape=(660, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #16: <trimesh.Trimesh(vertices.shape=(2126, 3), faces.shape=(4248, 3))>\n",
      "xvfb-run -n 8869 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(533, 3), faces.shape=(1062, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002276897430419922\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378016_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08269786834716797\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10019707679748535\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00043272972106933594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.100799560546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010166168212890625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004906177520751953\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.815914, 0.355768]))\n",
      "Sizes = [357, 705]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4591 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_406301.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_406301_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_24087.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_406301.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_406301_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_24087.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.291618617059151\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/602_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcce4b84b4e420791e5ad8c69675251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/317_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4f7802b3c243e998d3da9cdb570cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/931_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e21da24515542d9b59e7d2ca63c561c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #17: <trimesh.Trimesh(vertices.shape=(2110, 3), faces.shape=(4216, 3))>\n",
      "xvfb-run -n 2254 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(529, 3), faces.shape=(1054, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021409988403320312\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378017_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08278512954711914\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10219240188598633\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00046944618225097656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.1961669921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009503364562988281\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004734039306640625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([4, 1, 6, 3, 2, 0, 5]), array([0.6957455, 0.681171 , 0.663943 , 0.479034 , 0.341061 , 0.320237 ,\n",
      "       0.0387986]))\n",
      "Sizes = [120, 309, 69, 112, 67, 359, 18]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #18: <trimesh.Trimesh(vertices.shape=(2095, 3), faces.shape=(4190, 3))>\n",
      "xvfb-run -n 1691 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(523, 3), faces.shape=(1046, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003204345703125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378018_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09402322769165039\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11605095863342285\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005013942718505859\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00019812583923339844\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001949310302734375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005240201950073242\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 0, 4, 1, 2]), array([0.857085 , 0.74002  , 0.4682425, 0.3759775, 0.264959 ]))\n",
      "Sizes = [238, 144, 260, 372, 32]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #19: <trimesh.Trimesh(vertices.shape=(2078, 3), faces.shape=(4156, 3))>\n",
      "xvfb-run -n 1918 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(519, 3), faces.shape=(1038, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002129077911376953\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378019_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09436655044555664\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11314082145690918\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005075931549072266\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.459785461425781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010592937469482422\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005283832550048828\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 4, 2, 5, 3]), array([0.811039, 0.671971, 0.616674, 0.520867, 0.135781, 0.124959]))\n",
      "Sizes = [366, 182, 161, 229, 28, 72]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #20: <trimesh.Trimesh(vertices.shape=(2058, 3), faces.shape=(4112, 3))>\n",
      "xvfb-run -n 4941 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(516, 3), faces.shape=(1028, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022077560424804688\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378020_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08587527275085449\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10380125045776367\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005052089691162109\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.410743713378906e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010619163513183594\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004564523696899414\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.694526 , 0.3827955]))\n",
      "Sizes = [686, 342]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4026 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_692504.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_692504_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_563845.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_692504.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_692504_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_563845.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 7.624178687645888\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/670_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62ba10dd337494d9b02d4690e1c31f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/556_mesh \n",
      "clusters:3 \n",
      "smoothness:0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97654d7edc5e48f0b97164426f797131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/816_mesh \n",
      "clusters:3 \n",
      "smoothness:0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c096ab6b3e43a285d2ab46b170321f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #21: <trimesh.Trimesh(vertices.shape=(2023, 3), faces.shape=(4050, 3))>\n",
      "xvfb-run -n 5561 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(504, 3), faces.shape=(1012, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022101402282714844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378021_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07958650588989258\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09737133979797363\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004429817199707031\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.1484832763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009307861328125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004560232162475586\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 4, 0, 1, 3]), array([0.9015405, 0.632912 , 0.350319 , 0.329872 , 0.195833 ]))\n",
      "Sizes = [204, 529, 93, 64, 122]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #22: <trimesh.Trimesh(vertices.shape=(1995, 3), faces.shape=(3986, 3))>\n",
      "xvfb-run -n 1986 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(500, 3), faces.shape=(996, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021696090698242188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378022_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06216120719909668\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08080792427062988\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00044155120849609375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.2928924560546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011296272277832031\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004916191101074219\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.287128, 0.113131]))\n",
      "Sizes = [851, 145]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #23: <trimesh.Trimesh(vertices.shape=(1966, 3), faces.shape=(3940, 3))>\n",
      "xvfb-run -n 8364 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(488, 3), faces.shape=(984, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021314620971679688\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378023_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08699631690979004\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10492372512817383\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00043511390686035156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009329319000244141\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004657268524169922\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.488003 , 0.260311 , 0.1437635]))\n",
      "Sizes = [839, 119, 26]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_342290.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 16.672579043791114\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(839, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/239_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8891b881e6884480a0c98089af69ecb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_912357.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 16.672579043791114\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(839, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #24: <trimesh.Trimesh(vertices.shape=(1893, 3), faces.shape=(3786, 3))>\n",
      "xvfb-run -n 909 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(473, 3), faces.shape=(946, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00033164024353027344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378024_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0786123275756836\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09543800354003906\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005366802215576172\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00016498565673828125\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000888824462890625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004546642303466797\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 3, 0, 1]), array([0.869201 , 0.4992765, 0.342949 , 0.322056 ]))\n",
      "Sizes = [231, 478, 61, 176]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #25: <trimesh.Trimesh(vertices.shape=(1853, 3), faces.shape=(3710, 3))>\n",
      "xvfb-run -n 6892 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(926, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003199577331542969\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378025_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06273818016052246\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08237624168395996\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004105567932128906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.3882598876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00090789794921875\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004956722259521484\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5069765]))\n",
      "Sizes = [926]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_851570.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1090.437812159592\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(926, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/488_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd45570a51a644e08f803eda060bef2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_161425.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1090.437812159592\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(926, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #26: <trimesh.Trimesh(vertices.shape=(1848, 3), faces.shape=(3696, 3))>\n",
      "xvfb-run -n 8111 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(461, 3), faces.shape=(922, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.000213623046875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378026_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07050514221191406\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08649134635925293\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.000576019287109375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00016927719116210938\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008783340454101562\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004110097885131836\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.950704, 0.567639]))\n",
      "Sizes = [109, 813]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_295457.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 76.08359507498268\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(407, 3), faces.shape=(813, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/331_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea94ab493a9d4ba5af19861dbda5a66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2491 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_123710.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_123710_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_328949.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_123710.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_123710_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_328949.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 43.44296998828287\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(320, 3), faces.shape=(636, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #27: <trimesh.Trimesh(vertices.shape=(1833, 3), faces.shape=(3666, 3))>\n",
      "xvfb-run -n 4695 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(458, 3), faces.shape=(916, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002295970916748047\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378027_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07831716537475586\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09453272819519043\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00039386749267578125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.220008850097656e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008051395416259766\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004190683364868164\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.680617 , 0.576481 , 0.1993095]))\n",
      "Sizes = [241, 623, 52]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_832766.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.072649477915286\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(313, 3), faces.shape=(623, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/171_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22e5ece8a684882b7df6857c753027b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_426457.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 9.072649477915286\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(313, 3), faces.shape=(623, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #28: <trimesh.Trimesh(vertices.shape=(1799, 3), faces.shape=(3594, 3))>\n",
      "xvfb-run -n 8032 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(451, 3), faces.shape=(898, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022840499877929688\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378028_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08011603355407715\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09695982933044434\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004372596740722656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.649162292480469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008852481842041016\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004412651062011719\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 3, 2, 1]), array([0.7380135, 0.513742 , 0.3604765, 0.256314 ]))\n",
      "Sizes = [492, 191, 160, 55]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #29: <trimesh.Trimesh(vertices.shape=(1752, 3), faces.shape=(3504, 3))>\n",
      "xvfb-run -n 5277 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(438, 3), faces.shape=(876, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021886825561523438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378029_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0745232105255127\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09701275825500488\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005698204040527344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.459785461425781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008959770202636719\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004309892654418945\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 5, 0, 1, 4, 3]), array([0.847436 , 0.815448 , 0.519697 , 0.4579105, 0.308722 , 0.1494015]))\n",
      "Sizes = [233, 149, 111, 262, 49, 72]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #30: <trimesh.Trimesh(vertices.shape=(1743, 3), faces.shape=(3486, 3))>\n",
      "xvfb-run -n 2063 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(435, 3), faces.shape=(870, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024175643920898438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378030_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07570457458496094\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09366416931152344\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004947185516357422\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.412101745605469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008847713470458984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004255771636962891\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 5, 3, 7, 4, 2, 0, 6]), array([0.834288 , 0.777868 , 0.705495 , 0.359084 , 0.3286575, 0.1959   ,\n",
      "       0.11813  , 0.0909822]))\n",
      "Sizes = [265, 195, 206, 65, 68, 19, 21, 31]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #31: <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>\n",
      "xvfb-run -n 9560 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002720355987548828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378031_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04764127731323242\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06217694282531738\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00035762786865234375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.4345855712890625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008547306060791016\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004035234451293945\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5436805]))\n",
      "Sizes = [864]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_621044.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 192.8042238651348\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/274_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091ee167b0da41a0aafc5453c357fd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_481373.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 192.8042238651348\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #32: <trimesh.Trimesh(vertices.shape=(1732, 3), faces.shape=(3460, 3))>\n",
      "xvfb-run -n 5816 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(434, 3), faces.shape=(864, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021529197692871094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378032_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07499980926513672\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08966374397277832\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003724098205566406\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.267692565917969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007643699645996094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004058837890625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.4931345, 0.151261 , 0.129293 ]))\n",
      "Sizes = [782, 51, 31]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_955293.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 8.988688335851641\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(394, 3), faces.shape=(782, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/888_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f07e5f211c4a97ac14d070e8160dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #33: <trimesh.Trimesh(vertices.shape=(1728, 3), faces.shape=(3452, 3))>\n",
      "xvfb-run -n 4716 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(433, 3), faces.shape=(862, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00030040740966796875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378033_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0740041732788086\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09305357933044434\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00038695335388183594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.1484832763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007688999176025391\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0038220882415771484\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0, 3, 4]), array([0.861865  , 0.752679  , 0.339548  , 0.1312655 , 0.09738355]))\n",
      "Sizes = [380, 339, 73, 34, 36]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #34: <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3446, 3))>\n",
      "xvfb-run -n 1413 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(432, 3), faces.shape=(860, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002923011779785156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378034_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07123064994812012\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08712935447692871\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00040030479431152344\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.363059997558594e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008914470672607422\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0037908554077148438\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 4, 1, 2, 3]), array([0.833676, 0.755489, 0.53277 , 0.46087 , 0.300906]))\n",
      "Sizes = [310, 84, 275, 164, 27]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #35: <trimesh.Trimesh(vertices.shape=(1721, 3), faces.shape=(3438, 3))>\n",
      "xvfb-run -n 261 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(431, 3), faces.shape=(858, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024509429931640625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378035_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07240533828735352\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09521126747131348\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004177093505859375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.340576171875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009601116180419922\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004173994064331055\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 1, 3]), array([0.774578 , 0.5554635, 0.196183 , 0.086586 ]))\n",
      "Sizes = [367, 286, 196, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #36: <trimesh.Trimesh(vertices.shape=(1712, 3), faces.shape=(3420, 3))>\n",
      "xvfb-run -n 1263 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(429, 3), faces.shape=(854, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021266937255859375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378036_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07669186592102051\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09288740158081055\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004134178161621094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.53131103515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008566379547119141\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0041882991790771484\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.79745 , 0.616087, 0.486414]))\n",
      "Sizes = [194, 599, 61]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_938465.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 11.236096309695613\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(302, 3), faces.shape=(599, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/330_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c702e405342e44f4a873f2943f363a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #37: <trimesh.Trimesh(vertices.shape=(1694, 3), faces.shape=(3388, 3))>\n",
      "xvfb-run -n 4140 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(423, 3), faces.shape=(846, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022983551025390625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378037_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0786895751953125\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09401249885559082\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004394054412841797\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.817413330078125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0017483234405517578\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004131793975830078\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.5473465, 0.329473 , 0.145199 , 0.092385 ]))\n",
      "Sizes = [652, 121, 22, 51]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_684882.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 11.212033409933984\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(328, 3), faces.shape=(652, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/726_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666a85249ce7441c86495d1071088e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_79611.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 11.212033409933984\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(328, 3), faces.shape=(652, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #38: <trimesh.Trimesh(vertices.shape=(1671, 3), faces.shape=(3338, 3))>\n",
      "xvfb-run -n 6887 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(419, 3), faces.shape=(834, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003070831298828125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378038_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07001972198486328\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08655214309692383\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005168914794921875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.936622619628906e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008065700531005859\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.003780364990234375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3]), array([0.559573 , 0.396167 , 0.360544 , 0.0417005]))\n",
      "Sizes = [408, 174, 243, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #39: <trimesh.Trimesh(vertices.shape=(1653, 3), faces.shape=(3302, 3))>\n",
      "xvfb-run -n 6362 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(414, 3), faces.shape=(824, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023245811462402344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378039_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06786441802978516\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0824732780456543\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.000453948974609375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.887580871582031e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009927749633789062\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004061460494995117\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.48478 , 0.176214]))\n",
      "Sizes = [719, 105]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_114036.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 29.66519948271356\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(362, 3), faces.shape=(719, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/535_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471c4f828e6242eabebaab09ebcf865e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #40: <trimesh.Trimesh(vertices.shape=(1632, 3), faces.shape=(3260, 3))>\n",
      "xvfb-run -n 494 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691136309708378/decimation_meshlab_25951363.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691136309708378_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(409, 3), faces.shape=(814, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003056526184082031\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691136309708378040_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06673765182495117\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08341121673583984\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00035858154296875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.76837158203125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007750988006591797\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0036649703979492188\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2, 3]), array([0.712997, 0.581829, 0.571061, 0.107179]))\n",
      "Sizes = [396, 115, 283, 20]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 982.5359275341034\n",
      "Before Filtering the number of somas found = 5\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "xvfb-run -n 3695 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59427.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59427_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_449127.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59427.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59427_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_449127.mls is being deleted....\n",
      "xvfb-run -n 8189 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63513.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63513_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_626466.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63513.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63513_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_626466.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(12914, 3), faces.shape=(24833, 3))>, <trimesh.Trimesh(vertices.shape=(462, 3), faces.shape=(811, 3))>, <trimesh.Trimesh(vertices.shape=(374, 3), faces.shape=(674, 3))>, <trimesh.Trimesh(vertices.shape=(173, 3), faces.shape=(334, 3))>]\n",
      "viable_meshes = [0]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1047 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_838488.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_838488_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_149745.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_838488.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_838488_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_149745.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.499071875220271\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(47344, 3), faces.shape=(104378, 3))>, <trimesh.Trimesh(vertices.shape=(23783, 3), faces.shape=(50144, 3))>, <trimesh.Trimesh(vertices.shape=(22545, 3), faces.shape=(42346, 3))>, <trimesh.Trimesh(vertices.shape=(2926, 3), faces.shape=(7266, 3))>, <trimesh.Trimesh(vertices.shape=(1615, 3), faces.shape=(3558, 3))>, <trimesh.Trimesh(vertices.shape=(1528, 3), faces.shape=(3871, 3))>, <trimesh.Trimesh(vertices.shape=(1475, 3), faces.shape=(3390, 3))>, <trimesh.Trimesh(vertices.shape=(1368, 3), faces.shape=(3101, 3))>, <trimesh.Trimesh(vertices.shape=(1287, 3), faces.shape=(2888, 3))>, <trimesh.Trimesh(vertices.shape=(1242, 3), faces.shape=(2815, 3))>, <trimesh.Trimesh(vertices.shape=(1197, 3), faces.shape=(2636, 3))>, <trimesh.Trimesh(vertices.shape=(1184, 3), faces.shape=(2668, 3))>, <trimesh.Trimesh(vertices.shape=(1117, 3), faces.shape=(2430, 3))>, <trimesh.Trimesh(vertices.shape=(1115, 3), faces.shape=(2457, 3))>, <trimesh.Trimesh(vertices.shape=(978, 3), faces.shape=(2130, 3))>, <trimesh.Trimesh(vertices.shape=(937, 3), faces.shape=(2021, 3))>, <trimesh.Trimesh(vertices.shape=(883, 3), faces.shape=(1932, 3))>, <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1842, 3))>, <trimesh.Trimesh(vertices.shape=(825, 3), faces.shape=(1826, 3))>, <trimesh.Trimesh(vertices.shape=(815, 3), faces.shape=(1784, 3))>, <trimesh.Trimesh(vertices.shape=(747, 3), faces.shape=(1650, 3))>, <trimesh.Trimesh(vertices.shape=(695, 3), faces.shape=(1519, 3))>, <trimesh.Trimesh(vertices.shape=(483, 3), faces.shape=(1078, 3))>]\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "xvfb-run -n 2254 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95155.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95155_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_535306.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95155.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95155_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_535306.mls is being deleted....\n",
      "xvfb-run -n 320 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86285.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86285_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_987676.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86285.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_86285_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_987676.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(187, 3), faces.shape=(300, 3))>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viable_meshes = [0]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3016 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_848345.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_848345_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_268782.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_848345.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_848345_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_268782.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.064561349703069\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(47344, 3), faces.shape=(104378, 3))>, <trimesh.Trimesh(vertices.shape=(23783, 3), faces.shape=(50144, 3))>, <trimesh.Trimesh(vertices.shape=(22545, 3), faces.shape=(42346, 3))>, <trimesh.Trimesh(vertices.shape=(2926, 3), faces.shape=(7266, 3))>, <trimesh.Trimesh(vertices.shape=(1615, 3), faces.shape=(3558, 3))>, <trimesh.Trimesh(vertices.shape=(1528, 3), faces.shape=(3871, 3))>, <trimesh.Trimesh(vertices.shape=(1475, 3), faces.shape=(3390, 3))>, <trimesh.Trimesh(vertices.shape=(1368, 3), faces.shape=(3101, 3))>, <trimesh.Trimesh(vertices.shape=(1287, 3), faces.shape=(2888, 3))>, <trimesh.Trimesh(vertices.shape=(1242, 3), faces.shape=(2815, 3))>, <trimesh.Trimesh(vertices.shape=(1197, 3), faces.shape=(2636, 3))>, <trimesh.Trimesh(vertices.shape=(1184, 3), faces.shape=(2668, 3))>, <trimesh.Trimesh(vertices.shape=(1117, 3), faces.shape=(2430, 3))>, <trimesh.Trimesh(vertices.shape=(1115, 3), faces.shape=(2457, 3))>, <trimesh.Trimesh(vertices.shape=(978, 3), faces.shape=(2130, 3))>, <trimesh.Trimesh(vertices.shape=(937, 3), faces.shape=(2021, 3))>, <trimesh.Trimesh(vertices.shape=(883, 3), faces.shape=(1932, 3))>, <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1842, 3))>, <trimesh.Trimesh(vertices.shape=(825, 3), faces.shape=(1826, 3))>, <trimesh.Trimesh(vertices.shape=(815, 3), faces.shape=(1784, 3))>, <trimesh.Trimesh(vertices.shape=(747, 3), faces.shape=(1650, 3))>, <trimesh.Trimesh(vertices.shape=(695, 3), faces.shape=(1519, 3))>, <trimesh.Trimesh(vertices.shape=(483, 3), faces.shape=(1078, 3))>, <trimesh.Trimesh(vertices.shape=(12807, 3), faces.shape=(19863, 3))>, <trimesh.Trimesh(vertices.shape=(462, 3), faces.shape=(811, 3))>, <trimesh.Trimesh(vertices.shape=(369, 3), faces.shape=(572, 3))>, <trimesh.Trimesh(vertices.shape=(173, 3), faces.shape=(327, 3))>]\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "xvfb-run -n 1965 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36660.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36660_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_495247.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36660.off loaded has 45871 vn 88517 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_36660_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_495247.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 2163108\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 2163108\n",
      "LOG: 2 Successfully removed 73 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 73 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 2162232\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_495247.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 6867 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_53080.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_53080_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_993696.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_53080.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_53080_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_993696.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11753, 3), faces.shape=(20538, 3))>]\n",
      "viable_meshes = [0]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7036 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_49185.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_49185_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_549076.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_49185.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_49185_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_549076.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.489379246593704\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(47344, 3), faces.shape=(104378, 3))>, <trimesh.Trimesh(vertices.shape=(23783, 3), faces.shape=(50144, 3))>, <trimesh.Trimesh(vertices.shape=(22545, 3), faces.shape=(42346, 3))>, <trimesh.Trimesh(vertices.shape=(2926, 3), faces.shape=(7266, 3))>, <trimesh.Trimesh(vertices.shape=(1615, 3), faces.shape=(3558, 3))>, <trimesh.Trimesh(vertices.shape=(1528, 3), faces.shape=(3871, 3))>, <trimesh.Trimesh(vertices.shape=(1475, 3), faces.shape=(3390, 3))>, <trimesh.Trimesh(vertices.shape=(1368, 3), faces.shape=(3101, 3))>, <trimesh.Trimesh(vertices.shape=(1287, 3), faces.shape=(2888, 3))>, <trimesh.Trimesh(vertices.shape=(1242, 3), faces.shape=(2815, 3))>, <trimesh.Trimesh(vertices.shape=(1197, 3), faces.shape=(2636, 3))>, <trimesh.Trimesh(vertices.shape=(1184, 3), faces.shape=(2668, 3))>, <trimesh.Trimesh(vertices.shape=(1117, 3), faces.shape=(2430, 3))>, <trimesh.Trimesh(vertices.shape=(1115, 3), faces.shape=(2457, 3))>, <trimesh.Trimesh(vertices.shape=(978, 3), faces.shape=(2130, 3))>, <trimesh.Trimesh(vertices.shape=(937, 3), faces.shape=(2021, 3))>, <trimesh.Trimesh(vertices.shape=(883, 3), faces.shape=(1932, 3))>, <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1842, 3))>, <trimesh.Trimesh(vertices.shape=(825, 3), faces.shape=(1826, 3))>, <trimesh.Trimesh(vertices.shape=(815, 3), faces.shape=(1784, 3))>, <trimesh.Trimesh(vertices.shape=(747, 3), faces.shape=(1650, 3))>, <trimesh.Trimesh(vertices.shape=(695, 3), faces.shape=(1519, 3))>, <trimesh.Trimesh(vertices.shape=(483, 3), faces.shape=(1078, 3))>, <trimesh.Trimesh(vertices.shape=(12807, 3), faces.shape=(19863, 3))>, <trimesh.Trimesh(vertices.shape=(462, 3), faces.shape=(811, 3))>, <trimesh.Trimesh(vertices.shape=(369, 3), faces.shape=(572, 3))>, <trimesh.Trimesh(vertices.shape=(173, 3), faces.shape=(327, 3))>, <trimesh.Trimesh(vertices.shape=(187, 3), faces.shape=(298, 3))>]\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh was manifold\n",
      "xvfb-run -n 9326 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12884.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12884_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_946900.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12884.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12884_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_946900.mls is being deleted....\n",
      "xvfb-run -n 6300 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10286.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10286_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_8983.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10286.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10286_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_8983.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "viable_meshes = [0]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8349 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_565206.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_565206_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_858734.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_565206.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_565206_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_858734.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 202.51926545411854\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(1758, 3), faces.shape=(3491, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "Mesh was manifold\n",
      "xvfb-run -n 5601 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48890.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48890_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_639589.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48890.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48890_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_639589.mls is being deleted....\n",
      "xvfb-run -n 3506 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91175.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91175_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_813996.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91175.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_91175_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_813996.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 3\n",
      "viable_meshes = [0]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1227 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_280278.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_280278_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_178384.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_280278.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_280278_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_178384.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 110.78706523122729\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(895, 3), faces.shape=(1765, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/filtered_soma_list.pbz2\n",
      "File size is 10.06126 MB\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 3732 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25853.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25853_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_360757.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25853.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_25853_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_360757.mls is being deleted....\n",
      "xvfb-run -n 2488 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12208.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12208_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_710907.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12208.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_12208_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_710907.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 276\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166f84aad50a4c33977d28104552fc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 874622.2402303678, after = 3034532.751274416,\n",
      "ratio = 3.4695353167273075, difference = 2159910.5110440487\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 9468 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63099.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63099_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_428967.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63099.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_63099_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_428967.mls is being deleted....\n",
      "xvfb-run -n 8462 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40455.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40455_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_82079.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40455.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40455_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_82079.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 237\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c7764537594495815100cb59fe5054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 67976.181971821, after = 266604.35333739023,\n",
      "ratio = 3.922026003871606, difference = 198628.17136556923\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 1573 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10212.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10212_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_702608.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10212.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10212_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_702608.mls is being deleted....\n",
      "xvfb-run -n 5871 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_300.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_300_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_421197.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_300.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_300_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_421197.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 122\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c8675f7aa14f188f3823335a4e32ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 103030.13083757595, after = 253810.37406067463,\n",
      "ratio = 2.463457747722357, difference = 150780.2432230987\n"
     ]
    }
   ],
   "source": [
    "from soma_extraction_utils import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "segment_id = segment_id\n",
    "current_mesh_verts = current_neuron.vertices\n",
    "current_mesh_faces = current_neuron.faces\n",
    "current_mesh = None\n",
    "\n",
    "\n",
    "outer_decimation_ratio= 0.25\n",
    "large_mesh_threshold = 20000#60000,\n",
    "large_mesh_threshold_inner = 13000 #was changed so dont filter away som somas\n",
    "soma_width_threshold = 0.32\n",
    "soma_size_threshold = 9000 #changed this to smaller so didn't filter some somas away\n",
    "inner_decimation_ratio = 0.25\n",
    "volume_mulitplier=8\n",
    "#side_length_ratio_threshold=3\n",
    "side_length_ratio_threshold=6\n",
    "soma_size_threshold_max=240000#192000 #this puts at 12000 once decimated, another possible is 256000\n",
    "delete_files=True\n",
    "backtrack_soma_mesh_to_original=True #should either be None or \n",
    "boundary_vertices_threshold=None#700 the previous threshold used\n",
    "poisson_backtrack_distance_threshold=None#1500 the previous threshold used\n",
    "close_holes=False\n",
    "\n",
    "#------- 11/12 Additions --------------- #\n",
    "\n",
    "#these arguments are for removing inside pieces\n",
    "remove_inside_pieces = True\n",
    "size_threshold_to_remove=1000 #size accounting for the decimation\n",
    "\n",
    "\n",
    "pymeshfix_clean=False\n",
    "check_holes_before_pymeshfix=False\n",
    "second_poisson=False\n",
    "segmentation_at_end=True\n",
    "last_size_threshold = 2000#1300,\n",
    "\n",
    "largest_hole_threshold = 17000\n",
    "max_fail_loops = 10\n",
    "perform_pairing = False\n",
    "verbose = True\n",
    "return_glia_nuclei_pieces = True\n",
    "\n",
    "backtrack_soma_size_threshold = 13000\n",
    "filter_inside_meshes = True\n",
    "filter_inside_somas=True\n",
    "\n",
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "#Adjusting the thresholds based on the decimations\n",
    "large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "\n",
    "#adjusting for inner decimation\n",
    "soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "             f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "              f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "             f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "             f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "             f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "temp_folder = f\"./{segment_id}\"\n",
    "temp_object = Path(temp_folder)\n",
    "#make the temp folder if it doesn't exist\n",
    "temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#making the decimation and poisson objections\n",
    "Dec_outer = meshlab.Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "Dec_inner = meshlab.Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "Poisson_obj = meshlab.Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "\n",
    "recov_orig_mesh = trimesh.Trimesh(vertices=current_mesh_verts,faces=current_mesh_faces)\n",
    "\n",
    "recov_orig_mesh_no_interior, glia_pieces, nuclei_pieces  = tu.remove_nuclei_and_glia_meshes(recov_orig_mesh,verbose=True)\n",
    "#recov_orig_mesh_no_interior = tu.remove_mesh_interior(recov_orig_mesh)\n",
    "\n",
    "\n",
    "#Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "new_mesh,output_obj = Dec_outer(vertices=recov_orig_mesh_no_interior.vertices,\n",
    "         faces=recov_orig_mesh_no_interior.faces,\n",
    "         segment_id=segment_id,\n",
    "         return_mesh=True,\n",
    "         delete_temp_files=False)\n",
    "\n",
    "# if remove_inside_pieces:\n",
    "#     print(\"removing mesh interior after decimation\")\n",
    "#     new_mesh = tu.remove_mesh_interior(new_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "#preforming the splits of the decimated mesh\n",
    "\n",
    "mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "# --------- 1/11 Addition: Filtering away large meshes that are inside another --------- #\n",
    "if filter_inside_meshes:\n",
    "    print(f\"Filtering away larger meshes that are inside others, before # of meshes = {len(list_of_largest_mesh)}\")\n",
    "    list_of_largest_mesh = tu.filter_away_inside_meshes(list_of_largest_mesh,verbose=True,return_meshes=True)\n",
    "    print(f\"After # of meshes = {len(list_of_largest_mesh)}\")\n",
    "\n",
    "#if no significant pieces were found then will use smaller threshold\n",
    "if len(list_of_largest_mesh)<=0:\n",
    "    print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "    list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "total_soma_list = []\n",
    "total_classifier_list = []\n",
    "total_poisson_list = []\n",
    "total_soma_list_sdf = []\n",
    "\n",
    "\n",
    "\n",
    "#start iterating through where go through all pieces before the poisson reconstruction\n",
    "no_somas_found_in_big_loop = 0\n",
    "for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "    print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "    if remove_inside_pieces:\n",
    "        print(\"remove_inside_pieces requested \")\n",
    "        largest_mesh = tu.remove_mesh_interior(largest_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "\n",
    "    if pymeshfix_clean:\n",
    "        print(\"Requested pymeshfix_clean\")\n",
    "        \"\"\"\n",
    "        Don't have to check if manifold anymore actually just have to plug the holes\n",
    "        \"\"\"\n",
    "        hole_groups = tu.find_border_face_groups(largest_mesh)\n",
    "        if len(hole_groups) > 0:\n",
    "            largest_mesh_filled_holes = tu.fill_holes(largest_mesh,max_hole_size = 10000)\n",
    "        else:\n",
    "            largest_mesh_filled_holes = largest_mesh\n",
    "\n",
    "        if check_holes_before_pymeshfix:\n",
    "            hole_groups = tu.find_border_face_groups(largest_mesh_filled_holes)\n",
    "        else:\n",
    "            print(\"Not checking if there are still existing holes before pymeshfix\")\n",
    "            hole_groups = []\n",
    "\n",
    "        if len(hole_groups) > 0:\n",
    "            #segmentation_at_end = False\n",
    "            print(f\"*** COULD NOT FILL HOLES WITH MAX SIZE OF {np.max([len(k) for k in hole_groups])} so not applying pymeshfix and segmentation_at_end = {segmentation_at_end}\")\n",
    "\n",
    "#                 tu.write_neuron_off(largest_mesh_filled_holes,\"largest_mesh_filled_holes\")\n",
    "#                 raise Exception()\n",
    "        else:\n",
    "            print(\"Applying pymeshfix_clean because no more holes\")\n",
    "            largest_mesh = tu.pymeshfix_clean(largest_mesh_filled_holes,verbose=True)\n",
    "\n",
    "    if second_poisson:\n",
    "        print(\"Applying second poisson run\")\n",
    "        current_neuron_poisson = tu.poisson_surface_reconstruction(largest_mesh)\n",
    "        largest_mesh = tu.split_significant_pieces(current_neuron_poisson)[0]\n",
    "\n",
    "    somas_found_in_big_loop = False\n",
    "\n",
    "    largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "    pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "    pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "    print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "    # ******* This ERRORED AND CALLED OUR NERUON NONE: 77697401493989254 *********\n",
    "    new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "               faces=largest_mesh.faces,\n",
    "               return_mesh=True,\n",
    "               mesh_filename=largest_file_name,\n",
    "               delete_temp_files=False)\n",
    "\n",
    "\n",
    "    #splitting the Poisson into the largest pieces and ordering them\n",
    "    mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "    list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "    print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "    n_failed_inner_soma_loops = 0\n",
    "    for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "        to_add_list = []\n",
    "        to_add_list_sdf = []\n",
    "\n",
    "        print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "        largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "        #Decimate the inner poisson piece\n",
    "        largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                            vertices=largest_mesh_inner.vertices,\n",
    "                             faces=largest_mesh_inner.faces,\n",
    "                            mesh_filename=largest_mesh_path_inner,\n",
    "                             return_mesh=True,\n",
    "                             delete_temp_files=False)\n",
    "\n",
    "        dec_splits = tu.split_significant_pieces(largest_mesh_path_inner_decimated,significance_threshold=15)\n",
    "        print(f\"\\n-------Splits after inner decimation len = {len(dec_splits)}--------\\n\")\n",
    "\n",
    "        if len(dec_splits) == 0:\n",
    "            print(\"There were no signifcant splits after inner decimation\")\n",
    "            n_failed_inner_soma_loops += 1\n",
    "        else:\n",
    "            print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "            largest_mesh_path_inner_decimated_clean = dec_splits[0]\n",
    "            print(f\"largest_mesh_path_inner_decimated_clean = {largest_mesh_path_inner_decimated_clean}\\n\")\n",
    "\n",
    "            faces = np.array(largest_mesh_path_inner_decimated_clean.faces)\n",
    "            verts = np.array(largest_mesh_path_inner_decimated_clean.vertices)\n",
    "\n",
    "            # may need to do some processing\n",
    "\n",
    "\n",
    "            segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "            #print(f\"Before the classifier the pymeshfix_clean = {pymeshfix_clean}\")\n",
    "            verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                    import_Off_Flag=False,\n",
    "                                    segment_id=segment_id_new,\n",
    "                                    vertices=verts,\n",
    "                                     triangles=faces,\n",
    "                                    pymeshfix_Flag=False,\n",
    "                                     import_CGAL_Flag=False,\n",
    "                                     return_Only_Labels=True,\n",
    "                                     clusters=3,\n",
    "                                     smoothness=0.2,\n",
    "                                    soma_only=True,\n",
    "                                    return_classifier = True\n",
    "                                    )\n",
    "            print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "            total_classifier_list.append(classifier)\n",
    "            #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "            # Save all of the portions that resemble a soma\n",
    "            median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "            segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "            #order the compartments by greatest to smallest\n",
    "            sorted_medians = np.flip(np.argsort(median_values))\n",
    "            print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "            print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "            print(f\"soma_size_threshold = {soma_size_threshold}\")\n",
    "            print(f\"soma_size_threshold_max={soma_size_threshold_max}\")\n",
    "\n",
    "            valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "            valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "            print(\"valid_soma_segments_width\")\n",
    "\n",
    "            if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "\n",
    "\n",
    "                    if curr_side_len_check and curr_volume_check:\n",
    "                        #check if we can split this into two\n",
    "\n",
    "                        possible_smoothness = [0.2,0.05,0.01]\n",
    "                        for smooth_value in possible_smoothness:\n",
    "                            #1) Run th esegmentation algorithm again to segment the mesh (had to run the higher smoothing to seperate some)\n",
    "                            mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=smooth_value,verbose=True)\n",
    "                            mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                            #2) Filter out meshes by sizs and sdf threshold\n",
    "                            mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                            filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "                            if len(filtered_meshes_idx) >= 2:\n",
    "                                if verbose:\n",
    "                                    print(f\"Breakin on smoothness: {smooth_value}\")\n",
    "                                break\n",
    "\n",
    "                        if len(filtered_meshes_idx) >= 2:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            to_add_list_retry = []\n",
    "                            to_add_list_sdf_retry = []\n",
    "\n",
    "                            for f_m,f_m_sdf in zip(filtered_meshes,filtered_meshes_sdf):\n",
    "                                curr_side_len_check_retry = side_length_check(f_m,side_length_ratio_threshold)\n",
    "                                curr_volume_check_retry = soma_volume_check(f_m,volume_mulitplier)\n",
    "\n",
    "                                if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                    to_add_list_retry.append(f_m)\n",
    "                                    to_add_list_sdf_retry.append(f_m_sdf)\n",
    "\n",
    "                            if len(to_add_list_retry)>1:\n",
    "                                if verbose:\n",
    "                                    print(\"Using the new feature that split the soma further into more groups\")\n",
    "                                to_add_list += to_add_list_retry\n",
    "                                to_add_list_sdf += to_add_list_sdf_retry\n",
    "\n",
    "                            else:\n",
    "                                to_add_list.append(soma_mesh)\n",
    "                                to_add_list_sdf.append(sdf)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            to_add_list.append(soma_mesh)\n",
    "                            to_add_list_sdf.append(sdf)\n",
    "\n",
    "                    else:\n",
    "                        # ---------- 1/7 Addition: Trying one more additional cgal segmentation to see if there is actually a soma ---\n",
    "                        \"\"\"\n",
    "                        Pseudocode: \n",
    "                        1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        2) Filter out meshes by sizs and sdf threshold\n",
    "                        3) If there are any remaining meshes, pick the largest sdf mesh and test for volume and side length check\n",
    "                        --> if matches then adds\n",
    "                        \"\"\"\n",
    "\n",
    "                        print(f\"->Attempting retry of soma because failed first checks: \"\n",
    "                                 f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                        #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                        mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                        #2) Filter out meshes by sizs and sdf threshold\n",
    "                        mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                        filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "\n",
    "                        if len(filtered_meshes_idx) > 0:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            sdf_winning_index = np.argmax(filtered_meshes_sdf)\n",
    "                            soma_mesh_retry = filtered_meshes[sdf_winning_index]\n",
    "                            sdf_retry = filtered_meshes_sdf[sdf_winning_index]\n",
    "\n",
    "                            curr_side_len_check_retry = side_length_check(soma_mesh_retry,side_length_ratio_threshold)\n",
    "                            curr_volume_check_retry = soma_volume_check(soma_mesh_retry,volume_mulitplier)\n",
    "\n",
    "                            if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                to_add_list.append(soma_mesh_retry)\n",
    "                                to_add_list_sdf.append(sdf_retry)\n",
    "                            else:\n",
    "                                print(f\"--->This soma mesh was not added because failed retry of sphere validation:\\n \"\n",
    "                                     f\"soma_mesh = {soma_mesh_retry}, curr_side_len_check = {curr_side_len_check_retry}, curr_volume_check = {curr_volume_check_retry}\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(f\"Could not find valid soma mesh in retry\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "                n_failed_inner_soma_loops = 0\n",
    "\n",
    "            else:\n",
    "                n_failed_inner_soma_loops += 1\n",
    "\n",
    "        total_soma_list_sdf += to_add_list_sdf\n",
    "        total_soma_list += to_add_list\n",
    "\n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if n_failed_inner_soma_loops >= max_fail_loops:\n",
    "            print(f\"breaking inner loop because {max_fail_loops} soma fails in a row\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "    if somas_found_in_big_loop == False:\n",
    "        no_somas_found_in_big_loop += 1\n",
    "        if no_somas_found_in_big_loop >= max_fail_loops:\n",
    "            print(f\"breaking because {max_fail_loops} fails in a row in big loop\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        no_somas_found_in_big_loop = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "pairings = []\n",
    "\n",
    "if perform_pairing:\n",
    "    for y,soma_1 in enumerate(total_soma_list):\n",
    "        for z,soma_2 in enumerate(total_soma_list):\n",
    "            if y<z:\n",
    "                mesh_tree = KDTree(soma_1.vertices)\n",
    "                distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "                if np.min(distances) < 4000:\n",
    "                    pairings.append([y,z])\n",
    "\n",
    "\n",
    "#creating the combined meshes from the list\n",
    "total_soma_list_revised = []\n",
    "total_soma_list_revised_sdf = []\n",
    "if len(pairings) > 0:\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    Use a network function to find components\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    new_graph = nx.Graph()\n",
    "    new_graph.add_edges_from(pairings)\n",
    "    grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "    somas_being_combined = []\n",
    "    print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "    for comp in grouped_somas:\n",
    "        comp = list(comp)\n",
    "        somas_being_combined += list(comp)\n",
    "        current_mesh = total_soma_list[comp[0]]\n",
    "        for i in range(1,len(comp)):\n",
    "            current_mesh += total_soma_list[comp[i]] #just combining the actual meshes\n",
    "\n",
    "        total_soma_list_revised.append(current_mesh)\n",
    "        #where can average all of the sdf values\n",
    "        total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "    #add those that weren't combined to total_soma_list_revised\n",
    "    leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    if len(leftover_somas) > 0:\n",
    "        total_soma_list_revised += leftover_somas\n",
    "        total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "    print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "    print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "if len(total_soma_list_revised) == 0:\n",
    "    total_soma_list_revised = total_soma_list\n",
    "    total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "run_time = time.time() - global_start_time\n",
    "\n",
    "print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "#     import system_utils as su\n",
    "#     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "#     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "#need to erase all of the temporary files ******\n",
    "#import shutil\n",
    "#shutil.rmtree(directory)\n",
    "\n",
    "\"\"\"\n",
    "Running the extra tests that depend on\n",
    "- border vertices\n",
    "- how well the poisson matches the backtracked soma to the real mesh\n",
    "- other size checks\n",
    "\n",
    "\"\"\"\n",
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "\n",
    "for soma_mesh,curr_soma_sdf in zip(total_soma_list_revised,total_soma_list_revised_sdf):\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        print(\"Performing Soma Mesh Backtracking to original mesh\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "        soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)\n",
    "#             except:\n",
    "#                 import traceback\n",
    "#                 traceback.print_exc()\n",
    "#                 print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "#                 continue\n",
    "        \n",
    "        if soma_mesh is None:\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "        #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "        if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "            #soma_mesh.export(\"soma_mesh.off\")\n",
    "            if close_holes: \n",
    "                print(\"Using the close holes feature\")\n",
    "                fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                 self_itersect_faces=False)\n",
    "\n",
    "                soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                    vertices=soma_mesh.vertices,\n",
    "                                                     faces=soma_mesh.faces,\n",
    "                                                     return_mesh=True,\n",
    "                                                     delete_temp_files=True,\n",
    "                                                    )\n",
    "            else:\n",
    "                soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "            #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "            print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "            mesh_1 = soma_mesh_filled_holes\n",
    "            mesh_2 = soma_mesh_poisson\n",
    "\n",
    "            poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                              verbose=True)\n",
    "            print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "            if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                  f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                continue\n",
    "\n",
    "    if len(soma_mesh.faces) < 5:\n",
    "        print(f\"--> soma had very few faces ({soma_mesh}) so continuing\")\n",
    "        continue\n",
    "\n",
    "    #do the boundary check:\n",
    "    if not boundary_vertices_threshold is None:\n",
    "        print(\"USING boundary_vertices_threshold CHECK\")\n",
    "        soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "        print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "        large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "        print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "        if len(large_boundary_groups)>0:\n",
    "            print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                  f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "            continue\n",
    "\n",
    "    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "    if (not curr_side_len_check) or (not curr_volume_check):\n",
    "        print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "             f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "        continue\n",
    "\n",
    "    #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "    #If made it through all the checks then add to final list\n",
    "    filtered_soma_list.append(soma_mesh)\n",
    "    filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "\n",
    "    if len(soma_mesh_inside_pieces) > 0:\n",
    "        print(f\"About to add the following inside nuclei pieces after soma backtrack: {nuclei_pieces}\")\n",
    "        nuclei_pieces +=soma_mesh_inside_pieces\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Need to delete all files in the temp folder *****\n",
    "\"\"\"\n",
    "\n",
    "if delete_files:\n",
    "    #now erase all of the files used\n",
    "    from shutil import rmtree\n",
    "\n",
    "    #remove the directory with the meshes\n",
    "    rmtree(str(temp_object.absolute()))\n",
    "\n",
    "    #removing the temporary files\n",
    "    temp_folder = Path(\"./temp\")\n",
    "    temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "    seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "    for f in seg_temp_files:\n",
    "        f.unlink()\n",
    "\n",
    "# ----------- 11 /11 Addition that does a last step segmentation of the soma --------- #\n",
    "#return total_soma_list, run_time\n",
    "#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n",
    "\"\"\"\n",
    "Things we should ask about the segmentation:\n",
    "\n",
    "Advantages: \n",
    "1) could help filter away negatives\n",
    "\n",
    "Disadvantages:\n",
    "1) Can actually cut up the soma and then filter away the soma (not what we want)\n",
    "2) Could introduce a big hole (don't think can guard against this)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#filtered_soma_list_saved = copy.deepcopy(filtered_soma_list)\n",
    "import system_utils as su\n",
    "su.compressed_pickle(filtered_soma_list,\"filtered_soma_list\")\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "\n",
    "        print(\"Skipping the segmentatio filter at end\")\n",
    "        if not (len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold):\n",
    "            print(f\"Soma (size = {len(f_soma.faces)}, width={soma_width_threshold}) did not pass thresholds (size threshold={last_size_threshold}, width threshold = {soma_width_threshold}) \")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if segmentation_at_end:\n",
    "\n",
    "\n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "#                 print(f\"meshes_split = {meshes_split}\")\n",
    "#                 print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                print(f\"So just going with old somas\")\n",
    "\n",
    "                f_soma_final = f_soma\n",
    "                f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "            else:\n",
    "                meshes_split = np.array(meshes_split)\n",
    "                meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "                meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "                meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "                soma_width_threshold\n",
    "                #way to choose the index of the top candidate\n",
    "                top_candidate = 0\n",
    "\n",
    "\n",
    "                largest_hole_before_seg = tu.largest_hole_length(f_soma)\n",
    "                largest_hole_after_seg = tu.largest_hole_length(meshes_split_filtered[top_candidate])\n",
    "\n",
    "                print(f\"Largest hole before segmentation = {largest_hole_before_seg}, after = {largest_hole_after_seg},\"\n",
    "                      f\"\\nratio = {largest_hole_after_seg/largest_hole_before_seg}, difference = {largest_hole_after_seg - largest_hole_before_seg}\")\n",
    "\n",
    "                if largest_hole_after_seg < largest_hole_threshold:\n",
    "                    f_soma_final = meshes_split_filtered[top_candidate]\n",
    "                    f_soma_sdf_final = meshes_split_sdf_filtered[top_candidate]\n",
    "                else:\n",
    "                    f_soma_final = f_soma\n",
    "                    f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "        else:\n",
    "            f_soma_final = f_soma\n",
    "            f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "        filtered_soma_list_revised.append(f_soma_final)\n",
    "        filtered_soma_list_sdf_revised.append(f_soma_sdf_final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n",
    "\n",
    "    \"\"\"\n",
    "    # ----------- 1/7/21 ---------------#\n",
    "    Now was to stitch the somas together if they are touching\n",
    "\n",
    "    \"\"\"\n",
    "    if len(filtered_soma_list)>1:\n",
    "        connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                                 main_mesh=recov_orig_mesh_no_interior,\n",
    "                                                    return_connected_components=True)\n",
    "\n",
    "        filtered_soma_list_components = np.array([tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components])\n",
    "        filtered_soma_list_sdf_components = np.array([np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components])\n",
    "    elif len(filtered_soma_list)==1:\n",
    "        filtered_soma_list_components = filtered_soma_list\n",
    "        filtered_soma_list_sdf_components = filtered_soma_list_sdf\n",
    "    else:\n",
    "        filtered_soma_list_components = []\n",
    "        filtered_soma_list_sdf_components = np.array([])\n",
    "else:\n",
    "    filtered_soma_list_components = []\n",
    "    filtered_soma_list_sdf_components = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "#----------- 1/9 Addition: Final Size Threshold ------------- #\n",
    "if backtrack_soma_mesh_to_original:\n",
    "\n",
    "    filtered_soma_list_components_new = []\n",
    "    filtered_soma_list_sdf_components_new = []\n",
    "\n",
    "    for soma_mesh, soma_mesh_sdf in zip(filtered_soma_list_components,filtered_soma_list_sdf_components):\n",
    "        # --------- 1/9: Extra Size Threshold For Somas ------------- #\n",
    "        if len(soma_mesh.faces) < backtrack_soma_size_threshold:\n",
    "            print(f\"--->This soma mesh with size {len(soma_mesh.faces)} was not bigger than the threshold {backtrack_soma_size_threshold}\")\n",
    "            continue\n",
    "        else:\n",
    "            filtered_soma_list_components_new.append(soma_mesh)\n",
    "            filtered_soma_list_sdf_components_new.append(soma_mesh_sdf)\n",
    "\n",
    "    filtered_soma_list_components = filtered_soma_list_components_new\n",
    "    filtered_soma_list_sdf_components = np.array(filtered_soma_list_sdf_components_new)\n",
    "\n",
    "if filter_inside_somas:\n",
    "    if len(filtered_soma_list_components)>1:\n",
    "        keep_indices = tu.filter_away_inside_meshes(mesh_list = filtered_soma_list_components,\n",
    "                                    distance_type=\"shortest_vertex_distance\",\n",
    "                                    distance_threshold = 2000,\n",
    "                                    inside_percentage_threshold = 0.20,\n",
    "                                    verbose = False,\n",
    "                                    return_meshes = False,\n",
    "                                    )\n",
    "    else:\n",
    "        keep_indices = np.arange(len(filtered_soma_list_components))\n",
    "\n",
    "    filtered_soma_list_components = [k for i,k in enumerate(filtered_soma_list_components) if i in keep_indices]\n",
    "    filtered_soma_list_sdf_components = filtered_soma_list_sdf_components[keep_indices]\n",
    "\n",
    "\n",
    "\n",
    "if return_glia_nuclei_pieces:\n",
    "    return_value= list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components,glia_pieces, nuclei_pieces\n",
    "else:\n",
    "    return_value = list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dabed86114428981bdaebf59c07b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=nuclei_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f4d42bb1d2404cb0db139b94f457e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(filtered_soma_list_components[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da355a3adb5417aab5edbb4f388bae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93613d3f8830442bab2c152cf7059ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1619, 3))>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma_mesh_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9103512e1c0c435a87e7751f4a38ea5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The New Original Mesh Soma Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(3487556, 3), faces.shape=(6947494, 3))>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recov_orig_mesh_no_interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(57133, 3), faces.shape=(113379, 3))>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restricted_big_mesh,faces = tu.bbox_mesh_restriction(recov_orig_mesh_no_interior,soma_mesh_poisson,mult_ratio=2)\n",
    "restricted_big_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  import system_utils as su\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 10\n",
      "viable_meshes = [0]\n",
      "There were 9 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1619, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(53583, 3), faces.shape=(107579, 3))>\n",
      "\n",
      "inside Soma subtraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  import system_utils as su\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for soma mesh cancellation = 0.212\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(6645, 3), faces.shape=(12387, 3))>, <trimesh.Trimesh(vertices.shape=(4996, 3), faces.shape=(9821, 3))>, <trimesh.Trimesh(vertices.shape=(4313, 3), faces.shape=(8454, 3))>, <trimesh.Trimesh(vertices.shape=(2939, 3), faces.shape=(5789, 3))>, <trimesh.Trimesh(vertices.shape=(1976, 3), faces.shape=(3866, 3))>, <trimesh.Trimesh(vertices.shape=(1506, 3), faces.shape=(2917, 3))>, <trimesh.Trimesh(vertices.shape=(1094, 3), faces.shape=(2141, 3))>, <trimesh.Trimesh(vertices.shape=(711, 3), faces.shape=(1397, 3))>]\n",
      "Total time for Subtract Soam = 0.2122194766998291\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.053060293197631836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 19:32:48,362 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(30112, 3), faces.shape=(60116, 3))>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.original_mesh_soma(restricted_big_mesh,soma_meshes=[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980034a2fc6a4640934ad16906b1bb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(restr_mesh_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(45871, 3), faces.shape=(88517, 3))>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restr_split = tu.split_significant_pieces(restricted_big_mesh,significance_threshold=1000,connectivity=\"edges\")\n",
    "restr_mesh_to_test = restr_split[0]\n",
    "restr_mesh_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.mesh_interior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 705 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55061.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55061_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_656733.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55061.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_55061_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_656733.mls is being deleted....\n",
      "xvfb-run -n 3905 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_901.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_901_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_147939.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_901.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_901_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_147939.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  import system_utils as su\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11767, 3), faces.shape=(23565, 3))>, <trimesh.Trimesh(vertices.shape=(61, 3), faces.shape=(104, 3))>, <trimesh.Trimesh(vertices.shape=(51, 3), faces.shape=(74, 3))>, <trimesh.Trimesh(vertices.shape=(49, 3), faces.shape=(91, 3))>, <trimesh.Trimesh(vertices.shape=(48, 3), faces.shape=(103, 3))>, <trimesh.Trimesh(vertices.shape=(31, 3), faces.shape=(58, 3))>, <trimesh.Trimesh(vertices.shape=(31, 3), faces.shape=(58, 3))>, <trimesh.Trimesh(vertices.shape=(21, 3), faces.shape=(25, 3))>, <trimesh.Trimesh(vertices.shape=(20, 3), faces.shape=(30, 3))>, <trimesh.Trimesh(vertices.shape=(19, 3), faces.shape=(33, 3))>, <trimesh.Trimesh(vertices.shape=(15, 3), faces.shape=(15, 3))>, <trimesh.Trimesh(vertices.shape=(15, 3), faces.shape=(23, 3))>, <trimesh.Trimesh(vertices.shape=(12, 3), faces.shape=(16, 3))>]\n"
     ]
    }
   ],
   "source": [
    "restr_without_interior,rem_pieces = tu.remove_mesh_interior(restr_mesh_to_test,return_removed_pieces=True,size_threshold_to_remove=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec25fc72ba74ad3975997b6c8e778e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(restr_without_interior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8772c96efb4ac580867e5138598b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(restricted_big_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 1\n",
      "viable_meshes = [0]\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1619, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(40926, 3), faces.shape=(81092, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "Total Time for soma mesh cancellation = 0.118\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(6637, 3), faces.shape=(12375, 3))>, <trimesh.Trimesh(vertices.shape=(4918, 3), faces.shape=(9639, 3))>, <trimesh.Trimesh(vertices.shape=(4275, 3), faces.shape=(8350, 3))>, <trimesh.Trimesh(vertices.shape=(2939, 3), faces.shape=(5789, 3))>, <trimesh.Trimesh(vertices.shape=(1976, 3), faces.shape=(3866, 3))>, <trimesh.Trimesh(vertices.shape=(1502, 3), faces.shape=(2902, 3))>, <trimesh.Trimesh(vertices.shape=(1094, 3), faces.shape=(2141, 3))>, <trimesh.Trimesh(vertices.shape=(711, 3), faces.shape=(1397, 3))>]\n",
      "Total time for Subtract Soam = 0.11931490898132324\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.05882000923156738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 19:54:40,385 - base - face_normals all zero, ignoring!\n"
     ]
    }
   ],
   "source": [
    "new_somas = sm.original_mesh_soma(restr_without_interior,[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8bbd2a0f9b4c60b37a757b4742b22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(new_somas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The new Soma Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 1\n",
      "viable_meshes = [0]\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1619, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(40926, 3), faces.shape=(81092, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "Total Time for soma mesh cancellation = 0.098\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(4529, 3), faces.shape=(8902, 3))>, <trimesh.Trimesh(vertices.shape=(4078, 3), faces.shape=(7984, 3))>, <trimesh.Trimesh(vertices.shape=(2774, 3), faces.shape=(5447, 3))>, <trimesh.Trimesh(vertices.shape=(1803, 3), faces.shape=(3542, 3))>, <trimesh.Trimesh(vertices.shape=(1427, 3), faces.shape=(2762, 3))>, <trimesh.Trimesh(vertices.shape=(1016, 3), faces.shape=(1972, 3))>, <trimesh.Trimesh(vertices.shape=(826, 3), faces.shape=(1602, 3))>, <trimesh.Trimesh(vertices.shape=(656, 3), faces.shape=(1283, 3))>]\n",
      "Total time for Subtract Soam = 0.09890174865722656\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.037580251693725586\n"
     ]
    }
   ],
   "source": [
    "back_soma = sm.original_mesh_soma(restr_without_interior_largest,\n",
    "                      soma_mesh_poisson,\n",
    "    subtract_soma_distance_threshold=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d0a79fc4e547558e288835e29111ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(back_soma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = soma_mesh_poisson\n",
    "original_mesh = recov_orig_mesh_no_interior \n",
    "bbox_restriction_multiplying_ratio = 1.7\n",
    "match_distance_threshold = 1500\n",
    "mesh_significance_threshold = 1000\n",
    "return_inside_pieces = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 22:02:19,431 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,432 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,447 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,453 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,466 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,467 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,480 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,481 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,486 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,491 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,493 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,502 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,510 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,512 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,533 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,534 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,535 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,535 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,554 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,561 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,561 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,565 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,567 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,650 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,652 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,657 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,658 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,659 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,663 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,669 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,669 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,675 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,683 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,683 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,691 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,692 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,694 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,695 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,697 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,701 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,703 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,705 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,706 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,708 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,709 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,713 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,714 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,735 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,738 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,739 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,741 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,764 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,764 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,766 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,767 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,771 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,802 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,862 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,865 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,866 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,873 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,874 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,878 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,888 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,889 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,890 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,893 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,896 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,897 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,907 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:19,908 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,153 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,154 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,155 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,157 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,158 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,161 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,166 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,168 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,177 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,195 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,196 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,200 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,201 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,202 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,202 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,209 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,211 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,212 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,213 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,214 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,217 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,218 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,218 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,222 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,225 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,228 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,236 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,237 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,238 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,239 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,241 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,242 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,246 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,251 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,254 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-11 22:02:20,255 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,256 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,266 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,267 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,267 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,269 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,270 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,288 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,296 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,303 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,304 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,305 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,305 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,306 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,307 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,307 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,311 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,312 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,449 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,463 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,464 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,466 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,467 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,471 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,493 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,494 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,523 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,525 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,650 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,652 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,690 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,691 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,713 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,715 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,731 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,732 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,733 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,734 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,805 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,807 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,813 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,829 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,848 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,855 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,878 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,892 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,913 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,915 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,917 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,921 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:20,921 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,028 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,030 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,035 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,035 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,036 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,040 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,040 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,041 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,201 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,208 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,215 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,218 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-11 22:02:21,327 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 4378 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73779.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73779_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_388136.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73779.off loaded has 45871 vn 88517 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73779_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_388136.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 2163108\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 2163108\n",
      "LOG: 2 Successfully removed 73 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 73 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 2162232\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_388136.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 1041 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_84056.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_84056_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_149956.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_84056.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_84056_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_149956.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(11753, 3), faces.shape=(20538, 3))>]\n",
      "viable_meshes = [0]\n"
     ]
    }
   ],
   "source": [
    "final_soma_mesh,soma_inside_pieces = original_mesh_soma(\n",
    "    mesh = soma_mesh_poisson,\n",
    "    original_mesh = recov_orig_mesh_no_interior ,\n",
    "    bbox_restriction_multiplying_ratio = 1.7,\n",
    "    match_distance_threshold = 1500,\n",
    "    mesh_significance_threshold = 1000,\n",
    "    return_inside_pieces = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e11338c4dda4ad6855a85c3c05d3eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(final_soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db531e88a73c4a3288d484efa303bb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=soma_inside_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  import system_utils as su\n"
     ]
    }
   ],
   "source": [
    "restr_without_interior_largest = tu.split_significant_pieces(restr_without_interior)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f303ebadab8d4616921ed07effddb020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if return_idx:\n"
     ]
    }
   ],
   "source": [
    "divided_meshes,sdf_results = tu.mesh_segmentation(restr_without_interior_largest,clusters=3,smoothness=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divided_meshes[np.argmax(sdf_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divided_meshes = np.array(divided_meshes)\n",
    "sdf_results = np.array(sdf_results)\n",
    "\n",
    "meshes_len = np.array([len(k.faces) for k in divided_meshes ])\n",
    "possible_soma_idxs = np.where(meshes_len > 13000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30be160e113b4e84aa6d378b93389e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9f1207056d4e3a92bca5bbec79fc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(restr_without_interior_largest,\n",
    "                meshes=[divided_meshes[0],soma_mesh_poisson],\n",
    "                 meshes_colors=[\"red\",\"purple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4fbc79747e427687858fa9f990b727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(Out[129][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1391963. ,  627123.2,  898571.2],\n",
       "       [1406623. ,  643007.2,  910698.5]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu.bounding_box_corners(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.bbox_mesh_restriction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_soma_segments_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_somas = []\n",
    "if len(valid_soma_segments_width) > 0:\n",
    "    print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "    somas_found_in_big_loop = True\n",
    "    #get the meshes only if signfiicant length\n",
    "    labels_list = classifier.labels_list\n",
    "\n",
    "    for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "        submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "        soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "        total_somas.append(soma_mesh)\n",
    "\n",
    "        # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "\n",
    "        curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "        curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "        \n",
    "        print(f\"\\n\\n {curr_side_len_check}, {curr_volume_check} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(total_somas[1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Run th esegmentation algorithm again to segment the mesh\n",
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(total_somas[1],clusters=3,smoothness=0.01,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                  meshes_colors=\"random\"\n",
    "                 )\n",
    "#2) Filter out meshes by sizs and sdf threshold\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "nviz.plot_objects(meshes=mesh_extra[filtered_meshes_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mesh = mesh_extra[filtered_meshes_idx][0]\n",
    "\n",
    "side_length_check(test_mesh,side_length_ratio_threshold), soma_volume_check(test_mesh,volume_mulitplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[-1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "                    \n",
    "                    #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                    mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                    mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                    #2) Filter out meshes by sizs and sdf threshold\n",
    "                    mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                    filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.05,verbose=True)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "            mesh = recov_orig_mesh_no_interior,\n",
    "            soma_meshes=[soma_mesh_poisson],\n",
    "            sig_th_initial_split=15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ----------- 1/7/21 ---------------#\n",
    "Now was to stitch the somas together if they are touching\n",
    "\n",
    "\"\"\"\n",
    "connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                         main_mesh=recov_orig_mesh,\n",
    "                                            return_connected_components=True)\n",
    "\n",
    "filtered_soma_list_components = [tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components]\n",
    "filtered_soma_list_sdf_components = [np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "                                            mesh = recov_orig_mesh_no_interior,\n",
    "                                            soma_meshes=[soma_mesh_poisson],\n",
    "                                            sig_th_initial_split=15)[0]\n",
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_soma_meshes = su.decompress_pickle(\"seperate_soma_meshes\")\n",
    "nviz.plot_objects(meshes=seperate_soma_meshes,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_saved = su.decompress_pickle(\"filtered_soma_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(current_neuron,\n",
    "                #meshes=[return_value[0][0]],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "if len(filtered_meshes_idx) > 0:\n",
    "    filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "    filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "    \n",
    "    soma_mesh_retry = filtered_meshes[np.argmax(filtered_meshes_sdf)]\n",
    "\n",
    "nviz.plot_objects(soma_mesh_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_size_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(mesh_extra[0],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(largest_mesh_path_inner_decimated_clean,\n",
    "                 meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mesh_threshold_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=[k for k in ordered_mesh_splits_inner if len(k.faces)>800],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=dec_splits,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh[1],\n",
    "                  meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh,\n",
    "                 meshes_colors=[\"red\",\"black\"],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(main_mesh=current_neuron,\n",
    "                 meshes=filtered_soma_list,\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                                 current_neuron.vertices,\n",
    "                                                 current_neuron.faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
