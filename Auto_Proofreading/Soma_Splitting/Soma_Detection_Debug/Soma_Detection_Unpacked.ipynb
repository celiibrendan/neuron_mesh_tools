{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To debug why certain somas are not being detected\n",
    "in agreement with nucleus table\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:39:23,083 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-12 00:39:23,084 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-12 00:39:23,085 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-12 00:39:23,133 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-12 00:39:23,133 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-12 00:39:23,145 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:39:23,430 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import soma_extraction_utils as sm\n",
    "import datajoint_utils as du\n",
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-12 00:39:23,524 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-12 00:39:23,783 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking what neurons did not have 2 somas which should have (so can test on them now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/6 Debugging Missed Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 864691135012471798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_neuron = du.fetch_segment_id_mesh(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3015326193994460a06de15baed9bb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 3532 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10251.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10251_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_547108.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10251.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_10251_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_547108.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 30 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 30\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(9800, 3), faces.shape=(25581, 3))>, <trimesh.Trimesh(vertices.shape=(7469, 3), faces.shape=(15079, 3))>, <trimesh.Trimesh(vertices.shape=(4152, 3), faces.shape=(7633, 3))>, <trimesh.Trimesh(vertices.shape=(3965, 3), faces.shape=(9820, 3))>, <trimesh.Trimesh(vertices.shape=(3153, 3), faces.shape=(7636, 3))>, <trimesh.Trimesh(vertices.shape=(2985, 3), faces.shape=(6707, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4738, 3))>, <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3968, 3))>, <trimesh.Trimesh(vertices.shape=(1643, 3), faces.shape=(3781, 3))>, <trimesh.Trimesh(vertices.shape=(1596, 3), faces.shape=(3661, 3))>, <trimesh.Trimesh(vertices.shape=(1516, 3), faces.shape=(3504, 3))>, <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3215, 3))>, <trimesh.Trimesh(vertices.shape=(1204, 3), faces.shape=(2762, 3))>, <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2035, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1760, 3))>, <trimesh.Trimesh(vertices.shape=(776, 3), faces.shape=(1750, 3))>, <trimesh.Trimesh(vertices.shape=(704, 3), faces.shape=(1568, 3))>, <trimesh.Trimesh(vertices.shape=(557, 3), faces.shape=(1221, 3))>, <trimesh.Trimesh(vertices.shape=(330, 3), faces.shape=(733, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 1793791, Final mesh size: 1686623\n",
      "Total time = 88.04817962646484\n",
      "xvfb-run -n 5833 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25398391.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(196773, 3), faces.shape=(389836, 3))>]\n",
      "Filtering away larger meshes that are inside others, before # of meshes = 1\n",
      "After # of meshes = 1\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(196773, 3), faces.shape=(389836, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 1246 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_51808.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_51808_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_901149.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_51808.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_51808_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_901149.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 223\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 2933 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/poisson_718356.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(148604, 3), faces.shape=(297208, 3))>, <trimesh.Trimesh(vertices.shape=(6629, 3), faces.shape=(13258, 3))>, <trimesh.Trimesh(vertices.shape=(5941, 3), faces.shape=(11878, 3))>, <trimesh.Trimesh(vertices.shape=(4607, 3), faces.shape=(9210, 3))>, <trimesh.Trimesh(vertices.shape=(3403, 3), faces.shape=(6802, 3))>, <trimesh.Trimesh(vertices.shape=(3112, 3), faces.shape=(6220, 3))>, <trimesh.Trimesh(vertices.shape=(3096, 3), faces.shape=(6188, 3))>, <trimesh.Trimesh(vertices.shape=(2955, 3), faces.shape=(5906, 3))>, <trimesh.Trimesh(vertices.shape=(2886, 3), faces.shape=(5768, 3))>, <trimesh.Trimesh(vertices.shape=(2819, 3), faces.shape=(5634, 3))>, <trimesh.Trimesh(vertices.shape=(2559, 3), faces.shape=(5114, 3))>, <trimesh.Trimesh(vertices.shape=(2444, 3), faces.shape=(4884, 3))>, <trimesh.Trimesh(vertices.shape=(2123, 3), faces.shape=(4242, 3))>, <trimesh.Trimesh(vertices.shape=(2119, 3), faces.shape=(4234, 3))>, <trimesh.Trimesh(vertices.shape=(2055, 3), faces.shape=(4106, 3))>, <trimesh.Trimesh(vertices.shape=(1822, 3), faces.shape=(3640, 3))>, <trimesh.Trimesh(vertices.shape=(1789, 3), faces.shape=(3574, 3))>, <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>, <trimesh.Trimesh(vertices.shape=(1668, 3), faces.shape=(3332, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(148604, 3), faces.shape=(297208, 3))>\n",
      "xvfb-run -n 2656 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(37143, 3), faces.shape=(74286, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008540153503417969\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 10.27885890007019\n",
      "2) Finished: Generating CGAL segmentation for neuron: 11.349829912185669\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 3\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.024653196334838867\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.269050598144531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.062325477600097656\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.6669774055480957\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.79056\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 3,  9,  5,  1, 17, 12, 13, 27, 14, 22, 16, 23, 25,  2, 18, 11, 21,\n",
      "       26,  4, 28,  7,  8, 19, 15,  6, 24, 20,  0, 10]), array([0.79056   , 0.136687  , 0.129369  , 0.127203  , 0.120948  ,\n",
      "       0.115592  , 0.111158  , 0.100444  , 0.0873689 , 0.07936945,\n",
      "       0.0754867 , 0.0654376 , 0.0603283 , 0.0561189 , 0.0549179 ,\n",
      "       0.0542284 , 0.0530083 , 0.0482343 , 0.0472389 , 0.0472217 ,\n",
      "       0.0446679 , 0.0440112 , 0.04392775, 0.0430093 , 0.0383778 ,\n",
      "       0.03829   , 0.0378469 , 0.0364473 , 0.0316966 ]))\n",
      "Sizes = [12003, 71, 2631, 854, 1013, 1009, 413, 731, 595, 298, 760, 1231, 543, 9093, 1685, 2338, 3169, 301, 2511, 93, 799, 165, 2118, 5139, 7491, 5519, 449, 11137, 127]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5790 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_645104.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_645104_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_88935.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_645104.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_645104_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_88935.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.236696494994306\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(6629, 3), faces.shape=(13258, 3))>\n",
      "xvfb-run -n 909 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1656, 3), faces.shape=(3312, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00024390220642089844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179801_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.25576162338256836\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.30896472930908203\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0013096332550048828\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.8160552978515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.003072023391723633\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.015756845474243164\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 2, 6, 4, 1, 0, 5]), array([0.6626985, 0.65747  , 0.598473 , 0.574775 , 0.421091 , 0.408891 ,\n",
      "       0.0666687]))\n",
      "Sizes = [506, 1271, 492, 679, 225, 128, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 4]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_675673.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 141.65160227043663\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(638, 3), faces.shape=(1271, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/78_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abd61ce423c417ab1be19997393cca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_656293.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 257.14203803806026\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(343, 3), faces.shape=(679, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/866_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084482c9dfd64f80a64152ca7aec8de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_423645.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 257.14203803806026\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(343, 3), faces.shape=(679, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(5941, 3), faces.shape=(11878, 3))>\n",
      "xvfb-run -n 2333 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1486, 3), faces.shape=(2968, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002372264862060547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179802_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.21300411224365234\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.2607605457305908\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0011296272277832031\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.7206878662109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.002960681915283203\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.014324426651000977\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 2, 3, 0, 4, 6, 1, 7]), array([0.7200935, 0.6942665, 0.668283 , 0.591431 , 0.5610215, 0.536571 ,\n",
      "       0.417892 , 0.1117785]))\n",
      "Sizes = [186, 270, 919, 243, 744, 419, 173, 14]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [3, 4]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7070 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_476.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_476_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_658304.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_476.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_476_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_658304.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 259.5447627228786\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(464, 3), faces.shape=(919, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/35_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c37b6999aa34cc3ad597dfa29606f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4544 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_627037.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_627037_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_156925.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_627037.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_627037_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_156925.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 259.5447627228786\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(464, 3), faces.shape=(919, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "yz = 7.183014872250448 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_82329.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 57.4215866720134\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(376, 3), faces.shape=(744, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/366_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2575cf32b87140cf90e91002bf85bfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_456391.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 51.57863004423541\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(669, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(4607, 3), faces.shape=(9210, 3))>\n",
      "xvfb-run -n 6305 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1153, 3), faces.shape=(2302, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002086162567138672\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179803_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.14971661567687988\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.18689918518066406\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0010995864868164062\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.601478576660156e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0022122859954833984\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.011013984680175781\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3, 4, 5]), array([0.679087, 0.548484, 0.455138, 0.282237, 0.231887, 0.136759]))\n",
      "Sizes = [1634, 489, 122, 25, 21, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5361 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_777667.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_777667_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_663672.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_777667.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_777667_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_663672.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 178.14662628922514\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1634, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/311_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92615884412c4df3822700634cb04e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2045 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_277796.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_277796_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_704121.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_277796.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_277796_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_704121.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 108.72292752991105\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(501, 3), faces.shape=(992, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(3403, 3), faces.shape=(6802, 3))>\n",
      "xvfb-run -n 7887 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1700, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00027751922607421875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179804_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1061248779296875\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13252019882202148\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006175041198730469\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.0067901611328125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015435218811035156\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007781982421875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.602303 , 0.5017085]))\n",
      "Sizes = [1260, 440]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_345419.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 277.63181980017555\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(633, 3), faces.shape=(1260, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/857_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7ec8e4478f4cae9b558ee79de99c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_906542.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 277.63181980017555\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(633, 3), faces.shape=(1260, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(3112, 3), faces.shape=(6220, 3))>\n",
      "xvfb-run -n 5620 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(779, 3), faces.shape=(1554, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002110004425048828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179805_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11068224906921387\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1388087272644043\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006749629974365234\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00018310546875\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015211105346679688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007818460464477539\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.654923, 0.52473 , 0.183041]))\n",
      "Sizes = [662, 873, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_328328.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 103.82638042243838\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(334, 3), faces.shape=(662, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/562_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84de12708a8f49b5ae9afd4ddc21ee8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_756798.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 278.7141093328559\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(439, 3), faces.shape=(873, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/700_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3c3beae86c4bd3a948eabc1996e421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_733571.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 224.18209559716092\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(691, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(3096, 3), faces.shape=(6188, 3))>\n",
      "xvfb-run -n 5735 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(775, 3), faces.shape=(1546, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020456314086914062\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179806_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10598182678222656\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13274168968200684\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006628036499023438\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.935264587402344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0016567707061767578\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007233619689941406\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 3, 4, 1]), array([0.660538 , 0.547686 , 0.2940305, 0.176863 , 0.172141 ]))\n",
      "Sizes = [1175, 255, 56, 19, 41]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xz = 6.059748154561078 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_892938.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 154.45747060160994\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(1175, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/138_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efadc02953c4cc7a519ee8e2a15e1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 6.059748154561078 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_613257.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 154.45747060160994\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(1175, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(2955, 3), faces.shape=(5906, 3))>\n",
      "xvfb-run -n 8011 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1476, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022482872009277344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179807_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.1016845703125\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1317458152770996\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007114410400390625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.937980651855469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015673637390136719\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007394552230834961\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3, 7, 5, 6, 4]), array([0.672226 , 0.6604825, 0.458623 , 0.365507 , 0.325081 , 0.291945 ,\n",
      "       0.167578 , 0.0990604]))\n",
      "Sizes = [807, 380, 128, 67, 41, 17, 19, 17]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7910 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_104728.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_104728_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_984235.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_104728.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_104728_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_984235.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 69.80487444333703\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(409, 3), faces.shape=(807, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/447_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d706cc233084b489e5052eadf8b0f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(2886, 3), faces.shape=(5768, 3))>\n",
      "xvfb-run -n 4717 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(722, 3), faces.shape=(1440, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020933151245117188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179808_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10023856163024902\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12560701370239258\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005762577056884766\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.3882598876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001409769058227539\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0066585540771484375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.604129, 0.556553]))\n",
      "Sizes = [549, 891]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_487785.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 88.75069759490306\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(891, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/585_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2231cfbd8d642108478c7139af5f098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_5201.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 88.75069759490306\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(891, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(2819, 3), faces.shape=(5634, 3))>\n",
      "xvfb-run -n 2036 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(706, 3), faces.shape=(1408, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021839141845703125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179809_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0948793888092041\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11822652816772461\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005955696105957031\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.245208740234375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014529228210449219\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007178306579589844\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.599218, 0.247151]))\n",
      "Sizes = [1399, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_397060.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 561.4486105477504\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(702, 3), faces.shape=(1399, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/840_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba822afac3804eaa96a59179569e37c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_291695.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 561.4486105477504\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(702, 3), faces.shape=(1399, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(2559, 3), faces.shape=(5114, 3))>\n",
      "xvfb-run -n 2740 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(640, 3), faces.shape=(1276, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023436546325683594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08048319816589355\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10191130638122559\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006568431854248047\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.744529724121094e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001249074935913086\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006266117095947266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 0, 1, 2]), array([0.712119, 0.560148, 0.474173, 0.329113]))\n",
      "Sizes = [92, 468, 519, 197]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #11: <trimesh.Trimesh(vertices.shape=(2444, 3), faces.shape=(4884, 3))>\n",
      "xvfb-run -n 5604 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(612, 3), faces.shape=(1220, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00020956993103027344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10169744491577148\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12148141860961914\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004787445068359375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.458427429199219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010788440704345703\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005511283874511719\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0]), array([0.6131915, 0.5923535, 0.444457 ]))\n",
      "Sizes = [186, 350, 684]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7809 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_164227.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_164227_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_110385.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_164227.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_164227_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_110385.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 45.370955674798154\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(347, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/545_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f8da58198c46f5bdba0b126d4e5046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1328 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_822608.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_822608_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_117353.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_822608.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_822608_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_117353.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 45.370955674798154\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(347, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #12: <trimesh.Trimesh(vertices.shape=(2123, 3), faces.shape=(4242, 3))>\n",
      "xvfb-run -n 4380 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(532, 3), faces.shape=(1060, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002193450927734375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798012_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.057254791259765625\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07489848136901855\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004105567932128906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.57763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00092315673828125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0048007965087890625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5736015]))\n",
      "Sizes = [1060]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xy = 9.626576704722936 ratio was beyong 6 multiplier\n",
      "yz = 16.46616970616669 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_661525.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 30.74110770137506\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(532, 3), faces.shape=(1060, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/675_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1734a4fdf33944c992ea9c51d6847657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xy = 9.626576704722936 ratio was beyong 6 multiplier\n",
      "yz = 16.46616970616669 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_260719.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 30.74110770137506\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(532, 3), faces.shape=(1060, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #13: <trimesh.Trimesh(vertices.shape=(2119, 3), faces.shape=(4234, 3))>\n",
      "xvfb-run -n 770 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(531, 3), faces.shape=(1058, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002269744873046875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798013_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06354141235351562\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08904004096984863\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00042557716369628906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.38690185546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009472370147705078\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0046579837799072266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0]), array([0.699925, 0.659465, 0.599906]))\n",
      "Sizes = [136, 347, 575]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xy = 6.155996810201598 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_102243.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 41.55202305075764\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(291, 3), faces.shape=(575, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/816_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d4ee7161574c609b43d33a70d89604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #14: <trimesh.Trimesh(vertices.shape=(2055, 3), faces.shape=(4106, 3))>\n",
      "xvfb-run -n 9114 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(515, 3), faces.shape=(1026, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022411346435546875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798014_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06963682174682617\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08798003196716309\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00043964385986328125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00013303756713867188\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00091552734375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004734516143798828\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 3, 2, 0, 4]), array([0.668603 , 0.643396 , 0.375432 , 0.133734 , 0.0595034]))\n",
      "Sizes = [418, 487, 97, 13, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #15: <trimesh.Trimesh(vertices.shape=(1822, 3), faces.shape=(3640, 3))>\n",
      "xvfb-run -n 1766 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(456, 3), faces.shape=(908, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021004676818847656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798015_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0670621395111084\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08424949645996094\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00045180320739746094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.030632019042969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009179115295410156\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004486560821533203\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.663817, 0.55186 , 0.506387, 0.182284]))\n",
      "Sizes = [345, 276, 272, 15]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #16: <trimesh.Trimesh(vertices.shape=(1789, 3), faces.shape=(3574, 3))>\n",
      "xvfb-run -n 1554 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(892, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022077560424804688\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798016_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0721886157989502\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08940362930297852\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00045871734619140625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008802413940429688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004409313201904297\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0, 4, 3]), array([0.699151, 0.547616, 0.52513 , 0.260197, 0.118796]))\n",
      "Sizes = [261, 477, 119, 16, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #17: <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>\n",
      "xvfb-run -n 604 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(422, 3), faces.shape=(840, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00067138671875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798017_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05283498764038086\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06852006912231445\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00038743019104003906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.8650970458984375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008423328399658203\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004187107086181641\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.611835, 0.478513]))\n",
      "Sizes = [675, 165]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_292756.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 131.50242999985122\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(340, 3), faces.shape=(675, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/761_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9be2ce4f134487b88e7c50f498d484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_414379.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 131.50242999985122\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(340, 3), faces.shape=(675, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #18: <trimesh.Trimesh(vertices.shape=(1668, 3), faces.shape=(3332, 3))>\n",
      "xvfb-run -n 1344 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25226961.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(830, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002465248107910156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798018_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05703258514404297\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0711665153503418\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00040149688720703125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 6.103515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0012650489807128906\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0040895938873291016\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.518228]))\n",
      "Sizes = [830]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=75000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_634653.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 77.23818495648109\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(830, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/213_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a4c01679d043569d766dcba416ab32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_126379.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 77.23818495648109\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(830, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 306.5024321079254\n",
      "Before Filtering the number of somas found = 1\n",
      "xvfb-run -n 3120 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41925.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41925_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_864694.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41925.off loaded has 75284 vn 148918 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41925_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_864694.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 3593832\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 3593832\n",
      "LOG: 2 Successfully removed 13184 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 13184 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 3435624\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_864694.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 3135 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50733.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50733_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_241035.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50733.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_50733_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_241035.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(6098, 3), faces.shape=(14038, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2767, 3))>, <trimesh.Trimesh(vertices.shape=(811, 3), faces.shape=(1540, 3))>, <trimesh.Trimesh(vertices.shape=(774, 3), faces.shape=(1990, 3))>, <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1482, 3))>, <trimesh.Trimesh(vertices.shape=(383, 3), faces.shape=(904, 3))>, <trimesh.Trimesh(vertices.shape=(371, 3), faces.shape=(679, 3))>, <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(874, 3))>, <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(692, 3))>, <trimesh.Trimesh(vertices.shape=(296, 3), faces.shape=(707, 3))>, <trimesh.Trimesh(vertices.shape=(249, 3), faces.shape=(821, 3))>, <trimesh.Trimesh(vertices.shape=(243, 3), faces.shape=(577, 3))>, <trimesh.Trimesh(vertices.shape=(241, 3), faces.shape=(362, 3))>, <trimesh.Trimesh(vertices.shape=(232, 3), faces.shape=(347, 3))>, <trimesh.Trimesh(vertices.shape=(155, 3), faces.shape=(310, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8626 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_53733.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_53733_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_727290.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_53733.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_53733_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_727290.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.76493426005398\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6435 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_386791.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_386791_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_347135.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_386791.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_386791_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_347135.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.948845107915596\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(9800, 3), faces.shape=(25582, 3))>, <trimesh.Trimesh(vertices.shape=(7480, 3), faces.shape=(15092, 3))>, <trimesh.Trimesh(vertices.shape=(4152, 3), faces.shape=(7633, 3))>, <trimesh.Trimesh(vertices.shape=(3965, 3), faces.shape=(9822, 3))>, <trimesh.Trimesh(vertices.shape=(3153, 3), faces.shape=(7636, 3))>, <trimesh.Trimesh(vertices.shape=(2985, 3), faces.shape=(6707, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4738, 3))>, <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3968, 3))>, <trimesh.Trimesh(vertices.shape=(1643, 3), faces.shape=(3781, 3))>, <trimesh.Trimesh(vertices.shape=(1596, 3), faces.shape=(3661, 3))>, <trimesh.Trimesh(vertices.shape=(1516, 3), faces.shape=(3504, 3))>, <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3215, 3))>, <trimesh.Trimesh(vertices.shape=(1204, 3), faces.shape=(2762, 3))>, <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2035, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1760, 3))>, <trimesh.Trimesh(vertices.shape=(776, 3), faces.shape=(1750, 3))>, <trimesh.Trimesh(vertices.shape=(704, 3), faces.shape=(1568, 3))>, <trimesh.Trimesh(vertices.shape=(557, 3), faces.shape=(1221, 3))>, <trimesh.Trimesh(vertices.shape=(330, 3), faces.shape=(733, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 6171 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2537.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2537_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_89887.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2537.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2537_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_89887.mls is being deleted....\n",
      "xvfb-run -n 5875 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95261.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95261_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_908596.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95261.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_95261_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_908596.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 85\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b412c9d7e015446f8545f78dd3af1520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1127255.4274875335, after = 1350200.2868714402,\n",
      "ratio = 1.1977767007791784, difference = 222944.8593839067\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8212 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74246.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74246_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_270756.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74246.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_74246_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_270756.mls is being deleted....\n",
      "xvfb-run -n 771 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52466.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52466_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_717854.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52466.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_52466_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_717854.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 133\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb2e45ce9c24659bcbb5f42f6d8a557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2089422.6011259102, after = 1790721.515525703,\n",
      "ratio = 0.8570413254651077, difference = -298701.0856002071\n"
     ]
    }
   ],
   "source": [
    "somas = sm.extract_soma_center(segment_id,\n",
    "                      current_mesh_verts=current_neuron.vertices,\n",
    "                              current_mesh_faces=current_neuron.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<trimesh.Trimesh(vertices.shape=(19836, 3), faces.shape=(39237, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(12911, 3), faces.shape=(25158, 3))>],\n",
       " 306.5024309158325,\n",
       " array([0.79056, 0.79056]),\n",
       " [],\n",
       " [<trimesh.Trimesh(vertices.shape=(9800, 3), faces.shape=(25582, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(7480, 3), faces.shape=(15092, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(4152, 3), faces.shape=(7633, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(3965, 3), faces.shape=(9822, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(3153, 3), faces.shape=(7636, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2985, 3), faces.shape=(6707, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4738, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3968, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1643, 3), faces.shape=(3781, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1596, 3), faces.shape=(3661, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1516, 3), faces.shape=(3504, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3215, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1204, 3), faces.shape=(2762, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2035, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1760, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(776, 3), faces.shape=(1750, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(704, 3), faces.shape=(1568, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(557, 3), faces.shape=(1221, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(330, 3), faces.shape=(733, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(6098, 3), faces.shape=(14038, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2767, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(811, 3), faces.shape=(1540, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(774, 3), faces.shape=(1990, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1482, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(383, 3), faces.shape=(904, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(371, 3), faces.shape=(679, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(874, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(692, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(296, 3), faces.shape=(707, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(249, 3), faces.shape=(821, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(243, 3), faces.shape=(577, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(241, 3), faces.shape=(362, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(232, 3), faces.shape=(347, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(155, 3), faces.shape=(310, 3))>])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function that is unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 15000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 2307 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_83438.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_83438_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_887182.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_83438.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_83438_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_887182.mls is being deleted....\n",
      "There were 30 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 30\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(9800, 3), faces.shape=(25581, 3))>, <trimesh.Trimesh(vertices.shape=(7469, 3), faces.shape=(15079, 3))>, <trimesh.Trimesh(vertices.shape=(4152, 3), faces.shape=(7633, 3))>, <trimesh.Trimesh(vertices.shape=(3965, 3), faces.shape=(9820, 3))>, <trimesh.Trimesh(vertices.shape=(3153, 3), faces.shape=(7636, 3))>, <trimesh.Trimesh(vertices.shape=(2985, 3), faces.shape=(6707, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4738, 3))>, <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3968, 3))>, <trimesh.Trimesh(vertices.shape=(1643, 3), faces.shape=(3781, 3))>, <trimesh.Trimesh(vertices.shape=(1596, 3), faces.shape=(3661, 3))>, <trimesh.Trimesh(vertices.shape=(1516, 3), faces.shape=(3504, 3))>, <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3215, 3))>, <trimesh.Trimesh(vertices.shape=(1204, 3), faces.shape=(2762, 3))>, <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2035, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1760, 3))>, <trimesh.Trimesh(vertices.shape=(776, 3), faces.shape=(1750, 3))>, <trimesh.Trimesh(vertices.shape=(704, 3), faces.shape=(1568, 3))>, <trimesh.Trimesh(vertices.shape=(557, 3), faces.shape=(1221, 3))>, <trimesh.Trimesh(vertices.shape=(330, 3), faces.shape=(733, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 1793791, Final mesh size: 1686623\n",
      "Total time = 86.47985863685608\n",
      "xvfb-run -n 1743 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25718943.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(196773, 3), faces.shape=(389836, 3))>]\n",
      "Filtering away larger meshes that are inside others, before # of meshes = 1\n",
      "After # of meshes = 1\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(196773, 3), faces.shape=(389836, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 5601 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59047.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59047_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_750216.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59047.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_59047_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_750216.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 223\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece.off\n",
      "xvfb-run -n 3467 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/poisson_277886.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(148604, 3), faces.shape=(297208, 3))>, <trimesh.Trimesh(vertices.shape=(6629, 3), faces.shape=(13258, 3))>, <trimesh.Trimesh(vertices.shape=(5941, 3), faces.shape=(11878, 3))>, <trimesh.Trimesh(vertices.shape=(4607, 3), faces.shape=(9210, 3))>, <trimesh.Trimesh(vertices.shape=(3403, 3), faces.shape=(6802, 3))>, <trimesh.Trimesh(vertices.shape=(3112, 3), faces.shape=(6220, 3))>, <trimesh.Trimesh(vertices.shape=(3096, 3), faces.shape=(6188, 3))>, <trimesh.Trimesh(vertices.shape=(2955, 3), faces.shape=(5906, 3))>, <trimesh.Trimesh(vertices.shape=(2886, 3), faces.shape=(5768, 3))>, <trimesh.Trimesh(vertices.shape=(2819, 3), faces.shape=(5634, 3))>, <trimesh.Trimesh(vertices.shape=(2559, 3), faces.shape=(5114, 3))>, <trimesh.Trimesh(vertices.shape=(2444, 3), faces.shape=(4884, 3))>, <trimesh.Trimesh(vertices.shape=(2123, 3), faces.shape=(4242, 3))>, <trimesh.Trimesh(vertices.shape=(2119, 3), faces.shape=(4234, 3))>, <trimesh.Trimesh(vertices.shape=(2055, 3), faces.shape=(4106, 3))>, <trimesh.Trimesh(vertices.shape=(1822, 3), faces.shape=(3640, 3))>, <trimesh.Trimesh(vertices.shape=(1789, 3), faces.shape=(3574, 3))>, <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>, <trimesh.Trimesh(vertices.shape=(1668, 3), faces.shape=(3332, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(148604, 3), faces.shape=(297208, 3))>\n",
      "xvfb-run -n 7917 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(37143, 3), faces.shape=(74286, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005519390106201172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179800_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 10.045228481292725\n",
      "2) Finished: Generating CGAL segmentation for neuron: 11.348621129989624\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 3\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.025013208389282227\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.8160552978515625e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.06288433074951172\n",
      "8) Staring: Generating final Vertex and Face Labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8) Finished: Generating final Vertex and Face Labels: 0.3568689823150635\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.79056\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 3,  9,  5,  1, 17, 12, 13, 27, 14, 22, 16, 23, 25,  2, 18, 11, 21,\n",
      "       26,  4, 28,  7,  8, 19, 15,  6, 24, 20,  0, 10]), array([0.79056   , 0.136687  , 0.129369  , 0.127203  , 0.120948  ,\n",
      "       0.115592  , 0.111158  , 0.100444  , 0.0873689 , 0.07936945,\n",
      "       0.0754867 , 0.0654376 , 0.0603283 , 0.0561189 , 0.0549179 ,\n",
      "       0.0542284 , 0.0530083 , 0.0482343 , 0.0472389 , 0.0472217 ,\n",
      "       0.0446679 , 0.0440112 , 0.04392775, 0.0430093 , 0.0383778 ,\n",
      "       0.03829   , 0.0378469 , 0.0364473 , 0.0316966 ]))\n",
      "Sizes = [12003, 71, 2631, 854, 1013, 1009, 413, 731, 595, 298, 760, 1231, 543, 9093, 1685, 2338, 3169, 301, 2511, 93, 799, 165, 2118, 5139, 7491, 5519, 449, 11137, 127]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 781 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_969456.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_969456_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_810553.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_969456.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_969456_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_810553.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.236696494994306\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(6629, 3), faces.shape=(13258, 3))>\n",
      "xvfb-run -n 5402 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1656, 3), faces.shape=(3312, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007181167602539062\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179801_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.23946571350097656\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.30704736709594727\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.001247406005859375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.2438507080078125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.00316619873046875\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.015468120574951172\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 2, 6, 4, 1, 0, 5]), array([0.6626985, 0.65747  , 0.598473 , 0.574775 , 0.421091 , 0.408891 ,\n",
      "       0.0666687]))\n",
      "Sizes = [506, 1271, 492, 679, 225, 128, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 4]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_164316.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 141.65160227043663\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(638, 3), faces.shape=(1271, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/694_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804f482830b0493fb7fcff23ce531e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_190292.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 257.14203803806026\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(343, 3), faces.shape=(679, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/804_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758aee0ab4304b759b6dcd789250cd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_528945.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 257.14203803806026\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(343, 3), faces.shape=(679, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(5941, 3), faces.shape=(11878, 3))>\n",
      "xvfb-run -n 8715 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1486, 3), faces.shape=(2968, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022149085998535156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179802_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.19523239135742188\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.24137091636657715\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0010824203491210938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.57763671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0027577877044677734\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.01340341567993164\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([5, 2, 3, 0, 4, 6, 1, 7]), array([0.7200935, 0.6942665, 0.668283 , 0.591431 , 0.5610215, 0.536571 ,\n",
      "       0.417892 , 0.1117785]))\n",
      "Sizes = [186, 270, 919, 243, 744, 419, 173, 14]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [3, 4]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7626 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_285275.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_285275_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_549720.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_285275.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_285275_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_549720.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 259.5447627228786\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(464, 3), faces.shape=(919, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/922_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847873d9bc4947be8ff5635c2317b445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8012 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_863577.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_863577_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_987967.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_863577.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_863577_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_987967.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 259.5447627228786\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(464, 3), faces.shape=(919, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "yz = 7.183014872250448 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_943791.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 57.4215866720134\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(376, 3), faces.shape=(744, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/586_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d773a892b2743fa967aae3da2267c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_70626.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 51.57863004423541\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(338, 3), faces.shape=(669, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(4607, 3), faces.shape=(9210, 3))>\n",
      "xvfb-run -n 8991 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(1153, 3), faces.shape=(2302, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022149085998535156\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179803_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.15557646751403809\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1906280517578125\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0008451938629150391\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.000171661376953125\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.002113819122314453\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.011095523834228516\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3, 4, 5]), array([0.679087, 0.548484, 0.455138, 0.282237, 0.231887, 0.136759]))\n",
      "Sizes = [1634, 489, 122, 25, 21, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6612 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_242931.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_242931_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_119444.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_242931.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_242931_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_119444.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 178.14662628922514\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(822, 3), faces.shape=(1634, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/598_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c211ad538c124d918a463902abc7b4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2927 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_441985.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_441985_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_816422.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_441985.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_441985_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_816422.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 108.72292752991105\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(501, 3), faces.shape=(992, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(3403, 3), faces.shape=(6802, 3))>\n",
      "xvfb-run -n 425 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(852, 3), faces.shape=(1700, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021338462829589844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179804_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10914874076843262\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1364917755126953\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006694793701171875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.2928924560546875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0015187263488769531\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00839996337890625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.602303 , 0.5017085]))\n",
      "Sizes = [1260, 440]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_47380.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 277.63181980017555\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(633, 3), faces.shape=(1260, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/780_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1cb6a057564231826328ed2ede1528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_527293.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 277.63181980017555\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(633, 3), faces.shape=(1260, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #5: <trimesh.Trimesh(vertices.shape=(3112, 3), faces.shape=(6220, 3))>\n",
      "xvfb-run -n 4753 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(779, 3), faces.shape=(1554, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022411346435546875\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179805_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10439348220825195\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.12792110443115234\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006580352783203125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.367134094238281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014941692352294922\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0075626373291015625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 2]), array([0.654923, 0.52473 , 0.183041]))\n",
      "Sizes = [662, 873, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_557259.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 103.82638042243838\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(334, 3), faces.shape=(662, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/824_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec51ef73492471e99867129f940b062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_724454.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 278.7141093328559\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(439, 3), faces.shape=(873, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/759_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b61a214001d4f10afd2db226f36cfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_340853.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 224.18209559716092\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(349, 3), faces.shape=(691, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #6: <trimesh.Trimesh(vertices.shape=(3096, 3), faces.shape=(6188, 3))>\n",
      "xvfb-run -n 4607 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(775, 3), faces.shape=(1546, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023818016052246094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179806_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.11177468299865723\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1481163501739502\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0007703304290771484\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 8.511543273925781e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0018711090087890625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007752895355224609\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 2, 3, 4, 1]), array([0.660538 , 0.547686 , 0.2940305, 0.176863 , 0.172141 ]))\n",
      "Sizes = [1175, 255, 56, 19, 41]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xz = 6.059748154561078 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_937170.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 154.45747060160994\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(1175, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/773_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d9c24bb2094ef984f9255ecfd9f9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz = 6.059748154561078 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_881953.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 154.45747060160994\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(592, 3), faces.shape=(1175, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #7: <trimesh.Trimesh(vertices.shape=(2955, 3), faces.shape=(5906, 3))>\n",
      "xvfb-run -n 7120 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1476, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021696090698242188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179807_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09512853622436523\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11898231506347656\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0006146430969238281\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0002789497375488281\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014498233795166016\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007313966751098633\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0, 3, 7, 5, 6, 4]), array([0.672226 , 0.6604825, 0.458623 , 0.365507 , 0.325081 , 0.291945 ,\n",
      "       0.167578 , 0.0990604]))\n",
      "Sizes = [807, 380, 128, 67, 41, 17, 19, 17]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3270 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703828.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703828_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_781775.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703828.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_703828_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_781775.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 69.80487444333703\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(409, 3), faces.shape=(807, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/489_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc46d940ed04b0db8b0e8ad8cdaabc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #8: <trimesh.Trimesh(vertices.shape=(2886, 3), faces.shape=(5768, 3))>\n",
      "xvfb-run -n 3067 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(722, 3), faces.shape=(1440, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002186298370361328\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179808_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.10092020034790039\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.13690900802612305\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005981922149658203\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.125999450683594e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014488697052001953\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0072574615478515625\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.604129, 0.556553]))\n",
      "Sizes = [549, 891]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_709964.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 88.75069759490306\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(891, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/310_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354e858b3cd04c0a944ca58bf7968965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_18503.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 88.75069759490306\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(891, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #9: <trimesh.Trimesh(vertices.shape=(2819, 3), faces.shape=(5634, 3))>\n",
      "xvfb-run -n 8072 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(706, 3), faces.shape=(1408, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002193450927734375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113501247179809_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.09635400772094727\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.1212930679321289\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005865097045898438\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.269050598144531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0014760494232177734\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.007181644439697266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1]), array([0.599218, 0.247151]))\n",
      "Sizes = [1399, 9]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_329994.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 561.4486105477504\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(702, 3), faces.shape=(1399, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/849_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61cc6a544214391aa0cdb5affb99d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_766749.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 561.4486105477504\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(702, 3), faces.shape=(1399, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #10: <trimesh.Trimesh(vertices.shape=(2559, 3), faces.shape=(5114, 3))>\n",
      "xvfb-run -n 976 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(640, 3), faces.shape=(1276, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002028942108154297\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798010_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.08438444137573242\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.10663962364196777\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005290508270263672\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.9591064453125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011820793151855469\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.006234645843505859\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 0, 1, 2]), array([0.712119, 0.560148, 0.474173, 0.329113]))\n",
      "Sizes = [92, 468, 519, 197]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #11: <trimesh.Trimesh(vertices.shape=(2444, 3), faces.shape=(4884, 3))>\n",
      "xvfb-run -n 2604 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(612, 3), faces.shape=(1220, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002639293670654297\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798011_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0940399169921875\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.11624860763549805\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005366802215576172\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.507469177246094e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0013141632080078125\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00650477409362793\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0]), array([0.6131915, 0.5923535, 0.444457 ]))\n",
      "Sizes = [186, 350, 684]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5906 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_324614.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_324614_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_62841.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_324614.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_324614_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_62841.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 45.370955674798154\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(347, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/774_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51a4da02b264da794d345d50297a0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 3841 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_550319.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_550319_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_946401.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_550319.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_550319_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_946401.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 45.370955674798154\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(347, 3), faces.shape=(684, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #12: <trimesh.Trimesh(vertices.shape=(2123, 3), faces.shape=(4242, 3))>\n",
      "xvfb-run -n 6531 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(532, 3), faces.shape=(1060, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022602081298828125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798012_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06251072883605957\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08192610740661621\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004482269287109375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.316734313964844e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0010654926300048828\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005415678024291992\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.5736015]))\n",
      "Sizes = [1060]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xy = 9.626576704722936 ratio was beyong 6 multiplier\n",
      "yz = 16.46616970616669 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_846275.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 30.74110770137506\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(532, 3), faces.shape=(1060, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/184_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcc3fef77574b56b616fd2257a53928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xy = 9.626576704722936 ratio was beyong 6 multiplier\n",
      "yz = 16.46616970616669 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_764232.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 30.74110770137506\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(532, 3), faces.shape=(1060, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "----- working on mesh after poisson #13: <trimesh.Trimesh(vertices.shape=(2119, 3), faces.shape=(4234, 3))>\n",
      "xvfb-run -n 669 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(531, 3), faces.shape=(1058, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021123886108398438\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798013_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.07152652740478516\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.09020328521728516\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005791187286376953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.001203298568725586\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.005337715148925781\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 2, 0]), array([0.699925, 0.659465, 0.599906]))\n",
      "Sizes = [136, 347, 575]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "xy = 6.155996810201598 ratio was beyong 6 multiplier\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_991797.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 41.55202305075764\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(291, 3), faces.shape=(575, 3))>, curr_side_len_check = False, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/554_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fcbb823f3e434fa1ca774b32f857e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #14: <trimesh.Trimesh(vertices.shape=(2055, 3), faces.shape=(4106, 3))>\n",
      "xvfb-run -n 5627 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(515, 3), faces.shape=(1026, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00021576881408691406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798014_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06550240516662598\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08508920669555664\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005788803100585938\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.7206878662109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0011038780212402344\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004943370819091797\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 3, 2, 0, 4]), array([0.668603 , 0.643396 , 0.375432 , 0.133734 , 0.0595034]))\n",
      "Sizes = [418, 487, 97, 13, 11]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #15: <trimesh.Trimesh(vertices.shape=(1822, 3), faces.shape=(3640, 3))>\n",
      "xvfb-run -n 605 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(456, 3), faces.shape=(908, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022459030151367188\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798015_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0691828727722168\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.08591461181640625\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0005736351013183594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.4836273193359375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009019374847412109\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0044841766357421875\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2, 3]), array([0.663817, 0.55186 , 0.506387, 0.182284]))\n",
      "Sizes = [345, 276, 272, 15]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #16: <trimesh.Trimesh(vertices.shape=(1789, 3), faces.shape=(3574, 3))>\n",
      "xvfb-run -n 4277 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(892, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002200603485107422\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798016_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.06270360946655273\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.0800020694732666\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004410743713378906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.412101745605469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.000881195068359375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00445866584777832\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 1, 0, 4, 3]), array([0.699151, 0.547616, 0.52513 , 0.260197, 0.118796]))\n",
      "Sizes = [261, 477, 119, 16, 19]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #17: <trimesh.Trimesh(vertices.shape=(1683, 3), faces.shape=(3362, 3))>\n",
      "xvfb-run -n 2251 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(422, 3), faces.shape=(840, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002219676971435547\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798017_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05385947227478027\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06972026824951172\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003829002380371094\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.841255187988281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008523464202880859\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004148960113525391\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0]), array([0.611835, 0.478513]))\n",
      "Sizes = [675, 165]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_976677.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 131.50242999985122\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(340, 3), faces.shape=(675, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/900_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453f6689baf24a4ab0a577a23ffb3995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_372495.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 131.50242999985122\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(340, 3), faces.shape=(675, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #18: <trimesh.Trimesh(vertices.shape=(1668, 3), faces.shape=(3332, 3))>\n",
      "xvfb-run -n 5907 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691135012471798/decimation_meshlab_25413099.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135012471798_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(830, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023603439331054688\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/864691135012471798018_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05766940116882324\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.07312798500061035\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0003762245178222656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.3882598876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009169578552246094\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004236459732055664\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0]), array([0.518228]))\n",
      "Sizes = [830]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=15000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_897882.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 77.23818495648109\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(830, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/747_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3b00e0851043059bba788ce2c7fc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_386621.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 77.23818495648109\n",
      "--->This soma mesh was not added because failed retry of sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(417, 3), faces.shape=(830, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 301.8549528121948\n",
      "Before Filtering the number of somas found = 1\n",
      "\n",
      "---Performing Soma Mesh Backtracking to original mesh for poisson soma 0\n",
      "xvfb-run -n 2769 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20035.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20035_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_669232.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20035.off loaded has 75284 vn 148918 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_20035_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_669232.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 3593832\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 3593832\n",
      "LOG: 2 Successfully removed 13184 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 13184 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 3435624\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_669232.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 4667 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_43429.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_43429_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_785325.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_43429.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_43429_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_785325.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(6098, 3), faces.shape=(14038, 3))>, <trimesh.Trimesh(vertices.shape=(1042, 3), faces.shape=(2767, 3))>, <trimesh.Trimesh(vertices.shape=(811, 3), faces.shape=(1540, 3))>, <trimesh.Trimesh(vertices.shape=(774, 3), faces.shape=(1990, 3))>, <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1482, 3))>, <trimesh.Trimesh(vertices.shape=(383, 3), faces.shape=(904, 3))>, <trimesh.Trimesh(vertices.shape=(371, 3), faces.shape=(679, 3))>, <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(874, 3))>, <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(692, 3))>, <trimesh.Trimesh(vertices.shape=(296, 3), faces.shape=(707, 3))>, <trimesh.Trimesh(vertices.shape=(249, 3), faces.shape=(821, 3))>, <trimesh.Trimesh(vertices.shape=(243, 3), faces.shape=(577, 3))>, <trimesh.Trimesh(vertices.shape=(241, 3), faces.shape=(362, 3))>, <trimesh.Trimesh(vertices.shape=(232, 3), faces.shape=(347, 3))>, <trimesh.Trimesh(vertices.shape=(155, 3), faces.shape=(310, 3))>]\n",
      "After backtrack the found 2 possible somas: [<trimesh.Trimesh(vertices.shape=(19836, 3), faces.shape=(39237, 3))>, <trimesh.Trimesh(vertices.shape=(12911, 3), faces.shape=(25158, 3))>] \n",
      "\n",
      "--- workin on backtrack soma 0: <trimesh.Trimesh(vertices.shape=(19836, 3), faces.shape=(39237, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2506 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_141257.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_141257_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_912059.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_141257.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_141257_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_912059.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.76493426005398\n",
      "\n",
      "--- workin on backtrack soma 1: <trimesh.Trimesh(vertices.shape=(12911, 3), faces.shape=(25158, 3))>\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8114 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_157101.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_157101_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_62160.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_157101.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_157101_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_62160.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.948845107915596\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(9800, 3), faces.shape=(25582, 3))>, <trimesh.Trimesh(vertices.shape=(7480, 3), faces.shape=(15092, 3))>, <trimesh.Trimesh(vertices.shape=(4152, 3), faces.shape=(7633, 3))>, <trimesh.Trimesh(vertices.shape=(3965, 3), faces.shape=(9822, 3))>, <trimesh.Trimesh(vertices.shape=(3153, 3), faces.shape=(7636, 3))>, <trimesh.Trimesh(vertices.shape=(2985, 3), faces.shape=(6707, 3))>, <trimesh.Trimesh(vertices.shape=(2016, 3), faces.shape=(4738, 3))>, <trimesh.Trimesh(vertices.shape=(1725, 3), faces.shape=(3968, 3))>, <trimesh.Trimesh(vertices.shape=(1643, 3), faces.shape=(3781, 3))>, <trimesh.Trimesh(vertices.shape=(1596, 3), faces.shape=(3661, 3))>, <trimesh.Trimesh(vertices.shape=(1516, 3), faces.shape=(3504, 3))>, <trimesh.Trimesh(vertices.shape=(1392, 3), faces.shape=(3215, 3))>, <trimesh.Trimesh(vertices.shape=(1204, 3), faces.shape=(2762, 3))>, <trimesh.Trimesh(vertices.shape=(905, 3), faces.shape=(2035, 3))>, <trimesh.Trimesh(vertices.shape=(797, 3), faces.shape=(1760, 3))>, <trimesh.Trimesh(vertices.shape=(776, 3), faces.shape=(1750, 3))>, <trimesh.Trimesh(vertices.shape=(704, 3), faces.shape=(1568, 3))>, <trimesh.Trimesh(vertices.shape=(557, 3), faces.shape=(1221, 3))>, <trimesh.Trimesh(vertices.shape=(330, 3), faces.shape=(733, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8674 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68695.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68695_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_290371.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68695.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_68695_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_290371.mls is being deleted....\n",
      "xvfb-run -n 5261 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_15535.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_15535_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_612524.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_15535.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_15535_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_612524.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 85\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8473ab4df2b24ce2a73b876cde52a6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 1127255.4274875335, after = 1350200.2868714402,\n",
      "ratio = 1.1977767007791784, difference = 222944.8593839067\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 3048 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16598.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16598_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_424925.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16598.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_16598_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_424925.mls is being deleted....\n",
      "xvfb-run -n 9362 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29569.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29569_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_397349.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29569.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_29569_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_397349.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 133\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fd574ffe8341fb971a5dfbaef6707e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2089422.6011259102, after = 1790721.515525703,\n",
      "ratio = 0.8570413254651077, difference = -298701.0856002071\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-39-5626004edd16>, line 775)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-5626004edd16>\"\u001b[0;36m, line \u001b[0;32m775\u001b[0m\n\u001b[0;31m    return list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components,glia_pieces, nuclei_pieces\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from soma_extraction_utils import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "segment_id = segment_id\n",
    "current_mesh_verts = current_neuron.vertices\n",
    "current_mesh_faces = current_neuron.faces\n",
    "current_mesh = None\n",
    "\n",
    "\n",
    "outer_decimation_ratio= 0.25\n",
    "large_mesh_threshold = 20000#60000,\n",
    "large_mesh_threshold_inner = 13000 #was changed so dont filter away som somas\n",
    "soma_width_threshold = 0.32\n",
    "soma_size_threshold = 9000 #changed this to smaller so didn't filter some somas away\n",
    "inner_decimation_ratio = 0.25\n",
    "volume_mulitplier=8\n",
    "#side_length_ratio_threshold=3\n",
    "side_length_ratio_threshold=6\n",
    "soma_size_threshold_max=240000#192000 #this puts at 12000 once decimated, another possible is 256000\n",
    "delete_files=True\n",
    "backtrack_soma_mesh_to_original=True #should either be None or \n",
    "boundary_vertices_threshold=None#700 the previous threshold used\n",
    "poisson_backtrack_distance_threshold=None#1500 the previous threshold used\n",
    "close_holes=False\n",
    "\n",
    "#------- 11/12 Additions --------------- #\n",
    "\n",
    "#these arguments are for removing inside pieces\n",
    "remove_inside_pieces = True\n",
    "size_threshold_to_remove=1000 #size accounting for the decimation\n",
    "\n",
    "\n",
    "pymeshfix_clean=False\n",
    "check_holes_before_pymeshfix=False\n",
    "second_poisson=False\n",
    "segmentation_at_end=True\n",
    "last_size_threshold = 2000#1300,\n",
    "\n",
    "largest_hole_threshold = 17000\n",
    "max_fail_loops = 10\n",
    "perform_pairing = False\n",
    "verbose = True\n",
    "return_glia_nuclei_pieces = True\n",
    "\n",
    "backtrack_soma_size_threshold = 13000\n",
    "filter_inside_meshes = True\n",
    "filter_inside_somas=True\n",
    "\n",
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "#Adjusting the thresholds based on the decimations\n",
    "large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "\n",
    "#adjusting for inner decimation\n",
    "soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "             f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "              f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "             f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "             f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "             f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "temp_folder = f\"./{segment_id}\"\n",
    "temp_object = Path(temp_folder)\n",
    "#make the temp folder if it doesn't exist\n",
    "temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#making the decimation and poisson objections\n",
    "Dec_outer = meshlab.Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "Dec_inner = meshlab.Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "Poisson_obj = meshlab.Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "\n",
    "recov_orig_mesh = trimesh.Trimesh(vertices=current_mesh_verts,faces=current_mesh_faces)\n",
    "\n",
    "recov_orig_mesh_no_interior, glia_pieces, nuclei_pieces  = tu.remove_nuclei_and_glia_meshes(recov_orig_mesh,verbose=True)\n",
    "#recov_orig_mesh_no_interior = tu.remove_mesh_interior(recov_orig_mesh)\n",
    "\n",
    "\n",
    "#Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "new_mesh,output_obj = Dec_outer(vertices=recov_orig_mesh_no_interior.vertices,\n",
    "         faces=recov_orig_mesh_no_interior.faces,\n",
    "         segment_id=segment_id,\n",
    "         return_mesh=True,\n",
    "         delete_temp_files=False)\n",
    "\n",
    "# if remove_inside_pieces:\n",
    "#     print(\"removing mesh interior after decimation\")\n",
    "#     new_mesh = tu.remove_mesh_interior(new_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "#preforming the splits of the decimated mesh\n",
    "\n",
    "mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "# --------- 1/11 Addition: Filtering away large meshes that are inside another --------- #\n",
    "if filter_inside_meshes:\n",
    "    print(f\"Filtering away larger meshes that are inside others, before # of meshes = {len(list_of_largest_mesh)}\")\n",
    "    list_of_largest_mesh = tu.filter_away_inside_meshes(list_of_largest_mesh,verbose=True,return_meshes=True)\n",
    "    print(f\"After # of meshes = {len(list_of_largest_mesh)}\")\n",
    "\n",
    "\n",
    "#if no significant pieces were found then will use smaller threshold\n",
    "if len(list_of_largest_mesh)<=0:\n",
    "    print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "    list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "total_soma_list = []\n",
    "total_classifier_list = []\n",
    "total_poisson_list = []\n",
    "total_soma_list_sdf = []\n",
    "\n",
    "\n",
    "\n",
    "#start iterating through where go through all pieces before the poisson reconstruction\n",
    "no_somas_found_in_big_loop = 0\n",
    "for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "    print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "    if remove_inside_pieces:\n",
    "        print(\"remove_inside_pieces requested \")\n",
    "        largest_mesh = tu.remove_mesh_interior(largest_mesh,\n",
    "                                               size_threshold_to_remove=size_threshold_to_remove,\n",
    "                                              try_hole_close=False)\n",
    "\n",
    "\n",
    "    if pymeshfix_clean:\n",
    "        print(\"Requested pymeshfix_clean\")\n",
    "        \"\"\"\n",
    "        Don't have to check if manifold anymore actually just have to plug the holes\n",
    "        \"\"\"\n",
    "        hole_groups = tu.find_border_face_groups(largest_mesh)\n",
    "        if len(hole_groups) > 0:\n",
    "            largest_mesh_filled_holes = tu.fill_holes(largest_mesh,max_hole_size = 10000)\n",
    "        else:\n",
    "            largest_mesh_filled_holes = largest_mesh\n",
    "\n",
    "        if check_holes_before_pymeshfix:\n",
    "            hole_groups = tu.find_border_face_groups(largest_mesh_filled_holes)\n",
    "        else:\n",
    "            print(\"Not checking if there are still existing holes before pymeshfix\")\n",
    "            hole_groups = []\n",
    "\n",
    "        if len(hole_groups) > 0:\n",
    "            #segmentation_at_end = False\n",
    "            print(f\"*** COULD NOT FILL HOLES WITH MAX SIZE OF {np.max([len(k) for k in hole_groups])} so not applying pymeshfix and segmentation_at_end = {segmentation_at_end}\")\n",
    "\n",
    "#                 tu.write_neuron_off(largest_mesh_filled_holes,\"largest_mesh_filled_holes\")\n",
    "#                 raise Exception()\n",
    "        else:\n",
    "            print(\"Applying pymeshfix_clean because no more holes\")\n",
    "            largest_mesh = tu.pymeshfix_clean(largest_mesh_filled_holes,verbose=True)\n",
    "\n",
    "    if second_poisson:\n",
    "        print(\"Applying second poisson run\")\n",
    "        current_neuron_poisson = tu.poisson_surface_reconstruction(largest_mesh)\n",
    "        largest_mesh = tu.split_significant_pieces(current_neuron_poisson)[0]\n",
    "\n",
    "    somas_found_in_big_loop = False\n",
    "\n",
    "    largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "    pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "    pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "    print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "    # ******* This ERRORED AND CALLED OUR NERUON NONE: 77697401493989254 *********\n",
    "    new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "               faces=largest_mesh.faces,\n",
    "               return_mesh=True,\n",
    "               mesh_filename=largest_file_name,\n",
    "               delete_temp_files=False)\n",
    "\n",
    "\n",
    "    #splitting the Poisson into the largest pieces and ordering them\n",
    "    mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "    list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "    print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "    n_failed_inner_soma_loops = 0\n",
    "    for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "        to_add_list = []\n",
    "        to_add_list_sdf = []\n",
    "\n",
    "        print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "        largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "        #Decimate the inner poisson piece\n",
    "        largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                            vertices=largest_mesh_inner.vertices,\n",
    "                             faces=largest_mesh_inner.faces,\n",
    "                            mesh_filename=largest_mesh_path_inner,\n",
    "                             return_mesh=True,\n",
    "                             delete_temp_files=False)\n",
    "\n",
    "        dec_splits = tu.split_significant_pieces(largest_mesh_path_inner_decimated,significance_threshold=15)\n",
    "        print(f\"\\n-------Splits after inner decimation len = {len(dec_splits)}--------\\n\")\n",
    "\n",
    "        if len(dec_splits) == 0:\n",
    "            print(\"There were no signifcant splits after inner decimation\")\n",
    "            n_failed_inner_soma_loops += 1\n",
    "        else:\n",
    "            print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "            largest_mesh_path_inner_decimated_clean = dec_splits[0]\n",
    "            print(f\"largest_mesh_path_inner_decimated_clean = {largest_mesh_path_inner_decimated_clean}\\n\")\n",
    "\n",
    "            faces = np.array(largest_mesh_path_inner_decimated_clean.faces)\n",
    "            verts = np.array(largest_mesh_path_inner_decimated_clean.vertices)\n",
    "\n",
    "            # may need to do some processing\n",
    "\n",
    "\n",
    "            segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "            #print(f\"Before the classifier the pymeshfix_clean = {pymeshfix_clean}\")\n",
    "            verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                    import_Off_Flag=False,\n",
    "                                    segment_id=segment_id_new,\n",
    "                                    vertices=verts,\n",
    "                                     triangles=faces,\n",
    "                                    pymeshfix_Flag=False,\n",
    "                                     import_CGAL_Flag=False,\n",
    "                                     return_Only_Labels=True,\n",
    "                                     clusters=3,\n",
    "                                     smoothness=0.2,\n",
    "                                    soma_only=True,\n",
    "                                    return_classifier = True\n",
    "                                    )\n",
    "            print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "            total_classifier_list.append(classifier)\n",
    "            #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "            # Save all of the portions that resemble a soma\n",
    "            median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "            segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "            #order the compartments by greatest to smallest\n",
    "            sorted_medians = np.flip(np.argsort(median_values))\n",
    "            print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "            print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "            print(f\"soma_size_threshold = {soma_size_threshold}\")\n",
    "            print(f\"soma_size_threshold_max={soma_size_threshold_max}\")\n",
    "\n",
    "            valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "            valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "            print(\"valid_soma_segments_width\")\n",
    "\n",
    "            if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "\n",
    "\n",
    "                    if curr_side_len_check and curr_volume_check:\n",
    "                        #check if we can split this into two\n",
    "                        to_add_list.append(soma_mesh)\n",
    "                        to_add_list_sdf.append(sdf)\n",
    "\n",
    "                        \"\"\"  -----------Removed 1/12: When trying to force a split between them \n",
    "                        possible_smoothness = [0.2,0.05,0.01]\n",
    "                        for smooth_value in possible_smoothness:\n",
    "                            #1) Run th esegmentation algorithm again to segment the mesh (had to run the higher smoothing to seperate some)\n",
    "                            mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=smooth_value,verbose=True)\n",
    "                            mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                            #2) Filter out meshes by sizs and sdf threshold\n",
    "                            mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                            filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "                            if len(filtered_meshes_idx) >= 2:\n",
    "                                if verbose:\n",
    "                                    print(f\"Breakin on smoothness: {smooth_value}\")\n",
    "                                break\n",
    "\n",
    "                        if len(filtered_meshes_idx) >= 2:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            to_add_list_retry = []\n",
    "                            to_add_list_sdf_retry = []\n",
    "\n",
    "                            for f_m,f_m_sdf in zip(filtered_meshes,filtered_meshes_sdf):\n",
    "                                curr_side_len_check_retry = side_length_check(f_m,side_length_ratio_threshold)\n",
    "                                curr_volume_check_retry = soma_volume_check(f_m,volume_mulitplier)\n",
    "\n",
    "                                if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                    to_add_list_retry.append(f_m)\n",
    "                                    to_add_list_sdf_retry.append(f_m_sdf)\n",
    "\n",
    "                            if len(to_add_list_retry)>1:\n",
    "                                if verbose:\n",
    "                                    print(\"Using the new feature that split the soma further into more groups\")\n",
    "                                to_add_list += to_add_list_retry\n",
    "                                to_add_list_sdf += to_add_list_sdf_retry\n",
    "\n",
    "                            else:\n",
    "                                to_add_list.append(soma_mesh)\n",
    "                                to_add_list_sdf.append(sdf)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            to_add_list.append(soma_mesh)\n",
    "                            to_add_list_sdf.append(sdf)\n",
    "                        \"\"\"\n",
    "\n",
    "                    else:\n",
    "                        # ---------- 1/7 Addition: Trying one more additional cgal segmentation to see if there is actually a soma ---\n",
    "                        \"\"\"\n",
    "                        Pseudocode: \n",
    "                        1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        2) Filter out meshes by sizs and sdf threshold\n",
    "                        3) If there are any remaining meshes, pick the largest sdf mesh and test for volume and side length check\n",
    "                        --> if matches then adds\n",
    "                        \"\"\"\n",
    "\n",
    "                        print(f\"->Attempting retry of soma because failed first checks: \"\n",
    "                                 f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                        #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                        mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                        #2) Filter out meshes by sizs and sdf threshold\n",
    "                        mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                        filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "\n",
    "                        if len(filtered_meshes_idx) > 0:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            sdf_winning_index = np.argmax(filtered_meshes_sdf)\n",
    "                            soma_mesh_retry = filtered_meshes[sdf_winning_index]\n",
    "                            sdf_retry = filtered_meshes_sdf[sdf_winning_index]\n",
    "\n",
    "                            curr_side_len_check_retry = side_length_check(soma_mesh_retry,side_length_ratio_threshold)\n",
    "                            curr_volume_check_retry = soma_volume_check(soma_mesh_retry,volume_mulitplier)\n",
    "\n",
    "                            if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                to_add_list.append(soma_mesh_retry)\n",
    "                                to_add_list_sdf.append(sdf_retry)\n",
    "                            else:\n",
    "                                print(f\"--->This soma mesh was not added because failed retry of sphere validation:\\n \"\n",
    "                                     f\"soma_mesh = {soma_mesh_retry}, curr_side_len_check = {curr_side_len_check_retry}, curr_volume_check = {curr_volume_check_retry}\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(f\"Could not find valid soma mesh in retry\")\n",
    "                            continue\n",
    "\n",
    "\n",
    "                n_failed_inner_soma_loops = 0\n",
    "\n",
    "            else:\n",
    "                n_failed_inner_soma_loops += 1\n",
    "\n",
    "        total_soma_list_sdf += to_add_list_sdf\n",
    "        total_soma_list += to_add_list\n",
    "\n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if n_failed_inner_soma_loops >= max_fail_loops:\n",
    "            print(f\"breaking inner loop because {max_fail_loops} soma fails in a row\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "    if somas_found_in_big_loop == False:\n",
    "        no_somas_found_in_big_loop += 1\n",
    "        if no_somas_found_in_big_loop >= max_fail_loops:\n",
    "            print(f\"breaking because {max_fail_loops} fails in a row in big loop\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        no_somas_found_in_big_loop = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "pairings = []\n",
    "\n",
    "if perform_pairing:\n",
    "    for y,soma_1 in enumerate(total_soma_list):\n",
    "        for z,soma_2 in enumerate(total_soma_list):\n",
    "            if y<z:\n",
    "                mesh_tree = KDTree(soma_1.vertices)\n",
    "                distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "                if np.min(distances) < 4000:\n",
    "                    pairings.append([y,z])\n",
    "\n",
    "\n",
    "#creating the combined meshes from the list\n",
    "total_soma_list_revised = []\n",
    "total_soma_list_revised_sdf = []\n",
    "if len(pairings) > 0:\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    Use a network function to find components\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    new_graph = nx.Graph()\n",
    "    new_graph.add_edges_from(pairings)\n",
    "    grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "    somas_being_combined = []\n",
    "    print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "    for comp in grouped_somas:\n",
    "        comp = list(comp)\n",
    "        somas_being_combined += list(comp)\n",
    "        current_mesh = total_soma_list[comp[0]]\n",
    "        for i in range(1,len(comp)):\n",
    "            current_mesh += total_soma_list[comp[i]] #just combining the actual meshes\n",
    "\n",
    "        total_soma_list_revised.append(current_mesh)\n",
    "        #where can average all of the sdf values\n",
    "        total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "    #add those that weren't combined to total_soma_list_revised\n",
    "    leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    if len(leftover_somas) > 0:\n",
    "        total_soma_list_revised += leftover_somas\n",
    "        total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "    print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "    print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "if len(total_soma_list_revised) == 0:\n",
    "    total_soma_list_revised = total_soma_list\n",
    "    total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "run_time = time.time() - global_start_time\n",
    "\n",
    "print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "#     import system_utils as su\n",
    "#     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "#     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "#need to erase all of the temporary files ******\n",
    "#import shutil\n",
    "#shutil.rmtree(directory)\n",
    "\n",
    "\"\"\"\n",
    "Running the extra tests that depend on\n",
    "- border vertices\n",
    "- how well the poisson matches the backtracked soma to the real mesh\n",
    "- other size checks\n",
    "\n",
    "\"\"\"\n",
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "\n",
    "for yy,(soma_mesh,curr_soma_sdf) in enumerate(zip(total_soma_list_revised,total_soma_list_revised_sdf)):\n",
    "    add_inside_pieces_flag = False\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        if verbose:\n",
    "            print(f\"\\n---Performing Soma Mesh Backtracking to original mesh for poisson soma {yy}\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "        try:\n",
    "            soma_mesh_list,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                            original_mesh = recov_orig_mesh_no_interior,\n",
    "                                            mesh=soma_mesh_poisson,\n",
    "                                            soma_size_threshold=backtrack_soma_size_threshold)\n",
    "\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "\n",
    "        if soma_mesh_list is None:\n",
    "                print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        if verbose: \n",
    "            print(f\"After backtrack the found {len(soma_mesh_list)} possible somas: {soma_mesh_list} \")\n",
    "\n",
    "        for rr,soma_mesh in enumerate(soma_mesh_list):\n",
    "            if verbose:\n",
    "                print(f\"\\n--- workin on backtrack soma {rr}: {soma_mesh}\")\n",
    "\n",
    "            print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "            #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "            if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "                #soma_mesh.export(\"soma_mesh.off\")\n",
    "                if close_holes: \n",
    "                    print(\"Using the close holes feature\")\n",
    "                    fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                     self_itersect_faces=False)\n",
    "\n",
    "                    soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                        vertices=soma_mesh.vertices,\n",
    "                                                         faces=soma_mesh.faces,\n",
    "                                                         return_mesh=True,\n",
    "                                                         delete_temp_files=True,\n",
    "                                                        )\n",
    "                else:\n",
    "                    soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "                #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "                print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "                mesh_1 = soma_mesh_filled_holes\n",
    "                mesh_2 = soma_mesh_poisson\n",
    "\n",
    "                poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                                  verbose=True)\n",
    "                print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "                if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                      f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #do the boundary check:\n",
    "            if not boundary_vertices_threshold is None:\n",
    "                print(\"USING boundary_vertices_threshold CHECK\")\n",
    "                soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "                print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "                large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "                print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "                if len(large_boundary_groups)>0:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                          f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "                    continue\n",
    "\n",
    "            curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "            curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "            if (not curr_side_len_check) or (not curr_volume_check):\n",
    "                print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "                     f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                continue\n",
    "\n",
    "            #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "            #If made it through all the checks then add to final list\n",
    "            filtered_soma_list.append(soma_mesh)\n",
    "            filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "            add_inside_pieces_flag = True #setting flag so will add inside pieces\n",
    "\n",
    "\n",
    "    if len(soma_mesh_inside_pieces) > 0 and add_inside_pieces_flag:\n",
    "        print(f\"About to add the following inside nuclei pieces after soma backtrack: {nuclei_pieces}\")\n",
    "        nuclei_pieces +=soma_mesh_inside_pieces\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Need to delete all files in the temp folder *****\n",
    "\"\"\"\n",
    "\n",
    "if delete_files:\n",
    "    #now erase all of the files used\n",
    "    from shutil import rmtree\n",
    "\n",
    "    #remove the directory with the meshes\n",
    "    rmtree(str(temp_object.absolute()))\n",
    "\n",
    "    #removing the temporary files\n",
    "    temp_folder = Path(\"./temp\")\n",
    "    temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "    seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "    for f in seg_temp_files:\n",
    "        f.unlink()\n",
    "\n",
    "# ----------- 11 /11 Addition that does a last step segmentation of the soma --------- #\n",
    "#return total_soma_list, run_time\n",
    "#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n",
    "\"\"\"\n",
    "Things we should ask about the segmentation:\n",
    "\n",
    "Advantages: \n",
    "1) could help filter away negatives\n",
    "\n",
    "Disadvantages:\n",
    "1) Can actually cut up the soma and then filter away the soma (not what we want)\n",
    "2) Could introduce a big hole (don't think can guard against this)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#filtered_soma_list_saved = copy.deepcopy(filtered_soma_list)\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "\n",
    "        print(\"Skipping the segmentatio filter at end\")\n",
    "        if not (len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold):\n",
    "            print(f\"Soma (size = {len(f_soma.faces)}, width={soma_width_threshold}) did not pass thresholds (size threshold={last_size_threshold}, width threshold = {soma_width_threshold}) \")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if segmentation_at_end:\n",
    "\n",
    "\n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "#                 print(f\"meshes_split = {meshes_split}\")\n",
    "#                 print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                print(f\"So just going with old somas\")\n",
    "\n",
    "                f_soma_final = f_soma\n",
    "                f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "            else:\n",
    "                meshes_split = np.array(meshes_split)\n",
    "                meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "                meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "                meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "                soma_width_threshold\n",
    "                #way to choose the index of the top candidate\n",
    "                top_candidate = 0\n",
    "\n",
    "\n",
    "                largest_hole_before_seg = tu.largest_hole_length(f_soma)\n",
    "                largest_hole_after_seg = tu.largest_hole_length(meshes_split_filtered[top_candidate])\n",
    "\n",
    "                print(f\"Largest hole before segmentation = {largest_hole_before_seg}, after = {largest_hole_after_seg},\"\n",
    "                      f\"\\nratio = {largest_hole_after_seg/largest_hole_before_seg}, difference = {largest_hole_after_seg - largest_hole_before_seg}\")\n",
    "\n",
    "                if largest_hole_after_seg < largest_hole_threshold:\n",
    "                    f_soma_final = meshes_split_filtered[top_candidate]\n",
    "                    f_soma_sdf_final = meshes_split_sdf_filtered[top_candidate]\n",
    "                else:\n",
    "                    f_soma_final = f_soma\n",
    "                    f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "        else:\n",
    "            f_soma_final = f_soma\n",
    "            f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "        filtered_soma_list_revised.append(f_soma_final)\n",
    "        filtered_soma_list_sdf_revised.append(f_soma_sdf_final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n",
    "\n",
    "    \"\"\"\n",
    "    # ----------- 1/7/21 ---------------#\n",
    "    Now was to stitch the somas together if they are touching\n",
    "\n",
    "    \"\"\"\n",
    "    if len(filtered_soma_list)>1:\n",
    "        connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                                 main_mesh=recov_orig_mesh_no_interior,\n",
    "                                                    return_connected_components=True)\n",
    "\n",
    "        filtered_soma_list_components = np.array([tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components])\n",
    "        filtered_soma_list_sdf_components = np.array([np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components])\n",
    "    elif len(filtered_soma_list)==1:\n",
    "        filtered_soma_list_components = filtered_soma_list\n",
    "        filtered_soma_list_sdf_components = filtered_soma_list_sdf\n",
    "    else:\n",
    "        filtered_soma_list_components = []\n",
    "        filtered_soma_list_sdf_components = np.array([])\n",
    "else:\n",
    "    filtered_soma_list_components = []\n",
    "    filtered_soma_list_sdf_components = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "#----------- 1/9 Addition: Final Size Threshold ------------- #\n",
    "if backtrack_soma_mesh_to_original:\n",
    "\n",
    "    filtered_soma_list_components_new = []\n",
    "    filtered_soma_list_sdf_components_new = []\n",
    "\n",
    "    for soma_mesh, soma_mesh_sdf in zip(filtered_soma_list_components,filtered_soma_list_sdf_components):\n",
    "        # --------- 1/9: Extra Size Threshold For Somas ------------- #\n",
    "        if len(soma_mesh.faces) < backtrack_soma_size_threshold:\n",
    "            print(f\"--->This soma mesh with size {len(soma_mesh.faces)} was not bigger than the threshold {backtrack_soma_size_threshold}\")\n",
    "            continue\n",
    "        else:\n",
    "            filtered_soma_list_components_new.append(soma_mesh)\n",
    "            filtered_soma_list_sdf_components_new.append(soma_mesh_sdf)\n",
    "\n",
    "    filtered_soma_list_components = filtered_soma_list_components_new\n",
    "    filtered_soma_list_sdf_components = np.array(filtered_soma_list_sdf_components_new)\n",
    "\n",
    "if filter_inside_somas:\n",
    "    if len(filtered_soma_list_components)>1:\n",
    "        keep_indices = tu.filter_away_inside_meshes(mesh_list = filtered_soma_list_components,\n",
    "                                    distance_type=\"shortest_vertex_distance\",\n",
    "                                    distance_threshold = 2000,\n",
    "                                    inside_percentage_threshold = 0.20,\n",
    "                                    verbose = False,\n",
    "                                    return_meshes = False,\n",
    "                                    )\n",
    "    else:\n",
    "        keep_indices = np.arange(len(filtered_soma_list_components))\n",
    "\n",
    "    filtered_soma_list_components = [k for i,k in enumerate(filtered_soma_list_components) if i in keep_indices]\n",
    "    filtered_soma_list_sdf_components = filtered_soma_list_sdf_components[keep_indices]\n",
    "\n",
    "\n",
    "\n",
    "if return_glia_nuclei_pieces:\n",
    "    return_value= list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components,glia_pieces, nuclei_pieces\n",
    "else:\n",
    "    return_value = list(filtered_soma_list_components),run_time,filtered_soma_list_sdf_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03ee7d3d1654ab4b07dfd92060748ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 8551 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_499305.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_80906_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_499305.mls is being deleted....\n",
      "xvfb-run -n 4817 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_687930.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_2343_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_687930.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 86\n",
      "viable_meshes = [0]\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 7660 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_482671.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_49934_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_482671.mls is being deleted....\n",
      "xvfb-run -n 7046 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_70205.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_66113_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_70205.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (300) interior meshes present\n",
      "largest is 86\n",
      "viable_meshes = [0]\n"
     ]
    }
   ],
   "source": [
    "backtracked_somas = []\n",
    "for soma_mesh,curr_soma_sdf in zip(total_soma_list_revised,total_soma_list_revised_sdf):\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        print(\"Performing Soma Mesh Backtracking to original mesh\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "            #print(\"About to find original mesh\")\n",
    "\n",
    "\n",
    "        soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)\n",
    "        backtracked_somas.append(soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 5197 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_344509.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363.off loaded has 60255 vn 118370 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_38363_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_344509.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 2866560\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 2866560\n",
      "LOG: 2 Successfully removed 12914 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 12914 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 2711592\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_344509.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 9872 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_192902.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7453_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_192902.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2835: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(6098, 3), faces.shape=(14038, 3))>, <trimesh.Trimesh(vertices.shape=(811, 3), faces.shape=(1540, 3))>, <trimesh.Trimesh(vertices.shape=(774, 3), faces.shape=(1990, 3))>, <trimesh.Trimesh(vertices.shape=(644, 3), faces.shape=(1332, 3))>, <trimesh.Trimesh(vertices.shape=(552, 3), faces.shape=(1482, 3))>, <trimesh.Trimesh(vertices.shape=(383, 3), faces.shape=(904, 3))>, <trimesh.Trimesh(vertices.shape=(365, 3), faces.shape=(681, 3))>, <trimesh.Trimesh(vertices.shape=(345, 3), faces.shape=(874, 3))>, <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(692, 3))>, <trimesh.Trimesh(vertices.shape=(296, 3), faces.shape=(707, 3))>, <trimesh.Trimesh(vertices.shape=(249, 3), faces.shape=(821, 3))>, <trimesh.Trimesh(vertices.shape=(243, 3), faces.shape=(577, 3))>, <trimesh.Trimesh(vertices.shape=(241, 3), faces.shape=(362, 3))>, <trimesh.Trimesh(vertices.shape=(155, 3), faces.shape=(310, 3))>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    }
   ],
   "source": [
    "soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c04c65023942f0b6afec7192d9e4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Original Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(12841, 3), faces.shape=(25096, 3))>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd76d8adea649158df9fb728aa91870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh,soma_mesh_inside_pieces = sm.original_mesh_soma(\n",
    "                                        original_mesh = recov_orig_mesh_no_interior,\n",
    "                                        mesh=soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(filtered_soma_list_components[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The New Original Mesh Soma Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recov_orig_mesh_no_interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_big_mesh,faces = tu.bbox_mesh_restriction(recov_orig_mesh_no_interior,soma_mesh_poisson,mult_ratio=2)\n",
    "restricted_big_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.original_mesh_soma(restricted_big_mesh,soma_meshes=[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_mesh_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_split = tu.split_significant_pieces(restricted_big_mesh,significance_threshold=1000,connectivity=\"edges\")\n",
    "restr_mesh_to_test = restr_split[0]\n",
    "restr_mesh_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.mesh_interior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_without_interior,rem_pieces = tu.remove_mesh_interior(restr_mesh_to_test,return_removed_pieces=True,size_threshold_to_remove=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_without_interior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restricted_big_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_somas = sm.original_mesh_soma(restr_without_interior,[soma_mesh_poisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(new_somas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The new Soma Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_soma = sm.original_mesh_soma(restr_without_interior_largest,\n",
    "                      soma_mesh_poisson,\n",
    "    subtract_soma_distance_threshold=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(back_soma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = soma_mesh_poisson\n",
    "original_mesh = recov_orig_mesh_no_interior \n",
    "bbox_restriction_multiplying_ratio = 1.7\n",
    "match_distance_threshold = 1500\n",
    "mesh_significance_threshold = 1000\n",
    "return_inside_pieces = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_soma_mesh,soma_inside_pieces = original_mesh_soma(\n",
    "    mesh = soma_mesh_poisson,\n",
    "    original_mesh = recov_orig_mesh_no_interior ,\n",
    "    bbox_restriction_multiplying_ratio = 1.7,\n",
    "    match_distance_threshold = 1500,\n",
    "    mesh_significance_threshold = 1000,\n",
    "    return_inside_pieces = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(final_soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=soma_inside_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restr_without_interior_largest = tu.split_significant_pieces(restr_without_interior)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes,sdf_results = tu.mesh_segmentation(restr_without_interior_largest,clusters=3,smoothness=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes[np.argmax(sdf_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_meshes = np.array(divided_meshes)\n",
    "sdf_results = np.array(sdf_results)\n",
    "\n",
    "meshes_len = np.array([len(k.faces) for k in divided_meshes ])\n",
    "possible_soma_idxs = np.where(meshes_len > 13000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(restr_without_interior_largest,\n",
    "                meshes=[divided_meshes[0],soma_mesh_poisson],\n",
    "                 meshes_colors=[\"red\",\"purple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(Out[129][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.bounding_box_corners(soma_mesh_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.bbox_mesh_restriction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_soma_segments_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_somas = []\n",
    "if len(valid_soma_segments_width) > 0:\n",
    "    print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "    somas_found_in_big_loop = True\n",
    "    #get the meshes only if signfiicant length\n",
    "    labels_list = classifier.labels_list\n",
    "\n",
    "    for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "        submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "        soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "        total_somas.append(soma_mesh)\n",
    "\n",
    "        # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "\n",
    "        curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "        curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "        \n",
    "        print(f\"\\n\\n {curr_side_len_check}, {curr_volume_check} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(total_somas[1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Run th esegmentation algorithm again to segment the mesh\n",
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(total_somas[1],clusters=3,smoothness=0.01,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                  meshes_colors=\"random\"\n",
    "                 )\n",
    "#2) Filter out meshes by sizs and sdf threshold\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "nviz.plot_objects(meshes=mesh_extra[filtered_meshes_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mesh = mesh_extra[filtered_meshes_idx][0]\n",
    "\n",
    "side_length_check(test_mesh,side_length_ratio_threshold), soma_volume_check(test_mesh,volume_mulitplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[-1],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "                    \n",
    "                    #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                    mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                    mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                    #2) Filter out meshes by sizs and sdf threshold\n",
    "                    mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                    filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.05,verbose=True)\n",
    "nviz.plot_objects(meshes=mesh_extra,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "            mesh = recov_orig_mesh_no_interior,\n",
    "            soma_meshes=[soma_mesh_poisson],\n",
    "            sig_th_initial_split=15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(soma_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ----------- 1/7/21 ---------------#\n",
    "Now was to stitch the somas together if they are touching\n",
    "\n",
    "\"\"\"\n",
    "connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                         main_mesh=recov_orig_mesh,\n",
    "                                            return_connected_components=True)\n",
    "\n",
    "filtered_soma_list_components = [tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components]\n",
    "filtered_soma_list_sdf_components = [np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "                                            mesh = recov_orig_mesh_no_interior,\n",
    "                                            soma_meshes=[soma_mesh_poisson],\n",
    "                                            sig_th_initial_split=15)[0]\n",
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_soma_meshes = su.decompress_pickle(\"seperate_soma_meshes\")\n",
    "nviz.plot_objects(meshes=seperate_soma_meshes,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_saved = su.decompress_pickle(\"filtered_soma_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(current_neuron,\n",
    "                #meshes=[return_value[0][0]],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "if len(filtered_meshes_idx) > 0:\n",
    "    filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "    filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "    \n",
    "    soma_mesh_retry = filtered_meshes[np.argmax(filtered_meshes_sdf)]\n",
    "\n",
    "nviz.plot_objects(soma_mesh_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_size_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(mesh_extra[0],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(largest_mesh_path_inner_decimated_clean,\n",
    "                 meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mesh_threshold_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=[k for k in ordered_mesh_splits_inner if len(k.faces)>800],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=dec_splits,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh[1],\n",
    "                  meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh,\n",
    "                 meshes_colors=[\"red\",\"black\"],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(main_mesh=current_neuron,\n",
    "                 meshes=filtered_soma_list,\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                                 current_neuron.vertices,\n",
    "                                                 current_neuron.faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
