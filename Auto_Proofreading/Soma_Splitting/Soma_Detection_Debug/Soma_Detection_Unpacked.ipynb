{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To debug why certain somas are not being detected\n",
    "in agreement with nucleus table\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-07 22:55:11,658 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-07 22:55:11,659 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-07 22:55:11,660 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-07 22:55:11,671 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-07 22:55:11,672 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-07 22:55:11,689 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-07 22:55:11,930 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import soma_extraction_utils as sm\n",
    "import datajoint_utils as du\n",
    "import neuron_visualizations as nviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-07 22:56:30,966 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-07 22:56:31,296 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking what neurons did not have 2 somas which should have (so can test on them now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimation_version = 0\n",
    "decimation_ratio = 0.25\n",
    "key_source = (minnie.Decimation().proj(decimation_version='version')  & \n",
    "              dict(decimation_version=decimation_version,decimation_ratio=decimation_ratio)  \n",
    "              & minnie.MultiSomaProofread() & (dj.U(\"segment_id\") & (minnie.BaylorSegmentCentroid() & \"multiplicity=1\").proj()))\n",
    "key_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minnie.MultiSomaProofread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Mesh of the Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 864691135428492848 #worked when reset some of the parameters\n",
    "segment_id = 864691135939303681 #worked for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The double somas that should be worked on\n",
    "segment_id = 864691135065024068 #soma soma merger not want that\n",
    "segment_id = 864691134988385914 # soma soma merger\n",
    "segment_id = 864691135104011853\n",
    "segment_id = 864691135122297127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/6 Debugging Missed Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 864691134988385914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_neuron = du.fetch_segment_id_mesh(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37b71d8f6a34e31ad3fc20501ab936a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 3319 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5455.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5455_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_854127.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5455.off loaded has 627859 vn 1334901 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_5455_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_854127.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 31087428\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 31087428\n",
      "LOG: 2 Successfully removed 69602 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 69602 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 30252204\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_854127.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 5331 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_34247.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_34247_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_510840.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_34247.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_34247_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_510840.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2568: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  su.compressed_pickle(ordered_components,\"ordered_components\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(60983, 3), faces.shape=(163013, 3))>, <trimesh.Trimesh(vertices.shape=(37395, 3), faces.shape=(96155, 3))>]\n",
      "xvfb-run -n 4495 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25193471.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:05:30,544 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:30,642 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:30,715 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:30,886 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:30,888 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,060 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,064 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,077 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,078 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,123 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,125 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,126 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,127 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,129 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,130 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,140 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,157 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,361 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,364 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,522 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,543 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,564 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,573 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,592 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,593 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,595 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,616 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,617 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,629 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,637 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,652 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:31,689 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,639 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,664 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,665 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,669 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,673 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,676 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,681 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,681 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:05:32,701 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(68324, 3), faces.shape=(133613, 3))>, <trimesh.Trimesh(vertices.shape=(60830, 3), faces.shape=(118541, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(68324, 3), faces.shape=(133613, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3624 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_24587.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_24587_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_936943.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_24587.off loaded has 68324 vn 133613 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_24587_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_936943.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 3243132\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 3243132\n",
      "LOG: 2 Successfully removed 790 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 790 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 3233652\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_936943.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 6762 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30105.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30105_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_17791.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30105.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_30105_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_17791.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 145\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off\n",
      "xvfb-run -n 1643 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/poisson_585151.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(23843, 3), faces.shape=(47682, 3))>, <trimesh.Trimesh(vertices.shape=(1744, 3), faces.shape=(3484, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(23843, 3), faces.shape=(47682, 3))>\n",
      "xvfb-run -n 3697 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25497833.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(5961, 3), faces.shape=(11918, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0008924007415771484\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591400_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.000807285308838\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.210482120513916\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00435638427734375\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.009407281875610352\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.055597543716430664\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.115384\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 2,  8,  1,  0, 14, 15,  6,  5, 17, 11,  3, 10,  4,  7, 13,  9, 16,\n",
      "       12]), array([0.8133025 , 0.1246295 , 0.115384  , 0.1112635 , 0.0978866 ,\n",
      "       0.0956922 , 0.0830078 , 0.0572021 , 0.0509989 , 0.0472632 ,\n",
      "       0.045175  , 0.0444408 , 0.0429886 , 0.0375067 , 0.03397915,\n",
      "       0.0292611 , 0.0208762 , 0.0160651 ]))\n",
      "Sizes = [2624, 106, 4161, 378, 215, 126, 75, 221, 1531, 345, 325, 273, 876, 43, 332, 225, 25, 37]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2780 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_818369.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_818369_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_896108.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_818369.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_818369_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_896108.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.9300985008950597\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1744, 3), faces.shape=(3484, 3))>\n",
      "xvfb-run -n 2598 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25497833.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(437, 3), faces.shape=(870, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004725456237792969\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.04165506362915039\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06315946578979492\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00041484832763671875\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00011181831359863281\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008804798126220703\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.00428462028503418\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.573573, 0.310102, 0.237792]))\n",
      "Sizes = [288, 505, 77]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(60830, 3), faces.shape=(118541, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 2822 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_42690.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_42690_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_612162.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_42690.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_42690_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_612162.mls is being deleted....\n",
      "xvfb-run -n 8678 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7643.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7643_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_257761.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7643.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7643_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_257761.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 492\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off\n",
      "xvfb-run -n 7248 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/poisson_585151.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(16729, 3), faces.shape=(33458, 3))>, <trimesh.Trimesh(vertices.shape=(1887, 3), faces.shape=(3770, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(16729, 3), faces.shape=(33458, 3))>\n",
      "xvfb-run -n 9305 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25497833.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(4180, 3), faces.shape=(8360, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.001501321792602539\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591410_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6556370258331299\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.8129513263702393\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0028409957885742188\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 5.340576171875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.006860256195068359\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0395197868347168\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.620533\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 7, 1, 4, 5, 2, 3, 6]), array([0.620533  , 0.09013405, 0.0581121 , 0.0503794 , 0.0456572 ,\n",
      "       0.0405575 , 0.0375307 , 0.0269427 ]))\n",
      "Sizes = [3427, 104, 3806, 83, 113, 397, 233, 197]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4145 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_555619.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_555619_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_657269.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_555619.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_555619_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_657269.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 12.512593186682402\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1720, 3), faces.shape=(3427, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/350_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466ee813fbbe4e7db23b9cd261cb63e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4167 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282970.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282970_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_700287.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1216: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return total_submeshes,total_submeshes_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282970.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_282970_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_700287.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.301321749165639\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1887, 3), faces.shape=(3770, 3))>\n",
      "xvfb-run -n 6439 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25497833.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(473, 3), faces.shape=(942, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002224445343017578\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591411_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.05025291442871094\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06784629821777344\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00044274330139160156\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.7206878662109375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0009057521820068359\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004759788513183594\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 4, 2, 3]), array([0.6684745, 0.453435 , 0.354481 , 0.349022 , 0.305695 ]))\n",
      "Sizes = [254, 337, 53, 101, 197]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 199.6911780834198\n",
      "Before Filtering the number of somas found = 2\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:07:05,860 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 339\n",
      "viable_meshes = [0]\n",
      "There were 335 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1338, 3), faces.shape=(2624, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(531829, 3), faces.shape=(1053162, 3))>\n",
      "\n",
      "inside Soma subtraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:07:09,878 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:09,880 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:09,980 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:09,984 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:09,996 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:09,997 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,041 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,043 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,044 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,045 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,047 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,049 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,161 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,162 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,173 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,191 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,209 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,213 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,224 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,225 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,235 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,252 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,274 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,275 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,279 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,283 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,287 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,288 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:10,307 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for soma mesh cancellation = 2.048\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(256449, 3), faces.shape=(509469, 3))>, <trimesh.Trimesh(vertices.shape=(121859, 3), faces.shape=(242930, 3))>, <trimesh.Trimesh(vertices.shape=(76442, 3), faces.shape=(152185, 3))>, <trimesh.Trimesh(vertices.shape=(25234, 3), faces.shape=(50922, 3))>, <trimesh.Trimesh(vertices.shape=(16271, 3), faces.shape=(32482, 3))>, <trimesh.Trimesh(vertices.shape=(1727, 3), faces.shape=(3423, 3))>, <trimesh.Trimesh(vertices.shape=(1543, 3), faces.shape=(3071, 3))>, <trimesh.Trimesh(vertices.shape=(992, 3), faces.shape=(1938, 3))>, <trimesh.Trimesh(vertices.shape=(475, 3), faces.shape=(922, 3))>, <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(814, 3))>, <trimesh.Trimesh(vertices.shape=(244, 3), faces.shape=(294, 3))>]\n",
      "Total time for Subtract Soam = 2.0491700172424316\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.823897123336792\n",
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/seperate_soma_meshes.pbz2\n",
      "File size is 1.400915 MB\n",
      "poisson_backtrack_distance_threshold = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:07:12,243 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:12,461 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:12,486 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:12,534 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9911 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_289564.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_289564_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_333455.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_289564.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_289564_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_333455.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.311284291902997\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:07:30,953 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 339\n",
      "viable_meshes = [0]\n",
      "There were 335 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1324, 3), faces.shape=(2617, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(531829, 3), faces.shape=(1053162, 3))>\n",
      "\n",
      "inside Soma subtraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:07:34,683 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:34,913 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:34,915 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:34,920 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,014 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,015 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,026 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,048 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,057 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,075 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,076 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,078 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,098 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,099 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,111 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,122 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,174 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,198 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,199 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,203 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,207 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,210 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,215 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,216 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:35,235 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for soma mesh cancellation = 2.182\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(267249, 3), faces.shape=(530994, 3))>, <trimesh.Trimesh(vertices.shape=(160214, 3), faces.shape=(319106, 3))>, <trimesh.Trimesh(vertices.shape=(58758, 3), faces.shape=(117213, 3))>, <trimesh.Trimesh(vertices.shape=(12441, 3), faces.shape=(24738, 3))>, <trimesh.Trimesh(vertices.shape=(4779, 3), faces.shape=(9401, 3))>, <trimesh.Trimesh(vertices.shape=(3413, 3), faces.shape=(6793, 3))>, <trimesh.Trimesh(vertices.shape=(525, 3), faces.shape=(1026, 3))>, <trimesh.Trimesh(vertices.shape=(446, 3), faces.shape=(803, 3))>, <trimesh.Trimesh(vertices.shape=(438, 3), faces.shape=(851, 3))>, <trimesh.Trimesh(vertices.shape=(316, 3), faces.shape=(517, 3))>]\n",
      "Total time for Subtract Soam = 2.183222532272339\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.7816994190216064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:07:36,518 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:36,940 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:36,941 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/seperate_soma_meshes.pbz2\n",
      "File size is 1.095456 MB\n",
      "poisson_backtrack_distance_threshold = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-08 00:07:37,027 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,031 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,043 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,044 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,090 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,093 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,094 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,094 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,096 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-08 00:07:37,098 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7367 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_949084.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_949084_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_172519.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_949084.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_949084_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_172519.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.2357632380902634\n",
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/filtered_soma_list.pbz2\n",
      "File size is 4.561845 MB\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 7633 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35873.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35873_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_985089.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35873.off loaded has 27157 vn 49321 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_35873_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_985089.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1243620\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1243620\n",
      "LOG: 2 Successfully removed 1404 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 1404 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1226772\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_985089.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 4797 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7504.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7504_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_223268.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7504.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_7504_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_223268.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(6251, 3), faces.shape=(8626, 3))>, <trimesh.Trimesh(vertices.shape=(1053, 3), faces.shape=(1268, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ec0ea9b6ab42ecb7ee2f5cd440053c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=577.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timed out when trying to find the cycles!\n",
      "Finding the cycles did not work when doing the border vertex edge so using connected components\n",
      "Largest hole before segmentation = 5772240.714952491, after = 8131761.585747708,\n",
      "ratio = 1.4087703523318218, difference = 2359520.8707952164\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 3705 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_21044.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_21044_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_509230.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_21044.off loaded has 19325 vn 34284 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_21044_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_509230.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 875208\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 875208\n",
      "LOG: 2 Successfully removed 627 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 627 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 867684\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_509230.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 3900 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48104.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48104_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_854175.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48104.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_48104_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_854175.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5895, 3), faces.shape=(7617, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d501b0434fa14f34acb58367b550d159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timed out when trying to find the cycles!\n",
      "Finding the cycles did not work when doing the border vertex edge so using connected components\n",
      "Largest hole before segmentation = 3211000.817906505, after = 2903069.6986418907,\n",
      "ratio = 0.9041012018597435, difference = -307931.1192646143\n"
     ]
    }
   ],
   "source": [
    "# Trying the function as a whole\n",
    "somas = sm.extract_soma_center(segment_id,\n",
    "                            current_mesh_verts=current_neuron.vertices,\n",
    "                            current_mesh_faces=current_neuron.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<trimesh.Trimesh(vertices.shape=(21811, 3), faces.shape=(39427, 3))>,\n",
       "  <trimesh.Trimesh(vertices.shape=(14107, 3), faces.shape=(26667, 3))>],\n",
       " 199.69117665290833,\n",
       " array([0.8133025, 0.767351 ]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(current_neuron,\n",
    "                 meshes=somas[0],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function that is unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 5964 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41657.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41657_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_716578.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41657.off loaded has 627859 vn 1334901 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_41657_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_716578.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 31087428\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 31087428\n",
      "LOG: 2 Successfully removed 69602 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 69602 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 30252204\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_716578.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 9014 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_45472.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_45472_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_287140.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_45472.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_45472_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_287140.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2565: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(60983, 3), faces.shape=(163013, 3))>, <trimesh.Trimesh(vertices.shape=(37395, 3), faces.shape=(96155, 3))>]\n",
      "xvfb-run -n 8645 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25657112.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 22:58:38,455 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,554 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,627 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,798 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,800 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,971 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,975 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,988 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:38,989 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,035 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,036 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,038 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,038 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,040 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,042 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,051 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,069 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,271 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,275 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,421 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,436 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,456 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,478 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,487 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,506 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,507 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,509 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,530 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,531 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,544 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,552 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,565 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,605 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,639 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,665 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,666 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,670 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,674 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,677 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,682 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,682 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 22:58:39,704 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(68324, 3), faces.shape=(133613, 3))>, <trimesh.Trimesh(vertices.shape=(60830, 3), faces.shape=(118541, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(68324, 3), faces.shape=(133613, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3595 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65208.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65208_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_102087.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65208.off loaded has 68324 vn 133613 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_65208_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_102087.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 3243132\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 3243132\n",
      "LOG: 2 Successfully removed 790 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 790 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 3233652\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_102087.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 3421 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40626.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40626_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_564599.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40626.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_40626_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_564599.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 145\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off\n",
      "xvfb-run -n 8731 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/poisson_590891.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(23843, 3), faces.shape=(47682, 3))>, <trimesh.Trimesh(vertices.shape=(1744, 3), faces.shape=(3484, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(23843, 3), faces.shape=(47682, 3))>\n",
      "xvfb-run -n 2175 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25864999.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(5961, 3), faces.shape=(11918, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0011255741119384766\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591400_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.9973597526550293\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.2091209888458252\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00413060188293457\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00018858909606933594\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.009354352951049805\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.05564737319946289\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.115384\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 2,  8,  1,  0, 14, 15,  6,  5, 17, 11,  3, 10,  4,  7, 13,  9, 16,\n",
      "       12]), array([0.8133025 , 0.1246295 , 0.115384  , 0.1112635 , 0.0978866 ,\n",
      "       0.0956922 , 0.0830078 , 0.0572021 , 0.0509989 , 0.0472632 ,\n",
      "       0.045175  , 0.0444408 , 0.0429886 , 0.0375067 , 0.03397915,\n",
      "       0.0292611 , 0.0208762 , 0.0160651 ]))\n",
      "Sizes = [2624, 106, 4161, 378, 215, 126, 75, 221, 1531, 345, 325, 273, 876, 43, 332, 225, 25, 37]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width = [2]\n",
      "      ------ Found 1 viable somas: [2]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4562 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_268060.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_268060_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_41044.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_268060.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_268060_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_41044.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.9300985008950597\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1744, 3), faces.shape=(3484, 3))>\n",
      "xvfb-run -n 2462 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25864999.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(437, 3), faces.shape=(870, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002186298370361328\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591401_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.0404505729675293\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.05577564239501953\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00037217140197753906\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.506111145019531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0007734298706054688\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.0039103031158447266\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 2]), array([0.573573, 0.310102, 0.237792]))\n",
      "Sizes = [288, 505, 77]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width = []\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(60830, 3), faces.shape=(118541, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 6387 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75125.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75125_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_853128.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75125.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_75125_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_853128.mls is being deleted....\n",
      "xvfb-run -n 2629 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99395.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99395_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_219545.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99395.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_99395_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_219545.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 492\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off\n",
      "xvfb-run -n 5391 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/poisson_590891.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(16729, 3), faces.shape=(33458, 3))>, <trimesh.Trimesh(vertices.shape=(1887, 3), faces.shape=(3770, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(16729, 3), faces.shape=(33458, 3))>\n",
      "xvfb-run -n 9572 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25864999.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(4180, 3), faces.shape=(8360, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007064342498779297\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591410_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.6747288703918457\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.8312637805938721\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 0\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002927541732788086\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.1961669921875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007232666015625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.04111886024475098\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.620533\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 7, 1, 4, 5, 2, 3, 6]), array([0.620533  , 0.09013405, 0.0581121 , 0.0503794 , 0.0456572 ,\n",
      "       0.0405575 , 0.0375307 , 0.0269427 ]))\n",
      "Sizes = [3427, 104, 3806, 83, 113, 397, 233, 197]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width = [0]\n",
      "      ------ Found 1 viable somas: [0]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4276 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_828196.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_828196_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_526053.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_828196.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_828196_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_526053.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 12.512593186682402\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(1720, 3), faces.shape=(3427, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/239_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c9f4c2c17544a2adae0887732d5057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6354 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_146741.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_146741_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_112833.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1213: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_146741.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_146741_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_112833.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 4.301321749165639\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(1887, 3), faces.shape=(3770, 3))>\n",
      "xvfb-run -n 9644 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/864691134988385914/decimation_meshlab_25864999.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691134988385914_decimated_largest_piece_poisson_largest_inner.off\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(473, 3), faces.shape=(942, 3))>\n",
      "\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022530555725097656\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/86469113498838591411_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.047190189361572266\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.06381559371948242\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0004677772521972656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.649162292480469e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0008502006530761719\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.004301309585571289\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([1, 0, 4, 2, 3]), array([0.6684745, 0.453435 , 0.354481 , 0.349022 , 0.305695 ]))\n",
      "Sizes = [254, 337, 53, 101, 197]\n",
      "soma_size_threshold = 562.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width = []\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 188.10708332061768\n",
      "Before Filtering the number of somas found = 2\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 23:00:08,481 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 339\n",
      "viable_meshes = [0]\n",
      "There were 335 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1338, 3), faces.shape=(2624, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(531829, 3), faces.shape=(1053162, 3))>\n",
      "\n",
      "inside Soma subtraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 23:00:13,103 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,104 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,204 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,208 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,220 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,221 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,263 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,265 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,266 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,267 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,269 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,271 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,385 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,386 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,396 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,416 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,434 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,435 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,438 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,450 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,451 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,461 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,478 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,501 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,501 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,506 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,510 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,513 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,514 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:13,534 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for soma mesh cancellation = 2.638\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(256449, 3), faces.shape=(509469, 3))>, <trimesh.Trimesh(vertices.shape=(121859, 3), faces.shape=(242930, 3))>, <trimesh.Trimesh(vertices.shape=(76442, 3), faces.shape=(152185, 3))>, <trimesh.Trimesh(vertices.shape=(25234, 3), faces.shape=(50922, 3))>, <trimesh.Trimesh(vertices.shape=(16271, 3), faces.shape=(32482, 3))>, <trimesh.Trimesh(vertices.shape=(1727, 3), faces.shape=(3423, 3))>, <trimesh.Trimesh(vertices.shape=(1543, 3), faces.shape=(3071, 3))>, <trimesh.Trimesh(vertices.shape=(992, 3), faces.shape=(1938, 3))>, <trimesh.Trimesh(vertices.shape=(475, 3), faces.shape=(922, 3))>, <trimesh.Trimesh(vertices.shape=(448, 3), faces.shape=(814, 3))>, <trimesh.Trimesh(vertices.shape=(244, 3), faces.shape=(294, 3))>]\n",
      "Total time for Subtract Soam = 2.639545440673828\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.8147158622741699\n",
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/seperate_soma_meshes.pbz2\n",
      "File size is 1.400915 MB\n",
      "poisson_backtrack_distance_threshold = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 23:00:15,465 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:15,685 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:15,712 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:15,761 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6617 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_304403.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_304403_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_56131.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_304403.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_304403_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_56131.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.311284291902997\n",
      "Performing Soma Mesh Backtracking to original mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 23:00:33,854 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# total split meshes = 339\n",
      "viable_meshes = [0]\n",
      "There were 335 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1324, 3), faces.shape=(2617, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(531829, 3), faces.shape=(1053162, 3))>\n",
      "\n",
      "inside Soma subtraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 23:00:37,584 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,818 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,819 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,824 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,919 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,920 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,933 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,955 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,964 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,982 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,983 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:37,985 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,005 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,006 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,018 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,027 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,080 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,105 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,106 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,110 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,114 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,117 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,121 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,122 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:38,700 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for soma mesh cancellation = 2.766\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(267249, 3), faces.shape=(530994, 3))>, <trimesh.Trimesh(vertices.shape=(160214, 3), faces.shape=(319106, 3))>, <trimesh.Trimesh(vertices.shape=(58758, 3), faces.shape=(117213, 3))>, <trimesh.Trimesh(vertices.shape=(12441, 3), faces.shape=(24738, 3))>, <trimesh.Trimesh(vertices.shape=(4779, 3), faces.shape=(9401, 3))>, <trimesh.Trimesh(vertices.shape=(3413, 3), faces.shape=(6793, 3))>, <trimesh.Trimesh(vertices.shape=(525, 3), faces.shape=(1026, 3))>, <trimesh.Trimesh(vertices.shape=(446, 3), faces.shape=(803, 3))>, <trimesh.Trimesh(vertices.shape=(438, 3), faces.shape=(851, 3))>, <trimesh.Trimesh(vertices.shape=(316, 3), faces.shape=(517, 3))>]\n",
      "Total time for Subtract Soam = 2.766630172729492\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.7808723449707031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 23:00:39,987 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,409 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,411 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/seperate_soma_meshes.pbz2\n",
      "File size is 1.095456 MB\n",
      "poisson_backtrack_distance_threshold = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-01-07 23:00:40,489 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,492 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,505 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,506 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,548 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,550 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,551 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,552 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,554 - base - face_normals all zero, ignoring!\n",
      "WARNING - 2021-01-07 23:00:40,556 - base - face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1734 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_106338.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_106338_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_827568.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_106338.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/neuron_106338_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Poisson_temp/poisson_827568.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.2357632380902634\n",
      "Saved object at /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/filtered_soma_list.pbz2\n",
      "File size is 4.561845 MB\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 415 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93333.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93333_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_630846.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93333.off loaded has 27157 vn 49321 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_93333_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_630846.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1243620\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1243620\n",
      "LOG: 2 Successfully removed 1404 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 1404 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1226772\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_630846.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 5254 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8380.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8380_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_571187.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8380.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_8380_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_571187.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(6251, 3), faces.shape=(8626, 3))>, <trimesh.Trimesh(vertices.shape=(1053, 3), faces.shape=(1268, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1490d94713542438897e2590cbd1c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=577.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timed out when trying to find the cycles!\n",
      "Finding the cycles did not work when doing the border vertex edge so using connected components\n",
      "Largest hole before segmentation = 5772240.714952491, after = 8131761.585747708,\n",
      "ratio = 1.4087703523318218, difference = 2359520.8707952164\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 2792 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_79375.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_79375_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_934924.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_79375.off loaded has 19325 vn 34284 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_79375_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_934924.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 875208\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 875208\n",
      "LOG: 2 Successfully removed 627 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 627 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 867684\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/fill_holes_934924.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 1160 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73466.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73466_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_293786.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73466.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/neuron_73466_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/temp/remove_interior_293786.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(5895, 3), faces.shape=(7617, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a92e19045a476992c74368f0096e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timed out when trying to find the cycles!\n",
      "Finding the cycles did not work when doing the border vertex edge so using connected components\n",
      "Largest hole before segmentation = 3211000.817906505, after = 2903069.6986418907,\n",
      "ratio = 0.9041012018597435, difference = -307931.1192646143\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Done",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-50f81b068bcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_soma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiltered_soma_list_sdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Done"
     ]
    }
   ],
   "source": [
    "from soma_extraction_utils import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "segment_id = segment_id\n",
    "current_mesh_verts = current_neuron.vertices\n",
    "current_mesh_faces = current_neuron.faces\n",
    "current_mesh = None\n",
    "\n",
    "\n",
    "outer_decimation_ratio= 0.25\n",
    "large_mesh_threshold = 20000#60000,\n",
    "large_mesh_threshold_inner = 13000 #was changed so dont filter away som somas\n",
    "soma_width_threshold = 0.32\n",
    "soma_size_threshold = 9000 #changed this to smaller so didn't filter some somas away\n",
    "inner_decimation_ratio = 0.25\n",
    "volume_mulitplier=8\n",
    "#side_length_ratio_threshold=3\n",
    "side_length_ratio_threshold=6\n",
    "soma_size_threshold_max=192000 #this puts at 12000 once decimated, another possible is 256000\n",
    "delete_files=True\n",
    "backtrack_soma_mesh_to_original=True #should either be None or \n",
    "boundary_vertices_threshold=None#700 the previous threshold used\n",
    "poisson_backtrack_distance_threshold=None#1500 the previous threshold used\n",
    "close_holes=False\n",
    "\n",
    "#------- 11/12 Additions --------------- #\n",
    "\n",
    "#these arguments are for removing inside pieces\n",
    "remove_inside_pieces = True\n",
    "size_threshold_to_remove=1000 #size accounting for the decimation\n",
    "\n",
    "\n",
    "pymeshfix_clean=False\n",
    "check_holes_before_pymeshfix=False\n",
    "second_poisson=False\n",
    "segmentation_at_end=True\n",
    "last_size_threshold = 2000#1300,\n",
    "\n",
    "largest_hole_threshold = 17000\n",
    "max_fail_loops = np.inf\n",
    "perform_pairing = False\n",
    "\n",
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "#Adjusting the thresholds based on the decimations\n",
    "large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "\n",
    "#adjusting for inner decimation\n",
    "soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "             f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "              f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "             f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "             f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "             f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "temp_folder = f\"./{segment_id}\"\n",
    "temp_object = Path(temp_folder)\n",
    "#make the temp folder if it doesn't exist\n",
    "temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#making the decimation and poisson objections\n",
    "Dec_outer = meshlab.Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "Dec_inner = meshlab.Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "Poisson_obj = meshlab.Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "\n",
    "recov_orig_mesh = trimesh.Trimesh(vertices=current_mesh_verts,faces=current_mesh_faces)\n",
    "recov_orig_mesh_no_interior = tu.remove_mesh_interior(recov_orig_mesh)\n",
    "\n",
    "\n",
    "#Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "new_mesh,output_obj = Dec_outer(vertices=recov_orig_mesh_no_interior.vertices,\n",
    "         faces=recov_orig_mesh_no_interior.faces,\n",
    "         segment_id=segment_id,\n",
    "         return_mesh=True,\n",
    "         delete_temp_files=False)\n",
    "\n",
    "# if remove_inside_pieces:\n",
    "#     print(\"removing mesh interior after decimation\")\n",
    "#     new_mesh = tu.remove_mesh_interior(new_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "#preforming the splits of the decimated mesh\n",
    "\n",
    "mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "#if no significant pieces were found then will use smaller threshold\n",
    "if len(list_of_largest_mesh)<=0:\n",
    "    print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "    list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "total_soma_list = []\n",
    "total_classifier_list = []\n",
    "total_poisson_list = []\n",
    "total_soma_list_sdf = []\n",
    "\n",
    "\n",
    "\n",
    "#start iterating through where go through all pieces before the poisson reconstruction\n",
    "no_somas_found_in_big_loop = 0\n",
    "for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "    print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "    if remove_inside_pieces:\n",
    "        print(\"remove_inside_pieces requested \")\n",
    "        largest_mesh = tu.remove_mesh_interior(largest_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "\n",
    "    if pymeshfix_clean:\n",
    "        print(\"Requested pymeshfix_clean\")\n",
    "        \"\"\"\n",
    "        Don't have to check if manifold anymore actually just have to plug the holes\n",
    "        \"\"\"\n",
    "        hole_groups = tu.find_border_face_groups(largest_mesh)\n",
    "        if len(hole_groups) > 0:\n",
    "            largest_mesh_filled_holes = tu.fill_holes(largest_mesh,max_hole_size = 10000)\n",
    "        else:\n",
    "            largest_mesh_filled_holes = largest_mesh\n",
    "\n",
    "        if check_holes_before_pymeshfix:\n",
    "            hole_groups = tu.find_border_face_groups(largest_mesh_filled_holes)\n",
    "        else:\n",
    "            print(\"Not checking if there are still existing holes before pymeshfix\")\n",
    "            hole_groups = []\n",
    "\n",
    "        if len(hole_groups) > 0:\n",
    "            #segmentation_at_end = False\n",
    "            print(f\"*** COULD NOT FILL HOLES WITH MAX SIZE OF {np.max([len(k) for k in hole_groups])} so not applying pymeshfix and segmentation_at_end = {segmentation_at_end}\")\n",
    "\n",
    "#                 tu.write_neuron_off(largest_mesh_filled_holes,\"largest_mesh_filled_holes\")\n",
    "#                 raise Exception()\n",
    "        else:\n",
    "            print(\"Applying pymeshfix_clean because no more holes\")\n",
    "            largest_mesh = tu.pymeshfix_clean(largest_mesh_filled_holes,verbose=True)\n",
    "\n",
    "    if second_poisson:\n",
    "        print(\"Applying second poisson run\")\n",
    "        current_neuron_poisson = tu.poisson_surface_reconstruction(largest_mesh)\n",
    "        largest_mesh = tu.split_significant_pieces(current_neuron_poisson)[0]\n",
    "\n",
    "    somas_found_in_big_loop = False\n",
    "\n",
    "    largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "    pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "    pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "    print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "    # ******* This ERRORED AND CALLED OUR NERUON NONE: 77697401493989254 *********\n",
    "    new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "               faces=largest_mesh.faces,\n",
    "               return_mesh=True,\n",
    "               mesh_filename=largest_file_name,\n",
    "               delete_temp_files=False)\n",
    "\n",
    "\n",
    "    #splitting the Poisson into the largest pieces and ordering them\n",
    "    mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "    list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "    print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "    n_failed_inner_soma_loops = 0\n",
    "    for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "        to_add_list = []\n",
    "        to_add_list_sdf = []\n",
    "\n",
    "        print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "        largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "        #Decimate the inner poisson piece\n",
    "        largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                            vertices=largest_mesh_inner.vertices,\n",
    "                             faces=largest_mesh_inner.faces,\n",
    "                            mesh_filename=largest_mesh_path_inner,\n",
    "                             return_mesh=True,\n",
    "                             delete_temp_files=False)\n",
    "\n",
    "        dec_splits = tu.split_significant_pieces(largest_mesh_path_inner_decimated,significance_threshold=15)\n",
    "        print(f\"\\n-------Splits after inner decimation len = {len(dec_splits)}--------\\n\")\n",
    "\n",
    "        if len(dec_splits) == 0:\n",
    "            n_failed_inner_soma_loops += 1\n",
    "            print(f\"There were no signifcant splits after inner decimation so incrementing n_failed_inner_soma_loops to {n_failed_inner_soma_loops}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "            largest_mesh_path_inner_decimated_clean = dec_splits[0]\n",
    "            print(f\"largest_mesh_path_inner_decimated_clean = {largest_mesh_path_inner_decimated_clean}\\n\")\n",
    "\n",
    "            faces = np.array(largest_mesh_path_inner_decimated_clean.faces)\n",
    "            verts = np.array(largest_mesh_path_inner_decimated_clean.vertices)\n",
    "\n",
    "            # may need to do some processing\n",
    "\n",
    "\n",
    "            segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "            #print(f\"Before the classifier the pymeshfix_clean = {pymeshfix_clean}\")\n",
    "            verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                    import_Off_Flag=False,\n",
    "                                    segment_id=segment_id_new,\n",
    "                                    vertices=verts,\n",
    "                                     triangles=faces,\n",
    "                                    pymeshfix_Flag=False,\n",
    "                                     import_CGAL_Flag=False,\n",
    "                                     return_Only_Labels=True,\n",
    "                                     clusters=3,\n",
    "                                     smoothness=0.2,\n",
    "                                    soma_only=True,\n",
    "                                    return_classifier = True\n",
    "                                    )\n",
    "            print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "            total_classifier_list.append(classifier)\n",
    "            #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "            # Save all of the portions that resemble a soma\n",
    "            median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "            segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "            #order the compartments by greatest to smallest\n",
    "            sorted_medians = np.flip(np.argsort(median_values))\n",
    "            print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "            print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "            print(f\"soma_size_threshold = {soma_size_threshold}\")\n",
    "            print(f\"soma_size_threshold_max={soma_size_threshold_max}\")\n",
    "\n",
    "            valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "            valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "            print(f\"valid_soma_segments_width = {valid_soma_segments_width}\")\n",
    "\n",
    "            if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated_clean.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "                    \n",
    "                    \n",
    "                    if curr_side_len_check and curr_volume_check:\n",
    "                        to_add_list.append(soma_mesh)\n",
    "                        to_add_list_sdf.append(sdf)\n",
    "\n",
    "                    else:\n",
    "                        # ---------- 1/7 Addition: Trying one more additional cgal segmentation to see if there is actually a soma ---\n",
    "                        \"\"\"\n",
    "                        Pseudocode: \n",
    "                        1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        2) Filter out meshes by sizs and sdf threshold\n",
    "                        3) If there are any remaining meshes, pick the largest sdf mesh and test for volume and side length check\n",
    "                        --> if matches then adds\n",
    "                        \"\"\"\n",
    "                        \n",
    "                        print(f\"->Attempting retry of soma because failed first checks: \"\n",
    "                                 f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                        \n",
    "                        #1) Run th esegmentation algorithm again to segment the mesh\n",
    "                        mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "                        mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "                        #2) Filter out meshes by sizs and sdf threshold\n",
    "                        mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "                        filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "                        if len(filtered_meshes_idx) > 0:\n",
    "                            filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "                            filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "\n",
    "                            sdf_winning_index = np.argmax(filtered_meshes_sdf)\n",
    "                            soma_mesh_retry = filtered_meshes[sdf_winning_index]\n",
    "                            sdf_retry = filtered_meshes_sdf[sdf_winning_index]\n",
    "\n",
    "                            curr_side_len_check_retry = side_length_check(soma_mesh_retry,side_length_ratio_threshold)\n",
    "                            curr_volume_check_retry = soma_volume_check(soma_mesh_retry,volume_mulitplier)\n",
    "\n",
    "                            if curr_side_len_check_retry and curr_volume_check_retry:\n",
    "                                to_add_list.append(soma_mesh_retry)\n",
    "                                to_add_list_sdf.append(sdf_retry)\n",
    "                            else:\n",
    "                                print(f\"--->This soma mesh was not added because failed retry of sphere validation:\\n \"\n",
    "                                     f\"soma_mesh = {soma_mesh_retry}, curr_side_len_check = {curr_side_len_check_retry}, curr_volume_check = {curr_volume_check_retry}\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(f\"Could not find valid soma mesh in retry\")\n",
    "                            continue\n",
    "\n",
    "                n_failed_inner_soma_loops = 0\n",
    "\n",
    "            else:\n",
    "                n_failed_inner_soma_loops += 1\n",
    "\n",
    "        total_soma_list_sdf += to_add_list_sdf\n",
    "        total_soma_list += to_add_list\n",
    "\n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if n_failed_inner_soma_loops >= max_fail_loops:\n",
    "            print(\"breaking inner loop because 2 soma fails in a row\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "    if somas_found_in_big_loop == False:\n",
    "        no_somas_found_in_big_loop += 1\n",
    "        if no_somas_found_in_big_loop >= max_fail_loops:\n",
    "            print(\"breaking because 2 fails in a row in big loop\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        no_somas_found_in_big_loop = 0\n",
    "\n",
    "        \n",
    "\"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "pairings = []\n",
    "\n",
    "if perform_pairing:\n",
    "    for y,soma_1 in enumerate(total_soma_list):\n",
    "        for z,soma_2 in enumerate(total_soma_list):\n",
    "            if y<z:\n",
    "                mesh_tree = KDTree(soma_1.vertices)\n",
    "                distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "                if np.min(distances) < 4000:\n",
    "                    pairings.append([y,z])\n",
    "\n",
    "\n",
    "#creating the combined meshes from the list\n",
    "total_soma_list_revised = []\n",
    "total_soma_list_revised_sdf = []\n",
    "if len(pairings) > 0:\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    Use a network function to find components\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    new_graph = nx.Graph()\n",
    "    new_graph.add_edges_from(pairings)\n",
    "    grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "    somas_being_combined = []\n",
    "    print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "    for comp in grouped_somas:\n",
    "        comp = list(comp)\n",
    "        somas_being_combined += list(comp)\n",
    "        current_mesh = total_soma_list[comp[0]]\n",
    "        for i in range(1,len(comp)):\n",
    "            current_mesh += total_soma_list[comp[i]] #just combining the actual meshes\n",
    "\n",
    "        total_soma_list_revised.append(current_mesh)\n",
    "        #where can average all of the sdf values\n",
    "        total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "    #add those that weren't combined to total_soma_list_revised\n",
    "    leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    if len(leftover_somas) > 0:\n",
    "        total_soma_list_revised += leftover_somas\n",
    "        total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "    print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "    print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "if len(total_soma_list_revised) == 0:\n",
    "    total_soma_list_revised = total_soma_list\n",
    "    total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "run_time = time.time() - global_start_time\n",
    "\n",
    "print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "#     import system_utils as su\n",
    "#     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "#     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "#need to erase all of the temporary files ******\n",
    "#import shutil\n",
    "#shutil.rmtree(directory)\n",
    "\n",
    "\"\"\"\n",
    "Running the extra tests that depend on\n",
    "- border vertices\n",
    "- how well the poisson matches the backtracked soma to the real mesh\n",
    "- other size checks\n",
    "\n",
    "\"\"\"\n",
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "for soma_mesh,curr_soma_sdf in zip(total_soma_list_revised,total_soma_list_revised_sdf):\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        print(\"Performing Soma Mesh Backtracking to original mesh\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "        try:\n",
    "            #print(\"About to find original mesh\")\n",
    "            soma_mesh = original_mesh_soma(\n",
    "                                            mesh = recov_orig_mesh_no_interior,\n",
    "                                            soma_meshes=[soma_mesh_poisson],\n",
    "                                            sig_th_initial_split=15)[0]\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "        else:\n",
    "            if soma_mesh is None:\n",
    "                print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "        #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "        if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "            #soma_mesh.export(\"soma_mesh.off\")\n",
    "            if close_holes: \n",
    "                print(\"Using the close holes feature\")\n",
    "                fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                 self_itersect_faces=False)\n",
    "\n",
    "                soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                    vertices=soma_mesh.vertices,\n",
    "                                                     faces=soma_mesh.faces,\n",
    "                                                     return_mesh=True,\n",
    "                                                     delete_temp_files=True,\n",
    "                                                    )\n",
    "            else:\n",
    "                soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "            #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "            print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "            mesh_1 = soma_mesh_filled_holes\n",
    "            mesh_2 = soma_mesh_poisson\n",
    "\n",
    "            poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                              verbose=True)\n",
    "            print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "            if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                  f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                continue\n",
    "\n",
    "    if len(soma_mesh.faces) < 5:\n",
    "        print(f\"--> soma had very few faces ({soma_mesh}) so continuing\")\n",
    "        continue\n",
    "\n",
    "    #do the boundary check:\n",
    "    if not boundary_vertices_threshold is None:\n",
    "        print(\"USING boundary_vertices_threshold CHECK\")\n",
    "        soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "        print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "        large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "        print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "        if len(large_boundary_groups)>0:\n",
    "            print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                  f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "            continue\n",
    "\n",
    "    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "    if (not curr_side_len_check) or (not curr_volume_check):\n",
    "        print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "             f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "        continue\n",
    "\n",
    "    #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "    #If made it through all the checks then add to final list\n",
    "    filtered_soma_list.append(soma_mesh)\n",
    "    filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Need to delete all files in the temp folder *****\n",
    "\"\"\"\n",
    "\n",
    "if delete_files:\n",
    "    #now erase all of the files used\n",
    "    from shutil import rmtree\n",
    "\n",
    "    #remove the directory with the meshes\n",
    "    rmtree(str(temp_object.absolute()))\n",
    "\n",
    "    #removing the temporary files\n",
    "    temp_folder = Path(\"./temp\")\n",
    "    temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "    seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "    for f in seg_temp_files:\n",
    "        f.unlink()\n",
    "\n",
    "# ----------- 11 /11 Addition that does a last step segmentation of the soma --------- #\n",
    "#return total_soma_list, run_time\n",
    "#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n",
    "\"\"\"\n",
    "Things we should ask about the segmentation:\n",
    "\n",
    "Advantages: \n",
    "1) could help filter away negatives\n",
    "\n",
    "Disadvantages:\n",
    "1) Can actually cut up the soma and then filter away the soma (not what we want)\n",
    "2) Could introduce a big hole (don't think can guard against this)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#filtered_soma_list_saved = copy.deepcopy(filtered_soma_list)\n",
    "import system_utils as su\n",
    "su.compressed_pickle(filtered_soma_list,\"filtered_soma_list\")\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "\n",
    "        print(\"Skipping the segmentatio filter at end\")\n",
    "        if not (len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold):\n",
    "            print(f\"Soma (size = {len(f_soma.faces)}, width={soma_width_threshold}) did not pass thresholds (size threshold={last_size_threshold}, width threshold = {soma_width_threshold}) \")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if segmentation_at_end:\n",
    "\n",
    "\n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "#                 print(f\"meshes_split = {meshes_split}\")\n",
    "#                 print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                print(f\"So just going with old somas\")\n",
    "\n",
    "                f_soma_final = f_soma\n",
    "                f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "            else:\n",
    "                meshes_split = np.array(meshes_split)\n",
    "                meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "                meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "                meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "                soma_width_threshold\n",
    "                #way to choose the index of the top candidate\n",
    "                top_candidate = 0\n",
    "\n",
    "\n",
    "                largest_hole_before_seg = tu.largest_hole_length(f_soma)\n",
    "                largest_hole_after_seg = tu.largest_hole_length(meshes_split_filtered[top_candidate])\n",
    "\n",
    "                print(f\"Largest hole before segmentation = {largest_hole_before_seg}, after = {largest_hole_after_seg},\"\n",
    "                      f\"\\nratio = {largest_hole_after_seg/largest_hole_before_seg}, difference = {largest_hole_after_seg - largest_hole_before_seg}\")\n",
    "\n",
    "                if largest_hole_after_seg < largest_hole_threshold:\n",
    "                    f_soma_final = meshes_split_filtered[top_candidate]\n",
    "                    f_soma_sdf_final = meshes_split_sdf_filtered[top_candidate]\n",
    "                else:\n",
    "                    f_soma_final = f_soma\n",
    "                    f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "        else:\n",
    "            f_soma_final = f_soma\n",
    "            f_soma_sdf_final = f_soma_sdf\n",
    "\n",
    "\n",
    "        filtered_soma_list_revised.append(f_soma_final)\n",
    "        filtered_soma_list_sdf_revised.append(f_soma_sdf_final)\n",
    "\n",
    "\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n",
    "    \n",
    "\"\"\"\n",
    "# ----------- 1/7/21 ---------------#\n",
    "Now was to stitch the somas together if they are touching\n",
    "\n",
    "\"\"\"\n",
    "connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                         main_mesh=recov_orig_mesh,\n",
    "                                            return_connected_components=True)\n",
    "\n",
    "filtered_soma_list_components = [tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components]\n",
    "filtered_soma_list_sdf_components = [np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components]\n",
    "\n",
    "               \n",
    "\n",
    "return_value = list(filtered_soma_list),run_time,filtered_soma_list_sdf \n",
    "raise Exception(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ----------- 1/7/21 ---------------#\n",
    "Now was to stitch the somas together if they are touching\n",
    "\n",
    "\"\"\"\n",
    "connected_meshes_components = tu.mesh_list_connectivity(meshes=filtered_soma_list,\n",
    "                         main_mesh=recov_orig_mesh,\n",
    "                                            return_connected_components=True)\n",
    "\n",
    "filtered_soma_list_components = [tu.combine_meshes(filtered_soma_list[k]) for k in connected_meshes_components]\n",
    "filtered_soma_list_sdf_components = [np.mean(filtered_soma_list_sdf[k]) for k in connected_meshes_components]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<trimesh.Trimesh(vertices.shape=(21811, 3), faces.shape=(39427, 3))>,\n",
       " <trimesh.Trimesh(vertices.shape=(14107, 3), faces.shape=(26667, 3))>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_soma_list_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8133025, 0.767351 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_soma_list_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f9ffe377bf4f1ab5b76ef06f068a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list,\n",
    "                  meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soma_mesh = original_mesh_soma(\n",
    "                                            mesh = recov_orig_mesh_no_interior,\n",
    "                                            soma_meshes=[soma_mesh_poisson],\n",
    "                                            sig_th_initial_split=15)[0]\n",
    "soma_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_soma_meshes = su.decompress_pickle(\"seperate_soma_meshes\")\n",
    "nviz.plot_objects(meshes=seperate_soma_meshes,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list_saved = su.decompress_pickle(\"filtered_soma_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=total_soma_list_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(current_neuron,\n",
    "                #meshes=[return_value[0][0]],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_extra, mesh_extra_sdf = tu.mesh_segmentation(soma_mesh,clusters=3,smoothness=0.2,verbose=True)\n",
    "mesh_extra = np.array(mesh_extra)\n",
    "\n",
    "\n",
    "mesh_extra_lens = np.array([len(kk.faces) for kk in mesh_extra])\n",
    "filtered_meshes_idx = np.where((mesh_extra_lens >= soma_size_threshold) & (mesh_extra_lens <= soma_size_threshold_max) & (mesh_extra_sdf>soma_width_threshold))[0]\n",
    "\n",
    "if len(filtered_meshes_idx) > 0:\n",
    "    filtered_meshes = mesh_extra[filtered_meshes_idx]\n",
    "    filtered_meshes_sdf = mesh_extra_sdf[filtered_meshes_idx]\n",
    "    \n",
    "    soma_mesh_retry = filtered_meshes[np.argmax(filtered_meshes_sdf)]\n",
    "\n",
    "nviz.plot_objects(soma_mesh_retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_size_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(mesh_extra[0],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "tu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(largest_mesh_path_inner_decimated_clean,\n",
    "                 meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mesh_threshold_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh_inner[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=[k for k in ordered_mesh_splits_inner if len(k.faces)>800],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=dec_splits,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(list_of_largest_mesh[1],\n",
    "                  meshes=[soma_mesh],\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_largest_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh,\n",
    "                 meshes_colors=[\"red\",\"black\"],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=list_of_largest_mesh_inner,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_soma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_objects(main_mesh=current_neuron,\n",
    "                 meshes=filtered_soma_list,\n",
    "                 meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n",
    "                                                 current_neuron.vertices,\n",
    "                                                 current_neuron.faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
