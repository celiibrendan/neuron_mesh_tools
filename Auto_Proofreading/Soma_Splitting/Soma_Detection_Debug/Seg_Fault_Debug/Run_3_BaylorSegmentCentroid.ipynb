{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: Run the Soma Finding\\nAlgorithm for all the cells\\nin our final match\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: Run the Soma Finding\n",
    "Algorithm for all the cells\n",
    "in our final match\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_version = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-15 04:04:33,661 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-15 04:04:33,662 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-15 04:04:33,663 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-15 04:04:33,667 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-01-15 04:04:33,668 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-01-15 04:04:33,679 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-15 04:04:33,947 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-15 04:04:33,970 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-01-15 04:04:33,972 - settings - Setting database.user to celiib\n",
      "INFO - 2021-01-15 04:04:33,973 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-01-15 04:04:33,974 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 135 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-15 04:04:34,248 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the list of neurons to decompose for the mutli soma testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# soma_soma_table = pd.read_csv(\"Minnie65 core proofreading - Soma-Soma.csv\")\n",
    "# no_header = soma_soma_table.iloc[1:]\n",
    "# multi_soma_ids_str = no_header[\"Dendrites\"].to_numpy()\n",
    "# multi_soma_ids = multi_soma_ids_str[~np.isnan(multi_soma_ids_str.astype(\"float\"))].astype(\"int\")\n",
    "\n",
    "# @schema\n",
    "# class MultiSomaProofread(dj.Manual):\n",
    "#     definition=\"\"\"\n",
    "#     segment_id : bigint unsigned  #segment id for those to be decimated\n",
    "#     \"\"\"\n",
    "    \n",
    "# dict_of_seg = [dict(segment_id=k) for k in multi_soma_ids]\n",
    "# minnie.MultiSomaProofread.insert(dict_of_seg,skip_duplicates=True)\n",
    "# MultiSomaProofread()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "import neuron\n",
    "import trimesh_utils as tu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 7394\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)\n",
    "temporary_folder = 'decimation_temp'\n",
    "meshlab_scripts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class NeuronGliaNuclei(dj.Manual):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decimation.proj(decimation_version='version')\n",
    "    ver : decimal(6,2) #the version number of the materializaiton\n",
    "    ---\n",
    "    n_glia_faces              : int unsigned                 # The number of faces that were saved off as belonging to glia\n",
    "    glia_faces=NULL           : <faces>                      # faces indices that were saved off as belonging to glia (external storage)\n",
    "    n_nuclei_faces            : int unsigned                 # The number of faces that were saved off as belonging to nuclie\n",
    "    nuclei_faces=NULL         : <faces>                      # faces indices that were saved off as belonging to nuclei (external storage)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema.external['faces'].delete(delete_external_files=True)\n",
    "# schema.external['somas'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minnie.BaylorSegmentCentroid.delete()\n",
    "# minnie.NeuronGliaNuclei().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decimation_version = 0\n",
    "# decimation_ratio = 0.25\n",
    "# verts_min = 10000\n",
    "\n",
    "\n",
    "# key_source =  ((minnie.Decimation & f\"n_vertices > {verts_min}\").proj(decimation_version='version') & \n",
    "#                         \"decimation_version=\" + str(decimation_version) &\n",
    "#                    f\"decimation_ratio={decimation_ratio}\") & (dj.U(\"segment_id\") & (minnie.OldBaylorSegmentCentroid() & \"multiplicity<3\").proj()\n",
    "#                                                              & (dj.U(\"segment_id\") & nucleus_table))\n",
    "# key_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimation_version = 0\n",
    "decimation_ratio = 0.25\n",
    "verts_min = 10000\n",
    "current_version = 30\n",
    "\n",
    "\n",
    "import trimesh_utils as tu\n",
    "import soma_extraction_utils as sm\n",
    "@schema\n",
    "class BaylorSegmentCentroid(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decimation.proj(decimation_version='version')\n",
    "    soma_index : tinyint unsigned #index given to this soma to account for multiple somas in one base semgnet\n",
    "    ver : decimal(6,2) #the version number of the materializaiton\n",
    "    ---\n",
    "    centroid_x=NULL           : int unsigned                 # (EM voxels)\n",
    "    centroid_y=NULL           : int unsigned                 # (EM voxels)\n",
    "    centroid_z=NULL           : int unsigned                 # (EM voxels)\n",
    "    n_vertices=NULL           : bigint                 #number of vertices\n",
    "    n_faces=NULL            : bigint                  #number of faces\n",
    "    mesh: <somas>  #datajoint adapter to get the somas mesh objects\n",
    "    multiplicity=NULL         : tinyint unsigned             # the number of somas found for this base segment\n",
    "    sdf=NULL                  : double                       # sdf width value for the soma\n",
    "    volume=NULL               : double                       # the volume in billions (10*9 nm^3) of the convex hull\n",
    "    max_side_ratio=NULL       : double                       # the maximum of the side length ratios used for check if soma\n",
    "    bbox_volume_ratio=NULL    : double                       # ratio of bbox (axis aligned) volume to mesh volume to use for check if soma\n",
    "    max_hole_length=NULL      : double                    #euclidean distance of the maximum hole size\n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    key_source =  (((minnie.Decimation & f\"n_vertices > {verts_min}\").proj(decimation_version='version') & \n",
    "                            \"decimation_version=\" + str(decimation_version) &\n",
    "                       f\"decimation_ratio={decimation_ratio}\") & (dj.U(\"segment_id\") & minnie.NucleiSegmentsRun2()) & dict(segment_id=864691135462241437))\n",
    "                                                                 \n",
    "     \n",
    "\n",
    "    def make(self,key):\n",
    "        \"\"\"\n",
    "        Pseudocode: \n",
    "        1) Compute all of the\n",
    "        2) Save the mesh as an h5 py file\n",
    "        3) Store the saved path as the decomposition part of the dictionary and erase the vertices and faces\n",
    "        4) Insert\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #get the mesh data\n",
    "        print(f\"\\n\\n\\n---- Working on Neuron {key['segment_id']} ----\")\n",
    "        print(key)\n",
    "        new_mesh = (minnie.Decimation() & key).fetch1(\"mesh\")\n",
    "        current_mesh_verts,current_mesh_faces = new_mesh.vertices,new_mesh.faces\n",
    "\n",
    "        segment_id = key[\"segment_id\"]\n",
    "\n",
    "        (total_soma_list, \n",
    "         run_time, \n",
    "         total_soma_list_sdf,\n",
    "         glia_pieces,\n",
    "         nuclei_pieces) = sm.extract_soma_center(\n",
    "                            segment_id,\n",
    "                            current_mesh_verts,\n",
    "                            current_mesh_faces,\n",
    "            return_glia_nuclei_pieces=True,\n",
    "        )\n",
    "        \n",
    "        # -------- 1/9 Addition: Going to save off the glia and nuclei pieces ----------- #\n",
    "        \"\"\"\n",
    "        Psuedocode:\n",
    "        For both glia and nuclie pieces\n",
    "        1) If the length of array is greater than 0 --> combine the mesh and map the indices to original mesh\n",
    "        2) If not then just put None     \n",
    "        \"\"\"\n",
    "        orig_mesh = trimesh.Trimesh(vertices=current_mesh_verts,\n",
    "                                   faces=current_mesh_faces)\n",
    "        \n",
    "        if len(glia_pieces)>0:\n",
    "            glia_faces = tu.original_mesh_faces_map(orig_mesh,tu.combine_meshes(glia_pieces))\n",
    "            n_glia_faces = len(glia_faces)\n",
    "        else:\n",
    "            glia_faces = None\n",
    "            n_glia_faces = 0\n",
    "            \n",
    "        if len(nuclei_pieces)>0:\n",
    "            nuclei_faces = tu.original_mesh_faces_map(orig_mesh,tu.combine_meshes(nuclei_pieces))\n",
    "            n_nuclei_faces = len(nuclei_faces)\n",
    "        else:\n",
    "            nuclei_faces = None\n",
    "            n_nuclei_faces = 0\n",
    "            \n",
    "        # --------- saving the nuclei and glia saves\n",
    "        glia_path,nuclei_path = du.save_glia_nuclei_files(glia_faces=glia_faces,\n",
    "                                 nuclei_faces=nuclei_faces,\n",
    "                                 segment_id=segment_id)\n",
    "        \n",
    "        print(f\" glia_path = {glia_path} \\n nuclei_path = {nuclei_path}\")\n",
    "            \n",
    "        glia_nuclei_key = dict(key,\n",
    "                               ver=current_version,\n",
    "                               n_glia_faces=n_glia_faces,\n",
    "                               #glia_faces = glia_faces,\n",
    "                               glia_faces = glia_path,\n",
    "                               n_nuclei_faces = n_nuclei_faces,\n",
    "                               #nuclei_faces = nuclei_faces\n",
    "                               nuclei_faces = nuclei_path,\n",
    "                              )\n",
    "        \n",
    "        NeuronGliaNuclei.insert1(glia_nuclei_key,replace=True)\n",
    "        print(f\"Finished saving off glia and nuclei information : {glia_nuclei_key}\")\n",
    "        \n",
    "        # ---------------- End of 1/9 Addition --------------------------------- #\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"Run time was {run_time} \\n    total_soma_list = {total_soma_list}\"\n",
    "             f\"\\n    with sdf values = {total_soma_list_sdf}\")\n",
    "        \n",
    "        #check if soma list is empty and did not find soma\n",
    "        if len(total_soma_list) <= 0:\n",
    "            print(\"There were no somas found for this mesh so just writing empty data\")\n",
    "            \n",
    "\n",
    "            returned_file_path = tu.write_h5_file(\n",
    "                                                vertices=np.array([]),\n",
    "                                                  faces=np.array([]),\n",
    "                                                  segment_id=segment_id,\n",
    "                                                  filename = f'{segment_id}_0.h5',\n",
    "                                                    filepath=str(du.get_somas_path())\n",
    "                                                 )\n",
    "\n",
    "            \n",
    "            \n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=0,\n",
    "                               ver=current_version,\n",
    "                              centroid_x=None,\n",
    "                               centroid_y=None,\n",
    "                               centroid_z=None,\n",
    "                               #distance_from_prediction=None,\n",
    "                               #prediction_matching_index = None,\n",
    "                               n_vertices=0,\n",
    "                               n_faces=0,\n",
    "                               mesh=returned_file_path,\n",
    "                               multiplicity=0,\n",
    "                               sdf = None,\n",
    "                               volume = None,\n",
    "                               max_side_ratio = None,\n",
    "                               bbox_volume_ratio = None,\n",
    "                               max_hole_length=None,\n",
    "                               run_time=run_time\n",
    "                              )\n",
    "            \n",
    "            #raise Exception(\"to prevent writing because none were found\")\n",
    "            self.insert1(insert_dict,skip_duplicates=True)\n",
    "            return\n",
    "        \n",
    "        #if there is one or more soma found, get the volume and side length checks\n",
    "        max_side_ratio =  [np.max(sm.side_length_ratios(m)) for m in total_soma_list]\n",
    "        bbox_volume_ratio =  [sm.soma_volume_ratio(m) for m in total_soma_list]\n",
    "        dicts_to_insert = []\n",
    "\n",
    "\n",
    "        for i,(current_soma,soma_sdf,sz_ratio,vol_ratio) in enumerate(zip(total_soma_list,total_soma_list_sdf,max_side_ratio,bbox_volume_ratio)):\n",
    "            print(\"Trying to write off file\")\n",
    "            \"\"\" Currently don't need to export the meshes\n",
    "            current_soma.export(f\"{key['segment_id']}/{key['segment_id']}_soma_{i}.off\")\n",
    "            \"\"\"\n",
    "            auto_prediction_center = np.mean(current_soma.vertices,axis=0) / np.array([4,4,40])\n",
    "            auto_prediction_center = auto_prediction_center.astype(\"int\")\n",
    "            print(f\"Predicted Coordinates are {auto_prediction_center}\")\n",
    "            max_hole_length = tu.largest_hole_length(current_soma)\n",
    "            \n",
    "            returned_file_path = tu.write_h5_file(\n",
    "                                            vertices=current_soma.vertices,\n",
    "                                              faces=current_soma.faces,\n",
    "                                              segment_id=segment_id,\n",
    "                                              filename = f'{segment_id}_{i}.h5',\n",
    "                                                filepath=str(du.get_somas_path())\n",
    "                                             )\n",
    "\n",
    "\n",
    "\n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=i+1,\n",
    "                               ver=current_version,\n",
    "                              centroid_x=auto_prediction_center[0],\n",
    "                               centroid_y=auto_prediction_center[1],\n",
    "                               centroid_z=auto_prediction_center[2],\n",
    "                               n_vertices = len(current_soma.vertices),\n",
    "                               n_faces = len(current_soma.faces),\n",
    "                               mesh=returned_file_path,\n",
    "                               multiplicity=len(total_soma_list),\n",
    "                               sdf = np.round(soma_sdf,3),\n",
    "                               volume = current_soma.convex_hull.volume/1000000000,\n",
    "                               max_side_ratio = np.round(sz_ratio,3),\n",
    "                               bbox_volume_ratio = np.round(vol_ratio,3),\n",
    "                               max_hole_length = np.round(max_hole_length,3),\n",
    "                               run_time=np.round(run_time,4)\n",
    "                              )\n",
    "\n",
    "\n",
    "\n",
    "            dicts_to_insert.append(insert_dict)\n",
    "        self.insert(dicts_to_insert,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__baylor_segment_centroid'\")\n",
    "(curr_table)#.delete()#.delete()# & \"status='error'\"#.delete()\n",
    "#curr_table.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# key_hash,error_message = curr_table.fetch(\"key_hash\",\"error_message\")\n",
    "\n",
    "# df = pd.DataFrame.from_dict([dict(key_hash = k,error_message = m) for k,m in zip(key_hash,error_message)])\n",
    "# df\n",
    "# #df.columns = [\"error\",\"key_hash\"]\n",
    "# key_hashes_to_delete = df[df[\"error_message\"].str.contains(\"OSError\")][\"key_hash\"].to_numpy()\n",
    "\n",
    "# (curr_table & [dict(key_hash=k) for k in key_hashes_to_delete]).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-01-15 04:04:34,439 - autopopulate - Found 1 keys to populate\n",
      "INFO - 2021-01-15 04:04:34,447 - connection - Transaction started\n",
      "INFO - 2021-01-15 04:04:34,448 - autopopulate - Populating: {'segment_id': 864691135462241437, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n",
      "\n",
      "\n",
      "\n",
      "---- Working on Neuron 864691135462241437 ----\n",
      "{'segment_id': 864691135462241437, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25')}\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 5000.0 \n",
      "large_mesh_threshold_inner = 3250.0 \n",
      "soma_size_threshold = 562.5 \n",
      "soma_size_threshold_max = 75000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "max_mesh_sized_filtered_away = 22500.0\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_35184.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_35184_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_241940.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_35184.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_35184_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_241940.mls is being deleted....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:662: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 17 total interior meshes\n",
      "Pieces satisfying glia requirements (volume) (x >= 2500000000000): 0\n",
      "Pieces satisfying nuclie requirements: n_faces (700 <= x) and volume (x < 2500000000000) : 17\n",
      "inside remove_mesh_interior and using precomputed inside_pieces\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(17969, 3), faces.shape=(38609, 3))>, <trimesh.Trimesh(vertices.shape=(3429, 3), faces.shape=(6695, 3))>, <trimesh.Trimesh(vertices.shape=(1069, 3), faces.shape=(2417, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(1731, 3))>, <trimesh.Trimesh(vertices.shape=(668, 3), faces.shape=(1486, 3))>, <trimesh.Trimesh(vertices.shape=(517, 3), faces.shape=(768, 3))>, <trimesh.Trimesh(vertices.shape=(398, 3), faces.shape=(812, 3))>, <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(714, 3))>]\n",
      "\n",
      "\n",
      "Original Mesh size: 1325101, Final mesh size: 1271803\n",
      "Total time = 60.126779556274414\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/decimation_meshlab_25111235.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(147024, 3), faces.shape=(290931, 3))>, <trimesh.Trimesh(vertices.shape=(3665, 3), faces.shape=(5163, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(147024, 3), faces.shape=(290931, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_15849.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_15849_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_518712.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_15849.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_15849_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_518712.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 28\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece.off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:2940: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ordered_comp_indices = np.array([k.astype(\"int\") for k in ordered_components])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/poisson_513775.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(39520, 3), faces.shape=(79036, 3))>, <trimesh.Trimesh(vertices.shape=(3832, 3), faces.shape=(7668, 3))>, <trimesh.Trimesh(vertices.shape=(3292, 3), faces.shape=(6580, 3))>, <trimesh.Trimesh(vertices.shape=(2978, 3), faces.shape=(5952, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(39520, 3), faces.shape=(79036, 3))>\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/decimation_meshlab_2588451.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(9879, 3), faces.shape=(19754, 3))>\n",
      "\n",
      "perc_0_faces = 0.0003037359522122102\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/551_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe01205aced04d47a245c6d377c89307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ------ Found 1 viable somas: [0.835613]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_330501.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_330501_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_258027.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:1457: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_330501.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_330501_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_258027.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.1230278776243945\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(3832, 3), faces.shape=(7668, 3))>\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/decimation_meshlab_2588451.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(956, 3), faces.shape=(1916, 3))>\n",
      "\n",
      "perc_0_faces = 0.0015657620041753654\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/649_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44957eb909074971990b8ded0653a5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ------ Found 2 viable somas: [0.445064, 0.662737]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_649437.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 1142.2532178147246\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(470, 3), faces.shape=(935, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "perc_0_faces = 0.0010695187165775401\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/633_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5260d068d84592bf23f785d2dc771f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_124367.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 236.6546669328405\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(313, 3), faces.shape=(624, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "perc_0_faces = 0.003205128205128205\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/997_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a4985ade6d4bb28b545f89db3cae95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(3292, 3), faces.shape=(6580, 3))>\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/decimation_meshlab_2588451.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(824, 3), faces.shape=(1644, 3))>\n",
      "\n",
      "perc_0_faces = 0.0\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/581_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4361300761b4147950ea755fa8859ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(280, 3), faces.shape=(554, 3))>\n",
      "\n",
      "perc_0_faces = 0.0036101083032490976\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/896_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaa407f705f4a0e80558a2eb5ea16e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(180, 3), faces.shape=(354, 3))>\n",
      "\n",
      "perc_0_faces = 0.005649717514124294\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/175_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46b6466ed094ef89b610de979bdbd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(2978, 3), faces.shape=(5952, 3))>\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/decimation_meshlab_2588451.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(745, 3), faces.shape=(1486, 3))>\n",
      "\n",
      "perc_0_faces = 0.0\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/993_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90920513e2af45349be6a1b7e93d9a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    --- On segmentation loop 1 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(234, 3), faces.shape=(462, 3))>\n",
      "\n",
      "perc_0_faces = 0.0\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/169_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6934a451d2b549adb4047dc8140bc72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    --- On segmentation loop 2 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(100, 3), faces.shape=(194, 3))>\n",
      "\n",
      "perc_0_faces = 0.005154639175257732\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/631_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4c4ecd867f4a25a14bd5fbf0db8d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- working on large mesh #1: <trimesh.Trimesh(vertices.shape=(3665, 3), faces.shape=(5163, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_31836.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_31836_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_369516.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_31836.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_31836_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_369516.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 27\n",
      "pre_largest_mesh_path = /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece.off\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/poisson_513775.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(25200, 3), faces.shape=(50045, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(25200, 3), faces.shape=(50045, 3))>\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/864691135462241437/decimation_meshlab_2588451.mls\n",
      "\n",
      "-------Splits after inner decimation len = 1--------\n",
      "\n",
      "done exporting decimated mesh: neuron_864691135462241437_decimated_largest_piece_poisson_largest_inner.off\n",
      "\n",
      "    --- On segmentation loop 0 --\n",
      "largest_mesh_path_inner_decimated_clean = <trimesh.Trimesh(vertices.shape=(6428, 3), faces.shape=(12501, 3))>\n",
      "\n",
      "perc_0_faces = 0.9937604991600671\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/227_mesh \n",
      "clusters:3 \n",
      "smoothness:0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1512830416ea4f24a184ba80c1c6b5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ------ Found 3 viable somas: [0.48298, 0.721635, 0.7777185]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_190444.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_190444_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_654032.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_190444.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_190444_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_654032.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.006867842472806402\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_424770.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_424770_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_601974.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_424770.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_424770_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_601974.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.030709518040401663\n",
      "xy = 7.213232285386005 ratio was beyong 6 multiplier\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_953202.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_953202_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_610964.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_953202.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_953202_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_610964.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.00047046098396584047\n",
      "->Attempting retry of soma because failed first checks: soma_mesh = <trimesh.Trimesh(vertices.shape=(509, 3), faces.shape=(916, 3))>, curr_side_len_check = False, curr_volume_check = True\n",
      "perc_0_faces = 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465b6311116b48e5a76a03fea80f8d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not find valid soma mesh in retry\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 181.93482565879822\n",
      "Before Filtering the number of somas found = 3\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_95258.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_95258_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_386898.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_95258.off loaded has 48081 vn 98433 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_95258_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_386898.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 2335140\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 2335140\n",
      "LOG: 2 Successfully removed 10657 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 10657 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 2207256\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_386898.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_24797.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_24797_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_761733.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_24797.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_24797_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_761733.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(12307, 3), faces.shape=(28169, 3))>, <trimesh.Trimesh(vertices.shape=(920, 3), faces.shape=(2190, 3))>, <trimesh.Trimesh(vertices.shape=(339, 3), faces.shape=(852, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_474821.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_474821_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_358663.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_474821.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_474821_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_358663.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.045672394182002\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(18051, 3), faces.shape=(38667, 3))>, <trimesh.Trimesh(vertices.shape=(3435, 3), faces.shape=(6699, 3))>, <trimesh.Trimesh(vertices.shape=(1069, 3), faces.shape=(2417, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(1731, 3))>, <trimesh.Trimesh(vertices.shape=(668, 3), faces.shape=(1486, 3))>, <trimesh.Trimesh(vertices.shape=(523, 3), faces.shape=(772, 3))>, <trimesh.Trimesh(vertices.shape=(398, 3), faces.shape=(812, 3))>, <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(714, 3))>]\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_94022.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_94022_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_57154.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_94022.off loaded has 35820 vn 73864 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_94022_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_57154.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 1746048\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 1746048\n",
      "LOG: 2 Successfully removed 10594 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 10594 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 1618920\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_57154.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_74192.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_74192_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_782994.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_74192.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_74192_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_782994.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(12307, 3), faces.shape=(28169, 3))>, <trimesh.Trimesh(vertices.shape=(920, 3), faces.shape=(2190, 3))>, <trimesh.Trimesh(vertices.shape=(339, 3), faces.shape=(852, 3))>]\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_476736.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_476736_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_402496.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_476736.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_476736_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_402496.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = -0.007840372790765056\n",
      "About to add the following inside nuclei pieces after soma backtrack: [<trimesh.Trimesh(vertices.shape=(18051, 3), faces.shape=(38667, 3))>, <trimesh.Trimesh(vertices.shape=(3435, 3), faces.shape=(6699, 3))>, <trimesh.Trimesh(vertices.shape=(1069, 3), faces.shape=(2417, 3))>, <trimesh.Trimesh(vertices.shape=(772, 3), faces.shape=(1731, 3))>, <trimesh.Trimesh(vertices.shape=(668, 3), faces.shape=(1486, 3))>, <trimesh.Trimesh(vertices.shape=(523, 3), faces.shape=(772, 3))>, <trimesh.Trimesh(vertices.shape=(398, 3), faces.shape=(812, 3))>, <trimesh.Trimesh(vertices.shape=(335, 3), faces.shape=(714, 3))>, <trimesh.Trimesh(vertices.shape=(12307, 3), faces.shape=(28169, 3))>, <trimesh.Trimesh(vertices.shape=(920, 3), faces.shape=(2190, 3))>, <trimesh.Trimesh(vertices.shape=(339, 3), faces.shape=(852, 3))>]\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_67659.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_67659_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_64191.mls\n",
      "\n",
      "---- meshlab output -----\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n",
      "Current Plugins Dir is: /meshlab/src/distrib/plugins \n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Error While parsing the XML filter plugin descriptors: We are trying to load a xml file that does not correspond to any dll or javascript code; please delete all the spurious xml files\n",
      "Opening a file with extention off\n",
      "FilterScript\n",
      "Reading filter with name Remove Duplicate Vertices\n",
      "Reading filter with name Remove Faces from Non Manifold Edges\n",
      "Reading filter with name Close Holes\n",
      "    Reading Param with name MaxHoleSize : RichInt\n",
      "    Reading Param with name Selected : RichBool\n",
      "    Reading Param with name NewFaceSelected : RichBool\n",
      "    Reading Param with name SelfIntersection : RichBool\n",
      "Loading Plugins:\n",
      "Total 104 filtering actions\n",
      "Total 1 io plugins\n",
      "Mesh /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_67659.off loaded has 16121 vn 30608 fn\n",
      "output mesh  /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_67659_fill_holes.off\n",
      "Apply FilterScript: '/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_64191.mls'\n",
      "Starting Script of 3 actionsfilter: Remove Duplicate Vertices\n",
      "no additional memory available!!! memory required: 754200\n",
      "LOG: 2 Removed 0 duplicated vertices\n",
      "Removed 0 duplicated vertices\n",
      "filter: Remove Faces from Non Manifold Edges\n",
      "no additional memory available!!! memory required: 754200\n",
      "LOG: 2 Successfully removed 3473 non-manifold faces\n",
      "Removed 0 duplicated vertices\n",
      "Successfully removed 3473 non-manifold faces\n",
      "filter: Close Holes\n",
      "no additional memory available!!! memory required: 712524\n",
      "meshlabserver: ../../../../vcglib/vcg/complex/algorithms/hole.h:259: bool vcg::tri::TrivialEar<MESH>::Close(vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::PosType&, vcg::tri::TrivialEar<MESH>::FaceType*) [with MESH = CMeshO; vcg::tri::TrivialEar<MESH>::PosType = vcg::face::Pos<CFaceO>; typename MeshType::FaceType = CFaceO; vcg::tri::TrivialEar<MESH>::FaceType = CFaceO]: Assertion `e1.v->IsUserBit(NonManifoldBit())' failed.\n",
      "Aborted (core dumped)\n",
      "\n",
      "\n",
      " returncode ====== 134\n",
      "\n",
      " ------ Done with meshlab output------\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_64191.mls is being deleted....\n",
      "The hole closing did not work so continuing without\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_97606.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_97606_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_658106.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_97606.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_97606_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_658106.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(3204, 3), faces.shape=(6553, 3))>, <trimesh.Trimesh(vertices.shape=(334, 3), faces.shape=(765, 3))>]\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_58840.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_58840_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_317249.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_58840.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_58840_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_317249.mls is being deleted....\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_70249.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_70249_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_886681.mls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_70249.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_70249_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_886681.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 112\n",
      "Doing the soma segmentation filter at end\n",
      "perc_0_faces = 0.01695786228160329\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/32_mesh \n",
      "clusters:2 \n",
      "smoothness:0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599c80c44bdd45a488285fb67c6f4061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 94894.89497135965, after = 722201.878096015,\n",
      "\n",
      "ratio = 7.610545101651502, difference = 627306.9831246553\n",
      "Skipping the segmentatio filter at end\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_23862.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_23862_fill_holes.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_78690.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_23862.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_23862_fill_holes.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/fill_holes_78690.mls is being deleted....\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_87198.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_87198_remove_interior.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_343929.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_87198.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/neuron_87198_remove_interior.off\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/temp/remove_interior_343929.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present\n",
      "largest is 105\n",
      "Doing the soma segmentation filter at end\n",
      "perc_0_faces = 0.834129227170841\n",
      "Going to run cgal segmentation with:\n",
      "File: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/40_mesh \n",
      "clusters:2 \n",
      "smoothness:0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e35e46f2d44ea6b1218f8123ae9e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest hole before segmentation = 2403530.1475897506, after = 2465380.355857128,\n",
      "\n",
      "ratio = 1.0257330694725841, difference = 61850.208267377224\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462241437_glia.pbz2\n",
      "File size is 4.6e-05 MB\n",
      "Saved object at /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462241437_nuclei.pbz2\n",
      "File size is 0.080394 MB\n",
      " glia_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462241437_glia.pbz2 \n",
      " nuclei_path = /mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462241437_nuclei.pbz2\n",
      "Finished saving off glia and nuclei information : {'segment_id': 864691135462241437, 'decimation_version': 0, 'decimation_ratio': Decimal('0.25'), 'ver': 30, 'n_glia_faces': 0, 'glia_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462241437_glia.pbz2'), 'n_nuclei_faces': 84509, 'nuclei_faces': PosixPath('/mnt/dj-stor01/platinum/minnie65/02/glia_nuclei_faces/864691135462241437_nuclei.pbz2')}\n",
      "Run time was 181.93482494354248 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(22532, 3), faces.shape=(55019, 3))>]\n",
      "    with sdf values = [0.6592965]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_234225.off -o /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_234225_poisson.off -s /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_272830.mls\n",
      "removed temporary input file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_234225.off\n",
      "removed temporary output file: /notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/neuron_234225_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Auto_Proofreading/Soma_Splitting/Soma_Detection_Debug/Seg_Fault_Debug/Poisson_temp/poisson_272830.mls is being deleted....\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [383637 119880  23491]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/networkx_utils.py:556: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cycles_list_array = np.array(cycles_list)\n",
      "INFO - 2021-01-15 04:09:16,217 - connection - Transaction committed and closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Done\n",
      "Total time for BaylorSegmentCentroid populate = 281.79663467407227\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import trimesh_utils as tu\n",
    "sm = reload(sm)\n",
    "tu = reload(tu)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    BaylorSegmentCentroid.populate(reserve_jobs=True, suppress_errors=True)\n",
    "else:\n",
    "    BaylorSegmentCentroid.populate(reserve_jobs=True, suppress_errors=False)\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for BaylorSegmentCentroid populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
