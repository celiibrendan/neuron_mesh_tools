{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To save the validation synapse\n",
    "tables for different validations\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the virtual module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-26 14:19:06,680 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-05-26 14:19:06,681 - settings - Setting database.user to celiib\n",
      "INFO - 2021-05-26 14:19:06,682 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-05-26 14:19:06,683 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-05-26 14:19:06,684 - settings - Setting database.user to celiib\n",
      "INFO - 2021-05-26 14:19:06,685 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-05-26 14:19:06,690 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 134 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-26 14:19:07,525 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import system_utils as su\n",
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import neuron_utils as nru\n",
    "\n",
    "import neuron\n",
    "\n",
    "import neuron_visualizations as nviz\n",
    "\n",
    "import time\n",
    "\n",
    "import datajoint_utils as du\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import preprocessing_vp2 as pre\n",
    "\n",
    "# -- For the axon classification --\n",
    "\n",
    "import neuron_searching as ns\n",
    "\n",
    "import skeleton_utils as sk\n",
    "\n",
    "import numpy_utils as nu\n",
    "\n",
    "import networkx_utils as xu\n",
    "\n",
    "import system_utils as su\n",
    "\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "import trimesh_utils as tu\n",
    "import proofreading_utils as pru\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 3383\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat table to inherit from:\\nDecomposition Axon\\n\\nThings want to save off:\\n1) validation_df\\n2) validation_df_ext\\n3) neuron object\\n\\nFor presyn/postsyn\\n- TP... counts\\n- scores\\n\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What table to inherit from:\n",
    "Decomposition Axon\n",
    "\n",
    "Things want to save off:\n",
    "1) validation_df\n",
    "2) validation_df_ext\n",
    "3) neuron object\n",
    "\n",
    "For presyn/postsyn\n",
    "- TP... counts\n",
    "- scores\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minnie.AutoProofreadValidationScore4.drop()\n",
    "#minnie.schema.external['decomposition'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "import axon_utils as au\n",
    "import validation_utils as vu\n",
    "\n",
    "axon_version = au.axon_version\n",
    "\n",
    "verbose = True\n",
    "\n",
    "@schema\n",
    "class AutoProofreadValidationScore4(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.AutoProofreadValidationSegmentMap4()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    ---\n",
    "    decomposition        : <decomposition> # saved neuron object with high fidelity axon\n",
    "    axon_length=NULL: double # axon length of the filtered neuron\n",
    "    validation_df: longblob\n",
    "    validation_df_ext: longblob #\n",
    "    pre_tp: int unsigned #\n",
    "    pre_tn: int unsigned\n",
    "    pre_fp: int unsigned\n",
    "    pre_fn: int unsigned\n",
    "    \n",
    "    pre_precision=NULL: double\n",
    "    pre_recall=NULL: double\n",
    "    pre_f1=NULL: double\n",
    "    \n",
    "    \n",
    "    \n",
    "    post_tp: int unsigned\n",
    "    post_tn: int unsigned\n",
    "    post_fp: int unsigned\n",
    "    post_fn: int unsigned\n",
    "    \n",
    "    post_precision=NULL: double\n",
    "    post_recall=NULL: double\n",
    "    post_f1=NULL: double\n",
    "    \n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "    \n",
    "    \"\"\"\n",
    "                             \n",
    "    \n",
    "    #key_source = minnie.Decomposition() & minnie.NucleiSegmentsRun2() & \"segment_id=864691136540183458\"\n",
    "    pre_source = (minnie.AutoProofreadValidationSegmentMap4() & \n",
    "    (dj.U(\"old_segment_id\") & minnie.DecompositionAxon.proj(old_segment_id=\"segment_id\")))\n",
    "\n",
    "    key_source = (pre_source - \n",
    "                  du.current_validation_segment_id_exclude.proj(old_segment_id=\"segment_id\")\n",
    "                  #& dict(old_segment_id=864691135373402824)\n",
    "                 )\n",
    "    \n",
    "\n",
    "    def make(self,key):\n",
    "        whole_pass_time = time.time()\n",
    "        \n",
    "        # ----------- Doing the v4 Processing ------- #\n",
    "        \n",
    "        segment_id = key[\"segment_id\"]\n",
    "        if verbose:\n",
    "            print(f\"\\n-- Working on neuron {segment_id}---\")\n",
    "\n",
    "        segment_map_dict = (minnie.AutoProofreadValidationSegmentMap4() & dict(segment_id=segment_id)).fetch1()\n",
    "\n",
    "        #1) Find the coordinates of the nucleus for that new segment\n",
    "        nucleus_id = segment_map_dict[\"nucleus_id\"]\n",
    "        nuc_center_coords = du.nuclei_id_to_nucleus_centers(nucleus_id)\n",
    "        if verbose:\n",
    "            print(f\"nuc_center_coords = {nuc_center_coords}\")\n",
    "\n",
    "        #2) Make sure that same number of DecompositionAxon objects as in Decomposition\n",
    "        old_segment_id = segment_map_dict[\"old_segment_id\"]\n",
    "        if verbose:\n",
    "            print(f\"old_segment_id = {old_segment_id}\")\n",
    "\n",
    "        search_key = dict(segment_id=old_segment_id)\n",
    "        n_somas = len(minnie.BaylorSegmentCentroid() & search_key)\n",
    "        n_decomp_axon = len(minnie.DecompositionAxon() & search_key)\n",
    "        if verbose:\n",
    "            print(f\"# of somas = {n_somas} and # of DecompositionAxon = {n_decomp_axon}\")\n",
    "\n",
    "\n",
    "        if n_somas != n_decomp_axon:\n",
    "            raise Exception(f\"# of somas = {n_somas} NOT MATCH # of DecompositionAxon = {n_decomp_axon}\")\n",
    "\n",
    "        #3) Pick the neuron object that is closest and within a certain range of the nucleus\n",
    "        neuron_objs,split_idxs = du.decomposition_with_spine_recalculation(old_segment_id)\n",
    "        if n_somas > 1:\n",
    "            \"\"\"\n",
    "            Finding the closest soma:\n",
    "            1) For each neuron object get the mesh center of the soma object\n",
    "            2) Find the distance of each from the nucleus center\n",
    "            3) Find the arg min distance and make sure within threshold\n",
    "            4) Mark the current neuron and the current split index\n",
    "            \"\"\"\n",
    "            nuclei_distance_threshold = 15000\n",
    "\n",
    "            soma_center_coords = [k[\"S0\"].mesh_center for k in neuron_objs]\n",
    "            soma_distances = [np.linalg.norm(k-nuc_center_coords) for k in soma_center_coords]\n",
    "            min_dist_arg = np.argmin(soma_distances)\n",
    "            min_dist = soma_distances[min_dist_arg]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"soma_distances = {soma_distances}\")\n",
    "                print(f\"min_dist_arg = {min_dist_arg}, with min distance = {min_dist}\")\n",
    "\n",
    "            if min_dist > nuclei_distance_threshold:\n",
    "                raise Exception(f\"min_dist ({min_dist}) larger than nuclei_distance_threshold ({nuclei_distance_threshold})\")\n",
    "\n",
    "            neuron_obj = neuron_objs[min_dist_arg]\n",
    "            split_index = split_idxs[min_dist_arg]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Winning split_index = {split_index}\")\n",
    "        else:\n",
    "            split_index = split_idxs[0]\n",
    "            neuron_obj = neuron_objs[0]\n",
    "\n",
    "        \n",
    "        (filt_neuron,\n",
    "             return_synapse_df_revised,\n",
    "             return_synapse_df_errors,\n",
    "            return_validation_df_revised,\n",
    "            return_validation_df_extension) =  vu.filtered_neuron_score(neuron_obj = neuron_obj,   \n",
    "                                filter_list = pru.v4_exc_filters(),\n",
    "                                plot_limb_branch_filter_with_disconnect_effect = False,\n",
    "                                verbose = True,\n",
    "                                plot_score=False,\n",
    "                                nucleus_id = nucleus_id,\n",
    "                                return_synapse_df_errors=True,\n",
    "                                return_validation_df_extension = True,                                        \n",
    "                                split_index=split_index)\n",
    "        \n",
    "        print(f\"\\n\\n ----- Done Filtering ----------\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #------- saving off the filtered neuron\n",
    "        \n",
    "        save_time = time.time()\n",
    "        file_name = f\"{filt_neuron.segment_id}_{filt_neuron.description}_v4_val\"\n",
    "        ret_file_path = filt_neuron.save_compressed_neuron(output_folder=str(du.get_decomposition_path()),\n",
    "                                        file_name=file_name,        \n",
    "                                          return_file_path=True,\n",
    "                                         export_mesh=False,\n",
    "                                         suppress_output=True)\n",
    "\n",
    "        ret_file_path_str = str(ret_file_path.absolute()) + \".pbz2\"\n",
    "        print(f\"Save time = {time.time() - save_time}\")\n",
    "        \n",
    "        \n",
    "        # ---------- Getting the scores of the proofreading ----- #\n",
    "        presyn_scores_dict = vu.scores_presyn(return_validation_df_revised)\n",
    "        postsyn_scores_dict = vu.scores_postsyn(return_validation_df_revised)\n",
    "\n",
    "        cat = vu.synapse_validation_df_to_category_counts(return_validation_df_revised,\n",
    "                                            print_postsyn=True,\n",
    "                                            print_presyn=False)\n",
    "        \n",
    "        \n",
    "        run_time = np.round(time.time() - whole_pass_time,2)\n",
    "        \n",
    "        final_dict = dict(key,\n",
    "                          split_index = split_index,\n",
    "                          \n",
    "                          decomposition=ret_file_path_str,\n",
    "                          axon_length = filt_neuron.axon_length,\n",
    "                          \n",
    "                          validation_df = return_validation_df_revised.to_numpy(),\n",
    "                          validation_df_ext=return_validation_df_extension.to_numpy(),\n",
    "                          \n",
    "                          pre_tp=cat[\"presyn\"][\"TP\"],\n",
    "                            pre_tn=cat[\"presyn\"][\"TN\"],\n",
    "                            pre_fp=cat[\"presyn\"][\"FP\"],\n",
    "                            pre_fn=cat[\"presyn\"][\"FN\"],\n",
    "\n",
    "                            pre_precision=presyn_scores_dict[\"precision\"],\n",
    "                            pre_recall=presyn_scores_dict[\"recall\"],\n",
    "                            pre_f1=presyn_scores_dict[\"f1\"],\n",
    "\n",
    "\n",
    "\n",
    "                            post_tp=cat[\"postsyn\"][\"TP\"],\n",
    "                            post_tn=cat[\"postsyn\"][\"TN\"],\n",
    "                            post_fp=cat[\"postsyn\"][\"FP\"],\n",
    "                            post_fn=cat[\"postsyn\"][\"FN\"],\n",
    "\n",
    "                            post_precision=postsyn_scores_dict[\"precision\"],\n",
    "                            post_recall=postsyn_scores_dict[\"recall\"],\n",
    "                            post_f1=postsyn_scores_dict[\"f1\"],\n",
    "                          \n",
    "                          \n",
    "                          run_time = run_time\n",
    "                         )\n",
    "        \n",
    "        self.insert1(final_dict,skip_duplicates=True,allow_direct_insert=True)\n",
    "    \n",
    "        print(f\"\\n\\n ***------ Total time for {key['segment_id']} = {run_time} ------ ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>job reservation table for `microns_minnie65_02`</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">table_name</p>\n",
       "                                <span class=\"djtooltiptext\">className of the table</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">key_hash</p>\n",
       "                                <span class=\"djtooltiptext\">key hash</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">if tuple is missing, the job is available</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">key</p>\n",
       "                                <span class=\"djtooltiptext\">structure containing the key</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_message</p>\n",
       "                                <span class=\"djtooltiptext\">error message returned if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">error_stack</p>\n",
       "                                <span class=\"djtooltiptext\">error stack if failed</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">user</p>\n",
       "                                <span class=\"djtooltiptext\">database user</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">host</p>\n",
       "                                <span class=\"djtooltiptext\">system hostname</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">pid</p>\n",
       "                                <span class=\"djtooltiptext\">system process id</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">connection_id</p>\n",
       "                                <span class=\"djtooltiptext\">connection_id()</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">timestamp</p>\n",
       "                                <span class=\"djtooltiptext\">automatic timestamp</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr>  </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 0</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*table_name    *key_hash    status     key        error_message  error_stac user     host     pid     connection_id  timestamp    \n",
       "+------------+ +----------+ +--------+ +--------+ +------------+ +--------+ +------+ +------+ +-----+ +------------+ +-----------+\n",
       "\n",
       " (Total: 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__auto_proofread_validation_score4'\")\n",
    "(curr_table)#.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-05-26 14:19:24,217 - autopopulate - Found 3 keys to populate\n",
      "INFO - 2021-05-26 14:19:24,235 - connection - Transaction started\n",
      "INFO - 2021-05-26 14:19:24,237 - autopopulate - Populating: {'ver': Decimal('88.00'), 'nucleus_id': 533187, 'segment_id': 864691136227020113, 'old_ver': Decimal('0.08')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n",
      "\n",
      "-- Working on neuron 864691136227020113---\n",
      "nuc_center_coords = [1227456  854208  989480]\n",
      "old_segment_id = 864691135212632704\n",
      "# of somas = 1 and # of DecompositionAxon = 1\n",
      "**Using table __decomposition_axon for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Dont need spine recalculation\n",
      "Number of Neurons found = 1\n",
      "\n",
      "*****Using v4 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {'offset': 1500, 'comparison_distance': 2000, 'worst_case_match_threshold': 65, 'width_diff_max': 75, 'width_diff_perc': 60, 'match_threshold': 45, 'angle_buffer': 15, 'max_degree_to_resolve': 6, 'max_degree_to_resolve_wide': 8, 'match_method': 'best_match', 'kiss_check': True, 'kiss_check_bbox_longest_side_threshold': 450}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ----- Working on coordinate 0: [1264788.39258434  771490.14413958 1043340.42966265]--------\n",
      "kiss_check = True\n",
      "short_thick_endnodes_to_remove = [ 4  6  8 10 12 15 18 19 23 27 28 37 43 59 76 77 81]\n",
      "winning_downstream = 57,error_downstream = [51 58] \n",
      "coordinate [1264788.39258434  771490.14413958 1043340.42966265] had error branches [51 58]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 1: [1268261.40866743  825435.86886252  977413.75531851]--------\n",
      "kiss_check = True\n",
      "short_thick_endnodes_to_remove = [ 4  6  8 10 12 15 18 19 23 27 28 37 43 59 76 77 81]\n",
      "winning_downstream = None,error_downstream = [55 62 63] \n",
      "coordinate [1268261.40866743  825435.86886252  977413.75531851] had error branches [55 62 63]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 2: [1270695.49715187  826358.90945804  978466.43550785]--------\n",
      "kiss_check = True\n",
      "short_thick_endnodes_to_remove = [ 4  6  8 10 12 15 18 19 23 27 28 37 43 59 76 77 81]\n",
      "winning_downstream = 64,error_downstream = [50 65 67] \n",
      "coordinate [1270695.49715187  826358.90945804  978466.43550785] had error branches [50 65 67]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 3: [1272764.86745869  820871.88804301  975175.32411204]--------\n",
      "kiss_check = True\n",
      "short_thick_endnodes_to_remove = [ 4  6  8 10 12 15 18 19 23 27 28 37 43 59 76 77 81]\n",
      "winning_downstream = 56,error_downstream = [68 69] \n",
      "coordinate [1272764.86745869  820871.88804301  975175.32411204] had error branches [68 69]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 4: [1274570.92213105  827753.20282479  979003.10588919]--------\n",
      "kiss_check = True\n",
      "short_thick_endnodes_to_remove = [ 4  6  8 10 12 15 18 19 23 27 28 37 43 59 76 77 81]\n",
      "winning_downstream = 70,error_downstream = [61 71] \n",
      "coordinate [1274570.92213105  827753.20282479  979003.10588919] had error branches [61 71]--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 5: [1277322.66017049  827817.25990354  978785.43420486]--------\n",
      "kiss_check = True\n",
      "winning_downstream = None,error_downstream = [] \n",
      "coordinate [1277322.66017049  827817.25990354  978785.43420486] had error branches []--------\n",
      "\n",
      "\n",
      " ----- Working on coordinate 6: [1291809.5857779   788473.17450015  956455.38531199]--------\n",
      "kiss_check = True\n",
      "short_thick_endnodes_to_remove = [ 4  6  8 10 12 15 18 19 23 27 28 37 43 59 76 77 81]\n",
      "winning_downstream = 85,error_downstream = [84 86] \n",
      "coordinate [1291809.5857779   788473.17450015  956455.38531199] had error branches [84 86]--------\n",
      "limb_branch_dict_to_cancel = {'L2': array([51, 58, 55, 62, 63, 50, 65, 67, 68, 69, 61, 71, 84, 86])}\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = double_back_and_width_change\n",
      "function __name__ = filter_away_large_double_back_or_width_changes\n",
      "function arguments = {'perform_double_back_errors': True, 'skip_double_back_errors_for_axon': False, 'width_jump_threshold': 250, 'running_width_jump_method': True, 'double_back_axon_like_threshold': 145, 'double_back_threshold': 120, 'allow_axon_double_back_angle_with_top': None, 'allow_axon_double_back_angle_with_top_width_min': 140, 'skeletal_length_to_skip': 4000, 'comparison_distance': 3000, 'perform_width_errors': True, 'perform_axon_width_errors': False}\n",
      "\n",
      "\n",
      "limb_branch_dict_to_cancel = {'L1': [0, 8]}\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 74.24710988998413 -----\n",
      "\n",
      "--- Finished Part 1: Filtering Neuron -----\n",
      "Apply the presyn non_error\n",
      "For presyn: # valid synapses = 15, # error synapses  = 116, # error presyns = 9\n",
      "For postsyn: # valid synapses = 2594, # error synapses  = 11, # error presyns = 0\n",
      "presyn_error = [361989128 366364980 366364988 367270216 373610162 381478514 381630130\n",
      " 393906905 401357852]\n",
      "\n",
      "--- Finished Part 2: Filtering Synapses -----\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 2736\n",
      "n_valid_syn_ids_presyn = 15\n",
      "n_errored_syn_ids_presyn = 116\n",
      "n_valid_syn_ids_postsyn = 2594\n",
      "n_errored_syn_ids_postsyn = 11\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 2736\n",
      "n_valid_syn_ids_presyn = 15\n",
      "n_errored_syn_ids_presyn = 116\n",
      "n_valid_syn_ids_postsyn = 2594\n",
      "n_errored_syn_ids_postsyn = 11\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bb779f5f0dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mAutoProofreadValidationScore4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreserve_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mAutoProofreadValidationScore4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreserve_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Populate Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datajoint/autopopulate.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, suppress_errors, return_exception_objects, reserve_jobs, order, limit, max_calls, display_progress, *restrictions)\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_insert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                         \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-46d525b3ff30>\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    133\u001b[0m                                 \u001b[0mreturn_synapse_df_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                                 \u001b[0mreturn_validation_df_extension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                                 split_index=split_index)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\n ----- Done Filtering ----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/validation_utils.py\u001b[0m in \u001b[0;36mfiltered_neuron_score\u001b[0;34m(neuron_obj, filter_list, inh_exc_class, perform_axon_classification, plot_limb_branch_filter_with_disconnect_effect, plot_score, return_filtered_neuron, return_synapse_df, return_synapse_df_errors, return_validation_df, return_validation_df_extension, verbose, apply_non_axon_presyn_errors, nucleus_id, split_index)\u001b[0m\n\u001b[1;32m   2385\u001b[0m                                               \u001b[0mvalid_synapses_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_synapse_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"synapse_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m                                                 \u001b[0mpresyn_dendrite_synapses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynapse_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"presyn_error_syn_non_axon_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2387\u001b[0;31m                                                 soma_center = neuron_obj[neuron_obj.get_soma_node_names()[0]].mesh_center)\n\u001b[0m\u001b[1;32m   2388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/validation_utils.py\u001b[0m in \u001b[0;36msynapse_validation_df_single_neuron\u001b[0;34m(segment_id, verbose, remove_presyn_on_dendrite, count_presyn_on_dendrite_as_correct, add_false_true_positive_negative_labels, add_proofreading_segment_id, add_euclidean_distance_to_soma, include_extension_synapse, valid_synapses_ids, presyn_dendrite_synapses, soma_center)\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \"\"\"\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m#1) Get the extension synapse dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mext_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextension_synapse_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_segment_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m#2) Using the synapse ids in the current proofreading_synapse_df, restrict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/meshAfterParty/validation_utils.py\u001b[0m in \u001b[0;36mextension_synapse_dict\u001b[0;34m(segment_id, synapse_type, add_manual_valid_true, verbose)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0mcurr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"synapse_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn_table_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mcurr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"synapse_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0mcurr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"synapse_x\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m         \u001b[0mcurr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"synapse_y\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0mcurr_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"synapse_z\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "import neuron\n",
    "neuron = reload(neuron)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    AutoProofreadValidationScore4.populate(reserve_jobs=True, suppress_errors=True, order=\"random\")\n",
    "else:\n",
    "    AutoProofreadValidationScore4.populate(reserve_jobs=True, suppress_errors=False,order=\"random\")\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for AutoProofreadValidationScore4 populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
