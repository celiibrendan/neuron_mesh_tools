{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To save the validation synapse\n",
    "tables for different validations\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-23 19:28:56,277 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-23 19:28:56,279 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-23 19:28:56,281 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-23 19:28:56,282 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-23 19:28:56,282 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-23 19:28:56,283 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-23 19:28:56,288 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2021-06-23 19:28:56,290 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-23 19:28:56,304 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-23 19:28:56,890 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-23 19:28:56,949 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-23 19:28:56,950 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-23 19:28:56,951 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-23 19:28:56,952 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-23 19:28:57,557 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-23 19:28:57,614 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-23 19:28:57,615 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-23 19:28:57,616 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-23 19:28:57,617 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-23 19:28:57,618 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-23 19:28:57,618 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-23 19:28:57,623 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2021-06-23 19:28:58,320 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty\")\n",
    "\n",
    "import datajoint_utils as du\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it will have the adapter defined\n",
    "from datajoint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the virtual module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-23 19:28:58,428 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-23 19:28:58,429 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-23 19:28:58,429 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-23 19:28:58,430 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2021-06-23 19:28:58,431 - settings - Setting database.user to celiib\n",
      "INFO - 2021-06-23 19:28:58,432 - settings - Setting database.password to newceliipass\n",
      "INFO - 2021-06-23 19:28:58,435 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 125 sec before conneting\n",
      "Done sleeping\n",
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-06-23 19:28:59,173 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "import system_utils as su\n",
    "import minfig\n",
    "import time\n",
    "import numpy as np\n",
    "#want to add in a wait for the connection part\n",
    "random_sleep_sec = np.random.randint(0, 200)\n",
    "print(f\"Sleeping {random_sleep_sec} sec before conneting\")\n",
    "if not test_mode:\n",
    "    time.sleep(random_sleep_sec)\n",
    "print(\"Done sleeping\")\n",
    "\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import neuron_utils as nru\n",
    "\n",
    "import neuron\n",
    "\n",
    "import neuron_visualizations as nviz\n",
    "\n",
    "import time\n",
    "\n",
    "import datajoint_utils as du\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import preprocessing_vp2 as pre\n",
    "\n",
    "# -- For the axon classification --\n",
    "\n",
    "import neuron_searching as ns\n",
    "\n",
    "import skeleton_utils as sk\n",
    "\n",
    "import numpy_utils as nu\n",
    "\n",
    "import networkx_utils as xu\n",
    "\n",
    "import system_utils as su\n",
    "\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "\n",
    "import datajoint as dj\n",
    "\n",
    "from pykdtree.kdtree import KDTree\n",
    "import trimesh_utils as tu\n",
    "import proofreading_utils as pru\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No port chosen so picked random port 7974\n"
     ]
    }
   ],
   "source": [
    "import meshlab\n",
    "meshlab.set_meshlab_port(current_port=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat table to inherit from:\\nDecomposition Axon\\n\\nThings want to save off:\\n1) validation_df\\n2) validation_df_ext\\n3) neuron object\\n\\nFor presyn/postsyn\\n- TP... counts\\n- scores\\n\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What table to inherit from:\n",
    "Decomposition Axon\n",
    "\n",
    "Things want to save off:\n",
    "1) validation_df\n",
    "2) validation_df_ext\n",
    "3) neuron object\n",
    "\n",
    "For presyn/postsyn\n",
    "- TP... counts\n",
    "- scores\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minnie.AutoProofreadValidationScore6.drop()\n",
    "# minnie.schema.external['decomposition'].delete(delete_external_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import classification_utils as clu\n",
    "import proofreading_utils as pru\n",
    "import axon_utils as au\n",
    "import validation_utils as vu\n",
    "\n",
    "axon_version = au.axon_version\n",
    "\n",
    "verbose = True\n",
    "\n",
    "@schema\n",
    "class AutoProofreadValidationScore6(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.AutoProofreadValidationSegmentMap4()\n",
    "    split_index          : tinyint unsigned             # the index of the neuron object that resulted AFTER THE SPLITTING ALGORITHM\n",
    "    ---\n",
    "    decomposition        : <decomposition> # saved neuron object with high fidelity axon\n",
    "    axon_length=NULL: double # axon length of the filtered neuron\n",
    "    validation_df: longblob\n",
    "    validation_df_ext: longblob #\n",
    "    pre_tp: int unsigned #\n",
    "    pre_tn: int unsigned\n",
    "    pre_fp: int unsigned\n",
    "    pre_fn: int unsigned\n",
    "    \n",
    "    pre_precision=NULL: double\n",
    "    pre_recall=NULL: double\n",
    "    pre_f1=NULL: double\n",
    "    \n",
    "    \n",
    "    \n",
    "    post_tp: int unsigned\n",
    "    post_tn: int unsigned\n",
    "    post_fp: int unsigned\n",
    "    post_fn: int unsigned\n",
    "    \n",
    "    post_precision=NULL: double\n",
    "    post_recall=NULL: double\n",
    "    post_f1=NULL: double\n",
    "    \n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "    \n",
    "    \"\"\"\n",
    "                             \n",
    "    \n",
    "    #key_source = minnie.Decomposition() & minnie.NucleiSegmentsRun2() & \"segment_id=864691136540183458\"\n",
    "    pre_source = (minnie.AutoProofreadValidationSegmentMap4() & \n",
    "    (dj.U(\"old_segment_id\") & minnie.DecompositionCellType.proj(old_segment_id=\"segment_id\")))\n",
    "\n",
    "    key_source = (pre_source - \n",
    "                  du.current_validation_segment_id_exclude.proj(old_segment_id=\"segment_id\")\n",
    "                  #& dict(old_segment_id=864691135373402824)\n",
    "                 )\n",
    "    \n",
    "\n",
    "    def make(self,key):\n",
    "        whole_pass_time = time.time()\n",
    "        \n",
    "        # ----------- Doing the v4 Processing ------- #\n",
    "        \n",
    "        segment_id = key[\"segment_id\"]\n",
    "        if verbose:\n",
    "            print(f\"\\n-- Working on neuron {segment_id}---\")\n",
    "\n",
    "        segment_map_dict = (minnie.AutoProofreadValidationSegmentMap4() & dict(segment_id=segment_id)).fetch1()\n",
    "\n",
    "        #1) Find the coordinates of the nucleus for that new segment\n",
    "        nucleus_id = segment_map_dict[\"nucleus_id\"]\n",
    "        nuc_center_coords = du.nuclei_id_to_nucleus_centers(nucleus_id)\n",
    "        if verbose:\n",
    "            print(f\"nuc_center_coords = {nuc_center_coords}\")\n",
    "\n",
    "        #2) Make sure that same number of DecompositionCellType objects as in Decomposition\n",
    "        old_segment_id = segment_map_dict[\"old_segment_id\"]\n",
    "        if verbose:\n",
    "            print(f\"old_segment_id = {old_segment_id}\")\n",
    "\n",
    "        search_key = dict(segment_id=old_segment_id)\n",
    "        n_somas = len(minnie.BaylorSegmentCentroid() & search_key)\n",
    "        n_decomp_axon = len(minnie.DecompositionCellType() & search_key)\n",
    "        if verbose:\n",
    "            print(f\"# of somas = {n_somas} and # of DecompositionCellType = {n_decomp_axon}\")\n",
    "\n",
    "\n",
    "        if n_somas != n_decomp_axon:\n",
    "            raise Exception(f\"# of somas = {n_somas} NOT MATCH # of DecompositionCellType = {n_decomp_axon}\")\n",
    "\n",
    "        #3) Pick the neuron object that is closest and within a certain range of the nucleus\n",
    "        neuron_objs,split_idxs = du.decomposition_with_spine_recalculation(old_segment_id,\n",
    "                                                                          attempt_apply_spines_to_neuron = False)\n",
    "        if n_somas > 1:\n",
    "            \"\"\"\n",
    "            Finding the closest soma:\n",
    "            1) For each neuron object get the mesh center of the soma object\n",
    "            2) Find the distance of each from the nucleus center\n",
    "            3) Find the arg min distance and make sure within threshold\n",
    "            4) Mark the current neuron and the current split index\n",
    "            \"\"\"\n",
    "            nuclei_distance_threshold = 15000\n",
    "\n",
    "            soma_center_coords = [k[\"S0\"].mesh_center for k in neuron_objs]\n",
    "            soma_distances = [np.linalg.norm(k-nuc_center_coords) for k in soma_center_coords]\n",
    "            min_dist_arg = np.argmin(soma_distances)\n",
    "            min_dist = soma_distances[min_dist_arg]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"soma_distances = {soma_distances}\")\n",
    "                print(f\"min_dist_arg = {min_dist_arg}, with min distance = {min_dist}\")\n",
    "\n",
    "            if min_dist > nuclei_distance_threshold:\n",
    "                raise Exception(f\"min_dist ({min_dist}) larger than nuclei_distance_threshold ({nuclei_distance_threshold})\")\n",
    "\n",
    "            neuron_obj = neuron_objs[min_dist_arg]\n",
    "            split_index = split_idxs[min_dist_arg]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Winning split_index = {split_index}\")\n",
    "        else:\n",
    "            split_index = split_idxs[0]\n",
    "            neuron_obj = neuron_objs[0]\n",
    "\n",
    "        (filt_neuron,\n",
    "                     return_synapse_df_revised,\n",
    "                     return_synapse_df_errors,\n",
    "                    return_validation_df_revised,\n",
    "                    return_validation_df_extension) =  vu.filtered_neuron_score(neuron_obj = neuron_obj,   \n",
    "                                        filter_list = pru.v6_exc_filters(),\n",
    "                                        plot_limb_branch_filter_with_disconnect_effect = False,\n",
    "                                        verbose = True,\n",
    "                                        plot_score=False,\n",
    "                                        nucleus_id = nucleus_id,\n",
    "                                        return_synapse_df_errors=True,\n",
    "                                        return_validation_df_extension = True,                                        \n",
    "                                        split_index=split_index)\n",
    "        \n",
    "        print(f\"\\n\\n ----- Done Filtering ----------\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #------- saving off the filtered neuron\n",
    "        \n",
    "        save_time = time.time()\n",
    "        file_name = f\"{filt_neuron.segment_id}_{filt_neuron.description}_v6_val\"\n",
    "        ret_file_path = filt_neuron.save_compressed_neuron(output_folder=str(du.get_decomposition_path()),\n",
    "                                        file_name=file_name,        \n",
    "                                          return_file_path=True,\n",
    "                                         export_mesh=False,\n",
    "                                         suppress_output=True)\n",
    "\n",
    "        ret_file_path_str = str(ret_file_path.absolute()) + \".pbz2\"\n",
    "        print(f\"Save time = {time.time() - save_time}\")\n",
    "        \n",
    "        \n",
    "        # ---------- Getting the scores of the proofreading ----- #\n",
    "        presyn_scores_dict = vu.scores_presyn(return_validation_df_revised)\n",
    "        postsyn_scores_dict = vu.scores_postsyn(return_validation_df_revised)\n",
    "\n",
    "        cat = vu.synapse_validation_df_to_category_counts(return_validation_df_revised,\n",
    "                                            print_postsyn=True,\n",
    "                                            print_presyn=False)\n",
    "        \n",
    "        \n",
    "        run_time = np.round(time.time() - whole_pass_time,2)\n",
    "        \n",
    "        final_dict = dict(key,\n",
    "                          split_index = split_index,\n",
    "                          \n",
    "                          decomposition=ret_file_path_str,\n",
    "                          axon_length = filt_neuron.axon_length,\n",
    "                          \n",
    "                          validation_df = return_validation_df_revised.to_numpy(),\n",
    "                          validation_df_ext=return_validation_df_extension.to_numpy(),\n",
    "                          \n",
    "                          pre_tp=cat[\"presyn\"][\"TP\"],\n",
    "                            pre_tn=cat[\"presyn\"][\"TN\"],\n",
    "                            pre_fp=cat[\"presyn\"][\"FP\"],\n",
    "                            pre_fn=cat[\"presyn\"][\"FN\"],\n",
    "\n",
    "                            pre_precision=presyn_scores_dict[\"precision\"],\n",
    "                            pre_recall=presyn_scores_dict[\"recall\"],\n",
    "                            pre_f1=presyn_scores_dict[\"f1\"],\n",
    "\n",
    "\n",
    "\n",
    "                            post_tp=cat[\"postsyn\"][\"TP\"],\n",
    "                            post_tn=cat[\"postsyn\"][\"TN\"],\n",
    "                            post_fp=cat[\"postsyn\"][\"FP\"],\n",
    "                            post_fn=cat[\"postsyn\"][\"FN\"],\n",
    "\n",
    "                            post_precision=postsyn_scores_dict[\"precision\"],\n",
    "                            post_recall=postsyn_scores_dict[\"recall\"],\n",
    "                            post_f1=postsyn_scores_dict[\"f1\"],\n",
    "                          \n",
    "                          \n",
    "                          run_time = run_time\n",
    "                         )\n",
    "        \n",
    "        self.insert1(final_dict,skip_duplicates=True,allow_direct_insert=True)\n",
    "    \n",
    "        print(f\"\\n\\n ***------ Total time for {key['segment_id']} = {run_time} ------ ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_table = (minnie.schema.jobs & \"table_name='__auto_proofread_validation_score6'\")\n",
    "((curr_table) & \"key_hash = '20d538ddd000654f385978d50f2f8d55'\").delete()\n",
    "#curr_table#.delete()\n",
    "#curr_table.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate Started\n",
      "\n",
      "-- Working on neuron 864691135658054274---\n",
      "nuc_center_coords = [1417280  477312  777320]\n",
      "old_segment_id = 864691135012541942\n",
      "# of somas = 1 and # of DecompositionCellType = 1\n",
      "**Using table __decomposition_cell_type for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Number of Neurons found = 1\n",
      "\n",
      "*****Using v6 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 79.09456706047058 -----\n",
      "\n",
      "--- Finished Part 1: Filtering Neuron -----\n",
      "\n",
      "---Step 1: Computing synapse_dict---\n",
      "# of beginning_direct_connections = 4138 \n",
      "# of presyn: 264\n",
      "# of postsyn: 3874\n",
      "\n",
      "---Step 2: Computing mesh_label_dict---\n",
      "-- Working on presyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 0\n",
      "# of mesh_errored_syn_idx = 238\n",
      "# of valid_syn_idx = 26\n",
      "-- Working on postsyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 0\n",
      "# of mesh_errored_syn_idx = 2\n",
      "# of valid_syn_idx = 3872\n",
      "\n",
      "---Step 4: add_error_synapses_to_neuron_obj---\n",
      "Working on error_type = distance_errored\n",
      "Working on error_type = mesh_errored\n",
      "Total time for valid synapse objects = 0.001825094223022461\n",
      "\n",
      "--- Limb L0 soma calculation time = 0.985\n",
      "\n",
      "--- Limb L1 soma calculation time = 0.135\n",
      "\n",
      "--- Limb L2 soma calculation time = 0.244\n",
      "\n",
      "--- Limb L3 soma calculation time = 0.106\n",
      "\n",
      "--- Limb L4 soma calculation time = 0.06\n",
      "\n",
      "--- Limb L5 soma calculation time = 0.053\n",
      "\n",
      "--- Limb L6 soma calculation time = 0.091\n",
      "\n",
      "--- Limb L7 soma calculation time = 0.05\n",
      "Putting Soma Placeholders\n",
      "\n",
      "--- Soma 0 soma calculation time = 0.0\n",
      "Putting Error Placeholders\n",
      "\n",
      "--- Error soma calculation time = 0.054\n",
      "Total soma distance calculation time = 1.7788045406341553\n",
      "Time for 3875 synapse entries = 0.0298159122467041\n",
      "Time for 263 synapse entries = 0.0017642974853515625\n",
      "# of synapses in query = 23\n",
      "# of total_error_synapse_ids = 263\n",
      "set_presyns_on_dendrite_as_errors to default of True\n",
      "presyn_error = [410110672 437455384 433464786 439761080 439777694 443289842 447936297\n",
      " 438056641 445006697 445159735 452459865 450611604 459606997 461366926\n",
      " 474291538 474291695 474291992 438588528 444782685 474414996 465514327\n",
      " 474209611 474214005]\n",
      "\n",
      "--- Finished Part 2: Filtering Synapses -----\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 4138\n",
      "n_valid_syn_ids_presyn = 3\n",
      "n_errored_syn_ids_presyn = 261\n",
      "n_valid_syn_ids_postsyn = 3872\n",
      "n_errored_syn_ids_postsyn = 2\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 4138\n",
      "n_valid_syn_ids_presyn = 3\n",
      "n_errored_syn_ids_presyn = 261\n",
      "n_valid_syn_ids_postsyn = 3872\n",
      "n_errored_syn_ids_postsyn = 2\n",
      "\n",
      "--- Finished Part 3: Generating Validation Dataframe -----\n",
      "\n",
      "\n",
      " ----- Done Filtering ----------\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135012541942_0_25_axon_v6_v6_val\n",
      "Save time = 87.71305894851685\n",
      "Postsyn counts:\n",
      "TP:3870\n",
      "TN:2\n",
      "FP:2\n",
      "FN:0\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135658054274 = 240.73 ------ ***\n",
      "\n",
      "-- Working on neuron 864691135761858870---\n",
      "nuc_center_coords = [1243904  499008  859160]\n",
      "old_segment_id = 864691135474673984\n",
      "# of somas = 1 and # of DecompositionCellType = 1\n",
      "**Using table __decomposition_cell_type for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Number of Neurons found = 1\n",
      "\n",
      "*****Using v6 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Changing max_degree_to_resolve = 1000 because upstream width was 258.79214567385225 \n",
      "limb_branch_dict_to_cancel = {'L4': array([ 6, 20, 34, 36, 25, 29, 30])}\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 141.1158480644226 -----\n",
      "\n",
      "--- Finished Part 1: Filtering Neuron -----\n",
      "\n",
      "---Step 1: Computing synapse_dict---\n",
      "# of beginning_direct_connections = 5267 \n",
      "# of presyn: 149\n",
      "# of postsyn: 5118\n",
      "\n",
      "---Step 2: Computing mesh_label_dict---\n",
      "-- Working on presyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 0\n",
      "# of mesh_errored_syn_idx = 122\n",
      "# of valid_syn_idx = 27\n",
      "-- Working on postsyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 1\n",
      "# of mesh_errored_syn_idx = 8\n",
      "# of valid_syn_idx = 5109\n",
      "\n",
      "---Step 4: add_error_synapses_to_neuron_obj---\n",
      "Working on error_type = distance_errored\n",
      "Working on error_type = mesh_errored\n",
      "Total time for valid synapse objects = 0.0011196136474609375\n",
      "\n",
      "--- Limb L0 soma calculation time = 0.821\n",
      "\n",
      "--- Limb L1 soma calculation time = 0.248\n",
      "\n",
      "--- Limb L2 soma calculation time = 0.221\n",
      "\n",
      "--- Limb L3 soma calculation time = 0.128\n",
      "\n",
      "--- Limb L4 soma calculation time = 0.903\n",
      "\n",
      "--- Limb L5 soma calculation time = 0.141\n",
      "\n",
      "--- Limb L6 soma calculation time = 0.073\n",
      "\n",
      "--- Limb L7 soma calculation time = 0.0\n",
      "\n",
      "--- Limb L8 soma calculation time = 0.027\n",
      "Putting Soma Placeholders\n",
      "\n",
      "--- Soma 0 soma calculation time = 0.0\n",
      "Putting Error Placeholders\n",
      "\n",
      "--- Error soma calculation time = 0.049\n",
      "Total soma distance calculation time = 2.6126134395599365\n",
      "Time for 5114 synapse entries = 0.031565189361572266\n",
      "Time for 153 synapse entries = 0.0006797313690185547\n",
      "# of synapses in query = 22\n",
      "# of total_error_synapse_ids = 153\n",
      "set_presyns_on_dendrite_as_errors to default of True\n",
      "presyn_error = [369229394 377236860 369570071 377230699 384027731 412929311 402694685\n",
      " 398123813 399498456 402686868 404933079 413270251 357846340 379031302\n",
      " 359060644 364787251 365529863 365533219 365533854 372389045 385516127\n",
      " 349200118]\n",
      "\n",
      "--- Finished Part 2: Filtering Synapses -----\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 5267\n",
      "n_valid_syn_ids_presyn = 5\n",
      "n_errored_syn_ids_presyn = 144\n",
      "n_valid_syn_ids_postsyn = 5109\n",
      "n_errored_syn_ids_postsyn = 9\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 5267\n",
      "n_valid_syn_ids_presyn = 5\n",
      "n_errored_syn_ids_presyn = 144\n",
      "n_valid_syn_ids_postsyn = 5109\n",
      "n_errored_syn_ids_postsyn = 9\n",
      "\n",
      "--- Finished Part 3: Generating Validation Dataframe -----\n",
      "\n",
      "\n",
      " ----- Done Filtering ----------\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135474673984_0_25_axon_v6_v6_val\n",
      "Save time = 141.71420645713806\n",
      "Postsyn counts:\n",
      "TP:5095\n",
      "TN:4\n",
      "FP:14\n",
      "FN:5\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135761858870 = 364.24 ------ ***\n",
      "\n",
      "-- Working on neuron 864691135864188286---\n",
      "nuc_center_coords = [1382976  402624  753080]\n",
      "old_segment_id = 864691135501833053\n",
      "# of somas = 1 and # of DecompositionCellType = 1\n",
      "**Using table __decomposition_cell_type for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Number of Neurons found = 1\n",
      "\n",
      "*****Using v6 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {'L1': array([ 31,  47,  39,  40,  24,  41,  42,  44,  25,  49,  61,  72,  53,\n",
      "        62,  70,  82,  77,  83,  54,  76,  80,  48,  81,  86,  89,  94,\n",
      "        95,  97, 100,  66,  99,  87, 101, 108, 109,  91, 104, 112, 103,\n",
      "       113, 118,  10,  85,  98, 111, 114, 121, 125, 126, 150, 160, 165,\n",
      "       138, 161, 130, 141, 119, 131, 148, 163, 164, 426, 144, 171, 174,\n",
      "       187, 188, 145, 151, 169, 170, 172, 179, 181, 182, 201, 213, 214,\n",
      "       217, 220, 176, 192, 194, 208, 215, 216, 219, 189, 195, 198, 193,\n",
      "       210, 225, 227, 229, 235, 262, 286, 236, 239, 240, 248, 252, 255,\n",
      "       259, 260, 232, 246, 263, 287, 291, 294, 312, 313, 280, 305, 271,\n",
      "       296, 297, 249, 323, 315, 317, 336, 341, 344, 427, 378, 383, 350,\n",
      "       362, 416, 421, 447, 450, 436, 445, 432, 444, 449, 437, 452, 454,\n",
      "       456, 460, 461, 457, 463, 464, 478, 482, 476, 479, 481, 484])}\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 316.95862793922424 -----\n",
      "\n",
      "--- Finished Part 1: Filtering Neuron -----\n",
      "\n",
      "---Step 1: Computing synapse_dict---\n",
      "# of beginning_direct_connections = 6960 \n",
      "# of presyn: 232\n",
      "# of postsyn: 6728\n",
      "\n",
      "---Step 2: Computing mesh_label_dict---\n",
      "-- Working on presyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 0\n",
      "# of mesh_errored_syn_idx = 129\n",
      "# of valid_syn_idx = 103\n",
      "-- Working on postsyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 0\n",
      "# of mesh_errored_syn_idx = 25\n",
      "# of valid_syn_idx = 6703\n",
      "\n",
      "---Step 4: add_error_synapses_to_neuron_obj---\n",
      "Working on error_type = distance_errored\n",
      "Working on error_type = mesh_errored\n",
      "Total time for valid synapse objects = 0.0031981468200683594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limb L0 soma calculation time = 0.312\n",
      "\n",
      "--- Limb L1 soma calculation time = 0.936\n",
      "\n",
      "--- Limb L2 soma calculation time = 0.061\n",
      "\n",
      "--- Limb L3 soma calculation time = 0.159\n",
      "\n",
      "--- Limb L4 soma calculation time = 0.055\n",
      "\n",
      "--- Limb L5 soma calculation time = 0.058\n",
      "\n",
      "--- Limb L6 soma calculation time = 0.031\n",
      "\n",
      "--- Limb L7 soma calculation time = 0.0\n",
      "\n",
      "--- Limb L8 soma calculation time = 0.113\n",
      "\n",
      "--- Limb L9 soma calculation time = 0.087\n",
      "Putting Soma Placeholders\n",
      "\n",
      "--- Soma 0 soma calculation time = 0.0\n",
      "Putting Error Placeholders\n",
      "\n",
      "--- Error soma calculation time = 0.058\n",
      "Total soma distance calculation time = 1.870804786682129\n",
      "Time for 6754 synapse entries = 0.043234825134277344\n",
      "Time for 206 synapse entries = 0.0008127689361572266\n",
      "# of synapses in query = 52\n",
      "# of total_error_synapse_ids = 206\n",
      "set_presyns_on_dendrite_as_errors to default of True\n",
      "presyn_error = [371446679 362678282 384856723 389760801 404100809 409518729 424026551\n",
      " 420152653 411232292 411232574 423839819 424871582 425231251 449782140\n",
      " 449782176 449782210 449782406 431423059 440209727 425317200 436116473\n",
      " 436116478 436465398 437647769 453727922 463656101 463658803 453741839\n",
      " 438195770 446102210 453839623 459099216 459099325 431590648 424690899\n",
      " 452112239 452382962 455073201 458105885 458106275 451470040 451484074\n",
      " 451484099 451484140 451485377 451485615 418101906 425180586 403819916\n",
      " 425149160 418379227 418379239]\n",
      "\n",
      "--- Finished Part 2: Filtering Synapses -----\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 6960\n",
      "n_valid_syn_ids_presyn = 51\n",
      "n_errored_syn_ids_presyn = 181\n",
      "n_valid_syn_ids_postsyn = 6703\n",
      "n_errored_syn_ids_postsyn = 25\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 6960\n",
      "n_valid_syn_ids_presyn = 51\n",
      "n_errored_syn_ids_presyn = 181\n",
      "n_valid_syn_ids_postsyn = 6703\n",
      "n_errored_syn_ids_postsyn = 25\n",
      "\n",
      "--- Finished Part 3: Generating Validation Dataframe -----\n",
      "\n",
      "\n",
      " ----- Done Filtering ----------\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135501833053_0_25_soma_0_split_axon_v6_v6_val\n",
      "Save time = 178.62618350982666\n",
      "Postsyn counts:\n",
      "TP:6694\n",
      "TN:14\n",
      "FP:9\n",
      "FN:11\n",
      "\n",
      "\n",
      " ***------ Total time for 864691135864188286 = 627.89 ------ ***\n",
      "\n",
      "-- Working on neuron 864691136451224831---\n",
      "nuc_center_coords = [1348992  507328  695480]\n",
      "old_segment_id = 864691135726145172\n",
      "# of somas = 1 and # of DecompositionCellType = 1\n",
      "**Using table __decomposition_cell_type for table_to_neuron_objs**\n",
      "Decompressing Neuron in minimal output mode...please wait\n",
      "Number of Neurons found = 1\n",
      "\n",
      "*****Using v6 Filters!!!\n",
      "\n",
      "\n",
      "\n",
      "--- Working on filter 0:\n",
      "function = axon_on_dendrite_merges\n",
      "function __name__ = filter_away_axon_on_dendrite_merges\n",
      "function arguments = {'use_pre_existing_axon_labels': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "\n",
      "--- Working on filter 1:\n",
      "function = high_degree_branching\n",
      "function __name__ = filter_away_high_degree_branching\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {'L5': array([35, 37, 52, 54, 50, 51, 53])}\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "\n",
      "--- Working on filter 2:\n",
      "function = axon_webbing_t_merges\n",
      "function __name__ = filter_away_webbing_t_merges\n",
      "function arguments = {'child_width_maximum': 75, 'parent_width_maximum': 75, 'axon_only': True, 'error_if_web_is_none': True, 'web_size_threshold': 120, 'web_size_type': 'ray_trace_median', 'web_above_threshold': True}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 3:\n",
      "function = thick_t_merge\n",
      "function __name__ = filter_away_thick_t_merge\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 4:\n",
      "function = width_jump_up_dendrite\n",
      "function __name__ = filter_away_width_jump_up_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 5:\n",
      "function = width_jump_up_axon\n",
      "function __name__ = filter_away_width_jump_up_axon\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 6:\n",
      "function = double_back_dendrite\n",
      "function __name__ = filter_away_double_back_dendrite\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 7:\n",
      "function = double_back_axon_thin\n",
      "function __name__ = filter_away_double_back_axon_thin\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 8:\n",
      "function = double_back_axon_thick\n",
      "function __name__ = filter_away_double_back_axon_thick\n",
      "function arguments = {}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "--- Working on filter 9:\n",
      "function = axon_fork_divergence\n",
      "function __name__ = filter_away_small_axon_fork_divergence\n",
      "function arguments = {'divergence_threshold_mean': 165}\n",
      "\n",
      "\n",
      "Recieved another instance of Neuron class in init -- so just copying data\n",
      "limb_branch_dict_to_cancel = {}\n",
      "\n",
      "\n",
      "\n",
      " ---- Total time for applying filter: 104.12810325622559 -----\n",
      "\n",
      "--- Finished Part 1: Filtering Neuron -----\n",
      "\n",
      "---Step 1: Computing synapse_dict---\n",
      "# of beginning_direct_connections = 5196 \n",
      "# of presyn: 191\n",
      "# of postsyn: 5005\n",
      "\n",
      "---Step 2: Computing mesh_label_dict---\n",
      "-- Working on presyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 0\n",
      "# of mesh_errored_syn_idx = 151\n",
      "# of valid_syn_idx = 40\n",
      "-- Working on postsyn--\n",
      "Using original_mesh_method\n",
      "# of distance_errored_syn_idx = 1\n",
      "# of mesh_errored_syn_idx = 18\n",
      "# of valid_syn_idx = 4986\n",
      "\n",
      "---Step 4: add_error_synapses_to_neuron_obj---\n",
      "Working on error_type = distance_errored\n",
      "Working on error_type = mesh_errored\n",
      "Total time for valid synapse objects = 0.0012764930725097656\n",
      "\n",
      "--- Limb L0 soma calculation time = 0.799\n",
      "\n",
      "--- Limb L1 soma calculation time = 0.291\n",
      "\n",
      "--- Limb L2 soma calculation time = 0.146\n",
      "\n",
      "--- Limb L3 soma calculation time = 0.139\n",
      "\n",
      "--- Limb L4 soma calculation time = 0.137\n",
      "\n",
      "--- Limb L5 soma calculation time = 0.0\n",
      "\n",
      "--- Limb L6 soma calculation time = 0.127\n",
      "\n",
      "--- Limb L7 soma calculation time = 0.102\n",
      "\n",
      "--- Limb L8 soma calculation time = 0.061\n",
      "Putting Soma Placeholders\n",
      "\n",
      "--- Soma 0 soma calculation time = 0.0\n",
      "Putting Error Placeholders\n",
      "\n",
      "--- Error soma calculation time = 0.05\n",
      "Total soma distance calculation time = 1.8522346019744873\n",
      "Time for 4990 synapse entries = 0.032878875732421875\n",
      "Time for 206 synapse entries = 0.0008716583251953125\n",
      "# of synapses in query = 36\n",
      "# of total_error_synapse_ids = 206\n",
      "set_presyns_on_dendrite_as_errors to default of True\n",
      "presyn_error = [399065291 399066287 406747241 406887049 416136387 416136505 416183727\n",
      " 416811611 416811904 416812054 417928189 418404972 423872267 423956625\n",
      " 439195666 467405134 467405297 411875295 426035422 444515800 445205360\n",
      " 449076764 430341903 430342986 403787253 403788780 403788791 400279791\n",
      " 413588627 418040710 418774953 432579332 441440768 441842468 445995450\n",
      " 411690621]\n",
      "\n",
      "--- Finished Part 2: Filtering Synapses -----\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 5196\n",
      "n_valid_syn_ids_presyn = 4\n",
      "n_errored_syn_ids_presyn = 187\n",
      "n_valid_syn_ids_postsyn = 4986\n",
      "n_errored_syn_ids_postsyn = 19\n",
      "Synapsse Results:\n",
      "Total Number of Synapses = 5196\n",
      "n_valid_syn_ids_presyn = 4\n",
      "n_errored_syn_ids_presyn = 187\n",
      "n_valid_syn_ids_postsyn = 4986\n",
      "n_errored_syn_ids_postsyn = 19\n",
      "\n",
      "--- Finished Part 3: Generating Validation Dataframe -----\n",
      "\n",
      "\n",
      " ----- Done Filtering ----------\n",
      "Saving Neuorn in suppress_output mode...please wait\n",
      "Saved File at location: /mnt/dj-stor01/platinum/minnie65/02/decomposition/864691135726145172_0_25_axon_v6_v6_val\n",
      "Save time = 108.26951003074646\n",
      "Postsyn counts:\n",
      "TP:4971\n",
      "TN:7\n",
      "FP:15\n",
      "FN:12\n",
      "\n",
      "\n",
      " ***------ Total time for 864691136451224831 = 289.3 ------ ***\n",
      "Populate Done\n",
      "Total time for AutoProofreadValidationScore6 populate = 1528.5439553260803\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "pru = reload(pru)\n",
    "nru = reload(nru)\n",
    "import neuron\n",
    "neuron = reload(neuron)\n",
    "import datajoint_utils as du\n",
    "du = reload(du)\n",
    "\n",
    "start_time = time.time()\n",
    "if not test_mode:\n",
    "    time.sleep(random.randint(0, 800))\n",
    "print('Populate Started')\n",
    "if not test_mode:\n",
    "    AutoProofreadValidationScore6.populate(reserve_jobs=True, suppress_errors=True, order=\"random\")\n",
    "else:\n",
    "    AutoProofreadValidationScore6.populate(reserve_jobs=True, suppress_errors=False,order=\"random\")\n",
    "print('Populate Done')\n",
    "\n",
    "print(f\"Total time for AutoProofreadValidationScore6 populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
