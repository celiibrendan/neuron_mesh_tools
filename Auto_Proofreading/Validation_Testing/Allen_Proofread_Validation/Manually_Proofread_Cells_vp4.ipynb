{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To set up the tables that will \n",
    "be used for validation and to test the \n",
    "overall progress\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "sys.path.append(\"/meshAfterParty/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint_utils as du\n",
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import neuron_visualizations as nviz\n",
    "import datajoint as dj\n",
    "\n",
    "import proofreading_utils as pru\n",
    "import classification_utils as clu\n",
    "\n",
    "import neuron_utils as nru\n",
    "import validation_utils as vu\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validation_utils as vu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the Proofread Cells for the Vallidation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minnie.AutoProofreadValidationNeurons3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 864691136618412685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.plot_proofread_neuron(segment_id=segment_id,\n",
    "                       split_index=0,\n",
    "\n",
    "\n",
    "                      #for plotting the error faces\n",
    "                       plot_errored_faces=True,\n",
    "                       errored_faces_color=[1,0,0,0.2],\n",
    "\n",
    "                      #for plotting the synapse\n",
    "                      plot_synapses=True,\n",
    "                      synapse_scatter_size=0.3,\n",
    "                      valid_presyn_color=\"yellow\",\n",
    "                      valid_postsyn_color=\"aqua\",\n",
    "                      error_presyn_color=\"black\",\n",
    "                      error_postsyn_color=\"orange\",\n",
    "\n",
    "\n",
    "                      plot_nuclei=True,\n",
    "                      nuclei_color = \"brown\",\n",
    "                      nuclei_size = 1,#2500,\n",
    "                      nuclei_plot_type=\"scatter\",#other option is mesh\n",
    "\n",
    "                      plot_paired_nuceli=True,\n",
    "                      paired_nuclei_color = \"lime\",\n",
    "\n",
    "                      plot_axon=True,\n",
    "                      validation = True,\n",
    "                         \n",
    "                         plot_error_synapses=True,\n",
    "\n",
    "              verbose=False,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Statistics For the Neuron Proofreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_ids = du.proofreading_stats_table(validation=True).fetch(\"segment_id\")\n",
    "\n",
    "validation_dfs = [vu.synapse_validation_df_single_neuron(k,\n",
    "                                        remove_presyn_on_dendrite = False,\n",
    "                        count_presyn_on_dendrite_as_correct = True,) for k in segment_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dfs = [vu.synapse_validation_df_to_score_df(v_df)\n",
    "             for v_df in validation_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu.score_scatterplot(df = score_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the FP,FN information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = pd.concat(score_dfs)[[\"Type\",\"recall\",\"precision\",\"f1\"]]\n",
    "collapsed_df = new_dict.groupby(\"Type\").mean()\n",
    "\n",
    "vu.plot_scores(#need to order by \n",
    "    score_df = collapsed_df,\n",
    "    synapse_types = [\"presyn\",\"postsyn\",\"both\"],\n",
    "    score_types = [\"precision\",\"recall\",\"f1\"],\n",
    "    y_label='Statistics (Mean)',\n",
    "    title = \"Autoproofreading Validation (Mean) \\n Version 2\")\n",
    "\n",
    "collapsed_df = new_dict.groupby(\"Type\").median()\n",
    "\n",
    "vu.plot_scores(#need to order by \n",
    "    score_df = collapsed_df,\n",
    "    synapse_types = [\"presyn\",\"postsyn\",\"both\"],\n",
    "    score_types = [\"precision\",\"recall\",\"f1\"],\n",
    "    y_label='Statistics (Median)',\n",
    "    title = \"Autoproofreading Validation (Median) \\n Version 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The complete numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dfs_combined = pd.concat(validation_dfs)\n",
    "\n",
    "score_combined = vu.synapse_validation_df_to_score_df(validation_dfs_combined)\n",
    "total_score_df = score_combined[[\"Type\",\"precision\",\"recall\",\"f1\"]]\n",
    "total_score_df = total_score_df.set_index(\"Type\")\n",
    "total_score_df\n",
    "# score_dfs = [vu.synapse_validation_df_to_score_df(v_df)\n",
    "#              for v_df in validation_dfs]\n",
    "# score_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu.plot_scores(#need to order by \n",
    "    score_df = total_score_df,\n",
    "    synapse_types = [\"presyn\",\"postsyn\",\"both\"],\n",
    "    score_types = [\"precision\",\"recall\",\"f1\"],\n",
    "    y_label='Statistics',\n",
    "    title = \"Autoproofreading Validation (Cumulative) \\n Version 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Graph 1 -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.plot_proofread_neuron(segment_id,\n",
    "                        validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "Purpose: To graph a score feature against a neuron morphology statistic\n",
    "\n",
    "Pseudocode: \n",
    "1) Get the score statistic for ever neuron\n",
    "2) Get the morphological feature for every neuron\n",
    "3) Plot them against each other\n",
    "4) Optionally plot the histogram of each as well\n",
    "\"\"\"\n",
    "synapse_type = \"presyn\"\n",
    "score_statistic = \"recall\"\n",
    "score_tables = score_dfs\n",
    "morphology_statistic = \"axon_length\"\n",
    "verbose = True\n",
    "plot_individual_histograms = True\n",
    "fig_width = 5\n",
    "fig_height = 5\n",
    "\n",
    "score_statistic_name = f\"{synapse_type} {score_statistic}\"\n",
    "morphology_statistic_name = \"Axon Skeletal Length (um)\"\n",
    "\n",
    "#1) Get the score statistic for ever neuron\n",
    "score_per_neuron = []\n",
    "morph_per_neuron = []\n",
    "for j,k in enumerate(score_tables):\n",
    "    \n",
    "    #get the neuron name\n",
    "    curr_segment_id =k[\"old_segment_id\"][0]\n",
    "    \n",
    "    curr_score = k[(k[\"Type\"] == synapse_type)][score_statistic].to_list()[0] \n",
    "    score_per_neuron.append(curr_score)\n",
    "    \n",
    "    \n",
    "\n",
    "    #2) Get the morphological feature for every neuron\n",
    "    curr_morph = du.segment_id_to_autoproofread_neuron_features(segment_id = curr_segment_id,\n",
    "                                                   #split_index = 0,\n",
    "                                                   statistic_names = [morphology_statistic],\n",
    "                                                   validation = True,\n",
    "                                        )\n",
    "    morph_per_neuron.append(curr_morph)\n",
    "    \n",
    "    if False:\n",
    "        print(f\"Working on neuron {j}: {score_statistic} = {curr_score}, {morphology_statistic} = {curr_morph}\")\n",
    "\n",
    "#3) Plot them against each other\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "ax.scatter(morph_per_neuron,score_per_neuron)\n",
    "ax.set_xlabel(morphology_statistic_name)\n",
    "ax.set_ylabel(score_statistic_name)\n",
    "ax.set_title(f\"\")\n",
    "fig.show()\n",
    "\n",
    "if plot_individual_histograms:\n",
    "    individuals_names = [morphology_statistic_name,score_statistic_name]\n",
    "    individuals_data = [morph_per_neuron,score_per_neuron]\n",
    "    \n",
    "    for n,d in zip(individuals_names,individuals_data):\n",
    "        fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "        ax.hist(d,bins=20)\n",
    "        ax.set_xlabel(n)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"{n} frequency\")\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall Drop Off With Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To get the recall of each neuron (and overall)\n",
    "as a function of the euclidean distance from the soma center\n",
    "\n",
    "Pseudocode: \n",
    "a) Get the validation dataframes for all neurons (that come along with the synapse coordinates)\n",
    "b) Create a range of distance restrictions based on max and min distanes\n",
    "c) Create a sampling array for distances\n",
    "d) Iterate through the sampliing:\n",
    "   i) restrict the table to synapses under that distance\n",
    "   2) Compute the recall\n",
    "   3) Save in array\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_ids = du.proofreading_stats_table(validation=True).fetch(\"segment_id\")\n",
    "\n",
    "validation_dfs = [vu.synapse_validation_df_single_neuron(k,\n",
    "                                        remove_presyn_on_dendrite = False,\n",
    "                        count_presyn_on_dendrite_as_correct = True,) for k in segment_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment_id = 864691136008425132\n",
    "\n",
    "# curr_mesh = du.fetch_segment_id_mesh(segment_id)\n",
    "# soma_center = du.fetch_neuron_soma_center(segment_id)\n",
    "# nviz.plot_objects(curr_mesh,\n",
    "#                  scatters=[soma_center],\n",
    "#                  scatter_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_validation_df = pd.concat(validation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_length = 2000\n",
    "curr_query = f\"axon_length>{axon_length}\"\n",
    "curr_query_title = f\"Axon Length > {axon_length} um\"\n",
    "seg_ids_in_query = (minnie.AutoProofreadValidationNeurons() & curr_query).fetch(\"segment_id\")\n",
    "\n",
    "current_validation_df = cumulative_validation_df[cumulative_validation_df[\"old_segment_id\"].isin(seg_ids_in_query)]\n",
    "\n",
    "vu.score_vs_euclidean_synapse_threshold_analysis(current_validation_df,\n",
    "                                                title_append=f\"Neurons with {curr_query_title} ({len(seg_ids_in_query)} Neurons)\\n Version 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding The Stats for Different Types of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu.score_vs_euclidean_synapse_threshold_analysis(cumulative_validation_df,\n",
    "                                                title_append=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of the Recall Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu.synapse_distance_samples(cumulative_validation_df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict,n_syn_dict = vu.compute_score_as_function_of_synapse_euclidean_distance(cumulative_validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu.plot_score_as_function_of_synapse_euclidean_distance(score_dict,\n",
    "                                                     n_synapses_dict=n_syn_dict,\n",
    "                                                         title_append=\"Total\",\n",
    "                                                        plot_synapse_histograms=True,\n",
    "                                                       validation_df =cumulative_validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_dist = cumulative_validation_df[\"euclidean_distance_to_nuclei\"].to_numpy()\n",
    "_ = plt.hist(synapse_dist,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_distance_boundaries = [np.percentile(synapse_dist,5),np.percentile(synapse_dist,99)]\n",
    "syn_distance_interval = 5000\n",
    "syn_distance_samples = np.arange(*syn_distance_boundaries,syn_distance_interval)\n",
    "syn_distance_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_score[curr_score[\"Type\"] == s_type][\"recall\"].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_by_synapse_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Iterate through the sampliing:\n",
    "#    i) restrict the table to synapses under that distance\n",
    "#    2) Compute the recall\n",
    "#    3) Save in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_table[curr_table[\"synapse_type\"] == \"presyn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm_utils import tqdm\n",
    "validation_table = cumulative_validation_df\n",
    "\n",
    "\n",
    "for synapse_type in synapse_types:\n",
    "\n",
    "    title = f\"{synapse_type.capitalize()} Recall vs Synapses Within Euclidean Threshold\"\n",
    "    synapse_distances = syn_distance_samples/1000\n",
    "\n",
    "    recall_stats = recall_by_synapse_type[synapse_type]\n",
    "\n",
    "    #3) Plot them against each other\n",
    "    fig, axes = plt.subplots(1,2,figsize=(fig_width*2, fig_height))\n",
    "    ax = axes[0]\n",
    "    \n",
    "    ax.plot(synapse_distances,recall_stats)\n",
    "    ax.set_xlabel(f\"Euclidean Threshold (um)\")\n",
    "    ax.set_ylabel(f\"{synapse_type.capitalize()} Recall\")\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    syn_totals = n_synapses_by_synapse_type[synapse_type]\n",
    "    \n",
    "    title = f\"{synapse_type.capitalize()} Count vs Synapses Within Euclidean Threshold\"\n",
    "    ax = axes[1]\n",
    "    ax.plot(synapse_distances,syn_totals)\n",
    "    ax.set_xlabel(f\"Euclidean Threshold (um)\")\n",
    "    ax.set_ylabel(f\"Number of {synapse_type.capitalize()} Synapses\")\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To plot the recall vs synaptic distance\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for synapse_type in synapse_types:\n",
    "\n",
    "    title = f\"{synapse_type.capitalize()} Recall vs Synapses Within Euclidean Threshold\"\n",
    "    synapse_distances = syn_distance_samples/1000\n",
    "\n",
    "    recall_stats = recall_by_synapse_type[synapse_type]\n",
    "\n",
    "    #3) Plot them against each other\n",
    "    fig, axes = plt.subplots(1,2,figsize=(fig_width*2, fig_height))\n",
    "    ax = axes[0]\n",
    "    \n",
    "    ax.plot(synapse_distances,recall_stats)\n",
    "    ax.set_xlabel(f\"Euclidean Threshold (um)\")\n",
    "    ax.set_ylabel(f\"{synapse_type.capitalize()} Recall\")\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    syn_totals = n_synapses_by_synapse_type[synapse_type]\n",
    "    \n",
    "    title = f\"{synapse_type.capitalize()} Count vs Synapses Within Euclidean Threshold\"\n",
    "    ax = axes[1]\n",
    "    ax.plot(synapse_distances,syn_totals)\n",
    "    ax.set_xlabel(f\"Euclidean Threshold (um)\")\n",
    "    ax.set_ylabel(f\"Number of {synapse_type.capitalize()} Synapses\")\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minnie.AutoProofreadNeurons2() & dict(spine_category=\"densely_spined\") & \"axon_length>2000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
