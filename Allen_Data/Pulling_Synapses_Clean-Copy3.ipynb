{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To pull down the earliest version of thhe synapses from 11/9\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To pull down the earliest version of thhe synapses from 11/9\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "from annotationframeworkclient import FrameworkClient\n",
    "from IPython import html, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FrameworkClient('minnie65_phase3_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the synapses for the neurons we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-25 17:54:53,770 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2020-11-25 17:54:53,772 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2020-11-25 17:54:53,785 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-25 17:54:54,005 - settings - Setting enable_python_native_blobs to True\n"
     ]
    }
   ],
   "source": [
    "minnie,schema = du.configure_minnie_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "soma_segment_ids = np.unique((minnie.BaylorSegmentCentroid & \"multiplicity>0\").fetch(\"segment_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1231.3333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fix_dataframe_and_return_dict(df):\n",
    "    if len(df) == 0:\n",
    "        return []\n",
    "    df[[\"centroid_x\",\"centroid_y\",\"centroid_z\"]] = pd.DataFrame(df[\"ctr_pt_position\"].tolist(),index=df.index)\n",
    "    df_renamed = df.rename(columns=dict(pre_pt_root_id=\"presyn\",post_pt_root_id=\"postsyn\",id=\"synapse_id\"))\n",
    "    B = df_renamed.drop([\"valid\",\"pre_pt_position\",\"ctr_pt_position\",\"post_pt_position\"],axis=1)\n",
    "    B = B.astype({'size': \"int32\"})\n",
    "    #print(B.dtypes)\n",
    "    return B.to_dict(\"records\")\n",
    "\n",
    "\n",
    "\n",
    "verbose = False\n",
    "\n",
    "step_size = 10\n",
    "max_return_size = 200000\n",
    "total_ids = soma_segment_ids\n",
    "n_iterations = int(np.ceil(len(total_ids)/step_size))\n",
    "n_jobs = 6\n",
    "iterations_per_job = n_iterations/n_jobs\n",
    "iterations_per_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c126cd611f79488aacdf28f0c3dd1d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1925.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pseudocode: \n",
    "\n",
    "in batches of 100 segment ids\n",
    "\n",
    "for both presyn and postsyn:\n",
    "1) Get the rows for that attirbute and those segments and turn into dictionaries and add to list\n",
    "2a) If the result is less than 200k don't need to repeat again \n",
    "2b) If they are greater, then repeat 1 and 2 (and add offset) until less than 200k\n",
    "3) Write the entries to datajoint\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "job_idx = 4\n",
    "\n",
    "\n",
    "for i in tqdm(range(int(iterations_per_job*job_idx)+538,n_iterations)):\n",
    "    if i == (n_iterations - 1):\n",
    "        curr_seg_ids =  total_ids[i*step_size:]\n",
    "    else:\n",
    "        curr_seg_ids = total_ids[i*step_size:(i+1)*step_size]\n",
    "        \n",
    "    total_dicts = []\n",
    "    for filter_type in [\"pre_pt_root_id\",\"post_pt_root_id\"]:\n",
    "        curr_filter_dict = {filter_type:curr_seg_ids}\n",
    "        curr_offset = 0\n",
    "        #print(f\"curr_filter_dict = {curr_filter_dict}\")\n",
    "        while True:\n",
    "            df = client.materialize.query_table('synapses_pni_2',\n",
    "                                                #filter_in_dict=dict(func_id=[58941,16062]),\n",
    "                                                filter_in_dict=curr_filter_dict, #just excludes those\n",
    "\n",
    "                                                #filter_equal_dict=dict(func_id=58941),\n",
    "                                               offset=curr_offset ,#this is an integer that will set the offset\n",
    "                                                #select_columns=columns_we_want\n",
    "                                               )\n",
    "            \n",
    "            df_dicts = fix_dataframe_and_return_dict(df)\n",
    "            total_dicts += df_dicts\n",
    "            if len(df_dicts) < max_return_size:\n",
    "                break\n",
    "            else:\n",
    "                curr_offset += max_return_size\n",
    "    \n",
    "    #write the data to the datajoint table\n",
    "    if len(total_dicts) > 0:\n",
    "        if verbose:\n",
    "            print(f\"Inserting {len(total_dicts)} dictionaries \")\n",
    "        minnie.SynapseTest.insert(total_dicts,skip_duplicates=True)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"Skipping dictionary insertion because it was empty\")\n",
    "            \n",
    "    \n",
    "    #raise Exception(\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datajoint table to dump the results into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
