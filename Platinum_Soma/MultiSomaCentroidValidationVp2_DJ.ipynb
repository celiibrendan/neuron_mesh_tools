{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n**MORE ROBUST SOMA FINDNG ALGORITHM**\\nPurpose: Creates the table that will store the soma centroid from meshes used for testing\\n\\nPseudocode: \\n1) Pull down the mesh\\n2) Create a folder where all of the mesh pieces will be stored\\n3) Run the soma extraction to get the soma meshes\\n4) Calculate the soma centers and save the distance from the predicted soma centers\\n5) Things then to save off:\\n- index of the soma (based on tehe number of somas found for that one mesh)\\n- the soma center\\n- Distance from predicted soma center\\n- Mesh of the soma\\n- Time it took\\n6) Delete all the temporary files that were used for that certain mesh\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "**MORE ROBUST SOMA FINDNG ALGORITHM**\n",
    "Purpose: Creates the table that will store the soma centroid from meshes used for testing\n",
    "\n",
    "Pseudocode: \n",
    "1) Pull down the mesh\n",
    "2) Create a folder where all of the mesh pieces will be stored\n",
    "3) Run the soma extraction to get the soma meshes\n",
    "4) Calculate the soma centers and save the distance from the predicted soma centers\n",
    "5) Things then to save off:\n",
    "- index of the soma (based on tehe number of somas found for that one mesh)\n",
    "- the soma center\n",
    "- Distance from predicted soma center\n",
    "- Mesh of the soma\n",
    "- Time it took\n",
    "6) Delete all the temporary files that were used for that certain mesh\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@10.28.0.34:3306\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "m65 = dj.create_virtual_module('m65', 'microns_minnie65_01')\n",
    "schema = dj.schema(\"microns_minnie65_01\")\n",
    "dj.config[\"display.limit\"] = 30\n",
    "\n",
    "import minfig\n",
    "minnie = minfig.configure_minnie(return_virtual_module=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Renaming Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_table = dj.U(\"segment_id\",\"version\") & minnie.BaylorSegmentCentroid()\n",
    "\n",
    "# @schema\n",
    "# class BaylorTest(dj.Computed):\n",
    "#     definition=\"\"\"\n",
    "#     ->new_table\n",
    "#     ---\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgal_Segmentation_Module as csm\n",
    "from whole_neuron_classifier_datajoint_adapted import extract_branches_whole_neuron\n",
    "import whole_neuron_classifier_datajoint_adapted as wcda \n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import os\n",
    "from meshlab import Decimator , Poisson\n",
    "from pathlib import Path\n",
    "from pykdtree.kdtree import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>Segment IDs of core segments with multiple somas identified by the Allen Institute.</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation, should be mirrored in Segment table.</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">status</p>\n",
       "                                <span class=\"djtooltiptext\">verification status (NULL=not checked, 0=ignore, 1=partial, 2=complete)</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>77489456693007645</td>\n",
       "<td>5</td></tr><tr><td>81639563398742139</td>\n",
       "<td>2</td></tr><tr><td>82269790323894531</td>\n",
       "<td>2</td></tr><tr><td>84106524699939179</td>\n",
       "<td>3</td></tr><tr><td>86015414123380349</td>\n",
       "<td>2</td></tr><tr><td>86988687602705632</td>\n",
       "<td>2</td></tr><tr><td>89387891029279745</td>\n",
       "<td>2</td></tr><tr><td>90153356676844854</td>\n",
       "<td>2</td></tr><tr><td>90518669414951752</td>\n",
       "<td>2</td></tr><tr><td>90939989466098088</td>\n",
       "<td>2</td></tr><tr><td>91208269699305759</td>\n",
       "<td>2</td></tr><tr><td>92345990027434104</td>\n",
       "<td>2</td></tr><tr><td>94031059578350884</td>\n",
       "<td>2</td></tr><tr><td>94531956582329737</td>\n",
       "<td>2</td></tr><tr><td>96147481821744505</td>\n",
       "<td>2</td></tr><tr><td>102894772968611589</td>\n",
       "<td>2</td></tr><tr><td>107319757380005445</td>\n",
       "<td>6</td></tr><tr><td>107681564887986552</td>\n",
       "<td>2</td></tr><tr><td>107738877133006848</td>\n",
       "<td>4</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 19</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segment_id    status    \n",
       "+------------+ +--------+\n",
       "77489456693007 5         \n",
       "81639563398742 2         \n",
       "82269790323894 2         \n",
       "84106524699939 3         \n",
       "86015414123380 2         \n",
       "86988687602705 2         \n",
       "89387891029279 2         \n",
       "90153356676844 2         \n",
       "90518669414951 2         \n",
       "90939989466098 2         \n",
       "91208269699305 2         \n",
       "92345990027434 2         \n",
       "94031059578350 2         \n",
       "94531956582329 2         \n",
       "96147481821744 2         \n",
       "10289477296861 2         \n",
       "10731975738000 6         \n",
       "10768156488798 2         \n",
       "10773887713300 4         \n",
       " (Total: 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m65.AllenMultiSomas() & \"status > 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Segments That have multiple somas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>Decimated meshes</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">version</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_ratio</p>\n",
       "                                <span class=\"djtooltiptext\">ratio of remaining mesh vertices/faces (which ones depends on what metric the decimation technique uses)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_vertices</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_faces</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">mesh</p>\n",
       "                                <span class=\"djtooltiptext\">in-place path to the hdf5 (decimated) mesh file</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>77489456693007645</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>218373</td>\n",
       "<td>438232</td>\n",
       "<td>=BLOB=</td></tr><tr><td>81639563398742139</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>737715</td>\n",
       "<td>1478740</td>\n",
       "<td>=BLOB=</td></tr><tr><td>89387891029279745</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>577007</td>\n",
       "<td>1155202</td>\n",
       "<td>=BLOB=</td></tr><tr><td>90153356676844854</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>544744</td>\n",
       "<td>1090856</td>\n",
       "<td>=BLOB=</td></tr><tr><td>90518669414951752</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>147610</td>\n",
       "<td>296288</td>\n",
       "<td>=BLOB=</td></tr><tr><td>90939989466098088</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>369403</td>\n",
       "<td>740740</td>\n",
       "<td>=BLOB=</td></tr><tr><td>91208269699305759</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>1550148</td>\n",
       "<td>3100434</td>\n",
       "<td>=BLOB=</td></tr><tr><td>94031059578350884</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>1166108</td>\n",
       "<td>2335958</td>\n",
       "<td>=BLOB=</td></tr><tr><td>94531956582329737</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>305789</td>\n",
       "<td>616274</td>\n",
       "<td>=BLOB=</td></tr><tr><td>96147481821744505</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>110154</td>\n",
       "<td>220298</td>\n",
       "<td>=BLOB=</td></tr><tr><td>102894772968611589</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>600402</td>\n",
       "<td>1204160</td>\n",
       "<td>=BLOB=</td></tr><tr><td>107319757380005445</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>385607</td>\n",
       "<td>774152</td>\n",
       "<td>=BLOB=</td></tr><tr><td>107681564887986552</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>1455588</td>\n",
       "<td>2922789</td>\n",
       "<td>=BLOB=</td></tr><tr><td>107738877133006848</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>1361540</td>\n",
       "<td>2746652</td>\n",
       "<td>=BLOB=</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 14</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segment_id    *version    *decimation_ra n_vertices     n_faces     mesh      \n",
       "+------------+ +---------+ +------------+ +------------+ +---------+ +--------+\n",
       "77489456693007 0           0.25           218373         438232      =BLOB=    \n",
       "81639563398742 0           0.25           737715         1478740     =BLOB=    \n",
       "89387891029279 0           0.25           577007         1155202     =BLOB=    \n",
       "90153356676844 0           0.25           544744         1090856     =BLOB=    \n",
       "90518669414951 0           0.25           147610         296288      =BLOB=    \n",
       "90939989466098 0           0.25           369403         740740      =BLOB=    \n",
       "91208269699305 0           0.25           1550148        3100434     =BLOB=    \n",
       "94031059578350 0           0.25           1166108        2335958     =BLOB=    \n",
       "94531956582329 0           0.25           305789         616274      =BLOB=    \n",
       "96147481821744 0           0.25           110154         220298      =BLOB=    \n",
       "10289477296861 0           0.25           600402         1204160     =BLOB=    \n",
       "10731975738000 0           0.25           385607         774152      =BLOB=    \n",
       "10768156488798 0           0.25           1455588        2922789     =BLOB=    \n",
       "10773887713300 0           0.25           1361540        2746652     =BLOB=    \n",
       " (Total: 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minnie.Decimation() & (m65.AllenMultiSomas() & \"status > 0\").proj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Segments with One Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b>Decimated meshes</b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">version</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_ratio</p>\n",
       "                                <span class=\"djtooltiptext\">ratio of remaining mesh vertices/faces (which ones depends on what metric the decimation technique uses)</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_vertices</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">n_faces</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"nonprimary\">mesh</p>\n",
       "                                <span class=\"djtooltiptext\">in-place path to the hdf5 (decimated) mesh file</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>77000105634561899</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>208308</td>\n",
       "<td>417500</td>\n",
       "<td>=BLOB=</td></tr><tr><td>77490624856971637</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>81815</td>\n",
       "<td>163578</td>\n",
       "<td>=BLOB=</td></tr><tr><td>77773542942770096</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>197032</td>\n",
       "<td>394454</td>\n",
       "<td>=BLOB=</td></tr><tr><td>77907065489896172</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>102538</td>\n",
       "<td>205050</td>\n",
       "<td>=BLOB=</td></tr><tr><td>78488706738250432</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>131596</td>\n",
       "<td>272384</td>\n",
       "<td>=BLOB=</td></tr><tr><td>78971460928405166</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>214377</td>\n",
       "<td>429344</td>\n",
       "<td>=BLOB=</td></tr><tr><td>80512770407472498</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>227270</td>\n",
       "<td>454884</td>\n",
       "<td>=BLOB=</td></tr><tr><td>80583139755390727</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>340287</td>\n",
       "<td>681892</td>\n",
       "<td>=BLOB=</td></tr><tr><td>81082729277563634</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>225506</td>\n",
       "<td>451734</td>\n",
       "<td>=BLOB=</td></tr><tr><td>81160726756366710</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>50916</td>\n",
       "<td>101784</td>\n",
       "<td>=BLOB=</td></tr><tr><td>81499994678854295</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>259432</td>\n",
       "<td>521264</td>\n",
       "<td>=BLOB=</td></tr><tr><td>81722920929926107</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>200701</td>\n",
       "<td>402310</td>\n",
       "<td>=BLOB=</td></tr><tr><td>82071327468690082</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>123960</td>\n",
       "<td>246178</td>\n",
       "<td>=BLOB=</td></tr><tr><td>82556557103630384</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>75053</td>\n",
       "<td>150046</td>\n",
       "<td>=BLOB=</td></tr><tr><td>83404485518874835</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>460417</td>\n",
       "<td>922298</td>\n",
       "<td>=BLOB=</td></tr><tr><td>83970321556114526</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>96123</td>\n",
       "<td>191242</td>\n",
       "<td>=BLOB=</td></tr><tr><td>84178679680719429</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>340331</td>\n",
       "<td>684646</td>\n",
       "<td>=BLOB=</td></tr><tr><td>84947857186329612</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>256659</td>\n",
       "<td>515456</td>\n",
       "<td>=BLOB=</td></tr><tr><td>85235241769692816</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>267640</td>\n",
       "<td>536634</td>\n",
       "<td>=BLOB=</td></tr><tr><td>85379690109601323</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>312949</td>\n",
       "<td>626674</td>\n",
       "<td>=BLOB=</td></tr><tr><td>85934737323299893</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>183481</td>\n",
       "<td>367116</td>\n",
       "<td>=BLOB=</td></tr><tr><td>86984220970630648</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>311586</td>\n",
       "<td>622870</td>\n",
       "<td>=BLOB=</td></tr><tr><td>87070120987950376</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>65254</td>\n",
       "<td>130632</td>\n",
       "<td>=BLOB=</td></tr><tr><td>87477008539482641</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>170066</td>\n",
       "<td>339974</td>\n",
       "<td>=BLOB=</td></tr><tr><td>87770714912059957</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>179142</td>\n",
       "<td>358716</td>\n",
       "<td>=BLOB=</td></tr><tr><td>88127300343946400</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>123748</td>\n",
       "<td>247904</td>\n",
       "<td>=BLOB=</td></tr><tr><td>88252026865422450</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>395516</td>\n",
       "<td>791034</td>\n",
       "<td>=BLOB=</td></tr><tr><td>88257180826426268</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>185801</td>\n",
       "<td>371664</td>\n",
       "<td>=BLOB=</td></tr><tr><td>88473646507008821</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>169588</td>\n",
       "<td>339509</td>\n",
       "<td>=BLOB=</td></tr><tr><td>88478732822097637</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td>\n",
       "<td>26091</td>\n",
       "<td>52118</td>\n",
       "<td>=BLOB=</td> </tr> </tbody>\n",
       "            </table>\n",
       "            <p>...</p>\n",
       "            <p>Total: 102</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segment_id    *version    *decimation_ra n_vertices     n_faces     mesh      \n",
       "+------------+ +---------+ +------------+ +------------+ +---------+ +--------+\n",
       "77000105634561 0           0.25           208308         417500      =BLOB=    \n",
       "77490624856971 0           0.25           81815          163578      =BLOB=    \n",
       "77773542942770 0           0.25           197032         394454      =BLOB=    \n",
       "77907065489896 0           0.25           102538         205050      =BLOB=    \n",
       "78488706738250 0           0.25           131596         272384      =BLOB=    \n",
       "78971460928405 0           0.25           214377         429344      =BLOB=    \n",
       "80512770407472 0           0.25           227270         454884      =BLOB=    \n",
       "80583139755390 0           0.25           340287         681892      =BLOB=    \n",
       "81082729277563 0           0.25           225506         451734      =BLOB=    \n",
       "81160726756366 0           0.25           50916          101784      =BLOB=    \n",
       "81499994678854 0           0.25           259432         521264      =BLOB=    \n",
       "81722920929926 0           0.25           200701         402310      =BLOB=    \n",
       "82071327468690 0           0.25           123960         246178      =BLOB=    \n",
       "82556557103630 0           0.25           75053          150046      =BLOB=    \n",
       "83404485518874 0           0.25           460417         922298      =BLOB=    \n",
       "83970321556114 0           0.25           96123          191242      =BLOB=    \n",
       "84178679680719 0           0.25           340331         684646      =BLOB=    \n",
       "84947857186329 0           0.25           256659         515456      =BLOB=    \n",
       "85235241769692 0           0.25           267640         536634      =BLOB=    \n",
       "85379690109601 0           0.25           312949         626674      =BLOB=    \n",
       "85934737323299 0           0.25           183481         367116      =BLOB=    \n",
       "86984220970630 0           0.25           311586         622870      =BLOB=    \n",
       "87070120987950 0           0.25           65254          130632      =BLOB=    \n",
       "87477008539482 0           0.25           170066         339974      =BLOB=    \n",
       "87770714912059 0           0.25           179142         358716      =BLOB=    \n",
       "88127300343946 0           0.25           123748         247904      =BLOB=    \n",
       "88252026865422 0           0.25           395516         791034      =BLOB=    \n",
       "88257180826426 0           0.25           185801         371664      =BLOB=    \n",
       "88473646507008 0           0.25           169588         339509      =BLOB=    \n",
       "88478732822097 0           0.25           26091          52118       =BLOB=    \n",
       "   ...\n",
       " (Total: 102)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decimation_version = 0\n",
    "decimation_ratio = 0.25\n",
    "one_soma = (minnie.Decimation & (dj.U(\"segment_id\") & (m65.AllenSegmentCentroid & \"status=1\").proj()) & \"version=\" + str(decimation_version))\n",
    "one_soma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to check if in Allen Soma segment exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will Save for Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions For Soma Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking the new validation checks\n",
    "\"\"\"\n",
    "def side_length_ratios(current_mesh):\n",
    "    \"\"\"\n",
    "    Will compute the ratios of the bounding box sides\n",
    "    To be later used to see if there is skewness\n",
    "    \"\"\"\n",
    "\n",
    "    # bbox = current_mesh.bounding_box_oriented.vertices\n",
    "    bbox = current_mesh.bounding_box_oriented.vertices\n",
    "    x_axis_unique = np.unique(bbox[:,0])\n",
    "    y_axis_unique = np.unique(bbox[:,1])\n",
    "    z_axis_unique = np.unique(bbox[:,2])\n",
    "    x_length = (np.max(x_axis_unique) - np.min(x_axis_unique)).astype(\"float\")\n",
    "    y_length = (np.max(y_axis_unique) - np.min(y_axis_unique)).astype(\"float\")\n",
    "    z_length = (np.max(z_axis_unique) - np.min(z_axis_unique)).astype(\"float\")\n",
    "    #print(x_length,y_length,z_length)\n",
    "    #compute the ratios:\n",
    "    xy_ratio = float(x_length/y_length)\n",
    "    xz_ratio = float(x_length/z_length)\n",
    "    yz_ratio = float(y_length/z_length)\n",
    "    side_ratios = [xy_ratio,xz_ratio,yz_ratio]\n",
    "    flipped_side_ratios = []\n",
    "    for z in side_ratios:\n",
    "        if z < 1:\n",
    "            flipped_side_ratios.append(1/z)\n",
    "        else:\n",
    "            flipped_side_ratios.append(z)\n",
    "    return flipped_side_ratios\n",
    "\n",
    "def side_length_check(current_mesh,side_length_ratio_threshold=3):\n",
    "    side_length_ratio_names = [\"xy\",\"xz\",\"yz\"]\n",
    "    side_ratios = side_length_ratios(current_mesh)\n",
    "    pass_threshold = [(k <= side_length_ratio_threshold) and\n",
    "                      (k >= 1/side_length_ratio_threshold) for k in side_ratios]\n",
    "    for i,(rt,truth) in enumerate(zip(side_ratios,pass_threshold)):\n",
    "        if not truth:\n",
    "            print(f\"{side_length_ratio_names[i]} = {rt} ratio was beyong {side_length_ratio_threshold} multiplier\")\n",
    "\n",
    "    if False in pass_threshold:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "# current_Pmesh = trimesh.load_mesh(\"./12346/12346_poisson_soma.off\")\n",
    "# print(side_length_ratios(current_mesh))\n",
    "# side_length_check(current_mesh,side_length_ratio_threshold=1.55)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_mesh_piece(msh):\n",
    "    mesh_splits_inner = msh.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "    return ordered_mesh_splits_inner[0]\n",
    "def soma_volume_ratio(current_mesh):\n",
    "    \"\"\"\n",
    "    bounding_box_oriented: rotates the box to be less volume\n",
    "    bounding_box : does not rotate the box and makes it axis aligned\n",
    "    \n",
    "    ** checks to see if closed mesh and if not then make closed **\n",
    "    \"\"\"\n",
    "    poisson_temp_folder = Path.cwd() / \"Poisson_temp\"\n",
    "    poisson_temp_folder.mkdir(parents=True,exist_ok=True)\n",
    "    Poisson_obj_temp = Poisson(poisson_temp_folder,overwrite=True)\n",
    "    \n",
    "    #get the largest piece\n",
    "    lrg_mesh = largest_mesh_piece(current_mesh)\n",
    "    if not lrg_mesh.is_watertight:\n",
    "        print(\"Using Poisson Surface Reconstruction to make mesh watertight\")\n",
    "        #run the Poisson Surface reconstruction and get the largest piece\n",
    "        new_mesh_inner,poisson_file_obj = Poisson_obj_temp(vertices=lrg_mesh.vertices,\n",
    "               faces=lrg_mesh.faces,\n",
    "               return_mesh=True,\n",
    "               delete_temp_files=True)\n",
    "        lrg_mesh = largest_mesh_piece(new_mesh_inner)\n",
    "\n",
    "    #turn the mesh into a closed mesh based on \n",
    "    \n",
    "    ratio_val = lrg_mesh.bounding_box.volume/lrg_mesh.volume\n",
    "#     if ratio_val < 1:\n",
    "#         raise Exception(\"Less than 1 value in volume ratio computation\")\n",
    "    return ratio_val\n",
    "\n",
    "def soma_volume_check(current_mesh,multiplier=8):\n",
    "    ratio_val= soma_volume_ratio(current_mesh)\n",
    "    print(\"Inside sphere validater: ratio_val = \" + str(ratio_val))\n",
    "    if np.abs(ratio_val) > multiplier:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that will extract the Somas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_soma_center(segment_id,\n",
    "                        current_mesh_verts,\n",
    "                        current_mesh_faces,\n",
    "                       outer_decimation_ratio= 0.25,\n",
    "                        large_mesh_threshold = 60000,\n",
    "                        large_mesh_threshold_inner = 40000,\n",
    "                        soma_width_threshold = 0.32,\n",
    "                        soma_size_threshold = 20000,\n",
    "                       inner_decimation_ratio = 0.25,\n",
    "                       volume_mulitplier=8,\n",
    "                       side_length_ratio_threshold=3,\n",
    "                       soma_size_threshold_max=192000, #this puts at 12000 once decimated\n",
    "                       delete_files=True\n",
    "                       ):    \n",
    "    \"\"\"\n",
    "    Will extract the soma meshes (possible multiple) from\n",
    "    a single mesh\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    global_start_time = time.time()\n",
    "\n",
    "    #Adjusting the thresholds based on the decimations\n",
    "    large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "    large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "    soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "    soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "\n",
    "    #adjusting for inner decimation\n",
    "    soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "    soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "    print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "                 f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "                  f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "                 f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "                 f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "                 f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\")\n",
    "\n",
    "\n",
    "    # ------------------------------\n",
    "\n",
    "\n",
    "    temp_folder = f\"./{segment_id}\"\n",
    "    temp_object = Path(temp_folder)\n",
    "    #make the temp folder if it doesn't exist\n",
    "    temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    #making the decimation and poisson objections\n",
    "    Dec_outer = Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "    Dec_inner = Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "    Poisson_obj = Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "    #Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "    new_mesh,output_obj = Dec_outer(vertices=current_mesh_verts,\n",
    "             faces=current_mesh_faces,\n",
    "             segment_id=segment_id,\n",
    "             return_mesh=True,\n",
    "             delete_temp_files=False)\n",
    "\n",
    "    #preforming the splits of the decimated mesh\n",
    "\n",
    "    mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "    #get the largest mesh\n",
    "    mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "    total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "    ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "    list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "    print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "    #if no significant pieces were found then will use smaller threshold\n",
    "    if len(list_of_largest_mesh)<=0:\n",
    "        print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "        list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "    total_soma_list = []\n",
    "    total_classifier_list = []\n",
    "    total_poisson_list = []\n",
    "    total_soma_list_sdf = []\n",
    "\n",
    "    #start iterating through where go through all pieces before the poisson reconstruction\n",
    "    no_somas_found_in_big_loop = 0\n",
    "    for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "        print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "        somas_found_in_big_loop = False\n",
    "\n",
    "        largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "        pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "        pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "        print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "\n",
    "        new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "                   faces=largest_mesh.faces,\n",
    "                   return_mesh=True,\n",
    "                   mesh_filename=largest_file_name,\n",
    "                   delete_temp_files=False)\n",
    "\n",
    "\n",
    "        #splitting the Poisson into the largest pieces and ordering them\n",
    "        mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "        total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "        ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "        list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "        print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "        n_failed_inner_soma_loops = 0\n",
    "        for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "            print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "            largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "            #Decimate the inner poisson piece\n",
    "            largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                                vertices=largest_mesh_inner.vertices,\n",
    "                                 faces=largest_mesh_inner.faces,\n",
    "                                mesh_filename=largest_mesh_path_inner,\n",
    "                                 return_mesh=True,\n",
    "                                 delete_temp_files=False)\n",
    "\n",
    "            print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "            faces = np.array(largest_mesh_path_inner_decimated.faces)\n",
    "            verts = np.array(largest_mesh_path_inner_decimated.vertices)\n",
    "\n",
    "            segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "\n",
    "            verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                    import_Off_Flag=False,\n",
    "                                    segment_id=segment_id_new,\n",
    "                                    vertices=verts,\n",
    "                                     triangles=faces,\n",
    "                                    pymeshfix_Flag=False,\n",
    "                                     import_CGAL_Flag=False,\n",
    "                                     return_Only_Labels=True,\n",
    "                                     clusters=3,\n",
    "                                     smoothness=0.2,\n",
    "                                    soma_only=True,\n",
    "                                    return_classifier = True\n",
    "                                    )\n",
    "            print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "            total_classifier_list.append(classifier)\n",
    "            #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "            # Save all of the portions that resemble a soma\n",
    "            median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "            segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "            #order the compartments by greatest to smallest\n",
    "            sorted_medians = np.flip(np.argsort(median_values))\n",
    "            print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "            print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "\n",
    "            valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "            valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                                and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "            print(\"valid_soma_segments_width\")\n",
    "            to_add_list = []\n",
    "            to_add_list_sdf = []\n",
    "            if len(valid_soma_segments_width) > 0:\n",
    "                print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "                somas_found_in_big_loop = True\n",
    "                #get the meshes only if signfiicant length\n",
    "                labels_list = classifier.labels_list\n",
    "\n",
    "                for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                    submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                    soma_mesh = largest_mesh_path_inner_decimated.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                    \n",
    "                    if side_length_check(soma_mesh,side_length_ratio_threshold) and soma_volume_check(soma_mesh,volume_mulitplier):\n",
    "                        to_add_list.append(soma_mesh)\n",
    "                        to_add_list_sdf.append(sdf)\n",
    "                        \n",
    "                    else:\n",
    "                        print(f\"--->This soma mesh was not added because it did not pass the sphere validation: {soma_mesh}\")\n",
    "\n",
    "                n_failed_inner_soma_loops = 0\n",
    "\n",
    "            else:\n",
    "                n_failed_inner_soma_loops += 1\n",
    "\n",
    "            total_soma_list_sdf += to_add_list_sdf\n",
    "            total_soma_list += to_add_list\n",
    "\n",
    "            # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "            if n_failed_inner_soma_loops >= 2:\n",
    "                print(\"breaking inner loop because 2 soma fails in a row\")\n",
    "                break\n",
    "\n",
    "\n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if somas_found_in_big_loop == False:\n",
    "            no_somas_found_in_big_loop += 1\n",
    "            if no_somas_found_in_big_loop >= 2:\n",
    "                print(\"breaking because 2 fails in a row in big loop\")\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            no_somas_found_in_big_loop = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "    pairings = []\n",
    "    for y,soma_1 in enumerate(total_soma_list):\n",
    "        for z,soma_2 in enumerate(total_soma_list):\n",
    "            if y<z:\n",
    "                mesh_tree = KDTree(soma_1.vertices)\n",
    "                distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "                if np.min(distances) < 4000:\n",
    "                    pairings.append([y,z])\n",
    "\n",
    "\n",
    "    #creating the combined meshes from the list\n",
    "    total_soma_list_revised = []\n",
    "    total_soma_list_revised_sdf = []\n",
    "    if len(pairings) > 0:\n",
    "        \"\"\"\n",
    "        Pseudocode: \n",
    "        Use a network function to find components\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        import networkx as nx\n",
    "        new_graph = nx.Graph()\n",
    "        new_graph.add_edges_from(pairings)\n",
    "        grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "        somas_being_combined = []\n",
    "        print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "        for comp in grouped_somas:\n",
    "            comp = list(comp)\n",
    "            somas_being_combined += list(comp)\n",
    "            current_mesh = total_soma_list[comp[0]]\n",
    "            for i in range(1,len(comp)):\n",
    "                current_mesh += total_soma_list[comp[i]]\n",
    "\n",
    "            total_soma_list_revised.append(current_mesh)\n",
    "            #where can average all of the sdf values\n",
    "            total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "        #add those that weren't combined to total_soma_list_revised\n",
    "        leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "        leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "        if len(leftover_somas) > 0:\n",
    "            total_soma_list_revised += leftover_somas\n",
    "            total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "            \n",
    "        print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "        print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "    if len(total_soma_list_revised) == 0:\n",
    "        total_soma_list_revised = total_soma_list\n",
    "        total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "    run_time = time.time() - global_start_time\n",
    "\n",
    "    print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "\n",
    "    #need to erase all of the temporary files ******\n",
    "    #import shutil\n",
    "    #shutil.rmtree(directory)\n",
    "\n",
    "    \"\"\"\n",
    "    Need to delete all files in the temp folder *****\n",
    "    \"\"\"\n",
    "    \n",
    "    if delete_files:\n",
    "        #now erase all of the files used\n",
    "        from shutil import rmtree\n",
    "\n",
    "        #remove the directory with the meshes\n",
    "        rmtree(str(temp_object.absolute()))\n",
    "\n",
    "        #removing the temporary files\n",
    "        temp_folder = Path(\"./temp\")\n",
    "        temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "        seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "        for f in seg_temp_files:\n",
    "            f.unlink()\n",
    "\n",
    "    #return total_soma_list, run_time\n",
    "    return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how to erase the temp files\n",
    "# temp_folder = Path(\"./temp\")\n",
    "# temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "# seg_temp_files = [x for x in temp_files if str(ex_seg) in str(x)]\n",
    "# seg_temp_files\n",
    "# for f in seg_temp_files:\n",
    "#     f.unlink()\n",
    "# #str(temp_folder.absolute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        \n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">segment_id</p>\n",
       "                                <span class=\"djtooltiptext\">segment id unique within each Segmentation</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">version</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">decimation_ratio</p>\n",
       "                                <span class=\"djtooltiptext\">ratio of remaining mesh vertices/faces (which ones depends on what metric the decimation technique uses)</span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>77489456693007645</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>81639563398742139</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>89387891029279745</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>90153356676844854</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>90518669414951752</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>90939989466098088</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>91208269699305759</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>94031059578350884</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>94531956582329737</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>96147481821744505</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>102894772968611589</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>107319757380005445</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>107681564887986552</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td></tr><tr><td>107738877133006848</td>\n",
       "<td>0</td>\n",
       "<td>0.25</td> </tr> </tbody>\n",
       "            </table>\n",
       "            \n",
       "            <p>Total: 14</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*segment_id    *version    *decimation_ra\n",
       "+------------+ +---------+ +------------+\n",
       "77489456693007 0           0.25          \n",
       "81639563398742 0           0.25          \n",
       "89387891029279 0           0.25          \n",
       "90153356676844 0           0.25          \n",
       "90518669414951 0           0.25          \n",
       "90939989466098 0           0.25          \n",
       "91208269699305 0           0.25          \n",
       "94031059578350 0           0.25          \n",
       "94531956582329 0           0.25          \n",
       "96147481821744 0           0.25          \n",
       "10289477296861 0           0.25          \n",
       "10731975738000 0           0.25          \n",
       "10768156488798 0           0.25          \n",
       "10773887713300 0           0.25          \n",
       " (Total: 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(minnie.Decimation() & (m65.AllenMultiSomas() & \"status > 0\")).proj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimation_version = 0\n",
    "decimation_ratio = 0.25\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "- The error isn't computed anymore so disregarding these \n",
    "distance_from_prediction : double                   # the distance of the ALLEN predicted centroid soma center from the algorithms prediction\n",
    "prediction_matching_index : int unsigned            # the soma index that was used to compute the error\n",
    "\"\"\"\n",
    "\n",
    "@schema\n",
    "class BaylorSegmentCentroid(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decimation.proj(decimation_version='version')\n",
    "    soma_index : tinyint unsigned #index given to this soma to account for multiple somas in one base semgnet\n",
    "    ---\n",
    "    centroid_x=NULL           : int unsigned                 # (EM voxels)\n",
    "    centroid_y=NULL           : int unsigned                 # (EM voxels)\n",
    "    centroid_z=NULL           : int unsigned                 # (EM voxels)\n",
    "    n_vertices=NULL           : bigint                 #number of vertices\n",
    "    n_faces=NULL            : bigint                  #number of faces\n",
    "    soma_vertices=NULL        : longblob                # array of vertices\n",
    "    soma_faces=NULL           : longblob                   # array of faces\n",
    "    multiplicity=NULL         : tinyint unsigned             # the number of somas found for this base segment\n",
    "    sdf=NULL                  : double                       # sdf width value for the soma\n",
    "    max_side_ratio=NULL       : double                       # the maximum of the side length ratios used for check if soma\n",
    "    bbox_volume_ratio=NULL    : double                       # ratio of bbox (axis aligned) volume to mesh volume to use for check if soma\n",
    "    run_time=NULL : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #key_source = (minnie.Decimation & (dj.U(\"segment_id\") & (m65.AllenSegmentCentroid & \"status=1\").proj()) & \"version=\" + str(decimation_version))\n",
    "    #key_source = minnie.Decimation() & (m65.AllenMultiSomas() & \"status > 0\").proj()\n",
    "    \n",
    "    #cells that will be interesting to run\n",
    "    glias_with_soma = [95223204792538688, 104926944663346575]\n",
    "    glia_with_other_no_soma = [105930249090655379,97611893870642480]\n",
    "    glia = [96486475000365510]\n",
    "    interesting_single_soma = [90231147459666747]\n",
    "    \n",
    "    total_segments_to_test = interesting_single_soma + glias_with_soma + glia_with_other_no_soma + glia\n",
    "    key_source = minnie.Decimation.proj(decimation_version='version') & [dict(segment_id=k) for k in total_segments_to_test] & \"decimation_version=\" + str(decimation_version)\n",
    "    \n",
    "    def make(self,key):\n",
    "        #get the mesh data\n",
    "        print(f\"\\n\\n\\n---- Working on {key['segment_id']} ----\")\n",
    "        \n",
    "        new_mesh = (minnie.Decimation() & key).fetch1(\"mesh\")\n",
    "        current_mesh_verts,current_mesh_faces = new_mesh.vertices,new_mesh.faces\n",
    "        \n",
    "        segment_id = key[\"segment_id\"]\n",
    "        \n",
    "        (total_soma_list, \n",
    "         run_time, \n",
    "         total_soma_list_sdf) = extract_soma_center(\n",
    "                            segment_id,\n",
    "                            current_mesh_verts,\n",
    "                            current_mesh_faces,\n",
    "                            outer_decimation_ratio= 0.25,\n",
    "                            large_mesh_threshold = 60000,\n",
    "                            large_mesh_threshold_inner = 40000,\n",
    "                            soma_width_threshold = 0.32,\n",
    "                            soma_size_threshold = 20000,\n",
    "                           inner_decimation_ratio = 0.25,\n",
    "                           volume_mulitplier=7,\n",
    "                           side_length_ratio_threshold=3,\n",
    "                            soma_size_threshold_max=192000,\n",
    "                            delete_files=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Run time was {run_time} \\n    total_soma_list = {total_soma_list}\"\n",
    "             f\"\\n    with sdf values = {total_soma_list_sdf}\")\n",
    "        \n",
    "        #check if soma list is empty and did not find soma\n",
    "        if len(total_soma_list) <= 0:\n",
    "            print(\"There were no somas found for this mesh so just writing empty data\")\n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=0,\n",
    "                              centroid_x=None,\n",
    "                               centroid_y=None,\n",
    "                               centroid_z=None,\n",
    "                               #distance_from_prediction=None,\n",
    "                               #prediction_matching_index = None,\n",
    "                               n_vertices=0,\n",
    "                               n_faces=0,\n",
    "                               soma_vertices=None,\n",
    "                               soma_faces=None,\n",
    "                               multiplicity=0,\n",
    "                               sdf = None,\n",
    "                               max_side_ratio = None,\n",
    "                               bbox_volume_ratio = None,\n",
    "                               run_time=run_time\n",
    "                              )\n",
    "            \n",
    "            #raise Exception(\"to prevent writing because none were found\")\n",
    "            self.insert1(insert_dict,skip_duplicates=True)\n",
    "            return\n",
    "        \n",
    "        #if there is one or more soma found, get the volume and side length checks\n",
    "        max_side_ratio =  [np.max(side_length_ratios(m)) for m in total_soma_list]\n",
    "        bbox_volume_ratio =  [soma_volume_ratio(m) for m in total_soma_list]\n",
    "        dicts_to_insert = []\n",
    "        \n",
    "        \n",
    "        \"\"\"        \n",
    "        #DON'T NEED THE ERROR PREDICTION ANYMORE\n",
    "        new_array = (m65.AllenMultiSomas.Centroids()  & key).fetch(\"centroid_x\",\"centroid_y\",\"centroid_z\")\n",
    "        soma_ids = (m65.AllenMultiSomas.Centroids()  & key).fetch(\"soma_id\")\n",
    "        allen_centroid_prediction = np.array(new_array).T\n",
    "        allen_centroid_prediction\n",
    "        #print(\"soma_ids = \" + str(soma_ids))\n",
    "        from pykdtree.kdtree import KDTree\n",
    "        mesh_tree = KDTree(allen_centroid_prediction)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        for i,(current_soma,soma_sdf,sz_ratio,vol_ratio) in enumerate(zip(total_soma_list,total_soma_list_sdf,max_side_ratio,bbox_volume_ratio)):\n",
    "            print(\"Trying to write off file\")\n",
    "            \"\"\" Currently don't need to export the meshes\n",
    "            current_soma.export(f\"{key['segment_id']}/{key['segment_id']}_soma_{i}.off\")\n",
    "            \"\"\"\n",
    "            auto_prediction_center = np.mean(current_soma.vertices,axis=0) / np.array([4,4,40])\n",
    "            auto_prediction_center = auto_prediction_center.astype(\"int\")\n",
    "            print(f\"Predicted Coordinates are {auto_prediction_center}\")\n",
    "\n",
    "        #             distances,closest_node = mesh_tree.query(auto_prediction_center.reshape(1,3))\n",
    "        #             error_distance = distances[0]\n",
    "        #             prediction_matching_index = soma_ids[closest_node[0]] #closest nodes and the distances\n",
    "\n",
    "\n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=i+1,\n",
    "                              centroid_x=auto_prediction_center[0],\n",
    "                               centroid_y=auto_prediction_center[1],\n",
    "                               centroid_z=auto_prediction_center[2],\n",
    "        #                                distance_from_prediction=error_distance,\n",
    "        #                                prediction_matching_index = prediction_matching_index,\n",
    "                               n_vertices = len(current_soma.vertices),\n",
    "                               n_faces = len(current_soma.faces),\n",
    "                               soma_vertices=current_soma.vertices,\n",
    "                               soma_faces=current_soma.faces,\n",
    "                               multiplicity=len(total_soma_list),\n",
    "                               sdf = np.round(soma_sdf,3),\n",
    "                               max_side_ratio = np.round(sz_ratio,3),\n",
    "                               bbox_volume_ratio = np.round(vol_ratio,3),\n",
    "                               run_time=np.round(run_time,4)\n",
    "                              )\n",
    "\n",
    "\n",
    "\n",
    "            dicts_to_insert.append(insert_dict)\n",
    "        \n",
    "        #raise Exception(\"to prevent writing\")\n",
    "\n",
    "#         if len(total_soma_list) != len(soma_ids):\n",
    "#             raise Exception(\"to prevent writing SOMAS NOT EQUAL TO That registered in datase\")\n",
    "\n",
    "        self.insert(dicts_to_insert,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(SomaCentroidValidation & \"segment_id=90231147459666747\").delete()\n",
    "#(schema.jobs & \"table_name='__baylor_segment_centroid'\").delete()\n",
    "#m65.SomaCentroidValidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Working on 90231147459666747 ----\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 1250.0 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/90231147459666747/neuron_90231147459666747.off -o /notebooks/Platinum_Soma/90231147459666747/neuron_90231147459666747_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(21094, 3), faces.shape=(44146, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(21094, 3), faces.shape=(44146, 3))>\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/90231147459666747/neuron_90231147459666747_decimated_largest_piece.off\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/90231147459666747/neuron_90231147459666747_decimated_largest_piece.off -o /notebooks/Platinum_Soma/90231147459666747/neuron_90231147459666747_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(19614, 3), faces.shape=(39256, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(19614, 3), faces.shape=(39256, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/90231147459666747/neuron_90231147459666747_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/90231147459666747/neuron_90231147459666747_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_90231147459666747_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002295970916748047\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/9023114745966674700_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.0345680713653564\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.1760632991790771\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 3\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.00370025634765625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 4.839897155761719e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.008082389831542969\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.04701709747314453\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.862948\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([3, 6, 0, 7, 8, 1, 2, 4, 9, 5]), array([0.862948  , 0.508264  , 0.4436145 , 0.360678  , 0.30084   ,\n",
      "       0.09407265, 0.08290325, 0.07453685, 0.068238  , 0.06209535]))\n",
      "Sizes = [3369, 35, 1734, 291, 13, 1542, 1318, 632, 744, 136]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [3, 0]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 2.220917752024537\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 0.02326098655493476\n",
      "There were soma pairings: Connected components in = [{0, 1}] \n",
      "Final total_soma_list_revised = [<trimesh.Trimesh(vertices.shape=(2638, 3), faces.shape=(5103, 3))>]\n",
      "Final total_soma_list_revised_sdf = [0.4436145]\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 31.350095987319946\n",
      "Run time was 31.350095510482788 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(2638, 3), faces.shape=(5103, 3))>]\n",
      "    with sdf values = [0.4436145]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [196815 225397  19497]\n",
      "\n",
      "\n",
      "\n",
      "---- Working on 96486475000365510 ----\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 1250.0 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510.off -o /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(309698, 3), faces.shape=(685002, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(309698, 3), faces.shape=(685002, 3))>\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece.off\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece.off -o /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(750065, 3), faces.shape=(1503670, 3))>, <trimesh.Trimesh(vertices.shape=(6693, 3), faces.shape=(13418, 3))>, <trimesh.Trimesh(vertices.shape=(6677, 3), faces.shape=(13362, 3))>, <trimesh.Trimesh(vertices.shape=(5725, 3), faces.shape=(11462, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(750065, 3), faces.shape=(1503670, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003342628479003906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/9648647500036551000_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 237.3394434452057\n",
      "2) Finished: Generating CGAL segmentation for neuron: 243.23718905448914\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 206\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.13097739219665527\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 7.915496826171875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.34012579917907715\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 2.247418165206909\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.430647\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([206,  13,  90, 139, 258, 133,  51, 103, 227, 245, 252,  98,   2,\n",
      "       112, 278,  95,  71,  19,  69,  29,  14,  74, 154, 249, 192, 269,\n",
      "       106,  99, 208,  22, 220,  30,  23,   6, 210, 265,   3, 143, 270,\n",
      "        45, 264, 254,  55, 152,   8,  12, 171, 287,  63, 115, 108, 186,\n",
      "       242, 153,  67, 142, 107,  61, 162, 102,  64,  94, 276, 232,  36,\n",
      "        57,  93, 231,  34, 237, 215,  97,  52, 244,  17,  84, 230, 224,\n",
      "       127, 100,  42,  65, 263,   1,  66,   0, 128,  43,  28,  82, 130,\n",
      "       150,   4,  35,  91,  26,  33, 225, 272,  31, 282, 124,  11,  76,\n",
      "       205, 233, 219,  77, 101, 238,  59, 156, 214, 155, 246,  20, 118,\n",
      "        15, 248, 247, 221,  44,  96,   7, 161,  41,  58, 226, 235,  86,\n",
      "       169, 158, 173,  25,  72, 266,  70,  75, 211,  50, 126, 110, 120,\n",
      "       236,  24,  21,  80,  16, 147, 184,  81, 121, 182,  46,  83,  92,\n",
      "       140,  40, 213, 109, 157, 234, 271, 170, 129, 131,  60, 250,   5,\n",
      "       228,  88, 280, 138, 190,  85, 177, 199,  78, 149, 243, 166, 279,\n",
      "       284,  39, 159,  62, 267, 104,  38, 183, 187, 196, 113, 200, 141,\n",
      "        49,   9,  47, 222, 253, 175,  18,  73, 136,  10, 125, 202, 178,\n",
      "       281, 189, 259, 181,  48, 217, 180, 174, 165, 135, 163, 283,  56,\n",
      "       167, 275, 117, 212, 223, 209, 288,  27, 274, 164, 262,  79,  87,\n",
      "       144, 148, 191, 285, 137, 204, 286,  89, 201, 119, 176, 193, 172,\n",
      "       251, 207, 105, 257,  32, 168, 197, 146, 132, 218, 160, 123, 229,\n",
      "       179, 122, 240, 134, 255, 114, 203,  37,  68, 185,  54, 239, 273,\n",
      "       116, 260, 198, 261, 195, 268, 194, 241, 188, 256, 151,  53, 145,\n",
      "       216, 277, 111]), array([0.430647  , 0.2534705 , 0.236169  , 0.235718  , 0.160691  ,\n",
      "       0.153614  , 0.152395  , 0.150777  , 0.1500925 , 0.146458  ,\n",
      "       0.145912  , 0.144212  , 0.1437565 , 0.1429545 , 0.142265  ,\n",
      "       0.141834  , 0.139472  , 0.1392815 , 0.1391335 , 0.139023  ,\n",
      "       0.139005  , 0.138716  , 0.138671  , 0.13821   , 0.137478  ,\n",
      "       0.136523  , 0.1362765 , 0.1358315 , 0.1347795 , 0.134654  ,\n",
      "       0.132578  , 0.1325495 , 0.1323655 , 0.1323545 , 0.132326  ,\n",
      "       0.132292  , 0.1322495 , 0.132206  , 0.1318105 , 0.131018  ,\n",
      "       0.1308105 , 0.129042  , 0.127362  , 0.123872  , 0.122849  ,\n",
      "       0.120258  , 0.116173  , 0.1147135 , 0.114592  , 0.111439  ,\n",
      "       0.106444  , 0.105872  , 0.104453  , 0.104198  , 0.10336   ,\n",
      "       0.103285  , 0.1024445 , 0.101951  , 0.101921  , 0.101891  ,\n",
      "       0.1017235 , 0.100973  , 0.100487  , 0.100462  , 0.1003105 ,\n",
      "       0.09950995, 0.09942835, 0.09926945, 0.09915905, 0.0991184 ,\n",
      "       0.0990582 , 0.0989088 , 0.098701  , 0.0985617 , 0.09812045,\n",
      "       0.09797155, 0.09778605, 0.0976248 , 0.0971753 , 0.09714005,\n",
      "       0.09711075, 0.0967178 , 0.0964689 , 0.0960996 , 0.0960757 ,\n",
      "       0.0955839 , 0.0955452 , 0.0955136 , 0.0954464 , 0.0951636 ,\n",
      "       0.0950773 , 0.09483635, 0.094707  , 0.09446125, 0.0943535 ,\n",
      "       0.09397835, 0.0939589 , 0.0935303 , 0.09352845, 0.0933171 ,\n",
      "       0.0932124 , 0.0931351 , 0.0931124 , 0.0930572 , 0.0929677 ,\n",
      "       0.09278725, 0.0926737 , 0.092613  , 0.0925774 , 0.0924951 ,\n",
      "       0.0924274 , 0.0921475 , 0.09209745, 0.0918408 , 0.09171625,\n",
      "       0.0915505 , 0.0914782 , 0.0912679 , 0.09123295, 0.0911843 ,\n",
      "       0.0911151 , 0.0911106 , 0.0908026 , 0.09037235, 0.09027775,\n",
      "       0.0900172 , 0.0899574 , 0.0898638 , 0.08983405, 0.0892136 ,\n",
      "       0.0889198 , 0.0888741 , 0.0884905 , 0.0881408 , 0.0874806 ,\n",
      "       0.087366  , 0.08723455, 0.08709145, 0.0867293 , 0.08655945,\n",
      "       0.0864358 , 0.08639195, 0.0863543 , 0.0856223 , 0.0856154 ,\n",
      "       0.0855618 , 0.0852294 , 0.0851474 , 0.0850892 , 0.0848677 ,\n",
      "       0.0845406 , 0.0844122 , 0.084407  , 0.0842227 , 0.0841731 ,\n",
      "       0.0841593 , 0.08375925, 0.08345715, 0.0833113 , 0.08318245,\n",
      "       0.0827664 , 0.08181275, 0.0817566 , 0.0811667 , 0.08110635,\n",
      "       0.08100035, 0.080722  , 0.0804744 , 0.0804259 , 0.0801328 ,\n",
      "       0.0798984 , 0.0794599 , 0.07943195, 0.0793435 , 0.0789254 ,\n",
      "       0.07859795, 0.0781344 , 0.07799   , 0.07794005, 0.0776941 ,\n",
      "       0.0775776 , 0.0775338 , 0.07732105, 0.0765628 , 0.0764851 ,\n",
      "       0.0755825 , 0.0755187 , 0.0753709 , 0.0751549 , 0.0749793 ,\n",
      "       0.0749069 , 0.0746047 , 0.0745013 , 0.0742732 , 0.07422405,\n",
      "       0.07405375, 0.0739214 , 0.0723403 , 0.071899  , 0.0715045 ,\n",
      "       0.0713506 , 0.0710437 , 0.0709991 , 0.0700791 , 0.06998505,\n",
      "       0.0698874 , 0.0698404 , 0.069764  , 0.06961685, 0.0695503 ,\n",
      "       0.0694519 , 0.06940725, 0.0692494 , 0.0690112 , 0.0689757 ,\n",
      "       0.068915  , 0.0684111 , 0.0677705 , 0.0675558 , 0.0674262 ,\n",
      "       0.0668247 , 0.0663582 , 0.0661694 , 0.06595285, 0.0654152 ,\n",
      "       0.0648164 , 0.06460615, 0.0643664 , 0.0643454 , 0.0635425 ,\n",
      "       0.0634432 , 0.06291335, 0.06291075, 0.062857  , 0.0625242 ,\n",
      "       0.06209745, 0.060842  , 0.0606115 , 0.0595314 , 0.0594787 ,\n",
      "       0.0593776 , 0.0589442 , 0.0588294 , 0.0587583 , 0.0587517 ,\n",
      "       0.05861475, 0.05814395, 0.0580012 , 0.0572338 , 0.0567718 ,\n",
      "       0.05632025, 0.0563098 , 0.0561934 , 0.0556611 , 0.055529  ,\n",
      "       0.0550396 , 0.0550045 , 0.0549821 , 0.0542882 , 0.0540056 ,\n",
      "       0.0536324 , 0.0533179 , 0.0531311 , 0.0510276 , 0.050818  ,\n",
      "       0.0507161 , 0.05011335, 0.0494368 , 0.0493018 , 0.049124  ,\n",
      "       0.0486715 , 0.0479217 , 0.0469646 , 0.0465743 , 0.04637795,\n",
      "       0.0459158 , 0.04554215, 0.0452281 , 0.04516885, 0.04363485,\n",
      "       0.0402976 , 0.0400217 , 0.0397304 , 0.0396219 , 0.0382228 ,\n",
      "       0.0363545 , 0.0354607 , 0.0338115 , 0.0322725 ]))\n",
      "Sizes = [9511, 9418, 1619, 3346, 582, 197, 3671, 2566, 244, 193, 167, 315, 6428, 228, 481, 2310, 181, 7092, 1290, 6240, 1188, 5461, 1388, 606, 63, 199, 816, 524, 9020, 47719, 1127, 1322, 150, 7032, 453, 1335, 5004, 4168, 440, 208, 934, 195, 71, 293, 2174, 243, 53, 102, 532, 233, 1161, 145, 715, 611, 96, 931, 5740, 311, 443, 2811, 1016, 1883, 322, 8002, 1750, 288, 820, 1644, 4190, 3035, 181, 1158, 2865, 106, 15522, 262, 4306, 297, 1589, 2196, 3176, 2815, 573, 13715, 546, 12604, 6107, 5495, 425, 526, 1351, 610, 5420, 958, 737, 3190, 22019, 163, 542, 85, 172, 465, 3383, 592, 5515, 588, 1239, 7250, 3924, 143, 1729, 1669, 930, 711, 944, 693, 264, 825, 518, 699, 1319, 1129, 1693, 860, 2044, 1239, 443, 1251, 1056, 717, 164, 1176, 287, 1174, 347, 103, 506, 130, 337, 576, 148, 126, 349, 625, 2536, 627, 848, 475, 200, 709, 489, 268, 314, 267, 144, 165, 678, 258, 118, 86, 2813, 2430, 321, 169, 366, 136, 87, 169, 649, 141, 1271, 94, 110, 88, 167, 182, 65, 253, 84, 109, 56, 49, 114, 97, 369, 181, 663, 64, 1248, 57, 219, 79, 439, 43, 134, 90, 205, 91, 77, 330, 277, 49, 31, 67, 106, 110, 163, 49, 50, 93, 137, 58, 43, 207, 44, 99, 197, 136, 391, 55, 67, 73, 45, 264, 409, 111, 116, 69, 121, 135, 99, 64, 112, 59, 63, 184, 41, 68, 45, 77, 25, 83, 39, 43, 116, 48, 236, 122, 53, 145, 62, 99, 91, 53, 173, 59, 151, 117, 156, 85, 65, 59, 53, 69, 137, 79, 98, 71, 63, 77, 121, 49, 126, 61, 154, 35, 160, 45, 116, 58, 43, 39, 49, 37, 84, 73, 41, 123, 63]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [206]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 7.724715304345118\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(4833, 3), faces.shape=(9511, 3))>\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(6693, 3), faces.shape=(13418, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002186298370361328\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/9648647500036551001_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.3677375316619873\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.4207944869995117\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0013856887817382812\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.1021575927734375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.003001689910888672\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.01603531837463379\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1,  3,  4,  7,  6,  0, 12,  5,  8, 10,  2,  9, 11]), array([0.637279  , 0.57152   , 0.399979  , 0.393223  , 0.393187  ,\n",
      "       0.368136  , 0.211706  , 0.188838  , 0.1378305 , 0.1344535 ,\n",
      "       0.101619  , 0.09268695, 0.0705451 ]))\n",
      "Sizes = [1149, 467, 795, 598, 76, 77, 17, 67, 32, 32, 11, 16, 17]\n",
      "valid_soma_segments_width\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(6677, 3), faces.shape=(13362, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/96486475000365510/neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_96486475000365510_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002155303955078125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/9648647500036551002_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.41589879989624023\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.47176265716552734\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0013687610626220703\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.5299530029296875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0031414031982421875\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.016499757766723633\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 2,  0,  1,  5,  4,  8,  3,  6,  7, 10, 11, 12,  9]), array([0.623692 , 0.580559 , 0.571732 , 0.4392705, 0.396494 , 0.37417  ,\n",
      "       0.370563 , 0.199685 , 0.164341 , 0.12186  , 0.0925986, 0.0689913,\n",
      "       0.0628293]))\n",
      "Sizes = [359, 1084, 111, 420, 765, 107, 249, 37, 90, 49, 11, 23, 35]\n",
      "valid_soma_segments_width\n",
      "breaking inner loop because 2 soma fails in a row\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 479.3973054885864\n",
      "Run time was 479.39730501174927 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on 97611893870642480 ----\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 1250.0 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/97611893870642480/neuron_97611893870642480.off -o /notebooks/Platinum_Soma/97611893870642480/neuron_97611893870642480_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(39521, 3), faces.shape=(85382, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(39521, 3), faces.shape=(85382, 3))>\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/97611893870642480/neuron_97611893870642480_decimated_largest_piece.off\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/97611893870642480/neuron_97611893870642480_decimated_largest_piece.off -o /notebooks/Platinum_Soma/97611893870642480/neuron_97611893870642480_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(55492, 3), faces.shape=(111304, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(55492, 3), faces.shape=(111304, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/97611893870642480/neuron_97611893870642480_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/97611893870642480/neuron_97611893870642480_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_97611893870642480_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002238750457763672\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/9761189387064248000_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 4.459718227386475\n",
      "2) Finished: Generating CGAL segmentation for neuron: 4.853583335876465\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "soma_index = 3\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.009952545166015625\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00022554397583007812\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.023849964141845703\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.1930239200592041\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.295397\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([38, 45, 18,  3, 40, 39,  4,  2,  0, 47, 43,  1,  8, 46, 14, 11,  9,\n",
      "       26, 25, 44,  5, 27, 20, 13, 17, 28, 29, 37, 24, 19, 31, 34, 23, 36,\n",
      "        6, 15, 35,  7, 30, 22, 12, 33, 49, 48, 41, 32, 16, 42, 10, 21]), array([0.657211  , 0.614345  , 0.496254  , 0.295397  , 0.285533  ,\n",
      "       0.282438  , 0.282336  , 0.271702  , 0.2653895 , 0.239544  ,\n",
      "       0.2304125 , 0.218612  , 0.213274  , 0.20918   , 0.207241  ,\n",
      "       0.204062  , 0.196536  , 0.191252  , 0.186949  , 0.174784  ,\n",
      "       0.163295  , 0.160445  , 0.160292  , 0.156151  , 0.148981  ,\n",
      "       0.147078  , 0.1468215 , 0.146728  , 0.1428045 , 0.133788  ,\n",
      "       0.1298795 , 0.120949  , 0.113776  , 0.110985  , 0.109594  ,\n",
      "       0.100492  , 0.0991457 , 0.0952204 , 0.0867104 , 0.0826411 ,\n",
      "       0.0792857 , 0.0767616 , 0.0693329 , 0.0688827 , 0.05761925,\n",
      "       0.0476223 , 0.0474862 , 0.0464759 , 0.0447901 , 0.0357698 ]))\n",
      "Sizes = [1005, 229, 2813, 3720, 236, 434, 3165, 6725, 4600, 213, 44, 176, 234, 94, 599, 323, 89, 171, 215, 309, 311, 151, 77, 65, 89, 39, 124, 107, 64, 61, 84, 21, 45, 70, 91, 43, 616, 32, 31, 75, 21, 11, 21, 23, 26, 19, 17, 36, 39, 23]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [18]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 36.89190490641852\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(1450, 3), faces.shape=(2813, 3))>\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 39.31438636779785\n",
      "Run time was 39.31438326835632 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "\n",
      "\n",
      "\n",
      "---- Working on 104926944663346575 ----\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 1250.0 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575.off -o /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(374723, 3), faces.shape=(799930, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(374723, 3), faces.shape=(799930, 3))>\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece.off\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece.off -o /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(413861, 3), faces.shape=(829378, 3))>, <trimesh.Trimesh(vertices.shape=(7691, 3), faces.shape=(15378, 3))>, <trimesh.Trimesh(vertices.shape=(5630, 3), faces.shape=(11260, 3))>, <trimesh.Trimesh(vertices.shape=(5425, 3), faces.shape=(10850, 3))>, <trimesh.Trimesh(vertices.shape=(5086, 3), faces.shape=(10168, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(413861, 3), faces.shape=(829378, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003600120544433594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/10492694466334657500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 82.3111321926117\n",
      "2) Finished: Generating CGAL segmentation for neuron: 85.59756684303284\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 18\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.07387447357177734\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 7.009506225585938e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.19204306602478027\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 1.2478463649749756\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.8780509999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([18, 34,  1, 63, 64, 26, 31, 73, 75, 78, 72, 82, 40, 69, 77, 60, 91,\n",
      "       89, 17, 83, 25, 90, 80, 22, 68, 71, 19, 81, 13, 62,  7, 49, 55, 52,\n",
      "       65,  0, 24, 36,  4, 85, 86,  5, 11, 44, 79, 61, 29, 53, 57, 50,  6,\n",
      "       23, 66, 15, 16, 33, 42, 56, 43, 21, 20, 87, 76, 35,  8, 32, 41, 10,\n",
      "        9, 54, 39,  3, 14, 84,  2, 27, 88, 47, 12, 38, 67, 45, 59, 37, 46,\n",
      "       51, 58, 70, 74, 48, 28, 30]), array([0.878051  , 0.102979  , 0.09746415, 0.09650195, 0.084324  ,\n",
      "       0.0824653 , 0.0772672 , 0.076896  , 0.0599827 , 0.05967745,\n",
      "       0.0595303 , 0.0581509 , 0.05689515, 0.0559534 , 0.0546139 ,\n",
      "       0.0544673 , 0.0540878 , 0.0525649 , 0.05229415, 0.0519814 ,\n",
      "       0.0514696 , 0.0505231 , 0.0503215 , 0.04996905, 0.0497167 ,\n",
      "       0.0488099 , 0.0482175 , 0.0480559 , 0.04766985, 0.0459363 ,\n",
      "       0.044857  , 0.044474  , 0.04309195, 0.0425287 , 0.0425068 ,\n",
      "       0.0423164 , 0.04212045, 0.0419741 , 0.041677  , 0.0412426 ,\n",
      "       0.0411722 , 0.0411486 , 0.0411257 , 0.0406784 , 0.04053355,\n",
      "       0.0405187 , 0.04039685, 0.0403244 , 0.04010175, 0.0400673 ,\n",
      "       0.0400121 , 0.03959285, 0.03937955, 0.0391899 , 0.03911235,\n",
      "       0.038416  , 0.037975  , 0.0378862 , 0.0376372 , 0.03727   ,\n",
      "       0.03712915, 0.0366285 , 0.03660395, 0.0364128 , 0.0362152 ,\n",
      "       0.0358571 , 0.0358514 , 0.0354727 , 0.0353803 , 0.0352556 ,\n",
      "       0.0352383 , 0.03489425, 0.03489245, 0.0347066 , 0.0343974 ,\n",
      "       0.0342543 , 0.03382005, 0.03357745, 0.0324491 , 0.0322964 ,\n",
      "       0.0312662 , 0.0312626 , 0.0311105 , 0.0297086 , 0.0287732 ,\n",
      "       0.0261507 , 0.0259602 , 0.0243432 , 0.0201606 , 0.0191483 ,\n",
      "       0.0162659 , 0.01332205]))\n",
      "Sizes = [6008, 481, 26730, 1702, 699, 589, 2489, 183, 2477, 2046, 136, 287, 2912, 385, 1853, 169, 1382, 285, 1480, 364, 2201, 957, 1693, 5912, 2736, 525, 6815, 885, 700, 2274, 399, 128, 144, 96, 185, 7695, 2982, 91, 10808, 1149, 2116, 1470, 21919, 403, 1840, 3566, 36, 147, 248, 6389, 19569, 3732, 296, 1500, 7340, 4239, 1072, 609, 37, 2773, 1304, 443, 1130, 979, 7556, 399, 41, 5235, 185, 71, 775, 400, 5038, 29, 314, 211, 216, 106, 442, 139, 817, 313, 59, 53, 127, 249, 45, 90, 51, 79, 69, 46]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [18]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 3.0646369898052335\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(7691, 3), faces.shape=(15378, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0002014636993408203\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/10492694466334657501_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.2623915672302246\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.32456398010253906\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0015053749084472656\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.221366882324219e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0038347244262695312\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.01906728744506836\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 0, 1, 5, 4, 3, 6]), array([0.6606745, 0.589503 , 0.541654 , 0.3784615, 0.0985404, 0.0658513,\n",
      "       0.0580701]))\n",
      "Sizes = [388, 1324, 2025, 66, 11, 19, 11]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [0, 1]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 513.3622341718262\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(665, 3), faces.shape=(1324, 3))>\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 713.4999398881104\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(1016, 3), faces.shape=(2025, 3))>\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(5630, 3), faces.shape=(11260, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00032639503479003906\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/10492694466334657502_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.19515204429626465\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.24925899505615234\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0011591911315917969\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 4.863739013671875e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0026493072509765625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.014150857925415039\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 4, 1, 2, 5, 3]), array([0.6644205, 0.65259  , 0.554493 , 0.2882935, 0.206692 , 0.0425327]))\n",
      "Sizes = [376, 512, 1867, 20, 25, 14]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "xy = 7.724356736967669 ratio was beyong 3 multiplier\n",
      "yz = 5.160831551150013 ratio was beyong 3 multiplier\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(936, 3), faces.shape=(1867, 3))>\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(5425, 3), faces.shape=(10850, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00023102760314941406\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/10492694466334657503_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.20802927017211914\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.2603311538696289\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002604961395263672\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0003800392150878906\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005074024200439453\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.025249719619750977\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([0, 1, 3, 2]), array([0.628895  , 0.5725385 , 0.407314  , 0.10071405]))\n",
      "Sizes = [1195, 1448, 47, 22]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [1]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 517.4379353293044\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(725, 3), faces.shape=(1448, 3))>\n",
      "----- working on mesh after poisson #4: <trimesh.Trimesh(vertices.shape=(5086, 3), faces.shape=(10168, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/104926944663346575/neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_104926944663346575_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022864341735839844\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/10492694466334657504_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.17523455619812012\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.2181711196899414\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0010924339294433594\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.078315734863281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.0024509429931640625\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.012697935104370117\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 6,  8,  0,  1,  5,  4,  3,  7,  2,  9, 10]), array([0.789208 , 0.664442 , 0.6140215, 0.5276215, 0.513334 , 0.430408 ,\n",
      "       0.3289515, 0.3219325, 0.302701 , 0.208219 , 0.110378 ]))\n",
      "Sizes = [89, 154, 1104, 300, 533, 77, 38, 198, 23, 17, 9]\n",
      "valid_soma_segments_width\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 344.08684611320496\n",
      "Run time was 344.0868446826935 \n",
      "    total_soma_list = [<trimesh.Trimesh(vertices.shape=(3041, 3), faces.shape=(6008, 3))>]\n",
      "    with sdf values = [0.8780509999999999]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Trying to write off file\n",
      "Predicted Coordinates are [308824 161158  17567]\n",
      "\n",
      "\n",
      "\n",
      "---- Working on 105930249090655379 ----\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 1250.0 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379.off -o /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(121224, 3), faces.shape=(273846, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(121224, 3), faces.shape=(273846, 3))>\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated_largest_piece.off\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated_largest_piece.off -o /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(163592, 3), faces.shape=(327680, 3))>, <trimesh.Trimesh(vertices.shape=(16934, 3), faces.shape=(33916, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(163592, 3), faces.shape=(327680, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_105930249090655379_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003066062927246094\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/10593024909065537900_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 21.6044921875\n",
      "2) Finished: Generating CGAL segmentation for neuron: 22.959618091583252\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 4\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.04827618598937988\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure', 'soma'}\n",
      "6) Finished: Classifying Entire Neuron: 6.461143493652344e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.07554483413696289\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.5504312515258789\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.57274\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([124,   4,  99,  28, 134, 133,  25,  52,  79, 118,  75,  36,   1,\n",
      "       109,   3,  76,  47,   7,  55,  43,  87,   0,   8, 122,  74,  84,\n",
      "        31,  68,  92,  30,  96,  29,  10,  15, 108,  78,  94,  57,   9,\n",
      "        32,  50, 103,  80,  37,  13,  18,   2,  81,  58,   6, 105,  14,\n",
      "        34, 110,  91, 102, 114,  98,  82, 136,  63,  62, 117,  85,   5,\n",
      "        17,  27,  19,  66, 128, 116,  69,  38,  42,  90,  21,  48,  97,\n",
      "        89, 126,  16, 132,  86,  39, 112,  44,  51,  12, 101,  11,  61,\n",
      "        45,  46,  41,  71,  49, 125,  77,  24, 131, 135,  88,  22,  64,\n",
      "       129,  26,  95,  93, 104,  53,  54,  73, 100,  23,  72,  40,  70,\n",
      "        65, 106, 130,  83, 119,  60, 127, 111,  20, 107,  59,  67,  35,\n",
      "       115, 113, 123,  33,  56, 121, 120]), array([0.649195  , 0.57274   , 0.503598  , 0.482547  , 0.443386  ,\n",
      "       0.3735265 , 0.373125  , 0.3680715 , 0.3564965 , 0.356305  ,\n",
      "       0.339793  , 0.33473   , 0.329643  , 0.325623  , 0.32555   ,\n",
      "       0.307789  , 0.306532  , 0.3048765 , 0.3037275 , 0.301548  ,\n",
      "       0.299894  , 0.299789  , 0.298161  , 0.2923445 , 0.28589   ,\n",
      "       0.283315  , 0.231407  , 0.23024   , 0.2285485 , 0.226396  ,\n",
      "       0.224945  , 0.218458  , 0.218296  , 0.21774   , 0.215173  ,\n",
      "       0.214686  , 0.213001  , 0.212088  , 0.211002  , 0.2047605 ,\n",
      "       0.201706  , 0.2001385 , 0.199965  , 0.197755  , 0.189581  ,\n",
      "       0.1881025 , 0.1880375 , 0.185821  , 0.181957  , 0.180009  ,\n",
      "       0.175375  , 0.1729045 , 0.172633  , 0.171425  , 0.171024  ,\n",
      "       0.165314  , 0.165091  , 0.164083  , 0.1634405 , 0.1628195 ,\n",
      "       0.1623585 , 0.161849  , 0.159516  , 0.158816  , 0.157077  ,\n",
      "       0.155767  , 0.153769  , 0.153026  , 0.152227  , 0.152158  ,\n",
      "       0.151797  , 0.149923  , 0.149696  , 0.146769  , 0.146644  ,\n",
      "       0.1457425 , 0.145619  , 0.145068  , 0.143861  , 0.142509  ,\n",
      "       0.141795  , 0.140518  , 0.14019   , 0.131625  , 0.129094  ,\n",
      "       0.127746  , 0.126854  , 0.126027  , 0.123764  , 0.120427  ,\n",
      "       0.119526  , 0.119451  , 0.11881   , 0.118096  , 0.117436  ,\n",
      "       0.117064  , 0.1169205 , 0.113697  , 0.113172  , 0.1112365 ,\n",
      "       0.110721  , 0.110372  , 0.110124  , 0.109642  , 0.106834  ,\n",
      "       0.105885  , 0.105397  , 0.103423  , 0.101797  , 0.0932762 ,\n",
      "       0.0923347 , 0.0897979 , 0.0897742 , 0.0896344 , 0.0888101 ,\n",
      "       0.0821059 , 0.0816302 , 0.0760891 , 0.07415675, 0.0733184 ,\n",
      "       0.0730791 , 0.07304085, 0.0712779 , 0.0705645 , 0.0675946 ,\n",
      "       0.0674566 , 0.0648715 , 0.0642824 , 0.0641141 , 0.0618935 ,\n",
      "       0.0610634 , 0.0609535 , 0.05160695, 0.0467196 , 0.04180555,\n",
      "       0.0416968 , 0.0221229 ]))\n",
      "Sizes = [411, 7420, 187, 6213, 1420, 1524, 1127, 136, 314, 343, 307, 2129, 533, 421, 4745, 1503, 657, 1746, 420, 5309, 980, 17886, 874, 1348, 1397, 1334, 299, 193, 696, 324, 209, 120, 958, 1796, 4249, 640, 199, 643, 831, 188, 92, 326, 923, 103, 343, 88, 260, 216, 165, 431, 49, 454, 67, 123, 105, 61, 503, 213, 146, 118, 200, 101, 173, 110, 41, 71, 73, 64, 259, 124, 191, 39, 149, 25, 33, 130, 91, 93, 54, 45, 67, 39, 143, 57, 87, 65, 105, 35, 63, 69, 123, 101, 189, 45, 30, 27, 44, 63, 117, 26, 87, 107, 36, 63, 83, 82, 49, 19, 13, 49, 25, 23, 60, 15, 55, 15, 77, 81, 44, 36, 33, 36, 19, 15, 88, 19, 17, 17, 71, 17, 24, 15, 40, 42, 20, 23, 29]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 6 viable somas: [4, 28, 134, 133, 36, 3]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside sphere validater: ratio_val = 19.099209437995462\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(3801, 3), faces.shape=(7420, 3))>\n",
      "xz = 7.592520552912799 ratio was beyong 3 multiplier\n",
      "yz = 5.528065698746696 ratio was beyong 3 multiplier\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(3114, 3), faces.shape=(6213, 3))>\n",
      "xz = 4.504126071541775 ratio was beyong 3 multiplier\n",
      "yz = 3.1067421726641737 ratio was beyong 3 multiplier\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(718, 3), faces.shape=(1420, 3))>\n",
      "xz = 4.470097600509875 ratio was beyong 3 multiplier\n",
      "yz = 6.912898270958411 ratio was beyong 3 multiplier\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(767, 3), faces.shape=(1524, 3))>\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 27.800092114736877\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(1072, 3), faces.shape=(2129, 3))>\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 81.81651873734596\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(2385, 3), faces.shape=(4745, 3))>\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(16934, 3), faces.shape=(33916, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/105930249090655379/neuron_105930249090655379_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/decimation_meshlab_25.mls\n",
      "done exporting decimated mesh: neuron_105930249090655379_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00022029876708984375\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/10593024909065537901_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 1.1247889995574951\n",
      "2) Finished: Generating CGAL segmentation for neuron: 1.2618064880371094\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0033767223358154297\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 5.054473876953125e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.008547544479370117\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.046552419662475586\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 8,  7,  1,  3,  2,  0, 10,  5,  6, 12,  9, 15, 18, 16, 19, 13,  4,\n",
      "       17, 14, 11]), array([0.410617  , 0.397842  , 0.39707   , 0.35898   , 0.283429  ,\n",
      "       0.271448  , 0.2650705 , 0.237117  , 0.185321  , 0.164593  ,\n",
      "       0.143474  , 0.142762  , 0.112442  , 0.107875  , 0.0674869 ,\n",
      "       0.0511593 , 0.04143965, 0.0393053 , 0.0391936 , 0.037938  ]))\n",
      "Sizes = [332, 375, 2039, 1336, 296, 1885, 122, 1341, 171, 99, 87, 139, 27, 38, 9, 19, 116, 17, 15, 15]\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 3]\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 14.25233957055265\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(1027, 3), faces.shape=(2039, 3))>\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "xvfb-run -a -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off -s /notebooks/Platinum_Soma/poisson.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_None_poisson.off\n",
      "Inside sphere validater: ratio_val = 23.40640387832456\n",
      "--->This soma mesh was not added because it did not pass the sphere validation: <trimesh.Trimesh(vertices.shape=(665, 3), faces.shape=(1336, 3))>\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 142.71775770187378\n",
      "Run time was 142.71775341033936 \n",
      "    total_soma_list = []\n",
      "    with sdf values = []\n",
      "There were no somas found for this mesh so just writing empty data\n",
      "Total time for BaylorSegmentCentroid populate = 1130.0433793067932\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Actually will do the population\n",
    "\"\"\"\n",
    "\n",
    "#(schema.jobs & \"table_name='__whole_auto_annotations_label_clusters3'\")#.delete()\n",
    "dj.config[\"enable_python_native_blobs\"] = True\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "BaylorSegmentCentroid.populate(reserve_jobs=True)\n",
    "print(f\"Total time for BaylorSegmentCentroid populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-f807c83828ea>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-f807c83828ea>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    BaylorSegmentCentroid()new_coord = np.array([787264,901589,779901]) / np.array([4,4,40])\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "BaylorSegmentCentroid()new_coord = np.array([787264,901589,779901]) / np.array([4,4,40])\n",
    "# new_coord = new_coord.astype(\"int\")\n",
    "# print(f\"x {new_coord[0]}, y {new_coord[1]}, z {new_coord[2]}\")\n",
    "# # good coordinates for 90231147459666747: x 196816, y 225397, z 19497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_coord = np.array([787264,901589,779901]) / np.array([4,4,40])\n",
    "# new_coord = new_coord.astype(\"int\")\n",
    "# print(f\"x {new_coord[0]}, y {new_coord[1]}, z {new_coord[2]}\")\n",
    "# # good coordinates for 90231147459666747: x 196816, y 225397, z 19497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dj.config[\"display.limit\"] = 100\n",
    "# BaylorSegmentCentroid().drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
