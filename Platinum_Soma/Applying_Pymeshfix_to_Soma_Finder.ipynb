{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: To investigate how pymeshfix can be used \n",
    "in the soma finder to avoid complications from\n",
    "nuclei centers from messing up the \n",
    "automatic segmentation algorithm\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-12 00:44:58,104 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2020-11-12 00:44:58,106 - settings - Setting database.user to celiib\n",
      "INFO - 2020-11-12 00:44:58,107 - settings - Setting database.password to newceliipass\n",
      "WARNING - 2020-11-12 00:44:58,591 - trimesh_repair - Need to pip install annotationframeworkclient to repair mesh with pychunkedgraph\n",
      "WARNING - 2020-11-12 00:44:58,593 - trimesh_io - Need to pip install annotationframeworkclient to use dataset_name parameters\n",
      "INFO - 2020-11-12 00:44:58,802 - settings - Setting stores to {'minnie65': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65', 'stage': '/mnt/dj-stor01/platinum/minnie65'}, 'meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/meshes'}, 'decimated_meshes': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes', 'stage': '/mnt/dj-stor01/platinum/minnie65/02/decimated_meshes'}, 'skeletons': {'protocol': 'file', 'location': '/mnt/dj-stor01/platinum/minnie65/02/skeletons'}}\n",
      "INFO - 2020-11-12 00:44:58,803 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2020-11-12 00:44:58,815 - connection - Connected celiib@at-database.ad.bcm.edu:3306\n",
      "INFO - 2020-11-12 00:44:58,978 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting celiib@at-database.ad.bcm.edu:3306\n"
     ]
    }
   ],
   "source": [
    "import soma_extraction_utils as sm\n",
    "import datajoint_utils as du\n",
    "import datajoint_utils as du\n",
    "import neuron_visualizations as nviz\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2020-11-12 00:44:59,012 - settings - Setting database.host to at-database.ad.bcm.edu\n",
      "INFO - 2020-11-12 00:44:59,014 - settings - Setting database.user to celiib\n",
      "INFO - 2020-11-12 00:44:59,015 - settings - Setting database.password to newceliipass\n",
      "INFO - 2020-11-12 00:44:59,017 - settings - Setting enable_python_native_blobs to True\n",
      "INFO - 2020-11-12 00:44:59,187 - settings - Setting enable_python_native_blobs to True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path for external_segmentation_path = /mnt/dj-stor01/platinum/minnie65/02\n",
      "Current path for external_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/meshes\n",
      "Current path for external_decimated_mesh_path = /mnt/dj-stor01/platinum/minnie65/02/decimated_meshes\n",
      "Current path for external_skeleton_path = /mnt/dj-stor01/platinum/minnie65/02/skeletons\n"
     ]
    }
   ],
   "source": [
    "import minfig\n",
    "du.config_celii()\n",
    "du.set_minnie65_config_segmentation(minfig)\n",
    "du.print_minnie65_config_paths(minfig)\n",
    "\n",
    "#configuring will include the adapters\n",
    "minnie,schema = du.configure_minnie_vm()\n",
    "\n",
    "key_source = minnie.Decimation & (minnie.BaylorSegmentCentroid() & \"multiplicity>=2\").proj()\n",
    "segment_ids = key_source.fetch(\"segment_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying the new Soma Finder on Other Nucleus Containing cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_segment_id = 864691135099501344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87b4358348b42aba42bdcdae0e8971b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segment_id = segment_ids[31]\n",
    "print(f\"curr_segment_id = {segment_id}\")\n",
    "current_neuron = du.fetch_segment_id_mesh(segment_id)\n",
    "nviz.plot_objects(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 937.5 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 1409 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25488965.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231680, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231680, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 2264 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_24785.off -o /notebooks/Platinum_Soma/temp/neuron_24785_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_722891.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_24785.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_24785_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_722891.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(29555, 3), faces.shape=(54690, 3))>, <trimesh.Trimesh(vertices.shape=(3559, 3), faces.shape=(7212, 3))>, <trimesh.Trimesh(vertices.shape=(976, 3), faces.shape=(1652, 3))>]\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece.off\n",
      "xvfb-run -n 9082 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/12345/poisson_823218.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(101368, 3), faces.shape=(203016, 3))>, <trimesh.Trimesh(vertices.shape=(55459, 3), faces.shape=(110986, 3))>, <trimesh.Trimesh(vertices.shape=(9718, 3), faces.shape=(19440, 3))>, <trimesh.Trimesh(vertices.shape=(6767, 3), faces.shape=(13530, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(101368, 3), faces.shape=(203016, 3))>\n",
      "xvfb-run -n 6545 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25993004.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005908012390136719\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 22.55332088470459\n",
      "2) Finished: Generating CGAL segmentation for neuron: 23.781590938568115\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0313723087310791\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 8.440017700195312e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.07102775573730469\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.39896249771118164\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.6802779999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1, 29, 27,  2, 12, 32, 13,  4, 28, 11, 20, 33, 15, 36, 43, 34, 44,\n",
      "       38, 19,  8, 31, 37,  5,  9, 18, 14, 24, 26, 10,  6,  0, 42, 16, 23,\n",
      "       40, 22, 39, 21, 35, 41, 30,  3, 25, 45,  7, 17]), array([0.680278  , 0.499722  , 0.223745  , 0.214049  , 0.157586  ,\n",
      "       0.1259765 , 0.104008  , 0.0968842 , 0.0967386 , 0.09522005,\n",
      "       0.0899482 , 0.07902665, 0.07762755, 0.0759587 , 0.0732425 ,\n",
      "       0.0675465 , 0.0647603 , 0.0639117 , 0.0609724 , 0.059105  ,\n",
      "       0.0577701 , 0.05743495, 0.0562601 , 0.05442945, 0.05264595,\n",
      "       0.05134555, 0.0501832 , 0.0500232 , 0.0499582 , 0.0490282 ,\n",
      "       0.04850125, 0.0480491 , 0.0454696 , 0.0420843 , 0.0400004 ,\n",
      "       0.035764  , 0.0351403 , 0.0343896 , 0.0313892 , 0.0274444 ,\n",
      "       0.026561  , 0.0247598 , 0.0184582 , 0.0162388 , 0.0158222 ,\n",
      "       0.00856174]))\n",
      "Sizes = [7294, 2178, 9770, 13629, 392, 16, 17, 1104, 487, 404, 303, 330, 110, 241, 60, 66, 17, 67, 47, 119, 850, 108, 95, 1976, 150, 296, 83, 1311, 147, 40, 3612, 60, 1485, 58, 1194, 79, 219, 100, 1604, 123, 171, 39, 19, 24, 93, 153]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 29]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 602 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_156061.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_156061_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_137411.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_156061.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_156061_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_137411.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.17863811419665318\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7296 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_963253.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_963253_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_826533.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_963253.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_963253_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_826533.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.042454723429038\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(55459, 3), faces.shape=(110986, 3))>\n",
      "xvfb-run -n 5067 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25993004.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00034689903259277344\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234501_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 4.779897689819336\n",
      "2) Finished: Generating CGAL segmentation for neuron: 5.42451024055481\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 2\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.019780874252319336\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.772445678710938e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.03598284721374512\n",
      "8) Staring: Generating final Vertex and Face Labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8) Finished: Generating final Vertex and Face Labels: 0.1991572380065918\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.846518\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 4, 3, 5, 1, 0, 6]), array([0.846518  , 0.5292285 , 0.4709835 , 0.0640337 , 0.06392465,\n",
      "       0.0616208 , 0.05444875]))\n",
      "Sizes = [5307, 1454, 288, 7958, 11390, 865, 474]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 4]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 5176 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_183629.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_183629_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_90998.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_183629.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_183629_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_90998.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.5558136101151967\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4562 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_403952.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_403952_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_433342.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_403952.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_403952_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_433342.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.06209026513834883\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(9718, 3), faces.shape=(19440, 3))>\n",
      "xvfb-run -n 501 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25993004.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00077056884765625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234502_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.48542308807373047\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6092700958251953\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0038750171661376953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.843971252441406e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007700204849243164\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.038789987564086914\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([10,  2,  6,  1,  0,  3,  5,  4,  7,  9, 12,  8, 13, 11, 14]), array([0.659066 , 0.6505635, 0.636751 , 0.544794 , 0.520872 , 0.514886 ,\n",
      "       0.45508  , 0.4496345, 0.4279555, 0.3005005, 0.287983 , 0.2816845,\n",
      "       0.2035575, 0.1736045, 0.09592  ]))\n",
      "Sizes = [226, 206, 214, 375, 383, 942, 909, 692, 104, 214, 57, 172, 320, 30, 14]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_115562.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 568.6696877105156\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(474, 3), faces.shape=(942, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(6767, 3), faces.shape=(13530, 3))>\n",
      "xvfb-run -n 8500 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25993004.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.00032138824462890625\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234503_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.33323192596435547\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.4198582172393799\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0022437572479248047\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.0007021427154541016\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005257368087768555\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02737736701965332\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 0,  5,  3, 11,  8,  7,  2,  6,  9,  1, 10,  4]), array([0.6362575, 0.603852 , 0.603277 , 0.599556 , 0.565329 , 0.4844555,\n",
      "       0.421451 , 0.42001  , 0.411998 , 0.302279 , 0.141028 , 0.1391765]))\n",
      "Sizes = [466, 464, 390, 376, 348, 640, 142, 402, 58, 25, 47, 22]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "There were soma pairings: Connected components in = [{2, 3}] \n",
      "Final total_soma_list_revised = [<trimesh.Trimesh(vertices.shape=(3500, 3), faces.shape=(6761, 3))>, <trimesh.Trimesh(vertices.shape=(3923, 3), faces.shape=(7294, 3))>, <trimesh.Trimesh(vertices.shape=(1114, 3), faces.shape=(2178, 3))>]\n",
      "Final total_soma_list_revised_sdf = [0.5292285, 0.6802779999999999, 0.499722]\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 221.10613656044006\n",
      "Before Filtering the number of somas found = 3\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(3500, 3), faces.shape=(6761, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "There were 6 pieces found after size threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.874\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "Total time for Subtract Soam = 0.875028133392334\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.2775459289550781\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 6016 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_174801.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_174801_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_876455.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_174801.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_174801_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_876455.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.987947828960416\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(3923, 3), faces.shape=(7294, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "There were 9 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.807\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "Total time for Subtract Soam = 0.8078815937042236\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.3056652545928955\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2533 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_705042.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_705042_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_504727.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_705042.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_705042_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_504727.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.537389933430492\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1114, 3), faces.shape=(2178, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "There were 5 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.593\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "Total time for Subtract Soam = 0.5948548316955566\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.2686290740966797\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7541 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_402461.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_402461_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_680678.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_402461.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_402461_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_680678.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.074522921632522\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 967 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_82328.off -o /notebooks/Platinum_Soma/temp/neuron_82328_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_464224.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_82328.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_82328_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_464224.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1917, 3), faces.shape=(3662, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fec0fcbc63f405ab31ff28251df74d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(3284, 3), faces.shape=(6152, 3))>, <trimesh.Trimesh(vertices.shape=(465, 3), faces.shape=(849, 3))>, <trimesh.Trimesh(vertices.shape=(125, 3), faces.shape=(274, 3))>, <trimesh.Trimesh(vertices.shape=(86, 3), faces.shape=(163, 3))>, <trimesh.Trimesh(vertices.shape=(46, 3), faces.shape=(78, 3))>, <trimesh.Trimesh(vertices.shape=(51, 3), faces.shape=(54, 3))>, <trimesh.Trimesh(vertices.shape=(31, 3), faces.shape=(42, 3))>, <trimesh.Trimesh(vertices.shape=(19, 3), faces.shape=(19, 3))>, <trimesh.Trimesh(vertices.shape=(7, 3), faces.shape=(9, 3))>, <trimesh.Trimesh(vertices.shape=(8, 3), faces.shape=(7, 3))>, <trimesh.Trimesh(vertices.shape=(6, 3), faces.shape=(4, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>]\n",
      "meshes_split_sdf = [0.714565   0.233692   0.04803675 0.00930879 0.128653   0.5674505\n",
      " 0.039861   0.567193   0.0072391  0.706263   0.07695815 0.682508\n",
      " 0.405627  ]\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 4553 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_7158.off -o /notebooks/Platinum_Soma/temp/neuron_7158_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_778394.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_7158.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_7158_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_778394.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1030, 3), faces.shape=(1941, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca219cb9649491abcede077a183d6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(1465, 3), faces.shape=(2538, 3))>, <trimesh.Trimesh(vertices.shape=(303, 3), faces.shape=(601, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(552, 3))>, <trimesh.Trimesh(vertices.shape=(204, 3), faces.shape=(390, 3))>, <trimesh.Trimesh(vertices.shape=(66, 3), faces.shape=(134, 3))>, <trimesh.Trimesh(vertices.shape=(9, 3), faces.shape=(7, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>]\n",
      "meshes_split_sdf = [0.08201415 0.0130364  0.0178163  0.01185385 0.0112205  0.112518\n",
      " 0.41241    0.2739605  0.0496812  0.00442904 0.656093   0.38122\n",
      " 0.0342001  0.0283426  0.        ]\n",
      "No split meshes were above the width threshold (0.32) and size threshold (1300) so continuing\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 9180 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_51787.off -o /notebooks/Platinum_Soma/temp/neuron_51787_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_112648.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_51787.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_51787_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_112648.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present, largest is 551\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8ad6c9b3f24fba905d31ad11d27500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(1703, 3), faces.shape=(3294, 3))>, <trimesh.Trimesh(vertices.shape=(597, 3), faces.shape=(1388, 3))>, <trimesh.Trimesh(vertices.shape=(98, 3), faces.shape=(199, 3))>, <trimesh.Trimesh(vertices.shape=(56, 3), faces.shape=(107, 3))>, <trimesh.Trimesh(vertices.shape=(62, 3), faces.shape=(86, 3))>, <trimesh.Trimesh(vertices.shape=(39, 3), faces.shape=(81, 3))>, <trimesh.Trimesh(vertices.shape=(39, 3), faces.shape=(73, 3))>, <trimesh.Trimesh(vertices.shape=(30, 3), faces.shape=(57, 3))>, <trimesh.Trimesh(vertices.shape=(27, 3), faces.shape=(49, 3))>, <trimesh.Trimesh(vertices.shape=(22, 3), faces.shape=(39, 3))>, <trimesh.Trimesh(vertices.shape=(17, 3), faces.shape=(29, 3))>]\n",
      "meshes_split_sdf = [0.6745755  0.0611653  0.0109002  0.0109098  0.04792885 0.00813211\n",
      " 0.0232097  0.0268611  0.00997143 0.0146791  0.0107597 ]\n"
     ]
    }
   ],
   "source": [
    "sm = reload(sm)\n",
    "somas = sm.extract_soma_center(\n",
    "    segment_id=12345,\n",
    "    current_mesh_verts=current_neuron.vertices,\n",
    "    current_mesh_faces=current_neuron.faces\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c4e99ccb784e37abd58c547311c21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=somas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 937.5 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 6398 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25830570.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231680, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231680, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 3855 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_1354.off -o /notebooks/Platinum_Soma/temp/neuron_1354_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_911907.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_1354.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_1354_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_911907.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(29555, 3), faces.shape=(54690, 3))>, <trimesh.Trimesh(vertices.shape=(3559, 3), faces.shape=(7212, 3))>, <trimesh.Trimesh(vertices.shape=(976, 3), faces.shape=(1652, 3))>]\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece.off\n",
      "xvfb-run -n 9569 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/12345/poisson_298745.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(101368, 3), faces.shape=(203016, 3))>, <trimesh.Trimesh(vertices.shape=(55459, 3), faces.shape=(110986, 3))>, <trimesh.Trimesh(vertices.shape=(9718, 3), faces.shape=(19440, 3))>, <trimesh.Trimesh(vertices.shape=(6767, 3), faces.shape=(13530, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(101368, 3), faces.shape=(203016, 3))>\n",
      "xvfb-run -n 2394 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25240781.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0036101341247558594\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 21.894396543502808\n",
      "2) Finished: Generating CGAL segmentation for neuron: 23.034474849700928\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.03099536895751953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 8.821487426757812e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.06848716735839844\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.7919812202453613\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.6802779999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1, 29, 27,  2, 12, 32, 13,  4, 28, 11, 20, 33, 15, 36, 43, 34, 44,\n",
      "       38, 19,  8, 31, 37,  5,  9, 18, 14, 24, 26, 10,  6,  0, 42, 16, 23,\n",
      "       40, 22, 39, 21, 35, 41, 30,  3, 25, 45,  7, 17]), array([0.680278  , 0.499722  , 0.223745  , 0.214049  , 0.157586  ,\n",
      "       0.1259765 , 0.104008  , 0.0968842 , 0.0967386 , 0.09522005,\n",
      "       0.0899482 , 0.07902665, 0.07762755, 0.0759587 , 0.0732425 ,\n",
      "       0.0675465 , 0.0647603 , 0.0639117 , 0.0609724 , 0.059105  ,\n",
      "       0.0577701 , 0.05743495, 0.0562601 , 0.05442945, 0.05264595,\n",
      "       0.05134555, 0.0501832 , 0.0500232 , 0.0499582 , 0.0490282 ,\n",
      "       0.04850125, 0.0480491 , 0.0454696 , 0.0420843 , 0.0400004 ,\n",
      "       0.035764  , 0.0351403 , 0.0343896 , 0.0313892 , 0.0274444 ,\n",
      "       0.026561  , 0.0247598 , 0.0184582 , 0.0162388 , 0.0158222 ,\n",
      "       0.00856174]))\n",
      "Sizes = [7294, 2178, 9770, 13629, 392, 16, 17, 1104, 487, 404, 303, 330, 110, 241, 60, 66, 17, 67, 47, 119, 850, 108, 95, 1976, 150, 296, 83, 1311, 147, 40, 3612, 60, 1485, 58, 1194, 79, 219, 100, 1604, 123, 171, 39, 19, 24, 93, 153]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 29]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 364 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_958911.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_958911_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_535624.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_958911.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_958911_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_535624.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.17863811419665318\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1567 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_478806.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_478806_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_233926.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_478806.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_478806_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_233926.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.042454723429038\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(55459, 3), faces.shape=(110986, 3))>\n",
      "xvfb-run -n 6293 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25240781.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004012584686279297\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234501_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 4.519346475601196\n",
      "2) Finished: Generating CGAL segmentation for neuron: 5.174947500228882\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 2\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.016294240951538086\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00010347366333007812\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.04291415214538574\n",
      "8) Staring: Generating final Vertex and Face Labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8) Finished: Generating final Vertex and Face Labels: 0.7294266223907471\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.846518\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 4, 3, 5, 1, 0, 6]), array([0.846518  , 0.5292285 , 0.4709835 , 0.0640337 , 0.06392465,\n",
      "       0.0616208 , 0.05444875]))\n",
      "Sizes = [5307, 1454, 288, 7958, 11390, 865, 474]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 4]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4064 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_195156.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_195156_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_420339.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_195156.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_195156_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_420339.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.5558136101151967\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4674 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_887356.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_887356_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_784573.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_887356.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_887356_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_784573.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.06209026513834883\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(9718, 3), faces.shape=(19440, 3))>\n",
      "xvfb-run -n 6136 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25240781.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0007648468017578125\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234502_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.47303175926208496\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.5911412239074707\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.0029878616333007812\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 8.893013000488281e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007708549499511719\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.03799581527709961\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([10,  2,  6,  1,  0,  3,  5,  4,  7,  9, 12,  8, 13, 11, 14]), array([0.659066 , 0.6505635, 0.636751 , 0.544794 , 0.520872 , 0.514886 ,\n",
      "       0.45508  , 0.4496345, 0.4279555, 0.3005005, 0.287983 , 0.2816845,\n",
      "       0.2035575, 0.1736045, 0.09592  ]))\n",
      "Sizes = [226, 206, 214, 375, 383, 942, 909, 692, 104, 214, 57, 172, 320, 30, 14]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_381073.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 568.6696877105156\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(474, 3), faces.shape=(942, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(6767, 3), faces.shape=(13530, 3))>\n",
      "xvfb-run -n 8215 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25240781.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003368854522705078\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234503_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.32941412925720215\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.4418916702270508\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.007650852203369141\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 8.320808410644531e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.005619525909423828\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.02946329116821289\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 0,  5,  3, 11,  8,  7,  2,  6,  9,  1, 10,  4]), array([0.6362575, 0.603852 , 0.603277 , 0.599556 , 0.565329 , 0.4844555,\n",
      "       0.421451 , 0.42001  , 0.411998 , 0.302279 , 0.141028 , 0.1391765]))\n",
      "Sizes = [466, 464, 390, 376, 348, 640, 142, 402, 58, 25, 47, 22]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "There were soma pairings: Connected components in = [{2, 3}] \n",
      "Final total_soma_list_revised = [<trimesh.Trimesh(vertices.shape=(3500, 3), faces.shape=(6761, 3))>, <trimesh.Trimesh(vertices.shape=(3923, 3), faces.shape=(7294, 3))>, <trimesh.Trimesh(vertices.shape=(1114, 3), faces.shape=(2178, 3))>]\n",
      "Final total_soma_list_revised_sdf = [0.5292285, 0.6802779999999999, 0.499722]\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 208.03978657722473\n",
      "Before Filtering the number of somas found = 3\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(3500, 3), faces.shape=(6761, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "There were 6 pieces found after size threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.952\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "Total time for Subtract Soam = 0.953493595123291\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.29692959785461426\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8384 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_177645.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_177645_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_269024.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_177645.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_177645_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_269024.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.987947828960416\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(3923, 3), faces.shape=(7294, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "There were 9 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.9\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "Total time for Subtract Soam = 0.9009675979614258\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.3346073627471924\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8374 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_893369.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_893369_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_969242.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_893369.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_893369_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_969242.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.537389933430492\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1114, 3), faces.shape=(2178, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "There were 5 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.672\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "Total time for Subtract Soam = 0.6766910552978516\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.33019590377807617\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 4928 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_823949.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_823949_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_397134.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_823949.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_823949_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_397134.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.074522921632522\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-739983642add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcurrent_mesh_verts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_neuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcurrent_mesh_faces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_neuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msegmentation_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/meshAfterParty/soma_extraction_utils.py\u001b[0m in \u001b[0;36mextract_soma_center\u001b[0;34m(segment_id, current_mesh_verts, current_mesh_faces, outer_decimation_ratio, large_mesh_threshold, large_mesh_threshold_inner, soma_width_threshold, soma_size_threshold, inner_decimation_ratio, volume_mulitplier, side_length_ratio_threshold, soma_size_threshold_max, delete_files, backtrack_soma_mesh_to_original, boundary_vertices_threshold, poisson_backtrack_distance_threshold, close_holes, remove_inside_pieces, size_threshold_to_remove, pymeshfix_clean, check_holes_before_pymeshfix, second_poisson, segmentation_at_end, last_size_threshold)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;31m#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m     \u001b[0mfiltered_soma_list_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_soma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m     \u001b[0mfiltered_soma_list_sdf_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_soma_list_sdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'copy' is not defined"
     ]
    }
   ],
   "source": [
    "sm = reload(sm)\n",
    "somas = sm.extract_soma_center(\n",
    "segment_id=12345,\n",
    "    current_mesh_verts=current_neuron.vertices,\n",
    "    current_mesh_faces=current_neuron.faces,\n",
    "    segmentation_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<trimesh.Trimesh(vertices.shape=(2957, 3), faces.shape=(5709, 3))>,\n",
       "       <trimesh.Trimesh(vertices.shape=(1703, 3), faces.shape=(3294, 3))>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3758975ea9341bebc75f4f540633b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=somas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184f47a66456400783d8893ec95159be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(main_mesh=current_neuron,\n",
    "                meshes=somas[0],\n",
    "meshes_colors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424033eb033c45fbb2cdee895bb4b61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=somas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Kernel Dying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soma_extraction_utils import *\n",
    "\n",
    "outer_decimation_ratio= 0.25\n",
    "large_mesh_threshold = 60000\n",
    "large_mesh_threshold_inner = 40000\n",
    "soma_width_threshold = 0.32\n",
    "soma_size_threshold = 15000\n",
    "inner_decimation_ratio = 0.25\n",
    "volume_mulitplier=8\n",
    "#side_length_ratio_threshold=3\n",
    "side_length_ratio_threshold=6\n",
    "soma_size_threshold_max=192000 #this puts at 12000 once decimated, another possible is 256000\n",
    "delete_files=True\n",
    "backtrack_soma_mesh_to_original=True #should either be None or \n",
    "boundary_vertices_threshold=None#700 the previous threshold used\n",
    "poisson_backtrack_distance_threshold=None#1500 the previous threshold used\n",
    "close_holes=False\n",
    "\n",
    "#------- 11/12 Additions --------------- #\n",
    "\n",
    "#these arguments are for removing inside pieces\n",
    "remove_inside_pieces = True\n",
    "size_threshold_to_remove=1000 #size accounting for the decimation\n",
    "\n",
    "\n",
    "pymeshfix_clean=False\n",
    "check_holes_before_pymeshfix=False\n",
    "second_poisson=False\n",
    "segmentation_at_end=True\n",
    "last_size_threshold = 1300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 937.5 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "xvfb-run -n 9046 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25501658.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231680, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231680, 3))>\n",
      "remove_inside_pieces requested \n",
      "xvfb-run -n 4127 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_5596.off -o /notebooks/Platinum_Soma/temp/neuron_5596_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_126426.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_5596.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_5596_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_126426.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(29555, 3), faces.shape=(54690, 3))>, <trimesh.Trimesh(vertices.shape=(3559, 3), faces.shape=(7212, 3))>, <trimesh.Trimesh(vertices.shape=(976, 3), faces.shape=(1652, 3))>]\n",
      "pre_largest_mesh_path = /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece.off\n",
      "xvfb-run -n 9313 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson.off -s /notebooks/Platinum_Soma/12345/poisson_666916.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(101368, 3), faces.shape=(203016, 3))>, <trimesh.Trimesh(vertices.shape=(55459, 3), faces.shape=(110986, 3))>, <trimesh.Trimesh(vertices.shape=(9718, 3), faces.shape=(19440, 3))>, <trimesh.Trimesh(vertices.shape=(6767, 3), faces.shape=(13530, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(101368, 3), faces.shape=(203016, 3))>\n",
      "xvfb-run -n 8759 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25828050.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0005214214324951172\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234500_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 22.583467960357666\n",
      "2) Finished: Generating CGAL segmentation for neuron: 23.763896703720093\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.03540802001953125\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 8.392333984375e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.06783437728881836\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.3949391841888428\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.6802779999999999\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 1, 29, 27,  2, 12, 32, 13,  4, 28, 11, 20, 33, 15, 36, 43, 34, 44,\n",
      "       38, 19,  8, 31, 37,  5,  9, 18, 14, 24, 26, 10,  6,  0, 42, 16, 23,\n",
      "       40, 22, 39, 21, 35, 41, 30,  3, 25, 45,  7, 17]), array([0.680278  , 0.499722  , 0.223745  , 0.214049  , 0.157586  ,\n",
      "       0.1259765 , 0.104008  , 0.0968842 , 0.0967386 , 0.09522005,\n",
      "       0.0899482 , 0.07902665, 0.07762755, 0.0759587 , 0.0732425 ,\n",
      "       0.0675465 , 0.0647603 , 0.0639117 , 0.0609724 , 0.059105  ,\n",
      "       0.0577701 , 0.05743495, 0.0562601 , 0.05442945, 0.05264595,\n",
      "       0.05134555, 0.0501832 , 0.0500232 , 0.0499582 , 0.0490282 ,\n",
      "       0.04850125, 0.0480491 , 0.0454696 , 0.0420843 , 0.0400004 ,\n",
      "       0.035764  , 0.0351403 , 0.0343896 , 0.0313892 , 0.0274444 ,\n",
      "       0.026561  , 0.0247598 , 0.0184582 , 0.0162388 , 0.0158222 ,\n",
      "       0.00856174]))\n",
      "Sizes = [7294, 2178, 9770, 13629, 392, 16, 17, 1104, 487, 404, 303, 330, 110, 241, 60, 66, 17, 67, 47, 119, 850, 108, 95, 1976, 150, 296, 83, 1311, 147, 40, 3612, 60, 1485, 58, 1194, 79, 219, 100, 1604, 123, 171, 39, 19, 24, 93, 153]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [1, 29]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9174 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_571460.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_571460_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_88388.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_571460.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_571460_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_88388.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.17863811419665318\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 2519 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_661647.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_661647_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_770689.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_661647.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_661647_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_770689.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.042454723429038\n",
      "----- working on mesh after poisson #1: <trimesh.Trimesh(vertices.shape=(55459, 3), faces.shape=(110986, 3))>\n",
      "xvfb-run -n 324 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25828050.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0004971027374267578\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234501_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 4.940724849700928\n",
      "2) Finished: Generating CGAL segmentation for neuron: 5.558196783065796\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6]\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "changed the median value\n",
      "changed the mean value\n",
      "changed the max value\n",
      "soma_index = 2\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.016306638717651367\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'soma', 'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 0.00010347366333007812\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.038245201110839844\n",
      "8) Staring: Generating final Vertex and Face Labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8) Finished: Generating final Vertex and Face Labels: 0.20545482635498047\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0.846518\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([2, 4, 3, 5, 1, 0, 6]), array([0.846518  , 0.5292285 , 0.4709835 , 0.0640337 , 0.06392465,\n",
      "       0.0616208 , 0.05444875]))\n",
      "Sizes = [5307, 1454, 288, 7958, 11390, 865, 474]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 2 viable somas: [2, 4]\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1874 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_29900.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_29900_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_434829.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_29900.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_29900_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_434829.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 2.5558136101151967\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 7523 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_463530.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_463530_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_856969.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_463530.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_463530_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_856969.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.06209026513834883\n",
      "----- working on mesh after poisson #2: <trimesh.Trimesh(vertices.shape=(9718, 3), faces.shape=(19440, 3))>\n",
      "xvfb-run -n 8413 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25828050.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006067752838134766\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234502_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.4981703758239746\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.6018669605255127\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.003075122833251953\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 7.319450378417969e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.007015228271484375\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.037109375\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([10,  2,  6,  1,  0,  3,  5,  4,  7,  9, 12,  8, 13, 11, 14]), array([0.659066 , 0.6505635, 0.636751 , 0.544794 , 0.520872 , 0.514886 ,\n",
      "       0.45508  , 0.4496345, 0.4279555, 0.3005005, 0.287983 , 0.2816845,\n",
      "       0.2035575, 0.1736045, 0.09592  ]))\n",
      "Sizes = [226, 206, 214, 375, 383, 942, 909, 692, 104, 214, 57, 172, 320, 30, 14]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "      ------ Found 1 viable somas: [3]\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_658742.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 568.6696877105156\n",
      "--->This soma mesh was not added because it did not pass the sphere validation:\n",
      " soma_mesh = <trimesh.Trimesh(vertices.shape=(474, 3), faces.shape=(942, 3))>, curr_side_len_check = True, curr_volume_check = False\n",
      "----- working on mesh after poisson #3: <trimesh.Trimesh(vertices.shape=(6767, 3), faces.shape=(13530, 3))>\n",
      "xvfb-run -n 7236 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner.off -o /notebooks/Platinum_Soma/12345/neuron_12345_decimated_largest_piece_poisson_largest_inner_decimated.off -s /notebooks/Platinum_Soma/12345/decimation_meshlab_25828050.mls\n",
      "done exporting decimated mesh: neuron_12345_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0006625652313232422\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /notebooks/Platinum_Soma/temp/1234503_fixed \n",
      "1\n",
      "Finished CGAL segmentation algorithm: 0.3156719207763672\n",
      "2) Finished: Generating CGAL segmentation for neuron: 0.3968079090118408\n",
      "3) Staring: Generating Graph Structure and Identifying Soma using soma size threshold  = 3000\n",
      "my_list_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "soma_index = -1\n",
      "3) Finished: Generating Graph Structure and Identifying Soma: 0.002027750015258789\n",
      "Not finding the apical because soma_only option selected\n",
      "6) Staring: Classifying Entire Neuron\n",
      "Total Labels found = {'unsure'}\n",
      "6) Finished: Classifying Entire Neuron: 8.344650268554688e-05\n",
      "7) Staring: Transfering Segmentation Labels to Face Labels\n",
      "7) Finished: Transfering Segmentation Labels to Face Labels: 0.004975557327270508\n",
      "8) Staring: Generating final Vertex and Face Labels\n",
      "8) Finished: Generating final Vertex and Face Labels: 0.025705575942993164\n",
      "Returning the soma_sdf value AND the classifier\n",
      "soma_sdf_value = 0\n",
      "segmentation[sorted_medians],median_values[sorted_medians] = (array([ 0,  5,  3, 11,  8,  7,  2,  6,  9,  1, 10,  4]), array([0.6362575, 0.603852 , 0.603277 , 0.599556 , 0.565329 , 0.4844555,\n",
      "       0.421451 , 0.42001  , 0.411998 , 0.302279 , 0.141028 , 0.1391765]))\n",
      "Sizes = [466, 464, 390, 376, 348, 640, 142, 402, 58, 25, 47, 22]\n",
      "soma_size_threshold = 937.5\n",
      "soma_size_threshold_max=12000.0\n",
      "valid_soma_segments_width\n",
      "There were soma pairings: Connected components in = [{2, 3}] \n",
      "Final total_soma_list_revised = [<trimesh.Trimesh(vertices.shape=(3500, 3), faces.shape=(6761, 3))>, <trimesh.Trimesh(vertices.shape=(3923, 3), faces.shape=(7294, 3))>, <trimesh.Trimesh(vertices.shape=(1114, 3), faces.shape=(2178, 3))>]\n",
      "Final total_soma_list_revised_sdf = [0.5292285, 0.6802779999999999, 0.499722]\n",
      "\n",
      "\n",
      "\n",
      " Total time for run = 229.20709562301636\n",
      "Before Filtering the number of somas found = 3\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(3500, 3), faces.shape=(6761, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "There were 6 pieces found after size threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "Total Time for soma mesh cancellation = 1.124\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(80497, 3), faces.shape=(166609, 3))>, <trimesh.Trimesh(vertices.shape=(15615, 3), faces.shape=(32066, 3))>, <trimesh.Trimesh(vertices.shape=(5746, 3), faces.shape=(11402, 3))>, <trimesh.Trimesh(vertices.shape=(2882, 3), faces.shape=(5891, 3))>, <trimesh.Trimesh(vertices.shape=(2043, 3), faces.shape=(3869, 3))>, <trimesh.Trimesh(vertices.shape=(246, 3), faces.shape=(474, 3))>]\n",
      "Total time for Subtract Soam = 1.1253514289855957\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.30307483673095703\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 9801 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_609801.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_609801_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_914074.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_609801.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_609801_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_914074.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 3.987947828960416\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(3923, 3), faces.shape=(7294, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "There were 9 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.923\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(101774, 3), faces.shape=(208463, 3))>, <trimesh.Trimesh(vertices.shape=(740, 3), faces.shape=(1493, 3))>, <trimesh.Trimesh(vertices.shape=(546, 3), faces.shape=(1107, 3))>, <trimesh.Trimesh(vertices.shape=(329, 3), faces.shape=(661, 3))>, <trimesh.Trimesh(vertices.shape=(285, 3), faces.shape=(473, 3))>, <trimesh.Trimesh(vertices.shape=(183, 3), faces.shape=(363, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(340, 3))>, <trimesh.Trimesh(vertices.shape=(170, 3), faces.shape=(326, 3))>, <trimesh.Trimesh(vertices.shape=(140, 3), faces.shape=(279, 3))>]\n",
      "Total time for Subtract Soam = 0.9237537384033203\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.31580328941345215\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 8611 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_279837.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_279837_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_325230.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_279837.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_279837_poisson.off\n",
      "mesh.is_watertight = False\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_325230.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 0.537389933430492\n",
      "Performing Soma Mesh Backtracking to original mesh\n",
      "# total split meshes = 13\n",
      "viable_meshes = [0]\n",
      "There were 11 pieces found after size threshold\n",
      "# of soma containing seperate meshes = 1\n",
      "meshes with somas = {0: [0]}\n",
      "\n",
      "\n",
      "----Working on soma-containing mesh piece 0----\n",
      "current_soma_mesh_list = [<trimesh.Trimesh(vertices.shape=(1114, 3), faces.shape=(2178, 3))>]\n",
      "current_mesh = <trimesh.Trimesh(vertices.shape=(111972, 3), faces.shape=(231243, 3))>\n",
      "\n",
      "inside Soma subtraction\n",
      "mesh pieces in subtact soma BEFORE the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "There were 5 pieces found after size threshold\n",
      "mesh pieces in subtact soma AFTER the filtering inside pieces = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "Total Time for soma mesh cancellation = 0.704\n",
      "mesh_pieces_without_soma = [<trimesh.Trimesh(vertices.shape=(108110, 3), faces.shape=(223164, 3))>, <trimesh.Trimesh(vertices.shape=(507, 3), faces.shape=(987, 3))>, <trimesh.Trimesh(vertices.shape=(386, 3), faces.shape=(778, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(592, 3))>, <trimesh.Trimesh(vertices.shape=(171, 3), faces.shape=(320, 3))>]\n",
      "Total time for Subtract Soam = 0.7049565315246582\n",
      "Total time for Original_mesh_faces_map for mesh_pieces without soma= 0.33159565925598145\n",
      "poisson_backtrack_distance_threshold = None\n",
      "Using Poisson Surface Reconstruction for watertightness in soma_volume_ratio\n",
      "xvfb-run -n 1001 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/Poisson_temp/neuron_434018.off -o /notebooks/Platinum_Soma/Poisson_temp/neuron_434018_poisson.off -s /notebooks/Platinum_Soma/Poisson_temp/poisson_700592.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/Poisson_temp/neuron_434018.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/Poisson_temp/neuron_434018_poisson.off\n",
      "mesh.is_watertight = True\n",
      "/notebooks/Platinum_Soma/Poisson_temp/poisson_700592.mls is being deleted....\n",
      "Inside sphere validater: ratio_val = 5.074522921632522\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 5850 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_68410.off -o /notebooks/Platinum_Soma/temp/neuron_68410_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_546929.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_68410.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_68410_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_546929.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1917, 3), faces.shape=(3662, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb1d1c6a7244b5a9f34aecd4018a10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(3284, 3), faces.shape=(6152, 3))>, <trimesh.Trimesh(vertices.shape=(465, 3), faces.shape=(849, 3))>, <trimesh.Trimesh(vertices.shape=(125, 3), faces.shape=(274, 3))>, <trimesh.Trimesh(vertices.shape=(86, 3), faces.shape=(163, 3))>, <trimesh.Trimesh(vertices.shape=(46, 3), faces.shape=(78, 3))>, <trimesh.Trimesh(vertices.shape=(51, 3), faces.shape=(54, 3))>, <trimesh.Trimesh(vertices.shape=(31, 3), faces.shape=(42, 3))>, <trimesh.Trimesh(vertices.shape=(19, 3), faces.shape=(19, 3))>, <trimesh.Trimesh(vertices.shape=(7, 3), faces.shape=(9, 3))>, <trimesh.Trimesh(vertices.shape=(8, 3), faces.shape=(7, 3))>, <trimesh.Trimesh(vertices.shape=(6, 3), faces.shape=(4, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>]\n",
      "meshes_split_sdf = [0.714565   0.233692   0.04803675 0.00930879 0.128653   0.5674505\n",
      " 0.039861   0.567193   0.0072391  0.706263   0.07695815 0.682508\n",
      " 0.405627  ]\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 9881 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_40253.off -o /notebooks/Platinum_Soma/temp/neuron_40253_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_204664.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_40253.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_40253_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_204664.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1030, 3), faces.shape=(1941, 3))>]\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecb697b15514dac8cc8b09d530cba03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(1465, 3), faces.shape=(2538, 3))>, <trimesh.Trimesh(vertices.shape=(303, 3), faces.shape=(601, 3))>, <trimesh.Trimesh(vertices.shape=(300, 3), faces.shape=(552, 3))>, <trimesh.Trimesh(vertices.shape=(204, 3), faces.shape=(390, 3))>, <trimesh.Trimesh(vertices.shape=(66, 3), faces.shape=(134, 3))>, <trimesh.Trimesh(vertices.shape=(9, 3), faces.shape=(7, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(4, 3), faces.shape=(2, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>, <trimesh.Trimesh(vertices.shape=(3, 3), faces.shape=(1, 3))>]\n",
      "meshes_split_sdf = [0.08201415 0.0130364  0.0178163  0.01185385 0.0112205  0.112518\n",
      " 0.41241    0.2739605  0.0496812  0.00442904 0.656093   0.38122\n",
      " 0.0342001  0.0283426  0.        ]\n",
      "No split meshes were above the width threshold (0.32) and size threshold (1300) so continuing\n",
      "removing mesh interior before segmentation\n",
      "xvfb-run -n 9984 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_51856.off -o /notebooks/Platinum_Soma/temp/neuron_51856_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_262095.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_51856.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_51856_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_262095.mls is being deleted....\n",
      "THERE WERE NO MESH PIECES GREATER THAN THE significance_threshold\n",
      "No significant (1000) interior meshes present, largest is 551\n",
      "Doing the soma segmentation filter at end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1ec60fa6324c0398234ba5cc44d411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "meshes_split = [<trimesh.Trimesh(vertices.shape=(1703, 3), faces.shape=(3294, 3))>, <trimesh.Trimesh(vertices.shape=(597, 3), faces.shape=(1388, 3))>, <trimesh.Trimesh(vertices.shape=(98, 3), faces.shape=(199, 3))>, <trimesh.Trimesh(vertices.shape=(56, 3), faces.shape=(107, 3))>, <trimesh.Trimesh(vertices.shape=(62, 3), faces.shape=(86, 3))>, <trimesh.Trimesh(vertices.shape=(39, 3), faces.shape=(81, 3))>, <trimesh.Trimesh(vertices.shape=(39, 3), faces.shape=(73, 3))>, <trimesh.Trimesh(vertices.shape=(30, 3), faces.shape=(57, 3))>, <trimesh.Trimesh(vertices.shape=(27, 3), faces.shape=(49, 3))>, <trimesh.Trimesh(vertices.shape=(22, 3), faces.shape=(39, 3))>, <trimesh.Trimesh(vertices.shape=(17, 3), faces.shape=(29, 3))>]\n",
      "meshes_split_sdf = [0.6745755  0.0611653  0.0109002  0.0109098  0.04792885 0.00813211\n",
      " 0.0232097  0.0268611  0.00997143 0.0146791  0.0107597 ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Will extract the soma meshes (possible multiple) from\n",
    "a single mesh\n",
    "\n",
    "\"\"\"\n",
    "#Arguments:\n",
    "segment_id=12345\n",
    "current_mesh_verts=current_neuron.vertices\n",
    "current_mesh_faces=current_neuron.faces\n",
    "soma_width_threshold=0.32\n",
    "\n",
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "#Adjusting the thresholds based on the decimations\n",
    "large_mesh_threshold = large_mesh_threshold*outer_decimation_ratio\n",
    "large_mesh_threshold_inner = large_mesh_threshold_inner*outer_decimation_ratio\n",
    "soma_size_threshold = soma_size_threshold*outer_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*outer_decimation_ratio\n",
    "\n",
    "#adjusting for inner decimation\n",
    "soma_size_threshold = soma_size_threshold*inner_decimation_ratio\n",
    "soma_size_threshold_max = soma_size_threshold_max*inner_decimation_ratio\n",
    "print(f\"Current Arguments Using (adjusted for decimation):\\n large_mesh_threshold= {large_mesh_threshold}\"\n",
    "             f\" \\nlarge_mesh_threshold_inner = {large_mesh_threshold_inner}\"\n",
    "              f\" \\nsoma_size_threshold = {soma_size_threshold}\"\n",
    "             f\" \\nsoma_size_threshold_max = {soma_size_threshold_max}\"\n",
    "             f\"\\nouter_decimation_ratio = {outer_decimation_ratio}\"\n",
    "             f\"\\ninner_decimation_ratio = {inner_decimation_ratio}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "temp_folder = f\"./{segment_id}\"\n",
    "temp_object = Path(temp_folder)\n",
    "#make the temp folder if it doesn't exist\n",
    "temp_object.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#making the decimation and poisson objections\n",
    "Dec_outer = Decimator(outer_decimation_ratio,temp_folder,overwrite=True)\n",
    "Dec_inner = Decimator(inner_decimation_ratio,temp_folder,overwrite=True)\n",
    "Poisson_obj = Poisson(temp_folder,overwrite=True)\n",
    "\n",
    "#Step 1: Decimate the Mesh and then split into the seperate pieces\n",
    "new_mesh,output_obj = Dec_outer(vertices=current_mesh_verts,\n",
    "         faces=current_mesh_faces,\n",
    "         segment_id=segment_id,\n",
    "         return_mesh=True,\n",
    "         delete_temp_files=False)\n",
    "\n",
    "# if remove_inside_pieces:\n",
    "#     print(\"removing mesh interior after decimation\")\n",
    "#     new_mesh = tu.remove_mesh_interior(new_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "#preforming the splits of the decimated mesh\n",
    "\n",
    "mesh_splits = new_mesh.split(only_watertight=False)\n",
    "\n",
    "#get the largest mesh\n",
    "mesh_lengths = np.array([len(split.faces) for split in mesh_splits])\n",
    "\n",
    "\n",
    "total_mesh_split_lengths = [len(k.faces) for k in mesh_splits]\n",
    "ordered_mesh_splits = mesh_splits[np.flip(np.argsort(total_mesh_split_lengths))]\n",
    "list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold]\n",
    "\n",
    "print(f\"Total found significant pieces before Poisson = {list_of_largest_mesh}\")\n",
    "\n",
    "#if no significant pieces were found then will use smaller threshold\n",
    "if len(list_of_largest_mesh)<=0:\n",
    "    print(f\"Using smaller large_mesh_threshold because no significant pieces found with {large_mesh_threshold}\")\n",
    "    list_of_largest_mesh = [k for k in ordered_mesh_splits if len(k.faces) > large_mesh_threshold/2]\n",
    "\n",
    "total_soma_list = []\n",
    "total_classifier_list = []\n",
    "total_poisson_list = []\n",
    "total_soma_list_sdf = []\n",
    "\n",
    "\n",
    "\n",
    "#start iterating through where go through all pieces before the poisson reconstruction\n",
    "no_somas_found_in_big_loop = 0\n",
    "for i,largest_mesh in enumerate(list_of_largest_mesh):\n",
    "    print(f\"----- working on large mesh #{i}: {largest_mesh}\")\n",
    "\n",
    "    if remove_inside_pieces:\n",
    "        print(\"remove_inside_pieces requested \")\n",
    "        largest_mesh = tu.remove_mesh_interior(largest_mesh,size_threshold_to_remove=size_threshold_to_remove)\n",
    "\n",
    "\n",
    "    if pymeshfix_clean:\n",
    "        print(\"Requested pymeshfix_clean\")\n",
    "        \"\"\"\n",
    "        Don't have to check if manifold anymore actually just have to plug the holes\n",
    "        \"\"\"\n",
    "        hole_groups = tu.find_border_face_groups(largest_mesh)\n",
    "        if len(hole_groups) > 0:\n",
    "            largest_mesh_filled_holes = tu.fill_holes(largest_mesh,max_hole_size = 10000)\n",
    "        else:\n",
    "            largest_mesh_filled_holes = largest_mesh\n",
    "\n",
    "        if check_holes_before_pymeshfix:\n",
    "            hole_groups = tu.find_border_face_groups(largest_mesh_filled_holes)\n",
    "        else:\n",
    "            print(\"Not checking if there are still existing holes before pymeshfix\")\n",
    "            hole_groups = []\n",
    "\n",
    "        if len(hole_groups) > 0:\n",
    "            #segmentation_at_end = False\n",
    "            print(f\"*** COULD NOT FILL HOLES WITH MAX SIZE OF {np.max([len(k) for k in hole_groups])} so not applying pymeshfix and segmentation_at_end = {segmentation_at_end}\")\n",
    "\n",
    "#                 tu.write_neuron_off(largest_mesh_filled_holes,\"largest_mesh_filled_holes\")\n",
    "#                 raise Exception()\n",
    "        else:\n",
    "            print(\"Applying pymeshfix_clean because no more holes\")\n",
    "            largest_mesh = tu.pymeshfix_clean(largest_mesh_filled_holes,verbose=True)\n",
    "\n",
    "    if second_poisson:\n",
    "        print(\"Applying second poisson run\")\n",
    "        current_neuron_poisson = tu.poisson_surface_reconstruction(largest_mesh)\n",
    "        largest_mesh = tu.split_significant_pieces(current_neuron_poisson)[0]\n",
    "\n",
    "    somas_found_in_big_loop = False\n",
    "\n",
    "    largest_file_name = str(output_obj.stem) + \"_largest_piece.off\"\n",
    "    pre_largest_mesh_path = temp_object / Path(str(output_obj.stem) + \"_largest_piece.off\")\n",
    "    pre_largest_mesh_path = pre_largest_mesh_path.absolute()\n",
    "    print(f\"pre_largest_mesh_path = {pre_largest_mesh_path}\")\n",
    "    # ******* This ERRORED AND CALLED OUR NERUON NONE: 77697401493989254 *********\n",
    "    new_mesh_inner,poisson_file_obj = Poisson_obj(vertices=largest_mesh.vertices,\n",
    "               faces=largest_mesh.faces,\n",
    "               return_mesh=True,\n",
    "               mesh_filename=largest_file_name,\n",
    "               delete_temp_files=False)\n",
    "\n",
    "\n",
    "    #splitting the Poisson into the largest pieces and ordering them\n",
    "    mesh_splits_inner = new_mesh_inner.split(only_watertight=False)\n",
    "    total_mesh_split_lengths_inner = [len(k.faces) for k in mesh_splits_inner]\n",
    "    ordered_mesh_splits_inner = mesh_splits_inner[np.flip(np.argsort(total_mesh_split_lengths_inner))]\n",
    "\n",
    "    list_of_largest_mesh_inner = [k for k in ordered_mesh_splits_inner if len(k.faces) > large_mesh_threshold_inner]\n",
    "    print(f\"Total found significant pieces AFTER Poisson = {list_of_largest_mesh_inner}\")\n",
    "\n",
    "    n_failed_inner_soma_loops = 0\n",
    "    for j, largest_mesh_inner in enumerate(list_of_largest_mesh_inner):\n",
    "        print(f\"----- working on mesh after poisson #{j}: {largest_mesh_inner}\")\n",
    "\n",
    "        largest_mesh_path_inner = str(poisson_file_obj.stem) + \"_largest_inner.off\"\n",
    "\n",
    "        #Decimate the inner poisson piece\n",
    "        largest_mesh_path_inner_decimated,output_obj_inner = Dec_inner(\n",
    "                            vertices=largest_mesh_inner.vertices,\n",
    "                             faces=largest_mesh_inner.faces,\n",
    "                            mesh_filename=largest_mesh_path_inner,\n",
    "                             return_mesh=True,\n",
    "                             delete_temp_files=False)\n",
    "\n",
    "        print(f\"done exporting decimated mesh: {largest_mesh_path_inner}\")\n",
    "\n",
    "        faces = np.array(largest_mesh_path_inner_decimated.faces)\n",
    "        verts = np.array(largest_mesh_path_inner_decimated.vertices)\n",
    "\n",
    "        segment_id_new = int(str(segment_id) + f\"{i}{j}\")\n",
    "        #print(f\"Before the classifier the pymeshfix_clean = {pymeshfix_clean}\")\n",
    "        verts_labels, faces_labels, soma_value,classifier = wcda.extract_branches_whole_neuron(\n",
    "                                import_Off_Flag=False,\n",
    "                                segment_id=segment_id_new,\n",
    "                                vertices=verts,\n",
    "                                 triangles=faces,\n",
    "                                pymeshfix_Flag=False,\n",
    "                                 import_CGAL_Flag=False,\n",
    "                                 return_Only_Labels=True,\n",
    "                                 clusters=3,\n",
    "                                 smoothness=0.2,\n",
    "                                soma_only=True,\n",
    "                                return_classifier = True\n",
    "                                )\n",
    "        print(f\"soma_sdf_value = {soma_value}\")\n",
    "\n",
    "        total_classifier_list.append(classifier)\n",
    "        #total_poisson_list.append(largest_mesh_path_inner_decimated)\n",
    "\n",
    "        # Save all of the portions that resemble a soma\n",
    "        median_values = np.array([v[\"median\"] for k,v in classifier.sdf_final_dict.items()])\n",
    "        segmentation = np.array([k for k,v in classifier.sdf_final_dict.items()])\n",
    "\n",
    "        #order the compartments by greatest to smallest\n",
    "        sorted_medians = np.flip(np.argsort(median_values))\n",
    "        print(f\"segmentation[sorted_medians],median_values[sorted_medians] = {(segmentation[sorted_medians],median_values[sorted_medians])}\")\n",
    "        print(f\"Sizes = {[classifier.sdf_final_dict[g]['n_faces'] for g in segmentation[sorted_medians]]}\")\n",
    "        print(f\"soma_size_threshold = {soma_size_threshold}\")\n",
    "        print(f\"soma_size_threshold_max={soma_size_threshold_max}\")\n",
    "\n",
    "        valid_soma_segments_width = [g for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                            and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                            and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "        valid_soma_segments_sdf = [h for g,h in zip(segmentation[sorted_medians],median_values[sorted_medians]) if ((h > soma_width_threshold)\n",
    "                                                            and (classifier.sdf_final_dict[g][\"n_faces\"] > soma_size_threshold)\n",
    "                                                            and (classifier.sdf_final_dict[g][\"n_faces\"] < soma_size_threshold_max))]\n",
    "\n",
    "        print(\"valid_soma_segments_width\")\n",
    "        to_add_list = []\n",
    "        to_add_list_sdf = []\n",
    "        if len(valid_soma_segments_width) > 0:\n",
    "            print(f\"      ------ Found {len(valid_soma_segments_width)} viable somas: {valid_soma_segments_width}\")\n",
    "            somas_found_in_big_loop = True\n",
    "            #get the meshes only if signfiicant length\n",
    "            labels_list = classifier.labels_list\n",
    "\n",
    "            for v,sdf in zip(valid_soma_segments_width,valid_soma_segments_sdf):\n",
    "                submesh_face_list = np.where(classifier.labels_list == v)[0]\n",
    "                soma_mesh = largest_mesh_path_inner_decimated.submesh([submesh_face_list],append=True)\n",
    "\n",
    "                # ---------- No longer doing the extra checks in here --------- #\n",
    "\n",
    "\n",
    "                curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "                curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "                if curr_side_len_check and curr_volume_check:\n",
    "                    to_add_list.append(soma_mesh)\n",
    "                    to_add_list_sdf.append(sdf)\n",
    "\n",
    "                else:\n",
    "                    print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "                         f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "                    continue\n",
    "\n",
    "            n_failed_inner_soma_loops = 0\n",
    "\n",
    "        else:\n",
    "            n_failed_inner_soma_loops += 1\n",
    "\n",
    "        total_soma_list_sdf += to_add_list_sdf\n",
    "        total_soma_list += to_add_list\n",
    "\n",
    "        # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "        if n_failed_inner_soma_loops >= 2:\n",
    "            print(\"breaking inner loop because 2 soma fails in a row\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # --------------- KEEP TRACK IF FAILED TO FIND SOMA (IF TOO MANY FAILS THEN BREAK)\n",
    "    if somas_found_in_big_loop == False:\n",
    "        no_somas_found_in_big_loop += 1\n",
    "        if no_somas_found_in_big_loop >= 2:\n",
    "            print(\"breaking because 2 fails in a row in big loop\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        no_somas_found_in_big_loop = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" IF THERE ARE MULTIPLE SOMAS THAT ARE WITHIN A CERTAIN DISTANCE OF EACH OTHER THEN JUST COMBINE THEM INTO ONE\"\"\"\n",
    "pairings = []\n",
    "for y,soma_1 in enumerate(total_soma_list):\n",
    "    for z,soma_2 in enumerate(total_soma_list):\n",
    "        if y<z:\n",
    "            mesh_tree = KDTree(soma_1.vertices)\n",
    "            distances,closest_node = mesh_tree.query(soma_2.vertices)\n",
    "\n",
    "            if np.min(distances) < 4000:\n",
    "                pairings.append([y,z])\n",
    "\n",
    "\n",
    "#creating the combined meshes from the list\n",
    "total_soma_list_revised = []\n",
    "total_soma_list_revised_sdf = []\n",
    "if len(pairings) > 0:\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    Use a network function to find components\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import networkx as nx\n",
    "    new_graph = nx.Graph()\n",
    "    new_graph.add_edges_from(pairings)\n",
    "    grouped_somas = list(nx.connected_components(new_graph))\n",
    "\n",
    "    somas_being_combined = []\n",
    "    print(f\"There were soma pairings: Connected components in = {grouped_somas} \")\n",
    "    for comp in grouped_somas:\n",
    "        comp = list(comp)\n",
    "        somas_being_combined += list(comp)\n",
    "        current_mesh = total_soma_list[comp[0]]\n",
    "        for i in range(1,len(comp)):\n",
    "            current_mesh += total_soma_list[comp[i]] #just combining the actual meshes\n",
    "\n",
    "        total_soma_list_revised.append(current_mesh)\n",
    "        #where can average all of the sdf values\n",
    "        total_soma_list_revised_sdf.append(np.min(np.array(total_soma_list_sdf)[comp]))\n",
    "\n",
    "    #add those that weren't combined to total_soma_list_revised\n",
    "    leftover_somas = [total_soma_list[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    leftover_somas_sdfs = [total_soma_list_sdf[k] for k in range(0,len(total_soma_list)) if k not in somas_being_combined]\n",
    "    if len(leftover_somas) > 0:\n",
    "        total_soma_list_revised += leftover_somas\n",
    "        total_soma_list_revised_sdf += leftover_somas_sdfs\n",
    "\n",
    "    print(f\"Final total_soma_list_revised = {total_soma_list_revised}\")\n",
    "    print(f\"Final total_soma_list_revised_sdf = {total_soma_list_revised_sdf}\")\n",
    "\n",
    "\n",
    "if len(total_soma_list_revised) == 0:\n",
    "    total_soma_list_revised = total_soma_list\n",
    "    total_soma_list_revised_sdf = total_soma_list_sdf\n",
    "\n",
    "run_time = time.time() - global_start_time\n",
    "\n",
    "print(f\"\\n\\n\\n Total time for run = {time.time() - global_start_time}\")\n",
    "print(f\"Before Filtering the number of somas found = {len(total_soma_list_revised)}\")\n",
    "\n",
    "#     import system_utils as su\n",
    "#     su.compressed_pickle(total_soma_list_revised,\"total_soma_list_revised\")\n",
    "#     su.compressed_pickle(new_mesh,\"original_mesh\")\n",
    "\n",
    "#need to erase all of the temporary files ******\n",
    "#import shutil\n",
    "#shutil.rmtree(directory)\n",
    "\n",
    "\"\"\"\n",
    "Running the extra tests that depend on\n",
    "- border vertices\n",
    "- how well the poisson matches the backtracked soma to the real mesh\n",
    "- other size checks\n",
    "\n",
    "\"\"\"\n",
    "filtered_soma_list = []\n",
    "filtered_soma_list_sdf = []\n",
    "for soma_mesh,curr_soma_sdf in zip(total_soma_list_revised,total_soma_list_revised_sdf):\n",
    "    if backtrack_soma_mesh_to_original:\n",
    "        print(\"Performing Soma Mesh Backtracking to original mesh\")\n",
    "        soma_mesh_poisson = deepcopy(soma_mesh)\n",
    "        try:\n",
    "            #print(\"About to find original mesh\")\n",
    "            soma_mesh = original_mesh_soma(\n",
    "                                            mesh = new_mesh,\n",
    "                                            soma_meshes=[soma_mesh_poisson],\n",
    "                                            sig_th_initial_split=15)[0]\n",
    "        except:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "            continue\n",
    "        else:\n",
    "            if soma_mesh is None:\n",
    "                print(\"--->This soma mesh was not added because Was not able to backtrack soma to mesh\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"poisson_backtrack_distance_threshold = {poisson_backtrack_distance_threshold}\")\n",
    "        #do the check that tests if there is a max distance between poisson and backtrack:\n",
    "        if not poisson_backtrack_distance_threshold is None and poisson_backtrack_distance_threshold > 0:\n",
    "\n",
    "            #soma_mesh.export(\"soma_mesh.off\")\n",
    "            if close_holes: \n",
    "                print(\"Using the close holes feature\")\n",
    "                fill_hole_obj = meshlab.FillHoles(max_hole_size=2000,\n",
    "                                                 self_itersect_faces=False)\n",
    "\n",
    "                soma_mesh_filled_holes,output_subprocess_obj = fill_hole_obj(   \n",
    "                                                    vertices=soma_mesh.vertices,\n",
    "                                                     faces=soma_mesh.faces,\n",
    "                                                     return_mesh=True,\n",
    "                                                     delete_temp_files=True,\n",
    "                                                    )\n",
    "            else:\n",
    "                soma_mesh_filled_holes = soma_mesh\n",
    "\n",
    "\n",
    "            #soma_mesh_filled_holes.export(\"soma_mesh_filled_holes.off\")\n",
    "\n",
    "\n",
    "\n",
    "            print(\"APPLYING poisson_backtrack_distance_threshold CHECKS\")\n",
    "            mesh_1 = soma_mesh_filled_holes\n",
    "            mesh_2 = soma_mesh_poisson\n",
    "\n",
    "            poisson_max_distance = tu.max_distance_betwee_mesh_vertices(mesh_1,mesh_2,\n",
    "                                                              verbose=True)\n",
    "            print(f\"poisson_max_distance = {poisson_max_distance}\")\n",
    "            if poisson_max_distance > poisson_backtrack_distance_threshold:\n",
    "                print(f\"--->This soma mesh was not added because it did not pass the poisson_backtrack_distance check:\\n\"\n",
    "                  f\" poisson_max_distance = {poisson_max_distance}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "    #do the boundary check:\n",
    "    if not boundary_vertices_threshold is None:\n",
    "        print(\"USING boundary_vertices_threshold CHECK\")\n",
    "        soma_boundary_groups_sizes = np.array([len(k) for k in tu.find_border_face_groups(soma_mesh)])\n",
    "        print(f\"soma_boundary_groups_sizes = {soma_boundary_groups_sizes}\")\n",
    "        large_boundary_groups = soma_boundary_groups_sizes[soma_boundary_groups_sizes>boundary_vertices_threshold]\n",
    "        print(f\"large_boundary_groups = {large_boundary_groups} with boundary_vertices_threshold = {boundary_vertices_threshold}\")\n",
    "        if len(large_boundary_groups)>0:\n",
    "            print(f\"--->This soma mesh was not added because it did not pass the boundary vertices validation:\\n\"\n",
    "                  f\" large_boundary_groups = {large_boundary_groups}\")\n",
    "            continue\n",
    "\n",
    "    curr_side_len_check = side_length_check(soma_mesh,side_length_ratio_threshold)\n",
    "    curr_volume_check = soma_volume_check(soma_mesh,volume_mulitplier)\n",
    "    if (not curr_side_len_check) or (not curr_volume_check):\n",
    "        print(f\"--->This soma mesh was not added because it did not pass the sphere validation:\\n \"\n",
    "             f\"soma_mesh = {soma_mesh}, curr_side_len_check = {curr_side_len_check}, curr_volume_check = {curr_volume_check}\")\n",
    "        continue\n",
    "\n",
    "    #tu.write_neuron_off(soma_mesh_poisson,\"original_poisson.off\")\n",
    "    #If made it through all the checks then add to final list\n",
    "    filtered_soma_list.append(soma_mesh)\n",
    "    filtered_soma_list_sdf.append(curr_soma_sdf)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Need to delete all files in the temp folder *****\n",
    "\"\"\"\n",
    "\n",
    "if delete_files:\n",
    "    #now erase all of the files used\n",
    "    from shutil import rmtree\n",
    "\n",
    "    #remove the directory with the meshes\n",
    "    rmtree(str(temp_object.absolute()))\n",
    "\n",
    "    #removing the temporary files\n",
    "    temp_folder = Path(\"./temp\")\n",
    "    temp_files = [x for x in temp_folder.glob('**/*')]\n",
    "    seg_temp_files = [x for x in temp_files if str(segment_id) in str(x)]\n",
    "\n",
    "    for f in seg_temp_files:\n",
    "        f.unlink()\n",
    "\n",
    "# ----------- 11 /11 Addition that does a last step segmentation of the soma --------- #\n",
    "#return total_soma_list, run_time\n",
    "#return total_soma_list_revised,run_time,total_soma_list_revised_sdf\n",
    "\n",
    "filtered_soma_list_copy = copy.deepcopy(filtered_soma_list)\n",
    "filtered_soma_list_sdf_copy = copy.deepcopy(filtered_soma_list_sdf)\n",
    "\n",
    "if len(filtered_soma_list) > 0:\n",
    "    filtered_soma_list_revised = []\n",
    "    filtered_soma_list_sdf_revised = []\n",
    "    for f_soma,f_soma_sdf in zip(filtered_soma_list,filtered_soma_list_sdf):\n",
    "        if segmentation_at_end:\n",
    "            \n",
    "            if remove_inside_pieces:\n",
    "                print(\"removing mesh interior before segmentation\")\n",
    "                f_soma = tu.remove_mesh_interior(f_soma,size_threshold_to_remove=size_threshold_to_remove)\n",
    "            \n",
    "            print(\"Doing the soma segmentation filter at end\")\n",
    "\n",
    "            meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = f_soma,\n",
    "                smoothness=0.5\n",
    "            )\n",
    "            print(f\"meshes_split = {meshes_split}\")\n",
    "            print(f\"meshes_split_sdf = {meshes_split_sdf}\")\n",
    "\n",
    "            #applying the soma width and the soma size threshold\n",
    "            above_width_threshold_mask = meshes_split_sdf>=soma_width_threshold\n",
    "            meshes_split_sizes = np.array([len(k.faces) for k in meshes_split])\n",
    "            above_size_threshold_mask = meshes_split_sizes >= last_size_threshold\n",
    "\n",
    "            above_width_threshold_idx = np.where(above_width_threshold_mask & above_size_threshold_mask)[0]\n",
    "            if len(above_width_threshold_idx) == 0:\n",
    "                print(f\"No split meshes were above the width threshold ({soma_width_threshold}) and size threshold ({last_size_threshold}) so continuing\")\n",
    "                continue\n",
    "\n",
    "            meshes_split = np.array(meshes_split)\n",
    "            meshes_split_sdf = np.array(meshes_split_sdf)\n",
    "\n",
    "            meshes_split_filtered = meshes_split[above_width_threshold_idx]\n",
    "            meshes_split_sdf_filtered = meshes_split_sdf[above_width_threshold_idx]\n",
    "\n",
    "            soma_width_threshold\n",
    "            #way to choose the index of the top candidate\n",
    "            top_candidate = 0\n",
    "            filtered_soma_list_revised.append(meshes_split_filtered[top_candidate])\n",
    "            filtered_soma_list_sdf_revised.append(meshes_split_sdf_filtered[top_candidate])\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"Skipping the segmentatio filter at end\")\n",
    "            if len(f_soma.faces) >= last_size_threshold and f_soma_sdf >= soma_width_threshold:\n",
    "                filtered_soma_list_revised.append(f_soma)\n",
    "                filtered_soma_list_sdf_revised.append(f_soma_sdf)\n",
    "\n",
    "    filtered_soma_list = np.array(filtered_soma_list_revised)\n",
    "    filtered_soma_list_sdf = np.array(filtered_soma_list_sdf_revised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<trimesh.Trimesh(vertices.shape=(3284, 3), faces.shape=(6152, 3))>,\n",
       "       <trimesh.Trimesh(vertices.shape=(1703, 3), faces.shape=(3294, 3))>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_soma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bafb80837af4f5f849f6d580909cdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No meshes or skeletons passed to the plotting funciton",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-44250d836439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeshes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiltered_soma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/meshAfterParty/neuron_visualizations.py\u001b[0m in \u001b[0;36mplot_objects\u001b[0;34m(main_mesh, main_skeleton, main_mesh_color, main_skeleton_color, meshes, meshes_colors, mesh_alpha, skeletons, skeletons_colors, scatters, scatters_colors, scatter_size, main_scatter_color, buffer, axis_box_off, html_path, show_at_end, append_figure, flip_y)\u001b[0m\n\u001b[1;32m   1756\u001b[0m                             \u001b[0mshow_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_at_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m                             \u001b[0mappend_figure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_figure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m                             \u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflip_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1759\u001b[0m                            )\n\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mgraph_skeleton_and_mesh\u001b[0;34m(main_mesh_verts, main_mesh_faces, unique_skeleton_verts_final, edges_final, edge_coordinates, other_meshes, other_meshes_colors, mesh_alpha, other_meshes_face_components, other_skeletons, other_skeletons_colors, return_other_colors, main_mesh_color, main_skeleton_color, main_mesh_face_coloring, other_scatter, scatter_size, other_scatter_colors, main_scatter_color, buffer, axis_box_off, html_path, show_at_end, append_figure, flip_y)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m#create the main mesh vertices for setting the bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_mesh_vertices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No meshes or skeletons passed to the plotting funciton\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_mesh_vertices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mmain_mesh_vertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_mesh_vertices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: No meshes or skeletons passed to the plotting funciton"
     ]
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=filtered_soma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvfb-run -n 4966 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Soma/temp/neuron_33415.off -o /notebooks/Platinum_Soma/temp/neuron_33415_remove_interior.off -s /notebooks/Platinum_Soma/temp/remove_interior_130193.mls\n",
      "removed temporary input file: /notebooks/Platinum_Soma/temp/neuron_33415.off\n",
      "removed temporary output file: /notebooks/Platinum_Soma/temp/neuron_33415_remove_interior.off\n",
      "/notebooks/Platinum_Soma/temp/remove_interior_130193.mls is being deleted....\n",
      "Removing the following inside neurons: [<trimesh.Trimesh(vertices.shape=(1917, 3), faces.shape=(3662, 3))>, <trimesh.Trimesh(vertices.shape=(114, 3), faces.shape=(275, 3))>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef807b98a561475b86ea7faf052634d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meshAfterParty/trimesh_utils.py:996: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  total_submeshes_idx =np.array(list(total_submeshes_idx.values()))\n"
     ]
    }
   ],
   "source": [
    "ex_mesh = meshes=filtered_soma_list_copy[0]\n",
    "ex_mesh_removed_int = tu.remove_mesh_interior(ex_mesh,size_threshold_to_remove=200)\n",
    "meshes_split,meshes_split_sdf = tu.mesh_segmentation(\n",
    "                mesh = ex_mesh_removed_int,\n",
    "                return_meshes = True,\n",
    "                smoothness=0.5\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbeb967a12744322a6d200cd82cfef20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=meshes_split,\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just have to project onto real mesh with the insides already removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_utils as nu\n",
    "nu = reload(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.474904  , 0.04845755, 0.06567225, 0.0120533 , 0.01005964])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meshes_split_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_label_indexes = nu.divide_into_label_indexes(meshes_split_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007621803997962345\n",
      "0.00989771880757912\n",
      "0.030355032236993547\n",
      "0.04651907582024167\n",
      "0.49990378046921213\n"
     ]
    }
   ],
   "source": [
    "for lab_idx in mesh_label_indexes:\n",
    "    rs_distances = tu.ray_trace_distance(ex_mesh,\n",
    "                         face_inds=lab_idx)\n",
    "    print(np.median(rs_distances)/(5736*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'vertices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-6c7ce98d33db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m nviz.plot_objects(meshes=[meshes_split[0]],\n\u001b[0;32m----> 2\u001b[0;31m                  meshes_colors=\"random\")\n\u001b[0m",
      "\u001b[0;32m/meshAfterParty/neuron_visualizations.py\u001b[0m in \u001b[0;36mplot_objects\u001b[0;34m(main_mesh, main_skeleton, main_mesh_color, main_skeleton_color, meshes, meshes_colors, mesh_alpha, skeletons, skeletons_colors, scatters, scatters_colors, scatter_size, main_scatter_color, buffer, axis_box_off, html_path, show_at_end, append_figure, flip_y)\u001b[0m\n\u001b[1;32m   1756\u001b[0m                             \u001b[0mshow_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_at_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m                             \u001b[0mappend_figure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_figure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m                             \u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflip_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1759\u001b[0m                            )\n\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mgraph_skeleton_and_mesh\u001b[0;34m(main_mesh_verts, main_mesh_faces, unique_skeleton_verts_final, edges_final, edge_coordinates, other_meshes, other_meshes_colors, mesh_alpha, other_meshes_face_components, other_skeletons, other_skeletons_colors, return_other_colors, main_mesh_color, main_skeleton_color, main_mesh_face_coloring, other_scatter, scatter_size, other_scatter_colors, main_scatter_color, buffer, axis_box_off, html_path, show_at_end, append_figure, flip_y)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcurr_mesh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr_color\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_meshes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mother_meshes_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m#print(f\"flip_y = {flip_y}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mplot_ipv_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_mesh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_color\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflip_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mmain_mesh_vertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/skeleton_utils.py\u001b[0m in \u001b[0;36mplot_ipv_mesh\u001b[0;34m(mesh, color, flip_y)\u001b[0m\n\u001b[1;32m    157\u001b[0m                  flip_y=True):\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'vertices'"
     ]
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=[meshes_split[0]],\n",
    "                 meshes_colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bec0f7bec94a8cb19c04af9bd2ada1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(meshes=[filtered_soma_list_copy[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebe372a3ad14ad7b53b9af22f22617a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nviz.plot_objects(largest_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open3D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh_utils as tu\n",
    "pymesh_error_mesh = tu.load_mesh_no_processing(\"pymesh_erroring.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu = reload(tu)\n",
    "o_mesh = tu.convert_trimesh_to_o3d(pymesh_error_mesh)\n",
    "o_mesh.remove_unreferenced_vertices()\n",
    "o_mesh.remove_non_manifold_edges()\n",
    "new_trimesh = tu.convert_o3d_to_trimesh(o_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.poisson_surface_reconstruction(pymesh_error_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu = reload(tu)\n",
    "current_neuron_dec = tu.decimate(current_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_neuron_dec_poisson = tu.poisson_surface_reconstruction(tu.split_significant_pieces(current_neuron_dec)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.is_manifold(tu.split_significant_pieces(current_neuron_dec_poisson)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.get_non_manifold_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_mesh = tu.split_significant_pieces(current_neuron_poisson)[0]\n",
    "tu.is_manifold(largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.pymeshfix_clean(new_trimesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.geometry.TriangleMesh(vertices=pymesh_error_mesh.vertices,\n",
    "                         triangles=pymesh_error_mesh.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(o3d.geometry.TriangleMesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_vertex_manifold\n",
    "remove_unreferenced_vertices\n",
    "remove_non_manifold_edges\n",
    "get_non_manifold_vertices\n",
    "get_non_manifold_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mesh = o3d.io.read_triangle_mesh(\"pymesh_erroring.off\")\n",
    "np.asarray(mesh.get_non_manifold_edges()),np.asarray(mesh.get_non_manifold_vertices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for manifold mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymesh_error_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open3D options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For triangle meshes, you should check:\n",
    "\n",
    "(1) If it is manifold and;\n",
    "\n",
    "(2) If all vertices are inside of a closed fan.\n",
    "\n",
    "To check (1), just:\n",
    "\n",
    "(1.a) iterate over edges and check if each one is incident to just 1 or 2 faces and;\n",
    "\n",
    "(1.b) iterate over vertices and check if all incident faces form a closed or open fan.\n",
    "\n",
    "To check (2), just:\n",
    "\n",
    "(2.a) iterate vertices and check all incident edges to it. If all of them are incident to exact 2 faces, then this vertex pass the test. It fails otherwise.\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymesh_error_mesh.edges_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymesh_error_mesh_poisson = tu.poisson_surface_reconstruction(pymesh_error_mesh)\n",
    "largest_mesh = tu.split_significant_pieces(pymesh_error_mesh_poisson)[0]\n",
    "tu.write_neuron_off(largest_mesh,\"pymesh_error_mesh_poisson.off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tu.pymeshfix_clean(largest_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
