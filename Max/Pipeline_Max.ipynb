{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "sys.path.append(\"/meshAfterParty/\")\n",
    "\n",
    "# Requierd Libraries for Importing and Preprocessing\n",
    "import trimesh_utils as tu\n",
    "import neuron\n",
    "import time\n",
    "\n",
    "# Required Libraries for Visualization\n",
    "import skeleton_utils as sk\n",
    "import neuron_visualizations as nviz\n",
    "import networkx as nx\n",
    "\n",
    "# Other Required Libraries\n",
    "from neuron_searching import run_options\n",
    "import neuron_searching as ns\n",
    "\n",
    "import datajoint as dj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "\"\"\"\n",
    "/usr/local/lib/python3.6/dist-packages/datajoint/\n",
    "\n",
    "for Table\n",
    "- mouse ID\n",
    "- excititory or inhibitory\n",
    "- total spine count\n",
    "- spines her unit length\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new schema (Must begin with the user \"celiib_xxxx\")\n",
    "schema = dj.schema(\"celiib_max_schema\", context=None, connection=dj.conn(), create_schema=True, create_tables=True)\n",
    "\n",
    "######################## MANUAL TABLE\n",
    "@schema\n",
    "class Max_Example_Neurons3(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    # Maxs Test Table\n",
    "    cell_id                    : int                          # Unique cell ID\n",
    "    \"\"\"\n",
    "\n",
    "######################## COMPUTED TABLE\n",
    "@schema\n",
    "class Max_Example_Neurons_Computed1(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> Max_Example_Neurons3\n",
    "    n_spines: int\n",
    "    n_spines_per_skeletal_length: float\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        # Processing\n",
    "        print('Populating For: ', key)\n",
    "        '''\n",
    "        print(neuronFiles[key])\n",
    "        inhibitory_neuron = tu.load_mesh_no_processing(neuronsFolder+neuronFiles[key])\n",
    "\n",
    "        inhibitory_obj = neuron.Neuron(inhibitory_neuron,\n",
    "                              segment_id = seg_ID,\n",
    "                              description=desc,\n",
    "                              decomposition_type=\"meshafterparty\")\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        return_dict = dict(key, \n",
    "                          n_spines = 6,\n",
    "                          n_spines_per_skeletal_length = .2#,\n",
    "                        #test_var = 3\n",
    "                          )\n",
    "        self.insert1(return_dict, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert Cells to Manual Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "neuronsFolder = \"/notebooks/test_neurons/spine_detection/\"\n",
    "neuronFiles = [f for f in listdir(neuronsFolder) if isfile(join(neuronsFolder, f))]\n",
    "\n",
    "for fileIndx in range(len(neuronFiles)):\n",
    "    cell_id = int(neuronFiles[fileIndx].split('_')[0])\n",
    "    data = {'cell_id' : fileIndx}\n",
    "    Max_Example_Neurons3.insert1((data), skip_duplicates=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Computed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "        <style type=\"text/css\">\n",
       "            .Relation{\n",
       "                border-collapse:collapse;\n",
       "            }\n",
       "            .Relation th{\n",
       "                background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "                font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "            }\n",
       "            .Relation td{\n",
       "                padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "            }\n",
       "            .Relation tr:nth-child(odd){\n",
       "                background: #ffffff;\n",
       "            }\n",
       "            .Relation tr:nth-child(even){\n",
       "                background: #f3f1ff;\n",
       "            }\n",
       "            /* Tooltip container */\n",
       "            .djtooltip {\n",
       "            }\n",
       "            /* Tooltip text */\n",
       "            .djtooltip .djtooltiptext {\n",
       "                visibility: hidden;\n",
       "                width: 120px;\n",
       "                background-color: black;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                padding: 5px 0;\n",
       "                border-radius: 6px;\n",
       "                /* Position the tooltip text - see examples below! */\n",
       "                position: absolute;\n",
       "                z-index: 1;\n",
       "            }\n",
       "            #primary {\n",
       "                font-weight: bold;\n",
       "                color: black;\n",
       "            }\n",
       "\n",
       "            #nonprimary {\n",
       "                font-weight: normal;\n",
       "                color: white;\n",
       "            }\n",
       "\n",
       "            /* Show the tooltip text when you mouse over the tooltip container */\n",
       "            .djtooltip:hover .djtooltiptext {\n",
       "                visibility: visible;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <b></b>\n",
       "            <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "            <table border=\"1\" class=\"Relation\">\n",
       "                <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">cell_id</p>\n",
       "                                <span class=\"djtooltiptext\">Unique animal ID</span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">n_spines</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div></th><th><div class=\"djtooltip\">\n",
       "                                <p id=\"primary\">n_spines_per_skeletal_length</p>\n",
       "                                <span class=\"djtooltiptext\"></span>\n",
       "                            </div> </th> </tr> </thead>\n",
       "                <tbody> <tr> <td>1</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>2</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>3</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>4</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>5</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>6</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>7</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>8</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>9</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>10</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>11</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td></tr><tr><td>12</td>\n",
       "<td>6</td>\n",
       "<td>0.2</td> </tr> </tbody>\n",
       "            </table>\n",
       "            <p>...</p>\n",
       "            <p>Total: 42</p></div>\n",
       "            "
      ],
      "text/plain": [
       "*cell_id    *n_spines    *n_spines_per_\n",
       "+---------+ +----------+ +------------+\n",
       "1           6            0.2           \n",
       "2           6            0.2           \n",
       "3           6            0.2           \n",
       "4           6            0.2           \n",
       "5           6            0.2           \n",
       "6           6            0.2           \n",
       "7           6            0.2           \n",
       "8           6            0.2           \n",
       "9           6            0.2           \n",
       "10          6            0.2           \n",
       "11          6            0.2           \n",
       "12          6            0.2           \n",
       "   ...\n",
       " (Total: 42)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_Example_Neurons3()\n",
    "\n",
    "Max_Example_Neurons_Computed1.populate(reserve_jobs=True)\n",
    "Max_Example_Neurons_Computed1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90725377802114822_inhibitory_7.off\n",
      "--- 0) Having to preprocess the Neuron becuase no preprocessed data\n",
      "Please wait this could take a while.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569d32eeb1ab4596b58eb62e6f7ca791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fb21186e0c4b8dab104fd614b8c8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503f7160601c4ab7a90b8d3756f65816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc150d11a36241168b19c971f9874cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941f610c58d74fc0a532a9e23eb6dbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37f318590d143cc885b74597647482a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2174b4750bef4f02969f46adfcf985ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a351ba554704c2caa740a1312d3959d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f497734e7c34f659f6551927edf631b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7938f0ce886a4a19b41a6ddc6a538e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c316b9e14854e46bdfa456cbe568ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd63a5d8676746598fa9db688f61bd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e3d8879e804b12977a6af6adfc2575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb4e6058bda4e768dfc76be469ed585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbb17ff4385448a94a09dc7deed88de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e93b5b6b8446bc8aeb3888eb038508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07354b375c084ea88fd70fa61bb96d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e216a3a1c9cb490d81e03d1dd4abd322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203372d72a6044dc9cd80cf36213c845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0) Total time for preprocessing: 113.97880339622498\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- 1) Finished unpacking preprocessed materials: 3.5762786865234375e-06\n",
      "total_edges = [['S0', 'L0'], ['S0', 'L1'], ['S0', 'L2'], ['S0', 'L3'], ['S0', 'L4']]\n",
      "--- 2) Finished creating neuron connectivity graph: 0.00010585784912109375\n",
      "Having to generate soma_meshes_face_idx because none in preprocessed data\n",
      "--- 3a) Finshed generating soma_meshes_face_idx: 0.04369831085205078\n",
      "Using Poisson Surface Reconstruction to make mesh watertight\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "Using port = 1119\n",
      "xvfb-run -n 1119 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Max/Poisson_temp/neuron_480860.off -o /notebooks/Max/Poisson_temp/neuron_480860_poisson.off -s /notebooks/Max/Poisson_temp/poisson_838801.mls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n",
      "WARNING:trimesh:face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed temporary input file: /notebooks/Max/Poisson_temp/neuron_480860.off\n",
      "removed temporary output file: /notebooks/Max/Poisson_temp/neuron_480860_poisson.off\n",
      "/notebooks/Max/Poisson_temp/poisson_838801.mls is being deleted....\n",
      "--- 3) Finshed generating soma objects and adding them to concept graph: 9.497127532958984\n",
      "--- 4a) Finshed generating curr_limb_meshes_face_idx: 0.19853973388671875\n",
      "curr_limb_concept_networks= {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b6371240>}\n",
      "concept_network_dict = {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b6371240>}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b62cd320>}\n",
      "concept_network_dict = {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b62cd320>}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b66ed278>}\n",
      "concept_network_dict = {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b66ed278>}\n",
      "checking and resolving cycles\n",
      "No cycles to fix\n",
      "curr_limb_concept_networks= {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b6101ef0>}\n",
      "concept_network_dict = {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b6101ef0>}\n",
      "Concept graph size was 1 or less so returning original\n",
      "curr_limb_concept_networks= {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b66edfd0>}\n",
      "concept_network_dict = {0: <networkx_utils.GraphOrderedEdges object at 0x7f46b66edfd0>}\n",
      "Concept graph size was 1 or less so returning original\n",
      "--- 4) Finshed generating Limb objects and adding them to concept graph: 0.07700586318969727\n",
      "--- 5) SKIPPING Doing the adaptive mesh correspondence on the meshparty preprocessing ---\n",
      "--- 6) SKIPPING Using the computed_attribute_dict to populate neuron attributes ---\n",
      "Total time for neuron instance creation = 123.79597973823547\n"
     ]
    }
   ],
   "source": [
    "key = 1    \n",
    "print(neuronFiles[key])\n",
    "inhibitory_neuron = tu.load_mesh_no_processing(neuronsFolder+neuronFiles[key])\n",
    "seg_ID = int(neuronFiles[fileIndx].split('_')[0])\n",
    "num = neuronFiles[fileIndx].split('_')[2]\n",
    "desc = neuronFiles[fileIndx].split('_')[1] + '_' + num[0:-4]\n",
    "inhibitory_obj = neuron.Neuron(inhibitory_neuron,\n",
    "          segment_id = seg_ID,\n",
    "          description=desc,\n",
    "          decomposition_type=\"meshafterparty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing a Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "neuronsFolder = \"/notebooks/test_neurons/spine_detection/\"\n",
    "neuronFiles = [f for f in listdir(neuronsFolder) if isfile(join(neuronsFolder, f))]\n",
    "fileIndx = 1\n",
    "\n",
    "for fileIndx in range(len(neuronFiles)):\n",
    "    inhibitory_neuron = tu.load_mesh_no_processing(neuronsFolder+neuronFiles[fileIndx])\n",
    "\n",
    "    seg_ID = int(neuronFiles[fileIndx].split('_')[0])\n",
    "    num = neuronFiles[fileIndx].split('_')[2]\n",
    "    desc = neuronFiles[fileIndx].split('_')[1] + '_' + num[0:-4]\n",
    "\n",
    "    # Pre-Process each File\n",
    "    inhibitory_obj = neuron.Neuron(inhibitory_neuron,\n",
    "                                  segment_id = seg_ID,\n",
    "                                  description = desc,\n",
    "                                  decomposition_type = \"meshafterparty\")\n",
    "\n",
    "    # Calculate Spines \n",
    "    #inhibitory_obj.calculate_spines()\n",
    "\n",
    "    # Create Dictionary\n",
    "    data = {\n",
    "    'cell_id': fileIndx,\n",
    "    'type': desc[0],\n",
    "    'n_spines': 42,\n",
    "    'n_spines_per_skeletal_length': 6\n",
    "    }\n",
    "    \n",
    "    # Insert into table\n",
    "    Max_Example_Neurons2().insert1((data), skip_duplicates=True)\n",
    "    print(Max_Example_Neurons2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileIndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Max_Example_Neurons2().insert1((data), skip_duplicates=True)\n",
    "Max_Example_Neurons2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(neuronFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "file_dictionary = []\n",
    "for nf in neuronFiles:\n",
    "    current_file = Path(neuronsFolder) / Path(nf)\n",
    "    #file_dictionary.append(dict(file_name=str(current_file)))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    inhibitory_neuron = tu.load_mesh_no_processing(neuronsFolder+neuronFiles[fileIndx])\n",
    "\n",
    "    seg_ID = int(neuronFiles[1].split('_')[0])\n",
    "    num = neuronFiles[fileIndx].split('_')[2]\n",
    "    desc = neuronFiles[fileIndx].split('_')[1] + '_' + num[0:-4]\n",
    "    \n",
    "    inhibitory_obj = neuron.Neuron(current_file,\n",
    "                                  segment_id = seg_ID,\n",
    "                                  description=desc,\n",
    "                                  decomposition_type=\"meshafterparty\")\n",
    "    print(f\"Total time for processing inhibitory neuron = {time.time() - start_time}\")\n",
    "\n",
    "# Calculate Spines \n",
    "inhibitory_obj.calculate_spines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExampleNeurons.insert(dict(file_name=\"/notebooks/newfile.off\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(NeuronStats & \"n_spines<8\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema \n",
    "class NeuronStats(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> ExampleNeurons\n",
    "    --\n",
    "    n_spines: int\n",
    "    n_spines_per_skeletal_length: float\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self,key):\n",
    "        current_file = key[\"file_name\"]\n",
    "        \n",
    "        #..... do all your processing\n",
    "        \n",
    "        \n",
    "        return_dict = dict(key,\n",
    "                          n_spines= 6,\n",
    "                          n_spines_per_skeletal_length=.2)\n",
    "        self.insert1(return_dict,ignore_duplicates=True)\n",
    "        \n",
    "NeuronStats.populate(reserve_jobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimation_version = 0\n",
    "decimation_ratio = 0.25\n",
    "import time\n",
    "\n",
    "\n",
    "@schema\n",
    "class Martinotti_Attributes(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> minnie.Decimation #segment ids and mesh data for all decimated segments\n",
    "    soma_index : tinyint unsigned #index given to this soma to account for multiple somas in one base semgnet\n",
    "    ---\n",
    "    centroid_x           : int unsigned                 # (EM voxels)\n",
    "    centroid_y           : int unsigned                 # (EM voxels)\n",
    "    centroid_z           : int unsigned                 # (EM voxels)\n",
    "    distance_from_prediction : double                   # the distance of the ALLEN predicted centroid soma center from the algorithms prediction\n",
    "    soma_vertices             : longblob                # array of vertices\n",
    "    soma_faces             : longblob                   # array of faces\n",
    "    multiplicity         : tinyint unsigned             # the number of somas found for this base segment\n",
    "    run_time : double                   # the amount of time to run (seconds)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #further restrict table to include just subset\n",
    "    key_source = (minnie.Decimation & (dj.U(\"segment_id\") & (m65.AllenSegmentCentroid & \"status=1\").proj()) & \"version=\" + str(decimation_version))\n",
    "    \n",
    "    # MAKE IS WHAT CALCULATES THE ATTRIBUTES AND INSERTS IT INTO YOUR TABLE\n",
    "    def make(self,key):\n",
    "        \n",
    "        # Get the Mesh Data\n",
    "        print(f\"\\n\\n\\n---- Working on {key['segment_id']} ----\")\n",
    "        \n",
    "        new_mesh = (minnie.Decimation() & key).fetch1(\"mesh\")\n",
    "        current_mesh_verts,current_mesh_faces = new_mesh.vertices,new_mesh.faces\n",
    "        \n",
    "        segment_id = key[\"segment_id\"]\n",
    "        \n",
    "        # Extract Soma Center\n",
    "        total_soma_list, run_time = extract_soma_center(segment_id,current_mesh_verts,current_mesh_faces)\n",
    "        print(f\"Run time was {run_time}  and the total_soma_list = {total_soma_list} and \")\n",
    "        \n",
    "        # IF NO SOMA\n",
    "        if len(total_soma_list) <= 0:\n",
    "            print(\"There were no somas found for this mesh so just writing empty data\")\n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=-1,\n",
    "                              centroid_x=None,\n",
    "                               centroid_y=None,\n",
    "                               centroid_z=None,\n",
    "                               distance_from_prediction=None,\n",
    "                               soma_vertices=None,\n",
    "                               soma_faces=None,\n",
    "                               multiplicity=0,\n",
    "                               run_time=run_time\n",
    "                              )\n",
    "            \n",
    "            raise Exception(\"to prevent writing because none were found\")\n",
    "            # Store the attributes that you found in a dictionary\n",
    "            # Incert the row of attributes for that key\n",
    "            self.insert1(insert_dict,skip_duplicates=True)\n",
    "            return\n",
    "        \n",
    "        # If >0 Soma\n",
    "        \n",
    "        #get the soma prediction\n",
    "        c_x,c_y,c_z = (m65.AllenSegmentCentroid() & key).fetch1(\"centroid_x\",\"centroid_y\",\"centroid_z\")\n",
    "        allen_centroid_prediction = np.array([c_x,c_y,c_z])\n",
    "        \n",
    "        dicts_to_insert = []\n",
    "        \n",
    "        # If >1 Soma\n",
    "        if len(total_soma_list) > 1:\n",
    "            raise Exception(\"to prevent writing MULTILPLE SOMAS TO DATABASE\")\n",
    "            \n",
    "        for i,current_soma in enumerate(total_soma_list):\n",
    "            print(\"Trying to write off file\")\n",
    "            current_soma.export(f\"{key['segment_id']}/{key['segment_id']}_soma_{i}.off\")\n",
    "            auto_prediction_center = np.mean(current_soma.vertices,axis=0)\n",
    "            \n",
    "            error_distance = np.linalg.norm(allen_centroid_prediction-auto_prediction_center)\n",
    "            \n",
    "            insert_dict = dict(key,\n",
    "                              soma_index=i,\n",
    "                              centroid_x=auto_prediction_center[0],\n",
    "                               centroid_y=auto_prediction_center[1],\n",
    "                               centroid_z=auto_prediction_center[2],\n",
    "                               distance_from_prediction=error_distance,\n",
    "                               soma_vertices=current_soma.vertices,\n",
    "                               soma_faces=current_soma.faces,\n",
    "                               multiplicity=len(total_soma_list),\n",
    "                               run_time=run_time\n",
    "                              )\n",
    "            \n",
    "            \n",
    "            \n",
    "            dicts_to_insert.append(insert_dict)\n",
    "            \n",
    "        #raise Exception(\"to prevent writing\")\n",
    "            \n",
    "        self.insert(dicts_to_insert,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing the Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "inhibitory_obj = neuron.Neuron(inhibitory_neuron,\n",
    "                              segment_id = seg_ID,\n",
    "                              description=desc,\n",
    "                              decomposition_type=\"meshafterparty\")\n",
    "print(f\"Total time for processing inhibitory neuron = {time.time() - start_time}\")\n",
    "\n",
    "# Calculate Spines \n",
    "inhibitory_obj.calculate_spines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.visualize_neuron(inhibitory_obj,\n",
    "                     visualize_type=[\"mesh\",\"skeleton\"],\n",
    "                     limb_branch_dict=\"all\",\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Visualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = nviz.visualize_neuron(inhibitory_obj,\n",
    "                     visualize_type=[\"mesh\"],\n",
    "                      mesh_resolution=\"limb\",\n",
    "                     limb_branch_dict=\"all\",\n",
    "                                   mesh_color_alpha=1,\n",
    "                      return_color_dict=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib_utils as mu\n",
    "mu.plot_color_dict(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = nviz.visualize_neuron(inhibitory_obj,\n",
    "                     visualize_type=[\"mesh\"],\n",
    "                      mesh_resolution=\"branch\",\n",
    "                     limb_branch_dict=\"all\",\n",
    "                                   mesh_color_alpha=1,\n",
    "                      return_color_dict=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.plot_limb_concept_network_2D(inhibitory_obj,\n",
    "                                 limb_name=\"L0\",\n",
    "                                 node_colors=color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitory_obj[0][4].labels = [\"Axon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nviz.plot_spines(inhibitory_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soma, Limb, and Branch Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soma Object\n",
    "soma_idx = \"S0\"\n",
    "soma_object = inhibitory_obj.concept_network.nodes[soma_idx][\"data\"]\n",
    "\n",
    "# Limb Object\n",
    "limb_idx = \"L0\"\n",
    "limb_obj = inhibitory_obj.concept_network.nodes[limb_idx][\"data\"]\n",
    "\n",
    "# Branch Object\n",
    "branch_idx = 7\n",
    "branch_obj = limb_obj.concept_network.nodes[7][\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@run_options(run_type=\"Limb\")\n",
    "def limb_n_spine(curr_limb,limb_name=None,**kwargs):\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    1) Get all the branch names in the limb\n",
    "    2) For each branch:\n",
    "        a. get the number of spines and add to total\n",
    "    3) Return total spine count\n",
    "    \"\"\"\n",
    "    \n",
    "    #1) Get all the branch names in the limb\n",
    "    branch_names = list(curr_limb.concept_network.nodes())\n",
    "     \n",
    "    #2) For each branch:\n",
    "    #a. get the number of spines and add to total\n",
    "    total_spines = 0\n",
    "    for b in branch_names:\n",
    "        branch_obj = curr_limb.concept_network.nodes[b][\"data\"]\n",
    "        \n",
    "        if branch_obj.spines is None:\n",
    "            continue\n",
    "        else:\n",
    "            total_spines += len(branch_obj.spines)\n",
    "        \n",
    "    #3) Return total spine count\n",
    "    return total_spines\n",
    "\n",
    "@run_options(run_type=\"Limb\")\n",
    "def limb_n_spine_per_skeletal_length(curr_limb,\n",
    "                                     limb_name=None,\n",
    "                                     **kwargs):\n",
    "    \"\"\"\n",
    "    Pseudocode: \n",
    "    1) Get all the branch names in the limb\n",
    "    2) For each branch:\n",
    "        a. get the number of spines and add to total\n",
    "    3) Get total skeletal length\n",
    "    4) Return n_spine/length\n",
    "    \"\"\"\n",
    "    \n",
    "    #1) Get all the branch names in the limb\n",
    "    branch_names = list(curr_limb.concept_network.nodes())\n",
    "    \n",
    "    #2) For each branch:\n",
    "    #a. get the number of spines and add to total\n",
    "    total_spines = 0\n",
    "    for b in branch_names:\n",
    "        branch_obj = curr_limb.concept_network.nodes[b][\"data\"]\n",
    "        \n",
    "        if branch_obj.spines is None:\n",
    "            continue\n",
    "        else:\n",
    "            total_spines += len(branch_obj.spines)\n",
    "        \n",
    "    #3) Get total skeletal length\n",
    "    import skeleton_utils as sk\n",
    "    skeletal_length = sk.calculate_skeleton_distance(curr_limb.skeleton)\n",
    "\n",
    "    #4) Return n_spine/length\n",
    "    return total_spines/skeletal_length\n",
    "\n",
    "@run_options(run_type=\"Branch\")\n",
    "def axon_branch(curr_branch,name=None,branch_name=None,**kwargs):\n",
    "    if \"axon\" in curr_branch.labels or \"Axon\" in curr_branch.labels:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get the soma mesh center\n",
    "soma_obj = inhibitory_obj.concept_network.nodes[\"S0\"][\"data\"]\n",
    "soma_obj_mesh_center = soma_obj.mesh_center\n",
    "\n",
    "total_above_soma_distance = 0\n",
    "\n",
    "for limb_idx,branch_list in returned_output.items():\n",
    "    for b in branch_list:\n",
    "        print(f\"---- Working on limb {limb_idx} branch {b} ------\")\n",
    "        \n",
    "        # Get the branch mesh center\n",
    "        branch_obj = inhibitory_obj.concept_network.nodes[limb_idx][\"data\"].concept_network.nodes[b][\"data\"]\n",
    "        branch_obj_mesh_center = branch_obj.mesh_center\n",
    "        \n",
    "        y_difference = branch_obj_mesh_center[1] - soma_obj_mesh_center[1]\n",
    "        print(f\"y_difference = {y_difference}\")\n",
    "        \n",
    "        #c. RELU\n",
    "        if y_difference < 0:\n",
    "            y_difference = 0\n",
    "        \n",
    "        print(f\"y_difference = {y_difference}\")\n",
    "        \n",
    "        total_above_soma_distance += y_difference\n",
    "    \n",
    "total_above_soma_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Functions List\n",
    "functions_list=[\n",
    "limb_n_spine,\n",
    "limb_n_spine_per_skeletal_length,\n",
    "\"width\",\n",
    "axon_branch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitory_obj[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_spines = 0\n",
    "inhibitory_obj._index = -1\n",
    "for limb_obj in inhibitory_obj:\n",
    "    limb_obj._index = -1\n",
    "    for branch_obj in limb_obj:\n",
    "        if not branch_obj.spines is None:\n",
    "            total_spines += len(branch_obj.spines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_spines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_output = ns.query_neuron(inhibitory_obj, \n",
    "                         functions_list,\n",
    "                          query=\"\",\n",
    "                          return_dataframe=True,# Must be false in order to visualize\n",
    "                          return_limbs=False,\n",
    "                          return_limb_grouped_branches=True,\n",
    "                         print_flag=False)\n",
    "returned_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_branch_ex = dict(L1=[3,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nviz.visualize_neuron(inhibitory_obj, \n",
    "                     visualize_type=[\"mesh\", \"skeleton\"],\n",
    "                      limb_branch_dict=returned_output,\n",
    "                      mesh_color=\"red\",\n",
    "                      mesh_whole_neuron=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
