{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPurpose: New skeletonization method that does\\nnot use a recursive method but simply uses the followoing\\nalgorithm: \\n- Do mesh splitting to find which mesh pieces aren't connect to\\n  the soma\\n0) Do Soma Extraction and split the meshes from there\\nFor Each significant mesh that was split off in beginning\\n1) Poisson Surface Reconstruction\\n2) CGAL skeletonization of all signfiicant pieces\\n3) Using CGAL skeleton, find the leftover mesh not skeletonized\\n4) Do surface reconstruction on the parts that are left over\\n- with some downsampling\\n5) Stitch the skeleton \\n\\n\\n---- Afterwards stitching:\\n1) Compute the soma mesh center point\\n2) For meshes that were originally connected to soma\\na. Find the closest skeletal point to soma center\\nb. Add an edge from closest point to soma center\\n3) Then do stitching algorithm on all of remaining disconnected\\n    skeletons\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: New skeletonization method that does\n",
    "not use a recursive method but simply uses the followoing\n",
    "algorithm: \n",
    "- Do mesh splitting to find which mesh pieces aren't connect to\n",
    "  the soma\n",
    "0) Do Soma Extraction and split the meshes from there\n",
    "For Each significant mesh that was split off in beginning\n",
    "1) Poisson Surface Reconstruction\n",
    "2) CGAL skeletonization of all signfiicant pieces\n",
    "3) Using CGAL skeleton, find the leftover mesh not skeletonized\n",
    "4) Do surface reconstruction on the parts that are left over\n",
    "- with some downsampling\n",
    "5) Stitch the skeleton \n",
    "\n",
    "\n",
    "---- Afterwards stitching:\n",
    "1) Compute the soma mesh center point\n",
    "2) For meshes that were originally connected to soma\n",
    "a. Find the closest skeletal point to soma center\n",
    "b. Add an edge from closest point to soma center\n",
    "3) Then do stitching algorithm on all of remaining disconnected\n",
    "    skeletons\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykdtree.kdtree import KDTree\n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import calcification_Module as cm #module that allows for calcification\n",
    "import time\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshlab\n",
    "from importlib import reload\n",
    "meshlab = reload(meshlab)\n",
    "from meshlab import Decimator , Poisson\n",
    "import skeleton_utils as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Example Mesh and Example Soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soma_extraction_utils as soma_utils\n",
    "from pathlib import Path\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_somas(segment_id,main_mesh_total):\n",
    "    try:\n",
    "        current_soma = trimesh.load_mesh(\"./Dustin_soma.off\")\n",
    "        return [current_soma]\n",
    "    except:\n",
    "        print(\"No Soma currently available so must compute own\")\n",
    "        (total_soma_list, \n",
    "             run_time, \n",
    "             total_soma_list_sdf) = soma_utils.extract_soma_center(\n",
    "                                segment_id,\n",
    "                                main_mesh_total.vertices,\n",
    "                                main_mesh_total.faces,\n",
    "                                outer_decimation_ratio= 0.25,\n",
    "                                large_mesh_threshold = 60000,\n",
    "                                large_mesh_threshold_inner = 40000,\n",
    "                                soma_width_threshold = 0.32,\n",
    "                                soma_size_threshold = 20000,\n",
    "                               inner_decimation_ratio = 0.25,\n",
    "                               volume_mulitplier=7,\n",
    "                               side_length_ratio_threshold=3,\n",
    "                                soma_size_threshold_max=192000,\n",
    "                                delete_files=True\n",
    "            )\n",
    "        return total_soma_list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma List = [<trimesh.Trimesh(vertices.shape=(1864, 3), faces.shape=(3640, 3))>]\n",
      "soma_mesh_list_centers = [array([1326076.34924893,  732678.79350858,  884152.51410944])]\n"
     ]
    }
   ],
   "source": [
    "segment_id = 12345\n",
    "\n",
    "# Load soma mesh\n",
    "# #loads in the Dustin mesh\n",
    "main_mesh_path = Path(\"./Dustin.off\")\n",
    "main_mesh_total = trimesh.load_mesh(str(main_mesh_path.absolute()))\n",
    "\n",
    "soma_mesh_list = load_somas(segment_id,main_mesh_total)\n",
    "print(f\"Soma List = {soma_mesh_list}\")\n",
    "\n",
    "soma_mesh_list_centers = [np.array(np.mean(k.vertices,axis=0)).astype(\"float\")\n",
    "                           for k in soma_mesh_list]\n",
    "print(f\"soma_mesh_list_centers = {soma_mesh_list_centers}\")\n",
    "\n",
    "if len(soma_mesh_list) <= 0:\n",
    "    print(f\"**** No Somas Found for Mesh {segment_id}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "sk = reload(sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do mesh splitting to find which mesh pieces aren't connect to the soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_meshes = sk.split_significant_pieces(\n",
    "                            main_mesh_total,\n",
    "                            significance_threshold=15,\n",
    "                            print_flag=False)\n",
    "len(split_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find which bounding box contains the soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudocode: \n",
    "For all meshes in list\n",
    "1) compute soma center\n",
    "2) Find all the bounding boxes that contain the soma center\n",
    "3) Find the mesh with the closest distance from \n",
    "   one vertex to the soma center and tht is winner\n",
    "\"\"\"\n",
    "containing_mesh_indices=dict([(i,[]) for i,sm_c in enumerate(soma_mesh_list_centers)])\n",
    "for k,sm_center in enumerate(soma_mesh_list_centers):\n",
    "\n",
    "    viable_meshes = [j for j,m in enumerate(split_meshes) \n",
    "             if trimesh.bounds.contains(m.bounds,sm_center.reshape(-1,3))\n",
    "                    ]\n",
    "    if len(viable_meshes) == 0:\n",
    "        raise Exception(f\"The Soma {k} with {sm_center} was not contained in any of the boundying boxes\")\n",
    "    elif len(viable_meshes) == 1:\n",
    "        containing_mesh_indices[k] = viable_meshes[0]\n",
    "    else:\n",
    "        #find which mesh is closer to the soma midpoint\n",
    "        min_distances_to_soma = []\n",
    "        for v_i in viable_meshes:\n",
    "            # build the KD Tree\n",
    "            viable_neuron_kdtree = KDTree(soma_mesh_list[v_i].vertices)\n",
    "            distances,closest_node = viable_neuron_kdtree.query(sm_centers.reshape(-1,3))\n",
    "            min_distances_to_soma.append(np.min(distances))\n",
    "        print(f\"min_distances_to_soma = {min_distances_to_soma}\")\n",
    "        containing_mesh_indices[k] = np.argmin(min_distances_to_soma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <trimesh.Trimesh(vertices.shape=(325120, 3), faces.shape=(651866, 3))>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_soma_touching_meshes = [m for i,m in enumerate(split_meshes)\n",
    "                     if i not in list(containing_mesh_indices.values())]\n",
    "len(non_soma_touching_meshes)\n",
    "soma_touching_meshes = dict([(i,split_meshes[m_i]) \n",
    "                             for i,m_i in containing_mesh_indices.items()])\n",
    "soma_touching_meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: For each soma containing mesh: Do Skeletonization and stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - util functions for skeletonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_soma(current_soma,main_mesh):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    face_midpoints_soma = np.mean(current_soma.vertices[current_soma.faces],axis=1)\n",
    "\n",
    "\n",
    "    curr_mesh_bbox_restriction,faces_bbox_inclusion = (\n",
    "                    sk.bbox_mesh_restrcition(main_mesh,\n",
    "                                             current_soma.bounds,\n",
    "                                            mult_ratio=1.3)\n",
    "    )\n",
    "\n",
    "    face_midpoints_neuron = np.mean(curr_mesh_bbox_restriction.vertices[curr_mesh_bbox_restriction.faces],axis=1)\n",
    "\n",
    "    soma_kdtree = KDTree(face_midpoints_soma)\n",
    "\n",
    "    distances,closest_node = soma_kdtree.query(face_midpoints_neuron)\n",
    "\n",
    "    distance_threshold = 550\n",
    "    distance_passed_faces  = distances<distance_threshold\n",
    "\n",
    "    faces_to_keep = np.array(list(set(np.arange(0,len(main_mesh.faces))).difference(set(faces_bbox_inclusion[distance_passed_faces]))))\n",
    "    without_soma_mesh = main_mesh.submesh([faces_to_keep],append=True)\n",
    "\n",
    "    #get the significant mesh pieces\n",
    "    mesh_pieces = sk.split_significant_pieces(without_soma_mesh,significance_threshold=200)\n",
    "    print(f\"Total Time for soma mesh cancellation = {np.round(time.time() - start_time,3)}\")\n",
    "    return mesh_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPseudocode: \\n0) Do Soma Extraction and split the meshes from there\\nFor Each significant mesh that was split off in beginning\\n1) Poisson Surface Reconstruction\\n2) CGAL skeletonization of all signfiicant pieces \\n    (if above certain size ! threshold) \\n            --> if not skip straight to surface skeletonization\\n3) Using CGAL skeleton, find the leftover mesh not skeletonized\\n4) Do surface reconstruction on the parts that are left over\\n- with some downsampling\\n5) Stitch the skeleton \\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pseudocode: \n",
    "0) Do Soma Extraction and split the meshes from there\n",
    "For Each significant mesh that was split off in beginning\n",
    "1) Poisson Surface Reconstruction\n",
    "2) CGAL skeletonization of all signfiicant pieces \n",
    "    (if above certain size ! threshold) \n",
    "            --> if not skip straight to surface skeletonization\n",
    "3) Using CGAL skeleton, find the leftover mesh not skeletonized\n",
    "4) Do surface reconstruction on the parts that are left over\n",
    "- with some downsampling\n",
    "5) Stitch the skeleton \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - setting up the paths for data writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from shutil import rmtree\n",
    "from pathlib import Path\n",
    "\n",
    "mesh_base_path=Path(\"./Dustin_vp4/\")\n",
    "current_name=\"Dustin\"\n",
    "\n",
    "if mesh_base_path.exists():\n",
    "    rmtree(str(mesh_base_path.absolute()))\n",
    "mesh_base_path.mkdir(parents=True,exist_ok=True)\n",
    "print(list(mesh_base_path.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeletonize_connected_branch(current_mesh,\n",
    "                        output_folder=\"./temp\",\n",
    "                        delete_temp_files=True,\n",
    "                        name=\"None\",\n",
    "                        surface_reconstruction_size=50,\n",
    "                        n_surface_downsampling = 1,\n",
    "                        n_surface_samples=1000,\n",
    "                        skeleton_print=False,\n",
    "                        mesh_subtraction_distance_threshold=3000,\n",
    "                        mesh_subtraction_buffer=50,\n",
    "                        max_stitch_distance = 18000,\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Purpose: To take a mesh and construct a full skeleton of it\n",
    "    (Assuming the Soma is already extracted)\n",
    "    \n",
    "    1) Poisson Surface Reconstruction\n",
    "    2) CGAL skeletonization of all signfiicant pieces \n",
    "        (if above certain size ! threshold) \n",
    "                --> if not skip straight to surface skeletonization\n",
    "    3) Using CGAL skeleton, find the leftover mesh not skeletonized\n",
    "    4) Do surface reconstruction on the parts that are left over\n",
    "    - with some downsampling\n",
    "    5) Stitch the skeleton \n",
    "    \"\"\"\n",
    "    \n",
    "    #check that the mesh is all one piece\n",
    "    current_mesh_splits = sk.split_significant_pieces(current_mesh,\n",
    "                               significance_threshold=1)\n",
    "    if len(current_mesh_splits) > 1:\n",
    "        raise Exception(f\"The mesh passed has {len(current_mesh_splits)} pieces\")\n",
    "\n",
    "    # check the size of the branch and if small enough then just do\n",
    "    # Surface Skeletonization\n",
    "    if len(current_mesh.faces) < surface_reconstruction_size:\n",
    "        #do a surface skeletonization\n",
    "        surf_sk = sk.generate_surface_skeleton(current_mesh.vertices,\n",
    "                                    current_mesh.faces,\n",
    "                                    surface_samples=n_surface_samples,\n",
    "                                             n_surface_downsampling=n_surface_downsampling )\n",
    "        return surf_sk\n",
    "    else:\n",
    "    \n",
    "        #if can't simply do a surface skeletonization then \n",
    "        #use cgal method that requires temp folder\n",
    "\n",
    "        if type(output_folder) != type(Path()):\n",
    "            output_folder = Path(str(output_folder))\n",
    "            output_folder.mkdir(parents=True,exist_ok=True)\n",
    "            \n",
    "        # CGAL Step 1: Do Poisson Surface Reconstruction\n",
    "        Poisson_obj = Poisson(output_folder,overwrite=True)\n",
    "        \n",
    "\n",
    "        skeleton_start = time.time()\n",
    "        print(\"     Starting Screened Poisson\")\n",
    "        new_mesh,output_subprocess_obj = Poisson_obj(   \n",
    "                                    vertices=current_mesh.vertices,\n",
    "                                     faces=current_mesh.faces,\n",
    "                                    mesh_filename=name + \".off\",\n",
    "                                     return_mesh=True,\n",
    "                                     delete_temp_files=False,\n",
    "                                    )\n",
    "        print(f\"-----Time for Screened Poisson= {time.time()-skeleton_start}\")\n",
    "            \n",
    "        #2) Filter away for largest_poisson_piece:\n",
    "        mesh_pieces = sk.split_significant_pieces(new_mesh,\n",
    "                                            significance_threshold=surface_reconstruction_size)\n",
    "        \n",
    "        if skeleton_print:\n",
    "            print(f\"Signifiant mesh pieces of {surface_reconstruction_size} size \"\n",
    "                 f\"after poisson = {len(mesh_pieces)}\")\n",
    "        skeleton_ready_for_stitching = np.array([])\n",
    "        skeleton_files = [] # to be erased later on if need be\n",
    "        if len(mesh_pieces) <= 0:\n",
    "            if skeleton_print:\n",
    "                print(\"No signficant skeleton pieces so just doing surface skeletonization\")\n",
    "            # do surface skeletonization on all of the pieces\n",
    "            surface_mesh_pieces = sk.split_significant_pieces(new_mesh,\n",
    "                                            significance_threshold=2)\n",
    "            \n",
    "            #get the skeletons for all those pieces\n",
    "            current_mesh_skeleton_list = [\n",
    "                sk.generate_surface_skeleton(p.vertices,\n",
    "                                    p.faces,\n",
    "                                    surface_samples=n_surface_samples,\n",
    "                                    n_surface_downsampling=n_surface_downsampling )\n",
    "                for p in surface_mesh_pieces\n",
    "            ]\n",
    "            \n",
    "            skeleton_ready_for_stitching = np.vstack(current_mesh_skeleton_list)\n",
    "            \n",
    "            #will stitch them together later\n",
    "        else: #if there are parts that can do the cgal skeletonization\n",
    "            skeleton_start = time.time()\n",
    "            print(\"     Starting Calcification\")\n",
    "            for zz,piece in enumerate(mesh_pieces):\n",
    "                current_mesh_path = output_folder / f\"{name}_{zz}\"\n",
    "                \n",
    "                written_path = sk.write_neuron_off(piece,current_mesh_path)\n",
    "                \n",
    "                skeleton_start = time.time()\n",
    "                print(f\"Path sneding to calcification = {written_path[:-4]}\")\n",
    "                time.sleep(10)\n",
    "                cm.calcification(written_path[:-4])\n",
    "                print(f\"Time for skeletonizatin = {time.time() - skeleton_start}\")\n",
    "                time.sleep(10)\n",
    "                skeleton_files.append(str(current_mesh_path) + \"_skeleton.cgal\")\n",
    "                \n",
    "            if skeleton_print:\n",
    "                print(f\"-----Time for Running Calcification = {time.time()-skeleton_start}\")\n",
    "            \n",
    "            #collect the skeletons and subtract from the mesh\n",
    "            significant_poisson_skeleton = sk.read_skeleton_edges_coordinates(skeleton_files)\n",
    "            boolean_significance_threshold=5\n",
    "            \n",
    "            \n",
    "            mesh_pieces_leftover =  sk.mesh_subtraction_by_skeleton(current_mesh,\n",
    "                                                        significant_poisson_skeleton,\n",
    "                                                        buffer=mesh_subtraction_buffer,\n",
    "                                                        bbox_ratio=1.2,\n",
    "                                                        distance_threshold=significant_poisson_skeleton,\n",
    "                                                        significance_threshold=boolean_significance_threshold,\n",
    "                                                        print_flag=False\n",
    "                                                       )\n",
    "            \n",
    "            # *****adding another significance threshold*****\n",
    "            leftover_meshes_sig = [k for k in mesh_pieces_leftover if len(k.faces) > 50]\n",
    "            leftover_meshes = sk.combine_meshes(leftover_meshes_sig)\n",
    "            \n",
    "            leftover_meshes_sig_surf_sk = []\n",
    "            for m in tqdm(leftover_meshes_sig):\n",
    "                surf_sk = sk.generate_surface_skeleton(m.vertices,\n",
    "                                               m.faces,\n",
    "                                               surface_samples=n_surface_samples,\n",
    "                                    n_surface_downsampling=n_surface_downsampling )\n",
    "                if len(surf_sk) > 0:\n",
    "                    leftover_meshes_sig_surf_sk.append(surf_sk)\n",
    "            leftover_surfaces_total = np.vstack(leftover_meshes_sig_surf_sk)\n",
    "            \n",
    "            skeleton_ready_for_stitching = np.vstack([significant_poisson_skeleton,leftover_surfaces_total])\n",
    "        \n",
    "        #now want to stitch together whether generated from \n",
    "        if skeleton_print:\n",
    "            print(f\"After cgal process the un-stitched skeleton has shape {skeleton_ready_for_stitching.shape}\")\n",
    "        \n",
    "        stitched_skeletons_full = sk.stitch_skeleton(\n",
    "                                                  skeleton_ready_for_stitching,\n",
    "                                                  max_stitch_distance=max_stitch_distance,\n",
    "                                                  stitch_print = False,\n",
    "                                                  main_mesh = []\n",
    "                                                )\n",
    "        stitched_skeletons_full_cleaned = sk.clean_skeleton(stitched_skeletons_full)\n",
    "        \n",
    "        # erase the skeleton files if need to be\n",
    "        if delete_temp_files:\n",
    "            for sk_fi in skeleton_files:\n",
    "                Path(sk_fi).unlink()\n",
    "        \n",
    "        # if created temp folder then erase if empty\n",
    "        if str(output_folder.absolute()) == str(Path(\"./temp\").absolute()):\n",
    "            print(\"The process was using a temp folder\")\n",
    "            if len(list(output_folder.iterdir())) == 0:\n",
    "                print(\"Temp folder was empty so deleting it\")\n",
    "                if output_folder.exists():\n",
    "                    rmtree(str(output_folder.absolute()))\n",
    "        \n",
    "        return stitched_skeletons_full_cleaned    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calcification_Module as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm.calcification(\"/notebooks3/Users/celii/Documents/Complete_Pinky100_Pipeline/notebooks/Platinum/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time for soma mesh cancellation = 1.204\n",
      "     Starting Screened Poisson\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "Using port = 813\n",
      "xvfb-run -n 813 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0.off -o /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_poisson.off -s /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/poisson_183352.mls\n",
      "-----Time for Screened Poisson= 33.07263779640198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n",
      "face_normals all zero, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signifiant mesh pieces of 50 size after poisson = 502\n",
      "     Starting Calcification\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_0\n",
      "Time for skeletonizatin = 17.854615211486816\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_1\n",
      "Time for skeletonizatin = 10.098324298858643\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_2\n",
      "Time for skeletonizatin = 10.097452640533447\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_3\n",
      "Time for skeletonizatin = 10.185581684112549\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_4\n",
      "Time for skeletonizatin = 10.097547054290771\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_5\n",
      "Time for skeletonizatin = 10.133883237838745\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_6\n",
      "Time for skeletonizatin = 10.091771841049194\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_7\n",
      "Time for skeletonizatin = 10.135917663574219\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_8\n",
      "Time for skeletonizatin = 10.208145380020142\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_9\n",
      "Time for skeletonizatin = 10.086288690567017\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_10\n",
      "Time for skeletonizatin = 10.087900876998901\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_11\n",
      "Time for skeletonizatin = 10.088141441345215\n",
      "Path sneding to calcification = /notebooks/Platinum_Skeletonization_vp3/Dustin_vp4/Dustin_soma_0_branch_0_12\n",
      "Time for skeletonizatin = 10.231098175048828\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a3d4793437e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                        \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmesh_base_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                        \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdendrite_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                                         skeleton_print = True)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstitched_dendrite_skeleton\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-782f31db8a01>\u001b[0m in \u001b[0;36mskeletonize_connected_branch\u001b[0;34m(current_mesh, output_folder, delete_temp_files, name, surface_reconstruction_size, n_surface_downsampling, n_surface_samples, skeleton_print, mesh_subtraction_distance_threshold, mesh_subtraction_buffer, max_stitch_distance)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwritten_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time for skeletonizatin = {time.time() - skeleton_start}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mskeleton_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_mesh_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_skeleton.cgal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sk = reload(sk)\n",
    "\n",
    "soma_touching_meshes_skeletons = []\n",
    "for s_i,main_mesh in soma_touching_meshes.items():\n",
    "    #Do the mesh subtraction to get the disconnected pieces\n",
    "    current_soma = soma_mesh_list[s_i]\n",
    "    \n",
    "    mesh_pieces = subtract_soma(current_soma,main_mesh)\n",
    "\n",
    "    #get each branch skeleton\n",
    "    total_soma_skeletons = []\n",
    "    for dendrite_index,picked_dendrite in enumerate(mesh_pieces):\n",
    "        dendrite_name=current_name + f\"_soma_{s_i}_branch_{dendrite_index}\"\n",
    "        stitched_dendrite_skeleton = skeletonize_connected_branch(picked_dendrite,\n",
    "                                                       output_folder=mesh_base_path,\n",
    "                                                       name=dendrite_name,\n",
    "                                                        skeleton_print = True)\n",
    "        \n",
    "        if len(stitched_dendrite_skeleton)<=0:\n",
    "            print(f\"*** Dendrite {dendrite_index} did not have skeleton computed***\")\n",
    "        else: \n",
    "            total_soma_skeletons.append(stitched_dendrite_skeleton)\n",
    "    \n",
    "#     #stitch the branches skeleton to the soma centroid\n",
    "#     soma_stitched_dendrtie_skeletons = soma_skeleton_stitching(\n",
    "#                     total_soma_skeletons,\n",
    "#                     current_soma\n",
    "#     )\n",
    "    \n",
    "#     soma_touching_meshes_skeletons.append(soma_stitched_dendrtie_skeletons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Skeletonization of all non-soma touching branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch the All Soma touching and non soma touching branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
